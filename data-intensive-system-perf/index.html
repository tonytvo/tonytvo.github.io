<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><meta name="generator" content="Gatsby 5.14.0"/><meta data-react-helmet="true" name="description" content="design data intensive applications by Martin Kleppmann summary"/><meta data-react-helmet="true" property="og:title" content="design data intensive applications by Martin Kleppmann summary - wip"/><meta data-react-helmet="true" property="og:description" content="design data intensive applications by Martin Kleppmann summary"/><meta data-react-helmet="true" property="og:type" content="website"/><meta data-react-helmet="true" name="twitter:card" content="summary"/><meta data-react-helmet="true" name="twitter:creator" content="ttrungvo"/><meta data-react-helmet="true" name="twitter:title" content="design data intensive applications by Martin Kleppmann summary - wip"/><meta data-react-helmet="true" name="twitter:description" content="design data intensive applications by Martin Kleppmann summary"/><style data-href="/styles.8dfba4a7c3d44b256d62.css" data-identity="gatsby-global-css">@font-face{font-display:swap;font-family:Montserrat;font-style:normal;font-weight:100;src:local("Montserrat Thin "),local("Montserrat-Thin"),url(/static/montserrat-latin-100-8d7d79679b70dbe27172b6460e7a7910.woff2) format("woff2"),url(/static/montserrat-latin-100-ec38980a9e0119a379e2a9b3dbb1901a.woff) format("woff")}@font-face{font-display:swap;font-family:Montserrat;font-style:italic;font-weight:100;src:local("Montserrat Thin italic"),local("Montserrat-Thinitalic"),url(/static/montserrat-latin-100italic-e279051046ba1286706adc886cf1c96b.woff2) format("woff2"),url(/static/montserrat-latin-100italic-3b325a3173c8207435cd1b76e19bf501.woff) format("woff")}@font-face{font-display:swap;font-family:Montserrat;font-style:normal;font-weight:200;src:local("Montserrat Extra Light "),local("Montserrat-Extra Light"),url(/static/montserrat-latin-200-9d266fbbfa6cab7009bd56003b1eeb67.woff2) format("woff2"),url(/static/montserrat-latin-200-2d8ba08717110d27122e54c34b8a5798.woff) format("woff")}@font-face{font-display:swap;font-family:Montserrat;font-style:italic;font-weight:200;src:local("Montserrat Extra Light italic"),local("Montserrat-Extra Lightitalic"),url(/static/montserrat-latin-200italic-6e5b3756583bb2263eb062eae992735e.woff2) format("woff2"),url(/static/montserrat-latin-200italic-a0d6f343e4b536c582926255367a57da.woff) format("woff")}@font-face{font-display:swap;font-family:Montserrat;font-style:normal;font-weight:300;src:local("Montserrat Light "),local("Montserrat-Light"),url(/static/montserrat-latin-300-00b3e893aab5a8fd632d6342eb72551a.woff2) format("woff2"),url(/static/montserrat-latin-300-ea303695ceab35f17e7d062f30e0173b.woff) format("woff")}@font-face{font-display:swap;font-family:Montserrat;font-style:italic;font-weight:300;src:local("Montserrat Light italic"),local("Montserrat-Lightitalic"),url(/static/montserrat-latin-300italic-56f34ea368f6aedf89583d444bbcb227.woff2) format("woff2"),url(/static/montserrat-latin-300italic-54b0bf2c8c4c12ffafd803be2466a790.woff) format("woff")}@font-face{font-display:swap;font-family:Montserrat;font-style:normal;font-weight:400;src:local("Montserrat Regular "),local("Montserrat-Regular"),url(/static/montserrat-latin-400-b71748ae4f80ec8c014def4c5fa8688b.woff2) format("woff2"),url(/static/montserrat-latin-400-0659a9f4e90db5cf51b50d005bff1e41.woff) format("woff")}@font-face{font-display:swap;font-family:Montserrat;font-style:italic;font-weight:400;src:local("Montserrat Regular italic"),local("Montserrat-Regularitalic"),url(/static/montserrat-latin-400italic-6eed6b4cbb809c6efc7aa7ddad6dbe3e.woff2) format("woff2"),url(/static/montserrat-latin-400italic-7583622cfde30ae49086d18447ab28e7.woff) format("woff")}@font-face{font-display:swap;font-family:Montserrat;font-style:normal;font-weight:500;src:local("Montserrat Medium "),local("Montserrat-Medium"),url(/static/montserrat-latin-500-091b209546e16313fd4f4fc36090c757.woff2) format("woff2"),url(/static/montserrat-latin-500-edd311588712a96bbf435fad264fff62.woff) format("woff")}@font-face{font-display:swap;font-family:Montserrat;font-style:italic;font-weight:500;src:local("Montserrat Medium italic"),local("Montserrat-Mediumitalic"),url(/static/montserrat-latin-500italic-c90ced68b46050061d1a41842d6dfb43.woff2) format("woff2"),url(/static/montserrat-latin-500italic-5146cbfe02b1deea5dffea27a5f2f998.woff) format("woff")}@font-face{font-display:swap;font-family:Montserrat;font-style:normal;font-weight:600;src:local("Montserrat SemiBold "),local("Montserrat-SemiBold"),url(/static/montserrat-latin-600-0480d2f8a71f38db8633b84d8722e0c2.woff2) format("woff2"),url(/static/montserrat-latin-600-b77863a375260a05dd13f86a1cee598f.woff) format("woff")}@font-face{font-display:swap;font-family:Montserrat;font-style:italic;font-weight:600;src:local("Montserrat SemiBold italic"),local("Montserrat-SemiBolditalic"),url(/static/montserrat-latin-600italic-cf46ffb11f3a60d7df0567f8851a1d00.woff2) format("woff2"),url(/static/montserrat-latin-600italic-c4fcfeeb057724724097167e57bd7801.woff) format("woff")}@font-face{font-display:swap;font-family:Montserrat;font-style:normal;font-weight:700;src:local("Montserrat Bold "),local("Montserrat-Bold"),url(/static/montserrat-latin-700-7dbcc8a5ea2289d83f657c25b4be6193.woff2) format("woff2"),url(/static/montserrat-latin-700-99271a835e1cae8c76ef8bba99a8cc4e.woff) format("woff")}@font-face{font-display:swap;font-family:Montserrat;font-style:italic;font-weight:700;src:local("Montserrat Bold italic"),local("Montserrat-Bolditalic"),url(/static/montserrat-latin-700italic-c41ad6bdb4bd504a843d546d0a47958d.woff2) format("woff2"),url(/static/montserrat-latin-700italic-6779372f04095051c62ed36bc1dcc142.woff) format("woff")}@font-face{font-display:swap;font-family:Montserrat;font-style:normal;font-weight:800;src:local("Montserrat ExtraBold "),local("Montserrat-ExtraBold"),url(/static/montserrat-latin-800-db9a3e0ba7eaea32e5f55328ace6cf23.woff2) format("woff2"),url(/static/montserrat-latin-800-4e3c615967a2360f5db87d2f0fd2456f.woff) format("woff")}@font-face{font-display:swap;font-family:Montserrat;font-style:italic;font-weight:800;src:local("Montserrat ExtraBold italic"),local("Montserrat-ExtraBolditalic"),url(/static/montserrat-latin-800italic-bf45bfa14805969eda318973947bc42b.woff2) format("woff2"),url(/static/montserrat-latin-800italic-fe82abb0bcede51bf724254878e0c374.woff) format("woff")}@font-face{font-display:swap;font-family:Montserrat;font-style:normal;font-weight:900;src:local("Montserrat Black "),local("Montserrat-Black"),url(/static/montserrat-latin-900-e66c7edc609e24bacbb705175669d814.woff2) format("woff2"),url(/static/montserrat-latin-900-8211f418baeb8ec880b80ba3c682f957.woff) format("woff")}@font-face{font-display:swap;font-family:Montserrat;font-style:italic;font-weight:900;src:local("Montserrat Black italic"),local("Montserrat-Blackitalic"),url(/static/montserrat-latin-900italic-4454c775e48152c1a72510ceed3603e2.woff2) format("woff2"),url(/static/montserrat-latin-900italic-efcaa0f6a82ee0640b83a0916e6e8d68.woff) format("woff")}@font-face{font-display:swap;font-family:Merriweather;font-style:normal;font-weight:300;src:local("Merriweather Light "),local("Merriweather-Light"),url(/static/merriweather-latin-300-fc117160c69a8ea0851b26dd14748ee4.woff2) format("woff2"),url(/static/merriweather-latin-300-58b18067ebbd21fda77b67e73c241d3b.woff) format("woff")}@font-face{font-display:swap;font-family:Merriweather;font-style:italic;font-weight:300;src:local("Merriweather Light italic"),local("Merriweather-Lightitalic"),url(/static/merriweather-latin-300italic-fe29961474f8dbf77c0aa7b9a629e4bc.woff2) format("woff2"),url(/static/merriweather-latin-300italic-23c3f1f88683618a4fb8d265d33d383a.woff) format("woff")}@font-face{font-display:swap;font-family:Merriweather;font-style:normal;font-weight:400;src:local("Merriweather Regular "),local("Merriweather-Regular"),url(/static/merriweather-latin-400-d9479e8023bef9cbd9bf8d6eabd6bf36.woff2) format("woff2"),url(/static/merriweather-latin-400-040426f99ff6e00b86506452e0d1f10b.woff) format("woff")}@font-face{font-display:swap;font-family:Merriweather;font-style:italic;font-weight:400;src:local("Merriweather Regular italic"),local("Merriweather-Regularitalic"),url(/static/merriweather-latin-400italic-2de7bfeaf08fb03d4315d49947f062f7.woff2) format("woff2"),url(/static/merriweather-latin-400italic-79db67aca65f5285964ab332bd65f451.woff) format("woff")}@font-face{font-display:swap;font-family:Merriweather;font-style:normal;font-weight:700;src:local("Merriweather Bold "),local("Merriweather-Bold"),url(/static/merriweather-latin-700-4b08e01d805fa35d7bf777f1b24314ae.woff2) format("woff2"),url(/static/merriweather-latin-700-22fb8afba4ab1f093b6ef9e28a9b6e92.woff) format("woff")}@font-face{font-display:swap;font-family:Merriweather;font-style:italic;font-weight:700;src:local("Merriweather Bold italic"),local("Merriweather-Bolditalic"),url(/static/merriweather-latin-700italic-cd92541b177652fffb6e3b952f1c33f1.woff2) format("woff2"),url(/static/merriweather-latin-700italic-f87f3d87cea0dd0979bfc8ac9ea90243.woff) format("woff")}@font-face{font-display:swap;font-family:Merriweather;font-style:normal;font-weight:900;src:local("Merriweather Black "),local("Merriweather-Black"),url(/static/merriweather-latin-900-f813fc6a4bee46eda5224ac7ebf1b7be.woff2) format("woff2"),url(/static/merriweather-latin-900-5d4e42cb44410674acd99153d57df032.woff) format("woff")}@font-face{font-display:swap;font-family:Merriweather;font-style:italic;font-weight:900;src:local("Merriweather Black italic"),local("Merriweather-Blackitalic"),url(/static/merriweather-latin-900italic-b7901d85486871c1779c0e93ddd85656.woff2) format("woff2"),url(/static/merriweather-latin-900italic-9647f9fdab98756989a8a5550eb205c3.woff) format("woff")}


/*! normalize.css v8.0.1 | MIT License | github.com/necolas/normalize.css */html{-webkit-text-size-adjust:100%;line-height:1.15}body{margin:0}main{display:block}h1{font-size:2em;margin:.67em 0}hr{box-sizing:content-box;height:0;overflow:visible}pre{font-family:monospace,monospace;font-size:1em}a{background-color:transparent}abbr[title]{border-bottom:none;text-decoration:underline;-webkit-text-decoration:underline dotted;text-decoration:underline dotted}b,strong{font-weight:bolder}code,kbd,samp{font-family:monospace,monospace;font-size:1em}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}img{border-style:none}button,input,optgroup,select,textarea{font-family:inherit;font-size:100%;line-height:1.15;margin:0}button,input{overflow:visible}button,select{text-transform:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]::-moz-focus-inner,[type=reset]::-moz-focus-inner,[type=submit]::-moz-focus-inner,button::-moz-focus-inner{border-style:none;padding:0}[type=button]:-moz-focusring,[type=reset]:-moz-focusring,[type=submit]:-moz-focusring,button:-moz-focusring{outline:1px dotted ButtonText}fieldset{padding:.35em .75em .625em}legend{box-sizing:border-box;color:inherit;display:table;max-width:100%;padding:0;white-space:normal}progress{vertical-align:baseline}textarea{overflow:auto}[type=checkbox],[type=radio]{box-sizing:border-box;padding:0}[type=number]::-webkit-inner-spin-button,[type=number]::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}[type=search]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}details{display:block}summary{display:list-item}[hidden]{display:none}:root{--maxWidth-none:"none";--maxWidth-xs:20rem;--maxWidth-sm:24rem;--maxWidth-md:28rem;--maxWidth-lg:32rem;--maxWidth-xl:36rem;--maxWidth-2xl:42rem;--maxWidth-3xl:48rem;--maxWidth-4xl:56rem;--maxWidth-full:"100%";--maxWidth-wrapper:var(--maxWidth-2xl);--spacing-px:"1px";--spacing-0:0;--spacing-1:0.25rem;--spacing-2:0.5rem;--spacing-3:0.75rem;--spacing-4:1rem;--spacing-5:1.25rem;--spacing-6:1.5rem;--spacing-8:2rem;--spacing-10:2.5rem;--spacing-12:3rem;--spacing-16:4rem;--spacing-20:5rem;--spacing-24:6rem;--spacing-32:8rem;--fontFamily-sans:Montserrat,system-ui,-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";--fontFamily-serif:"Merriweather","Georgia",Cambria,"Times New Roman",Times,serif;--font-body:var(--fontFamily-serif);--font-heading:var(--fontFamily-sans);--fontWeight-normal:400;--fontWeight-medium:500;--fontWeight-semibold:600;--fontWeight-bold:700;--fontWeight-extrabold:800;--fontWeight-black:900;--fontSize-root:16px;--lineHeight-none:1;--lineHeight-tight:1.1;--lineHeight-normal:1.5;--lineHeight-relaxed:1.625;--fontSize-0:0.833rem;--fontSize-1:1rem;--fontSize-2:1.2rem;--fontSize-3:1.44rem;--fontSize-4:1.728rem;--fontSize-5:2.074rem;--fontSize-6:2.488rem;--fontSize-7:2.986rem;--color-primary:#005b99;--color-text:#2e353f;--color-text-light:#4f5969;--color-heading:#1a202c;--color-heading-black:#000;--color-accent:#d1dce5}*,:after,:before{box-sizing:border-box}html{-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;font-size:var(--fontSize-root);line-height:var(--lineHeight-normal)}body{color:var(--color-text);font-family:var(--font-body);font-size:var(--fontSize-1)}footer{padding:var(--spacing-6) var(--spacing-0)}hr{background:var(--color-accent);border:0;height:1px}h1,h2,h3,h4,h5,h6{font-family:var(--font-heading);letter-spacing:-.025em;line-height:var(--lineHeight-tight);margin-bottom:var(--spacing-6);margin-top:var(--spacing-12)}h2,h3,h4,h5,h6{color:var(--color-heading);font-weight:var(--fontWeight-bold)}h1{color:var(--color-heading-black);font-size:var(--fontSize-6);font-weight:var(--fontWeight-black)}h2{font-size:var(--fontSize-5)}h3{font-size:var(--fontSize-4)}h4{font-size:var(--fontSize-3)}h5{font-size:var(--fontSize-2)}h6{font-size:var(--fontSize-1)}h1>a,h2>a,h3>a,h4>a,h5>a,h6>a{color:inherit;text-decoration:none}p{--baseline-multiplier:0.179;--x-height-multiplier:0.35;line-height:var(--lineHeight-relaxed);margin:var(--spacing-0) var(--spacing-0) var(--spacing-8) var(--spacing-0)}ol,p,ul{padding:var(--spacing-0)}ol,ul{list-style-image:none;list-style-position:outside;margin-bottom:var(--spacing-8);margin-left:var(--spacing-0);margin-right:var(--spacing-0)}ol li,ul li{padding-left:var(--spacing-0)}li>p,ol li,ul li{margin-bottom:calc(var(--spacing-8)/2)}li :last-child{margin-bottom:var(--spacing-0)}li>ul{margin-left:var(--spacing-8);margin-top:calc(var(--spacing-8)/2)}blockquote{border-left:var(--spacing-1) solid var(--color-primary);color:var(--color-text-light);font-size:var(--fontSize-2);font-style:italic;margin-bottom:var(--spacing-8);margin-left:calc(var(--spacing-6)*-1);margin-right:var(--spacing-8);padding:var(--spacing-0) var(--spacing-0) var(--spacing-0) var(--spacing-6)}blockquote>:last-child{margin-bottom:var(--spacing-0)}blockquote>ol,blockquote>ul{list-style-position:inside}table{border-collapse:collapse;border-spacing:.25rem;margin-bottom:var(--spacing-8);width:100%}table thead tr th{border-bottom:1px solid var(--color-accent)}a{color:var(--color-primary)}a:focus,a:hover{text-decoration:none}.global-wrapper{margin:var(--spacing-0) auto;max-width:var(--maxWidth-wrapper);padding:var(--spacing-10) var(--spacing-5)}.global-wrapper[data-is-root-path=true] .bio{margin-bottom:var(--spacing-20)}.global-header{margin-bottom:var(--spacing-12)}.main-heading{font-size:var(--fontSize-7);margin:0}.post-list-item{margin-bottom:var(--spacing-8);margin-top:var(--spacing-8)}.post-list-item p{margin-bottom:var(--spacing-0)}.post-list-item h2{color:var(--color-primary);font-size:var(--fontSize-4);margin-bottom:var(--spacing-2);margin-top:var(--spacing-0)}.post-list-item header{margin-bottom:var(--spacing-4)}.header-link-home{font-family:var(--font-heading);font-size:var(--fontSize-2);font-weight:var(--fontWeight-bold);text-decoration:none}.bio{display:flex;margin-bottom:var(--spacing-16)}.bio p,.bio-avatar{margin-bottom:var(--spacing-0)}.bio-avatar{border-radius:100%;margin-right:var(--spacing-4);min-width:50px}.blog-post header h1{margin:var(--spacing-0) var(--spacing-0) var(--spacing-4) var(--spacing-0)}.blog-post header p{font-family:var(--font-heading);font-size:var(--fontSize-2)}.blog-post-nav ul{margin:var(--spacing-0)}.gatsby-highlight{margin-bottom:var(--spacing-8)}@media (max-width:42rem){blockquote{margin-left:var(--spacing-0);padding:var(--spacing-0) var(--spacing-0) var(--spacing-0) var(--spacing-4)}ol,ul{list-style-position:inside}}code[class*=language-],pre[class*=language-]{word-wrap:normal;background:none;color:#000;font-family:Consolas,Monaco,Andale Mono,Ubuntu Mono,monospace;font-size:1em;-webkit-hyphens:none;hyphens:none;line-height:1.5;tab-size:4;text-align:left;text-shadow:0 1px #fff;white-space:pre;word-break:normal;word-spacing:normal}code[class*=language-] ::selection,code[class*=language-]::selection,pre[class*=language-] ::selection,pre[class*=language-]::selection{background:#b3d4fc;text-shadow:none}@media print{code[class*=language-],pre[class*=language-]{text-shadow:none}}pre[class*=language-]{margin:.5em 0;overflow:auto;padding:1em}:not(pre)>code[class*=language-],pre[class*=language-]{background:#f5f2f0}:not(pre)>code[class*=language-]{border-radius:.3em;padding:.1em;white-space:normal}.token.cdata,.token.comment,.token.doctype,.token.prolog{color:#708090}.token.punctuation{color:#999}.token.namespace{opacity:.7}.token.boolean,.token.constant,.token.deleted,.token.number,.token.property,.token.symbol,.token.tag{color:#905}.token.attr-name,.token.builtin,.token.char,.token.inserted,.token.selector,.token.string{color:#690}.language-css .token.string,.style .token.string,.token.entity,.token.operator,.token.url{background:hsla(0,0%,100%,.5);color:#9a6e3a}.token.atrule,.token.attr-value,.token.keyword{color:#07a}.token.class-name,.token.function{color:#dd4a68}.token.important,.token.regex,.token.variable{color:#e90}.token.bold,.token.important{font-weight:700}.token.italic{font-style:italic}.token.entity{cursor:help}</style><style>.gatsby-image-wrapper{position:relative;overflow:hidden}.gatsby-image-wrapper picture.object-fit-polyfill{position:static!important}.gatsby-image-wrapper img{bottom:0;height:100%;left:0;margin:0;max-width:none;padding:0;position:absolute;right:0;top:0;width:100%;object-fit:cover}.gatsby-image-wrapper [data-main-image]{opacity:0;transform:translateZ(0);transition:opacity .25s linear;will-change:opacity}.gatsby-image-wrapper-constrained{display:inline-block;vertical-align:top}</style><noscript><style>.gatsby-image-wrapper noscript [data-main-image]{opacity:1!important}.gatsby-image-wrapper [data-placeholder-image]{opacity:0!important}</style></noscript><script type="module">const e="undefined"!=typeof HTMLImageElement&&"loading"in HTMLImageElement.prototype;e&&document.body.addEventListener("load",(function(e){const t=e.target;if(void 0===t.dataset.mainImage)return;if(void 0===t.dataset.gatsbyImageSsr)return;let a=null,n=t;for(;null===a&&n;)void 0!==n.parentNode.dataset.gatsbyImageWrapper&&(a=n.parentNode),n=n.parentNode;const o=a.querySelector("[data-placeholder-image]"),r=new Image;r.src=t.currentSrc,r.decode().catch((()=>{})).then((()=>{t.style.opacity=1,o&&(o.style.opacity=0,o.style.transition="opacity 500ms linear")}))}),!0);</script><style type="text/css">
    .anchor.before {
      position: absolute;
      top: 0;
      left: 0;
      transform: translateX(-100%);
      padding-right: 4px;
    }
    .anchor.after {
      display: inline-block;
      padding-left: 4px;
    }
    h1 .anchor svg,
    h2 .anchor svg,
    h3 .anchor svg,
    h4 .anchor svg,
    h5 .anchor svg,
    h6 .anchor svg {
      visibility: hidden;
    }
    h1:hover .anchor svg,
    h2:hover .anchor svg,
    h3:hover .anchor svg,
    h4:hover .anchor svg,
    h5:hover .anchor svg,
    h6:hover .anchor svg,
    h1 .anchor:focus svg,
    h2 .anchor:focus svg,
    h3 .anchor:focus svg,
    h4 .anchor:focus svg,
    h5 .anchor:focus svg,
    h6 .anchor:focus svg {
      visibility: visible;
    }
  </style><script>
    document.addEventListener("DOMContentLoaded", function(event) {
      var hash = window.decodeURI(location.hash.replace('#', ''))
      if (hash !== '') {
        var element = document.getElementById(hash)
        if (element) {
          var scrollTop = window.pageYOffset || document.documentElement.scrollTop || document.body.scrollTop
          var clientTop = document.documentElement.clientTop || document.body.clientTop || 0
          var offset = element.getBoundingClientRect().top + scrollTop - clientTop
          // Wait for the browser to finish rendering before scrolling.
          setTimeout((function() {
            window.scrollTo(0, offset - 0)
          }), 0)
        }
      }
    })
  </script><link rel="alternate" type="application/rss+xml" title="Tony Vo Blog RSS Feed" href="/rss.xml"/><link rel="icon" href="/favicon-32x32.png?v=b811602c8c8ce14b66aae6613c8968f4" type="image/png"/><link rel="manifest" href="/manifest.webmanifest" crossorigin="anonymous"/><link rel="apple-touch-icon" sizes="48x48" href="/icons/icon-48x48.png?v=b811602c8c8ce14b66aae6613c8968f4"/><link rel="apple-touch-icon" sizes="72x72" href="/icons/icon-72x72.png?v=b811602c8c8ce14b66aae6613c8968f4"/><link rel="apple-touch-icon" sizes="96x96" href="/icons/icon-96x96.png?v=b811602c8c8ce14b66aae6613c8968f4"/><link rel="apple-touch-icon" sizes="144x144" href="/icons/icon-144x144.png?v=b811602c8c8ce14b66aae6613c8968f4"/><link rel="apple-touch-icon" sizes="192x192" href="/icons/icon-192x192.png?v=b811602c8c8ce14b66aae6613c8968f4"/><link rel="apple-touch-icon" sizes="256x256" href="/icons/icon-256x256.png?v=b811602c8c8ce14b66aae6613c8968f4"/><link rel="apple-touch-icon" sizes="384x384" href="/icons/icon-384x384.png?v=b811602c8c8ce14b66aae6613c8968f4"/><link rel="apple-touch-icon" sizes="512x512" href="/icons/icon-512x512.png?v=b811602c8c8ce14b66aae6613c8968f4"/><title data-react-helmet="true">design data intensive applications by Martin Kleppmann summary - wip | Conversations on agile technical practices and investments</title></head><body><div id="___gatsby"><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><div class="global-wrapper" data-is-root-path="false"><header class="global-header"><a class="header-link-home" href="/">Conversations on agile technical practices and investments</a></header><main><article class="blog-post" itemscope="" itemType="http://schema.org/Article"><header><h1 itemProp="headline">design data intensive applications by Martin Kleppmann summary - wip</h1><p>July 23, 2024</p></header><section itemProp="articleBody"><h1 id="todo" style="position:relative;"><a href="#todo" aria-label="todo permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>todo</h1>
<ul>
<li>examples from the current system.</li>
<li>surface the critical examples based on experience.</li>
<li>it could be code, database queries, etc…</li>
<li>go as broad as possible for the first attempt</li>
</ul>
<h1 id="table-of-contents" style="position:relative;"><a href="#table-of-contents" aria-label="table of contents permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Table of Contents</h1>
<div class="table-of-contents">
<ul>
<li>
<p><a href="#todo">todo</a></p>
</li>
<li>
<p><a href="#key-takeaways">key takeaways</a></p>
</li>
<li>
<p><a href="#foundations-of-data-systems">Foundations of Data Systems</a></p>
<ul>
<li>
<p><a href="#reliable-scalable-and-maintainable-applications">Reliable, scalable, and maintainable applications</a></p>
<ul>
<li>
<p><a href="#reliability">Reliability</a></p>
</li>
<li>
<p><a href="#scalability">Scalability</a></p>
<ul>
<li><a href="#twitter-example">Twitter example</a></li>
<li><a href="#describing-performance">Describing performance</a></li>
<li><a href="#approaches-for-coping-with-load">Approaches for coping with load</a></li>
</ul>
</li>
<li>
<p><a href="#maintainability">Maintainability</a></p>
<ul>
<li><a href="#operability-making-life-easy-for-operations">Operability: making life easy for operations</a></li>
<li><a href="#simplicity-managing-complexity">Simplicity: managing complexity</a></li>
<li><a href="#evolvability-making-change-easy">Evolvability: making change easy</a></li>
</ul>
</li>
</ul>
</li>
<li>
<p><a href="#data-models-and-query-language">Data models and query language</a></p>
<ul>
<li>
<p><a href="#relational-model-vs-document-model">Relational model vs document model</a></p>
<ul>
<li><a href="#the-network-model">The network model</a></li>
<li><a href="#the-relational-model">The relational model</a></li>
<li><a href="#schema-flexibility">Schema flexibility</a></li>
<li><a href="#data-locality-for-queries">Data locality for queries</a></li>
<li><a href="#convergence-of-document-and-relational-databases">Convergence of document and relational databases</a></li>
</ul>
</li>
<li>
<p><a href="#query-languages-for-data">Query languages for data</a></p>
<ul>
<li><a href="#declarative-queries-on-the-web">Declarative queries on the web</a></li>
<li><a href="#mapreduce-querying">MapReduce querying</a></li>
</ul>
</li>
<li>
<p><a href="#graph-like-data-models">Graph-like data models</a></p>
<ul>
<li><a href="#property-graphs">Property graphs</a></li>
<li><a href="#triple-stores-and-sparql">Triple-stores and SPARQL</a></li>
<li><a href="#the-sparql-query-language">The SPARQL query language</a></li>
<li><a href="#the-foundation-datalog">The foundation: Datalog</a></li>
</ul>
</li>
</ul>
</li>
<li>
<p><a href="#storage-and-retrieval">Storage and retrieval</a></p>
<ul>
<li>
<p><a href="#data-structures-that-power-up-your-database">Data structures that power up your database</a></p>
<ul>
<li><a href="#hash-indexes">Hash indexes</a></li>
<li><a href="#sstables-and-lsm-trees">SSTables and LSM-Trees</a></li>
<li><a href="#b-trees">B-trees</a></li>
<li><a href="#b-trees-and-lsm-trees">B-trees and LSM-trees</a></li>
<li><a href="#other-indexing-structures">Other indexing structures</a></li>
<li><a href="#full-text-search-and-fuzzy-indexes">Full-text search and fuzzy indexes</a></li>
<li><a href="#keeping-everything-in-memory">Keeping everything in memory</a></li>
</ul>
</li>
<li>
<p><a href="#transaction-processing-or-analytics">Transaction processing or analytics?</a></p>
<ul>
<li><a href="#data-warehousing">Data warehousing</a></li>
</ul>
</li>
<li>
<p><a href="#column-oriented-storage">Column-oriented storage</a></p>
</li>
</ul>
</li>
<li>
<p><a href="#encoding-and-evolution">Encoding and evolution</a></p>
<ul>
<li>
<p><a href="#formats-for-encoding-data">Formats for encoding data</a></p>
<ul>
<li>
<p><a href="#binary-encoding">Binary encoding</a></p>
<ul>
<li><a href="#avro">Avro</a></li>
</ul>
</li>
</ul>
</li>
<li>
<p><a href="#modes-of-dataflow">Modes of dataflow</a></p>
<ul>
<li><a href="#via-databases">Via databases</a></li>
<li><a href="#via-service-calls">Via service calls</a></li>
<li><a href="#via-asynchronous-message-passing">Via asynchronous message passing</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><a href="#distributed-data">Distributed Data</a></p>
<ul>
<li>
<p><a href="#replication">Replication</a></p>
<ul>
<li>
<p><a href="#leaders-and-followers">Leaders and followers</a></p>
<ul>
<li>
<p><a href="#synchronous-vs-asynchronous">Synchronous vs asynchronous</a></p>
</li>
<li>
<p><a href="#setting-up-new-followers">Setting up new followers</a></p>
</li>
<li>
<p><a href="#handling-node-outages">Handling node outages</a></p>
</li>
<li>
<p><a href="#follower-failure-catchup-recovery">Follower failure: catchup recovery</a></p>
</li>
<li>
<p><a href="#leader-failure-failover">Leader failure: failover</a></p>
</li>
<li>
<p><a href="#implementation-of-replication-logs">Implementation of replication logs</a></p>
<ul>
<li><a href="#statement-based-replication">Statement-based replication</a></li>
<li><a href="#write-ahead-log-wal-shipping">Write-ahead log (WAL) shipping</a></li>
<li><a href="#logical-row-based-log-replication">Logical (row-based) log replication</a></li>
<li><a href="#trigger-based-replication">Trigger-based replication</a></li>
</ul>
</li>
</ul>
</li>
<li>
<p><a href="#problems-with-replication-lag">Problems with replication lag</a></p>
<ul>
<li><a href="#reading-your-own-writes">Reading your own writes</a></li>
<li><a href="#monotonic-reads">Monotonic reads</a></li>
<li><a href="#consistent-prefix-reads">Consistent prefix reads</a></li>
<li><a href="#solutions-for-replication-lag">Solutions for replication lag</a></li>
</ul>
</li>
<li>
<p><a href="#multi-leader-replication">Multi-leader replication</a></p>
<ul>
<li>
<p><a href="#use-cases-for-multi-leader-replication">Use cases for multi-leader replication</a></p>
<ul>
<li><a href="#multi-datacenter-operation">Multi-datacenter operation</a></li>
<li><a href="#clients-with-offline-operation">Clients with offline operation</a></li>
</ul>
</li>
<li>
<p><a href="#collaborative-editing">Collaborative editing</a></p>
</li>
<li>
<p><a href="#handling-write-conflicts">Handling write conflicts</a></p>
<ul>
<li><a href="#synchronous-vs-asynchronous-conflict-detection">Synchronous vs asynchronous conflict detection</a></li>
<li><a href="#conflict-avoidance">Conflict avoidance</a></li>
<li><a href="#converging-toward-a-consistent-state">Converging toward a consistent state</a></li>
<li><a href="#custom-conflict-resolution">Custom conflict resolution</a></li>
</ul>
</li>
<li>
<p><a href="#multi-leader-replication-topologies">Multi-leader replication topologies</a></p>
</li>
</ul>
</li>
<li>
<p><a href="#leaderless-replication">Leaderless replication</a></p>
<ul>
<li>
<p><a href="#quorums-for-reading-and-writing">Quorums for reading and writing</a></p>
</li>
<li>
<p><a href="#sloppy-quorums-and-hinted-handoff">Sloppy quorums and hinted handoff</a></p>
<ul>
<li><a href="#multi-datacenter-operation-1">Multi-datacenter operation</a></li>
</ul>
</li>
<li>
<p><a href="#detecting-concurrent-writes">Detecting concurrent writes</a></p>
<ul>
<li><a href="#capturing-the-happens-before-relationship">Capturing the happens-before relationship</a></li>
<li><a href="#merging-concurrently-written-values">Merging concurrently written values</a></li>
</ul>
</li>
<li>
<p><a href="#version-vectors">Version vectors</a></p>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><a href="#partitioning">Partitioning</a></p>
<ul>
<li>
<p><a href="#partitioning-and-replication">Partitioning and replication</a></p>
</li>
<li>
<p><a href="#partition-of-key-value-data">Partition of key-value data</a></p>
<ul>
<li><a href="#partition-by-key-range">Partition by key range</a></li>
<li><a href="#partitioning-by-hash-of-key">Partitioning by hash of key</a></li>
<li><a href="#skewed-workloads-and-relieving-hot-spots">Skewed workloads and relieving hot spots</a></li>
</ul>
</li>
<li>
<p><a href="#partitioning-and-secondary-indexes">Partitioning and secondary indexes</a></p>
<ul>
<li><a href="#partitioning-secondary-indexes-by-document">Partitioning secondary indexes by document</a></li>
<li><a href="#partitioning-secondary-indexes-by-term">Partitioning secondary indexes by term</a></li>
</ul>
</li>
<li>
<p><a href="#rebalancing-partitions">Rebalancing partitions</a></p>
<ul>
<li><a href="#automatic-versus-manual-rebalancing">Automatic versus manual rebalancing</a></li>
</ul>
</li>
<li>
<p><a href="#request-routing">Request routing</a></p>
<ul>
<li><a href="#parallel-query-execution">Parallel query execution</a></li>
</ul>
</li>
</ul>
</li>
<li>
<p><a href="#transactions">Transactions</a></p>
<ul>
<li>
<p><a href="#the-slippery-concept-of-a-transaction">The slippery concept of a transaction</a></p>
<ul>
<li><a href="#acid">ACID</a></li>
<li><a href="#handling-errors-and-aborts">Handling errors and aborts</a></li>
</ul>
</li>
<li>
<p><a href="#weak-isolation-levels">Weak isolation levels</a></p>
<ul>
<li>
<p><a href="#read-committed">Read committed</a></p>
</li>
<li>
<p><a href="#snapshot-isolation-and-repeatable-read">Snapshot isolation and repeatable read</a></p>
</li>
<li>
<p><a href="#preventing-lost-updates">Preventing lost updates</a></p>
<ul>
<li><a href="#atomic-write-operations">Atomic write operations</a></li>
<li><a href="#explicit-locking">Explicit locking</a></li>
<li><a href="#automatically-detecting-lost-updates">Automatically detecting lost updates</a></li>
<li><a href="#compare-and-set">Compare-and-set</a></li>
<li><a href="#conflict-resolution-and-replication">Conflict resolution and replication</a></li>
</ul>
</li>
<li>
<p><a href="#write-skew-and-phantoms">Write skew and phantoms</a></p>
</li>
</ul>
</li>
<li>
<p><a href="#serializability">Serializability</a></p>
<ul>
<li>
<p><a href="#actual-serial-execution">Actual serial execution</a></p>
<ul>
<li><a href="#encapsulating-transactions-in-stored-procedures">Encapsulating transactions in stored procedures</a></li>
<li><a href="#partitioning-1">Partitioning</a></li>
</ul>
</li>
<li>
<p><a href="#two-phase-locking-2pl">Two-phase locking (2PL)</a></p>
<ul>
<li><a href="#predicate-locks">Predicate locks</a></li>
<li><a href="#index-range-locks">Index-range locks</a></li>
</ul>
</li>
<li>
<p><a href="#serializable-snapshot-isolation-ssi">Serializable snapshot isolation (SSI)</a></p>
<ul>
<li><a href="#pesimistic-versus-optimistic-concurrency-control">Pesimistic versus optimistic concurrency control</a></li>
<li><a href="#performance-of-serializable-snapshot-isolation">Performance of serializable snapshot isolation</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><a href="#the-trouble-with-distributed-systems">The trouble with distributed systems</a></p>
<ul>
<li>
<p><a href="#faults-and-partial-failures">Faults and partial failures</a></p>
</li>
<li>
<p><a href="#unreliable-networks">Unreliable networks</a></p>
<ul>
<li><a href="#timeouts-and-unbounded-delays">Timeouts and unbounded delays</a></li>
<li><a href="#network-congestion-and-queueing">Network congestion and queueing</a></li>
<li><a href="#synchronous-vs-ashynchronous-networks">Synchronous vs ashynchronous networks</a></li>
</ul>
</li>
<li>
<p><a href="#unreliable-clocks">Unreliable clocks</a></p>
<ul>
<li>
<p><a href="#timestamps-for-ordering-events">Timestamps for ordering events</a></p>
</li>
<li>
<p><a href="#clock-readings-have-a-confidence-interval">Clock readings have a confidence interval</a></p>
</li>
<li>
<p><a href="#process-pauses">Process pauses</a></p>
<ul>
<li><a href="#response-time-guarantees">Response time guarantees</a></li>
</ul>
</li>
</ul>
</li>
<li>
<p><a href="#knowledge-truth-and-lies">Knowledge, truth and lies</a></p>
<ul>
<li><a href="#fencing-tokens">Fencing tokens</a></li>
<li><a href="#byzantine-faults">Byzantine faults</a></li>
</ul>
</li>
</ul>
</li>
<li>
<p><a href="#consistency-and-consensus">Consistency and consensus</a></p>
<ul>
<li>
<p><a href="#consistency-guarantees">Consistency guarantees</a></p>
</li>
<li>
<p><a href="#linearizability">Linearizability</a></p>
<ul>
<li><a href="#locking-and-leader-election">Locking and leader election</a></li>
<li><a href="#constraints-and-uniqueness-guarantees">Constraints and uniqueness guarantees</a></li>
<li><a href="#implementing-linearizable-systems">Implementing linearizable systems</a></li>
<li><a href="#the-unhelpful-cap-theorem">The unhelpful CAP theorem</a></li>
</ul>
</li>
<li>
<p><a href="#ordering-guarantees">Ordering guarantees</a></p>
</li>
<li>
<p><a href="#distributed-transactions-and-consensus">Distributed transactions and consensus</a></p>
<ul>
<li>
<p><a href="#atomic-commit-and-two-phase-commit-2pc">Atomic commit and two-phase commit (2PC)</a></p>
</li>
<li>
<p><a href="#three-phase-commit">Three-phase commit</a></p>
</li>
<li>
<p><a href="#fault-tolerant-consensus">Fault-tolerant consensus</a></p>
<ul>
<li><a href="#single-leader-replication-and-consensus">Single-leader replication and consensus</a></li>
</ul>
</li>
<li>
<p><a href="#membership-and-coordination-services">Membership and coordination services</a></p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><a href="#derived-data">Derived Data</a></p>
<ul>
<li>
<p><a href="#batch-processing">Batch processing</a></p>
<ul>
<li>
<p><a href="#batch-processing-with-unix-tools">Batch processing with Unix tools</a></p>
</li>
<li>
<p><a href="#map-reduce-and-distributed-filesystems">Map reduce and distributed filesystems</a></p>
<ul>
<li><a href="#key-value-stores-as-batch-process-output">Key-value stores as batch process output</a></li>
</ul>
</li>
<li>
<p><a href="#beyond-mapreduce">Beyond MapReduce</a></p>
<ul>
<li><a href="#graphs-and-iterative-processing">Graphs and iterative processing</a></li>
</ul>
</li>
</ul>
</li>
<li>
<p><a href="#stream-processing">Stream processing</a></p>
<ul>
<li>
<p><a href="#transmitting-event-streams">Transmitting event streams</a></p>
<ul>
<li>
<p><a href="#messaging-systems">Messaging systems</a></p>
<ul>
<li><a href="#direct-messaging-from-producers-to-consumers">Direct messaging from producers to consumers</a></li>
<li><a href="#message-brokers">Message brokers</a></li>
<li><a href="#partitioned-logs">Partitioned logs</a></li>
</ul>
</li>
</ul>
</li>
<li>
<p><a href="#databases-and-streams">Databases and streams</a></p>
<ul>
<li><a href="#event-sourcing">Event sourcing</a></li>
</ul>
</li>
<li>
<p><a href="#processing-streams">Processing Streams</a></p>
<ul>
<li><a href="#stream-stream-joins">Stream-stream joins</a></li>
<li><a href="#stream-table-joins">Stream-table joins</a></li>
<li><a href="#table-table-join">Table-table join</a></li>
<li><a href="#time-dependence-join">Time-dependence join</a></li>
<li><a href="#fault-tolerance">Fault tolerance</a></li>
</ul>
</li>
</ul>
</li>
<li>
<p><a href="#the-future-of-data-systems">The future of data systems</a></p>
<ul>
<li>
<p><a href="#data-integration">Data integration</a></p>
<ul>
<li><a href="#batch-and-stream-processing">Batch and stream processing</a></li>
<li><a href="#lambda-architecture">Lambda architecture</a></li>
</ul>
</li>
<li>
<p><a href="#unbundling-databases">Unbundling databases</a></p>
<ul>
<li>
<p><a href="#creating-an-index">Creating an index</a></p>
</li>
<li>
<p><a href="#separation-of-application-code-and-state">Separation of application code and state</a></p>
</li>
<li>
<p><a href="#dataflow-interplay-between-state-changes-and-application-code">Dataflow, interplay between state changes and application code</a></p>
</li>
<li>
<p><a href="#stream-processors-and-services">Stream processors and services</a></p>
</li>
<li>
<p><a href="#observing-derived-state">Observing derived state</a></p>
<ul>
<li><a href="#materialised-views-and-caching">Materialised views and caching</a></li>
<li><a href="#read-are-events-too">Read are events too</a></li>
</ul>
</li>
</ul>
</li>
<li>
<p><a href="#aiming-for-correctness">Aiming for correctness</a></p>
<ul>
<li>
<p><a href="#the-end-to-end-argument-for-databases">The end-to-end argument for databases</a></p>
</li>
<li>
<p><a href="#enforcing-constraints">Enforcing constraints</a></p>
<ul>
<li><a href="#uniqueness-constraints-require-consensus">Uniqueness constraints require consensus</a></li>
<li><a href="#uniqueness-in-log-based-messaging">Uniqueness in log-based messaging</a></li>
<li><a href="#multi-partition-request-processing">Multi-partition request processing</a></li>
</ul>
</li>
<li>
<p><a href="#timeliness-and-integrity">Timeliness and integrity</a></p>
</li>
<li>
<p><a href="#correctness-and-dataflow-systems">Correctness and dataflow systems</a></p>
</li>
<li>
<p><a href="#coordination-avoiding-data-systems">Coordination-avoiding data-systems</a></p>
</li>
<li>
<p><a href="#trust-but-verify">Trust, but verify</a></p>
</li>
</ul>
</li>
<li>
<p><a href="#doing-the-right-thing">Doing the right thing</a></p>
<ul>
<li><a href="#privacy-and-tracking">Privacy and tracking</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><a href="#introduction-of-systems-performance-enterprise-and-the-cloud"><strong>Introduction of “Systems Performance: Enterprise and the Cloud”</strong></a></p>
<ul>
<li>
<ul>
<li><a href="#11-systems-performance"><strong>1.1 Systems Performance</strong></a></li>
<li><a href="#12-roles"><strong>1.2 Roles</strong></a></li>
<li><a href="#13-activities"><strong>1.3 Activities</strong></a></li>
<li><a href="#14-perspectives"><strong>1.4 Perspectives</strong></a></li>
<li><a href="#15-performance-is-challenging"><strong>1.5 Performance is Challenging</strong></a></li>
<li><a href="#16-latency"><strong>1.6 Latency</strong></a></li>
<li><a href="#17-observability"><strong>1.7 Observability</strong></a></li>
<li><a href="#18-experimentation"><strong>1.8 Experimentation</strong></a></li>
<li><a href="#19-cloud-computing"><strong>1.9 Cloud Computing</strong></a></li>
<li><a href="#110-methodologies"><strong>1.10 Methodologies</strong></a></li>
<li><a href="#111-case-studies"><strong>1.11 Case Studies</strong></a></li>
<li><a href="#112-references"><strong>1.12 References</strong></a></li>
</ul>
</li>
</ul>
</li>
<li>
<p><a href="#methodologies"><strong>Methodologies</strong></a></p>
<ul>
<li>
<p><a href="#concepts">Concepts</a></p>
</li>
<li>
<p><a href="#methodology"><strong>Methodology</strong></a></p>
</li>
<li>
<p><a href="#monitoring">Monitoring</a></p>
<ul>
<li><a href="#time-based-patterns"><strong>Time-Based Patterns</strong></a></li>
<li><a href="#monitoring-products"><strong>Monitoring Products</strong></a></li>
<li><a href="#summary-since-boot"><strong>Summary-Since-Boot</strong></a></li>
<li><a href="#real-time-vs-historical-monitoring"><strong>Real-Time vs. Historical Monitoring</strong></a></li>
<li><a href="#anomaly-detection"><strong>Anomaly Detection</strong></a></li>
<li><a href="#alerting"><strong>Alerting</strong></a></li>
<li><a href="#visualization-techniques"><strong>Visualization Techniques</strong></a></li>
<li><a href="#monitoring-granularity"><strong>Monitoring Granularity</strong></a></li>
<li><a href="#metric-aggregation-and-data-retention"><strong>Metric Aggregation and Data Retention</strong></a></li>
<li><a href="#synthetic-monitoring"><strong>Synthetic Monitoring</strong></a></li>
<li><a href="#end-user-experience-monitoring-eum"><strong>End-User Experience Monitoring (EUM)</strong></a></li>
</ul>
</li>
<li>
<p><a href="#visualizations">Visualizations</a></p>
<ul>
<li><a href="#1-line-charts">1. <strong>Line Charts</strong></a></li>
<li><a href="#2-scatter-plots">2. <strong>Scatter Plots</strong></a></li>
<li><a href="#3-heat-maps">3. <strong>Heat Maps</strong></a></li>
<li><a href="#4-timeline-charts">4. <strong>Timeline Charts</strong></a></li>
<li><a href="#5-surface-plots">5. <strong>Surface Plots</strong></a></li>
<li><a href="#6-flame-graphs">6. <strong>Flame Graphs</strong></a></li>
<li><a href="#7-stacked-area-charts">7. <strong>Stacked Area Charts</strong></a></li>
<li><a href="#8-histograms">8. <strong>Histograms</strong></a></li>
<li><a href="#9-box-plots">9. <strong>Box Plots</strong></a></li>
<li><a href="#10-sunburst-diagrams">10. <strong>Sunburst Diagrams</strong></a></li>
<li><a href="#11-treemaps">11. <strong>Treemaps</strong></a></li>
<li><a href="#12-sparkline-charts">12. <strong>Sparkline Charts</strong></a></li>
</ul>
</li>
</ul>
</li>
<li>
<p><a href="#chapter-4-observability-tools"><strong>Chapter 4: Observability Tools</strong></a></p>
<ul>
<li>
<p><a href="#41-tool-coverage"><strong>4.1 Tool Coverage</strong></a></p>
<ul>
<li><a href="#static-performance-tools"><strong>Static Performance Tools</strong></a></li>
<li><a href="#crisis-tools"><strong>Crisis Tools</strong></a></li>
</ul>
</li>
<li>
<p><a href="#42-tool-types"><strong>4.2 Tool Types</strong></a></p>
<ul>
<li><a href="#fixed-counters"><strong>Fixed Counters</strong></a></li>
<li><a href="#profiling"><strong>Profiling</strong></a></li>
<li><a href="#tracing"><strong>Tracing</strong></a></li>
<li><a href="#monitoring-1"><strong>Monitoring</strong></a></li>
</ul>
</li>
<li>
<p><a href="#43-observability-sources"><strong>4.3 Observability Sources</strong></a></p>
<ul>
<li><a href="#proc-filesystem"><strong><code class="language-text">/proc</code> Filesystem</strong></a></li>
<li><a href="#sys-filesystem"><strong><code class="language-text">/sys</code> Filesystem</strong></a></li>
<li><a href="#tracepoints"><strong>Tracepoints</strong></a></li>
<li><a href="#kprobes-and-uprobes"><strong>kprobes and uprobes</strong></a></li>
<li><a href="#usdt-user-level-statically-defined-tracing"><strong>USDT (User-Level Statically Defined Tracing)</strong></a></li>
</ul>
</li>
<li>
<p><a href="#44-tool-summaries"><strong>4.4 Tool Summaries</strong></a></p>
<ul>
<li><a href="#sar-system-activity-reporter"><strong><code class="language-text">sar</code> (System Activity Reporter)</strong></a></li>
<li><a href="#tracing-utilities"><strong>Tracing Utilities</strong></a></li>
<li><a href="#visualization-tools"><strong>Visualization Tools</strong></a></li>
</ul>
</li>
<li>
<p><a href="#45-observing-observability"><strong>4.5 Observing Observability</strong></a></p>
</li>
<li>
<p><a href="#exercises"><strong>Exercises</strong></a></p>
</li>
</ul>
</li>
<li>
<p><a href="#chapter-5-applications"><strong>Chapter 5: Applications</strong></a></p>
<ul>
<li>
<p><a href="#51-application-level-performance-concepts"><strong>5.1 Application-Level Performance Concepts</strong></a></p>
<ul>
<li><a href="#511-objectives"><strong>5.1.1 Objectives</strong></a></li>
<li><a href="#512-observability"><strong>5.1.2 Observability</strong></a></li>
<li><a href="#513-big-o-notation"><strong>5.1.3 Big O Notation</strong></a></li>
</ul>
</li>
<li>
<p><a href="#52-application-performance-techniques"><strong>5.2 Application Performance Techniques</strong></a></p>
<ul>
<li><a href="#521-selecting-io-sizes"><strong>5.2.1 Selecting I/O Sizes</strong></a></li>
<li><a href="#522-caching"><strong>5.2.2 Caching</strong></a></li>
<li><a href="#523-buffering"><strong>5.2.3 Buffering</strong></a></li>
<li><a href="#524-polling"><strong>5.2.4 Polling</strong></a></li>
<li><a href="#525-concurrency-and-parallelism"><strong>5.2.5 Concurrency and Parallelism</strong></a></li>
<li><a href="#526-non-blocking-io"><strong>5.2.6 Non-Blocking I/O</strong></a></li>
<li><a href="#527-processor-binding"><strong>5.2.7 Processor Binding</strong></a></li>
</ul>
</li>
<li>
<p><a href="#53-programming-languages-and-environments"><strong>5.3 Programming Languages and Environments</strong></a></p>
<ul>
<li><a href="#531-compiled-languages"><strong>5.3.1 Compiled Languages</strong></a></li>
<li><a href="#532-interpreted-languages"><strong>5.3.2 Interpreted Languages</strong></a></li>
<li><a href="#533-virtual-machines"><strong>5.3.3 Virtual Machines</strong></a></li>
<li><a href="#534-garbage-collection"><strong>5.3.4 Garbage Collection</strong></a></li>
</ul>
</li>
<li>
<p><a href="#54-observability-and-profiling-methods"><strong>5.4 Observability and Profiling Methods</strong></a></p>
<ul>
<li><a href="#541-cpu-profiling"><strong>5.4.1 CPU Profiling</strong></a></li>
<li><a href="#542-off-cpu-analysis"><strong>5.4.2 Off-CPU Analysis</strong></a></li>
<li><a href="#543-syscall-analysis"><strong>5.4.3 Syscall Analysis</strong></a></li>
<li><a href="#544-use-method-utilization-saturation-errors"><strong>5.4.4 USE Method (Utilization, Saturation, Errors)</strong></a></li>
<li><a href="#545-thread-state-analysis"><strong>5.4.5 Thread State Analysis</strong></a></li>
<li><a href="#546-lock-analysis"><strong>5.4.6 Lock Analysis</strong></a></li>
<li><a href="#547-distributed-tracing"><strong>5.4.7 Distributed Tracing</strong></a></li>
<li><a href="#548-static-performance-tuning"><strong>5.4.8 Static Performance Tuning</strong></a></li>
<li><a href="#549-micro-benchmarking"><strong>5.4.9 Micro-Benchmarking</strong></a></li>
<li><a href="#5410-performance-monitoring-tools"><strong>5.4.10 Performance Monitoring Tools</strong></a></li>
</ul>
</li>
<li>
<p><a href="#55-observability-tools"><strong>5.5 Observability Tools</strong></a></p>
<ul>
<li><a href="#551-perf"><strong>5.5.1 <code class="language-text">perf</code></strong></a></li>
<li><a href="#552-profile"><strong>5.5.2 <code class="language-text">profile</code></strong></a></li>
<li><a href="#553-offcputime"><strong>5.5.3 <code class="language-text">offcputime</code></strong></a></li>
<li><a href="#554-strace"><strong>5.5.4 <code class="language-text">strace</code></strong></a></li>
<li><a href="#555-execsnoop"><strong>5.5.5 <code class="language-text">execsnoop</code></strong></a></li>
<li><a href="#556-syscount"><strong>5.5.6 <code class="language-text">syscount</code></strong></a></li>
<li><a href="#557-bpftrace"><strong>5.5.7 <code class="language-text">bpftrace</code></strong></a></li>
</ul>
</li>
<li>
<p><a href="#56-gotchas"><strong>5.6 Gotchas</strong></a></p>
<ul>
<li><a href="#561-missing-symbols"><strong>5.6.1 Missing Symbols</strong></a></li>
<li><a href="#562-missing-stacks"><strong>5.6.2 Missing Stacks</strong></a></li>
<li><a href="#563-overhead-from-profiling-tools"><strong>5.6.3 Overhead from Profiling Tools</strong></a></li>
<li><a href="#564-sampling-bias"><strong>5.6.4 Sampling Bias</strong></a></li>
<li><a href="#565-ignoring-distributed-context"><strong>5.6.5 Ignoring Distributed Context</strong></a></li>
</ul>
</li>
<li>
<p><a href="#advanced-examples"><strong>Advanced Examples</strong></a></p>
<ul>
<li><a href="#example-1-diagnosing-high-io-latency"><strong>Example 1: Diagnosing High I/O Latency</strong></a></li>
<li><a href="#example-2-investigating-lock-contention"><strong>Example 2: Investigating Lock Contention</strong></a></li>
</ul>
</li>
<li>
<p><a href="#exercises-1"><strong>Exercises</strong></a></p>
</li>
</ul>
</li>
<li>
<p><a href="#chapter-6-cpus"><strong>Chapter 6: CPUs</strong></a></p>
<ul>
<li>
<p><a href="#61-terminology"><strong>6.1 Terminology</strong></a></p>
</li>
<li>
<p><a href="#62-models"><strong>6.2 Models</strong></a></p>
</li>
<li>
<p><a href="#63-concepts"><strong>6.3 Concepts</strong></a></p>
</li>
<li>
<p><a href="#64-architecture"><strong>6.4 Architecture</strong></a></p>
</li>
<li>
<p><a href="#65-methodology"><strong>6.5 Methodology</strong></a></p>
<ul>
<li>
<p><a href="#651-use-method"><strong>6.5.1 USE Method</strong></a></p>
<ul>
<li><a href="#utilization"><strong>Utilization</strong></a></li>
<li><a href="#saturation"><strong>Saturation</strong></a></li>
<li><a href="#errors"><strong>Errors</strong></a></li>
</ul>
</li>
<li>
<p><a href="#652-cycle-analysis"><strong>6.5.2 Cycle Analysis</strong></a></p>
<ul>
<li><a href="#cpu-cycle-categories"><strong>CPU Cycle Categories</strong></a></li>
<li><a href="#tool-example"><strong>Tool Example</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#653-profiling-workloads"><strong>6.5.3 Profiling Workloads</strong></a></p>
<ul>
<li><a href="#steps"><strong>Steps</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#654-run-queue-analysis"><strong>6.5.4 Run Queue Analysis</strong></a></p>
<ul>
<li><a href="#symptoms-of-overloaded-run-queues"><strong>Symptoms of Overloaded Run Queues</strong>:</a></li>
<li><a href="#tools"><strong>Tools</strong>:</a></li>
<li><a href="#example"><strong>Example</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#655-observability-with-cpu-specific-metrics"><strong>6.5.5 Observability with CPU-Specific Metrics</strong></a></p>
<ul>
<li><a href="#metrics-to-observe"><strong>Metrics to Observe</strong>:</a></li>
<li><a href="#tool-example-1"><strong>Tool Example</strong>:</a></li>
<li><a href="#output-example"><strong>Output Example</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#656-branch-misprediction-analysis"><strong>6.5.6 Branch Misprediction Analysis</strong></a></p>
<ul>
<li><a href="#what-are-branch-mispredictions"><strong>What Are Branch Mispredictions?</strong></a></li>
<li><a href="#tool-example-2"><strong>Tool Example</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#657-memory-bottleneck-analysis"><strong>6.5.7 Memory Bottleneck Analysis</strong></a></p>
<ul>
<li><a href="#cache-misses"><strong>Cache Misses</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#658-real-world-use-case-optimizing-a-web-server"><strong>6.5.8 Real-World Use Case: Optimizing a Web Server</strong></a></p>
<ul>
<li><a href="#scenario"><strong>Scenario</strong>:</a></li>
<li><a href="#steps-1"><strong>Steps</strong>:</a></li>
<li><a href="#result"><strong>Result</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#key-takeaways-for-methodology"><strong>Key Takeaways for Methodology</strong></a></p>
</li>
</ul>
</li>
<li>
<p><a href="#66-observability-tools"><strong>6.6 Observability Tools</strong></a></p>
<ul>
<li>
<p><a href="#661-basic-tools"><strong>6.6.1 Basic Tools</strong></a></p>
<ul>
<li><a href="#uptime"><strong><code class="language-text">uptime</code></strong></a></li>
<li><a href="#top"><strong><code class="language-text">top</code></strong></a></li>
<li><a href="#vmstat"><strong><code class="language-text">vmstat</code></strong></a></li>
<li><a href="#htop"><strong><code class="language-text">htop</code></strong></a></li>
</ul>
</li>
<li>
<p><a href="#662-advanced-tools"><strong>6.6.2 Advanced Tools</strong></a></p>
<ul>
<li><a href="#perf"><strong><code class="language-text">perf</code></strong></a></li>
<li><a href="#bpftrace"><strong><code class="language-text">bpftrace</code></strong></a></li>
<li><a href="#turbostat"><strong><code class="language-text">turbostat</code></strong></a></li>
<li><a href="#cpudist"><strong><code class="language-text">cpudist</code></strong></a></li>
<li><a href="#runqlat"><strong><code class="language-text">runqlat</code></strong></a></li>
</ul>
</li>
<li>
<p><a href="#663-specialized-tools"><strong>6.6.3 Specialized Tools</strong></a></p>
<ul>
<li><a href="#flame-graphs"><strong>Flame Graphs</strong></a></li>
<li><a href="#heat-maps"><strong>Heat Maps</strong></a></li>
</ul>
</li>
<li>
<p><a href="#664-real-world-examples"><strong>6.6.4 Real-World Examples</strong></a></p>
<ul>
<li><a href="#example-1-diagnosing-high-cpu-utilization"><strong>Example 1: Diagnosing High CPU Utilization</strong></a></li>
<li><a href="#example-2-investigating-run-queue-delays"><strong>Example 2: Investigating Run Queue Delays</strong></a></li>
<li><a href="#example-3-analyzing-cache-performance"><strong>Example 3: Analyzing Cache Performance</strong></a></li>
</ul>
</li>
<li>
<p><a href="#key-takeaways-1"><strong>Key Takeaways</strong></a></p>
</li>
</ul>
</li>
<li>
<p><a href="#67-visualizations"><strong>6.7 Visualizations</strong></a></p>
<ul>
<li>
<p><a href="#671-heat-maps"><strong>6.7.1 Heat Maps</strong></a></p>
<ul>
<li><a href="#definition"><strong>Definition</strong>:</a></li>
<li><a href="#use-cases"><strong>Use Cases</strong>:</a></li>
<li><a href="#tools-1"><strong>Tools</strong>:</a></li>
<li><a href="#example-1"><strong>Example</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#672-flame-graphs"><strong>6.7.2 Flame Graphs</strong></a></p>
<ul>
<li><a href="#definition-1"><strong>Definition</strong>:</a></li>
<li><a href="#key-features"><strong>Key Features</strong>:</a></li>
<li><a href="#steps-to-generate"><strong>Steps to Generate</strong>:</a></li>
<li><a href="#use-cases-1"><strong>Use Cases</strong>:</a></li>
<li><a href="#example-2"><strong>Example</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#673-run-queue-latency-graphs"><strong>6.7.3 Run Queue Latency Graphs</strong></a></p>
<ul>
<li><a href="#definition-2"><strong>Definition</strong>:</a></li>
<li><a href="#purpose"><strong>Purpose</strong>:</a></li>
<li><a href="#tools-2"><strong>Tools</strong>:</a></li>
<li><a href="#use-cases-2"><strong>Use Cases</strong>:</a></li>
<li><a href="#example-3"><strong>Example</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#674-gantt-charts-for-cpu-scheduling"><strong>6.7.4 Gantt Charts for CPU Scheduling</strong></a></p>
<ul>
<li><a href="#definition-3"><strong>Definition</strong>:</a></li>
<li><a href="#use-cases-3"><strong>Use Cases</strong>:</a></li>
<li><a href="#tools-3"><strong>Tools</strong>:</a></li>
<li><a href="#example-4"><strong>Example</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#675-histogram-visualizations"><strong>6.7.5 Histogram Visualizations</strong></a></p>
<ul>
<li><a href="#definition-4"><strong>Definition</strong>:</a></li>
<li><a href="#tools-4"><strong>Tools</strong>:</a></li>
<li><a href="#example-5"><strong>Example</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#676-real-time-dashboards"><strong>6.7.6 Real-Time Dashboards</strong></a></p>
<ul>
<li><a href="#definition-5"><strong>Definition</strong>:</a></li>
<li><a href="#tools-5"><strong>Tools</strong>:</a></li>
<li><a href="#use-cases-4"><strong>Use Cases</strong>:</a></li>
<li><a href="#example-6"><strong>Example</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#677-practical-example-end-to-end-visualization-workflow"><strong>6.7.7 Practical Example: End-to-End Visualization Workflow</strong></a></p>
<ul>
<li><a href="#scenario-1"><strong>Scenario</strong>:</a></li>
<li><a href="#steps-2"><strong>Steps</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#key-takeaways-2"><strong>Key Takeaways</strong></a></p>
</li>
</ul>
</li>
<li>
<p><a href="#68-experimentation"><strong>6.8 Experimentation</strong></a></p>
<ul>
<li>
<p><a href="#681-objectives-of-experimentation"><strong>6.8.1 Objectives of Experimentation</strong></a></p>
</li>
<li>
<p><a href="#682-types-of-experiments"><strong>6.8.2 Types of Experiments</strong></a></p>
<ul>
<li><a href="#6821-synthetic-workload-testing"><strong>6.8.2.1 Synthetic Workload Testing</strong></a></li>
<li><a href="#6822-real-world-workload-simulation"><strong>6.8.2.2 Real-World Workload Simulation</strong></a></li>
<li><a href="#6823-scaling-experiments"><strong>6.8.2.3 Scaling Experiments</strong></a></li>
</ul>
</li>
<li>
<p><a href="#683-methodology-for-experimentation"><strong>6.8.3 Methodology for Experimentation</strong></a></p>
</li>
<li>
<p><a href="#684-tools-for-experimentation"><strong>6.8.4 Tools for Experimentation</strong></a></p>
<ul>
<li><a href="#perf-1"><strong><code class="language-text">perf</code></strong></a></li>
<li><a href="#bpftrace-1"><strong><code class="language-text">bpftrace</code></strong></a></li>
<li><a href="#stress-ng"><strong><code class="language-text">stress-ng</code></strong></a></li>
<li><a href="#flame-graphs-1"><strong>Flame Graphs</strong></a></li>
</ul>
</li>
<li>
<p><a href="#685-practical-examples-of-experimentation"><strong>6.8.5 Practical Examples of Experimentation</strong></a></p>
<ul>
<li><a href="#example-1-optimizing-a-web-server"><strong>Example 1: Optimizing a Web Server</strong></a></li>
<li><a href="#example-2-numa-performance-tuning"><strong>Example 2: NUMA Performance Tuning</strong></a></li>
<li><a href="#example-3-branch-misprediction-mitigation"><strong>Example 3: Branch Misprediction Mitigation</strong></a></li>
</ul>
</li>
<li>
<p><a href="#686-best-practices-for-experimentation"><strong>6.8.6 Best Practices for Experimentation</strong></a></p>
</li>
<li>
<p><a href="#key-takeaways-3"><strong>Key Takeaways</strong></a></p>
</li>
</ul>
</li>
<li>
<p><a href="#69-tuning"><strong>6.9 Tuning</strong></a></p>
<ul>
<li>
<p><a href="#691-objectives-of-cpu-tuning"><strong>6.9.1 Objectives of CPU Tuning</strong></a></p>
</li>
<li>
<p><a href="#692-tuning-techniques"><strong>6.9.2 Tuning Techniques</strong></a></p>
<ul>
<li><a href="#6921-compiler-optimizations"><strong>6.9.2.1 Compiler Optimizations</strong></a></li>
<li><a href="#6922-numa-non-uniform-memory-access-optimization"><strong>6.9.2.2 NUMA (Non-Uniform Memory Access) Optimization</strong></a></li>
<li><a href="#6923-thread-and-process-affinity"><strong>6.9.2.3 Thread and Process Affinity</strong></a></li>
<li><a href="#6924-scaling-governors"><strong>6.9.2.4 Scaling Governors</strong></a></li>
<li><a href="#6925-cache-optimization"><strong>6.9.2.5 Cache Optimization</strong></a></li>
<li><a href="#6926-multithreading-and-parallelization"><strong>6.9.2.6 Multithreading and Parallelization</strong></a></li>
<li><a href="#6927-interrupt-handling"><strong>6.9.2.7 Interrupt Handling</strong></a></li>
</ul>
</li>
<li>
<p><a href="#693-tools-for-cpu-tuning"><strong>6.9.3 Tools for CPU Tuning</strong></a></p>
<ul>
<li><a href="#1-perf"><strong>1. <code class="language-text">perf</code></strong></a></li>
<li><a href="#2-numactl"><strong>2. <code class="language-text">numactl</code></strong></a></li>
<li><a href="#3-cpupower"><strong>3. <code class="language-text">cpupower</code></strong></a></li>
<li><a href="#4-taskset"><strong>4. <code class="language-text">taskset</code></strong></a></li>
<li><a href="#5-chrt"><strong>5. <code class="language-text">chrt</code></strong></a></li>
</ul>
</li>
<li>
<p><a href="#694-real-world-examples"><strong>6.9.4 Real-World Examples</strong></a></p>
<ul>
<li><a href="#example-1-optimizing-a-web-server-1"><strong>Example 1: Optimizing a Web Server</strong></a></li>
<li><a href="#example-2-numa-optimization-in-a-database"><strong>Example 2: NUMA Optimization in a Database</strong></a></li>
<li><a href="#example-3-reducing-cache-misses-in-machine-learning"><strong>Example 3: Reducing Cache Misses in Machine Learning</strong></a></li>
</ul>
</li>
<li>
<p><a href="#key-takeaways-4"><strong>Key Takeaways</strong></a></p>
</li>
<li>
<p><a href="#610-exercises"><strong>6.10 Exercises</strong></a></p>
</li>
<li>
<p><a href="#key-takeaways-5"><strong>Key Takeaways</strong></a></p>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><a href="#chapter-7-memory"><strong>Chapter 7: Memory</strong></a></p>
<ul>
<li>
<p><a href="#71-terminology"><strong>7.1 Terminology</strong></a></p>
<ul>
<li><a href="#key-terms-in-memory-management"><strong>Key Terms in Memory Management</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#72-concepts"><strong>7.2 Concepts</strong></a></p>
<ul>
<li><a href="#721-virtual-memory"><strong>7.2.1 Virtual Memory</strong></a></li>
<li><a href="#722-paging-and-demand-paging"><strong>7.2.2 Paging and Demand Paging</strong></a></li>
<li><a href="#723-overcommit"><strong>7.2.3 Overcommit</strong></a></li>
<li><a href="#724-file-system-cache-usage"><strong>7.2.4 File System Cache Usage</strong></a></li>
<li><a href="#725-allocators-and-shared-memory"><strong>7.2.5 Allocators and Shared Memory</strong></a></li>
</ul>
</li>
<li>
<p><a href="#73-architecture"><strong>7.3 Architecture</strong></a></p>
<ul>
<li><a href="#731-hardware"><strong>7.3.1 Hardware</strong></a></li>
<li><a href="#732-software"><strong>7.3.2 Software</strong></a></li>
</ul>
</li>
<li>
<p><a href="#74-methodology"><strong>7.4 Methodology</strong></a></p>
<ul>
<li>
<p><a href="#741-steps-for-memory-performance-analysis"><strong>7.4.1 Steps for Memory Performance Analysis</strong></a></p>
<ul>
<li>
<p><a href="#step-1-characterize-memory-usage"><strong>Step 1: Characterize Memory Usage</strong></a></p>
<ul>
<li><a href="#understanding-process-level-memory"><strong>Understanding Process-Level Memory</strong></a></li>
<li><a href="#monitoring-overall-system-memory"><strong>Monitoring Overall System Memory</strong></a></li>
</ul>
</li>
<li>
<p><a href="#step-2-detect-memory-leaks"><strong>Step 2: Detect Memory Leaks</strong></a></p>
<ul>
<li><a href="#definition-6"><strong>Definition</strong>:</a></li>
<li><a href="#tools-6"><strong>Tools</strong>:</a></li>
<li><a href="#example-7"><strong>Example</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#step-3-analyze-cache-and-swap-activity"><strong>Step 3: Analyze Cache and Swap Activity</strong></a></p>
<ul>
<li><a href="#cache-analysis"><strong>Cache Analysis</strong></a></li>
<li><a href="#swap-activity"><strong>Swap Activity</strong></a></li>
<li><a href="#example-8"><strong>Example</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#step-4-monitor-application-specific-memory-usage"><strong>Step 4: Monitor Application-Specific Memory Usage</strong></a></p>
<ul>
<li><a href="#tools-7"><strong>Tools</strong>:</a></li>
<li><a href="#example-9"><strong>Example</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#step-5-detect-inefficient-memory-access-patterns"><strong>Step 5: Detect Inefficient Memory Access Patterns</strong></a></p>
<ul>
<li><a href="#definition-7"><strong>Definition</strong>:</a></li>
<li><a href="#tools-8"><strong>Tools</strong>:</a></li>
<li><a href="#example-10"><strong>Example</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#step-6-tune-memory-usage"><strong>Step 6: Tune Memory Usage</strong></a></p>
<ul>
<li><a href="#tuning-swappiness"><strong>Tuning Swappiness</strong></a></li>
<li><a href="#use-huge-pages"><strong>Use Huge Pages</strong></a></li>
<li><a href="#numa-optimizations"><strong>NUMA Optimizations</strong></a></li>
</ul>
</li>
</ul>
</li>
<li>
<p><a href="#742-practical-examples"><strong>7.4.2 Practical Examples</strong></a></p>
<ul>
<li><a href="#example-1-memory-leak-in-a-web-application"><strong>Example 1: Memory Leak in a Web Application</strong></a></li>
<li><a href="#example-2-cache-optimization-in-a-database"><strong>Example 2: Cache Optimization in a Database</strong></a></li>
<li><a href="#example-3-reducing-swapping-in-a-batch-process"><strong>Example 3: Reducing Swapping in a Batch Process</strong></a></li>
</ul>
</li>
<li>
<p><a href="#key-takeaways-6"><strong>Key Takeaways</strong></a></p>
</li>
</ul>
</li>
<li>
<p><a href="#75-observability-tools"><strong>7.5 Observability Tools</strong></a></p>
<ul>
<li>
<p><a href="#751-system-level-observability-tools"><strong>7.5.1 System-Level Observability Tools</strong></a></p>
<ul>
<li><a href="#1-vmstat"><strong>1. <code class="language-text">vmstat</code></strong></a></li>
<li><a href="#2-free"><strong>2. <code class="language-text">free</code></strong></a></li>
<li><a href="#3-tophtop"><strong>3. <code class="language-text">top</code>/<code class="language-text">htop</code></strong></a></li>
<li><a href="#4-sar"><strong>4. <code class="language-text">sar</code></strong></a></li>
<li><a href="#5-slabtop"><strong>5. <code class="language-text">slabtop</code></strong></a></li>
</ul>
</li>
<li>
<p><a href="#752-application-specific-observability-tools"><strong>7.5.2 Application-Specific Observability Tools</strong></a></p>
<ul>
<li>
<p><a href="#1-pmap"><strong>1. <code class="language-text">pmap</code></strong></a></p>
</li>
<li>
<p><a href="#2-memory-profilers"><strong>2. Memory Profilers</strong></a></p>
<ul>
<li><a href="#for-python"><strong>For Python</strong>:</a></li>
<li><a href="#for-java"><strong>For Java</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#3-tracing-allocations-with-bpftrace"><strong>3. Tracing Allocations with <code class="language-text">bpftrace</code></strong></a></p>
</li>
</ul>
</li>
<li>
<p><a href="#753-advanced-tools"><strong>7.5.3 Advanced Tools</strong></a></p>
<ul>
<li><a href="#1-perf-1"><strong>1. <code class="language-text">perf</code></strong></a></li>
<li><a href="#2-bcc-tools"><strong>2. BCC Tools</strong></a></li>
</ul>
</li>
<li>
<p><a href="#754-practical-examples"><strong>7.5.4 Practical Examples</strong></a></p>
<ul>
<li><a href="#example-1-diagnosing-high-swap-usage"><strong>Example 1: Diagnosing High Swap Usage</strong></a></li>
<li><a href="#example-2-identifying-a-memory-leak"><strong>Example 2: Identifying a Memory Leak</strong></a></li>
<li><a href="#example-3-cache-optimization-in-a-scientific-application"><strong>Example 3: Cache Optimization in a Scientific Application</strong></a></li>
</ul>
</li>
<li>
<p><a href="#key-takeaways-7"><strong>Key Takeaways</strong></a></p>
</li>
</ul>
</li>
<li>
<p><a href="#76-tuning"><strong>7.6 Tuning</strong></a></p>
<ul>
<li>
<p><a href="#761-virtual-memory-tuning"><strong>7.6.1 Virtual Memory Tuning</strong></a></p>
<ul>
<li><a href="#1-adjusting-swappiness"><strong>1. Adjusting Swappiness</strong></a></li>
<li><a href="#2-increasing-virtual-memory-limits"><strong>2. Increasing Virtual Memory Limits</strong></a></li>
</ul>
</li>
<li>
<p><a href="#762-swap-space-optimization"><strong>7.6.2 Swap Space Optimization</strong></a></p>
<ul>
<li><a href="#1-proper-swap-sizing"><strong>1. Proper Swap Sizing</strong></a></li>
<li><a href="#2-monitoring-swap-performance"><strong>2. Monitoring Swap Performance</strong></a></li>
</ul>
</li>
<li>
<p><a href="#763-file-system-cache-tuning"><strong>7.6.3 File System Cache Tuning</strong></a></p>
<ul>
<li><a href="#1-adjusting-cache-pressure"><strong>1. Adjusting Cache Pressure</strong></a></li>
<li><a href="#2-maximizing-cache-usage"><strong>2. Maximizing Cache Usage</strong></a></li>
</ul>
</li>
<li>
<p><a href="#764-numa-tuning"><strong>7.6.4 NUMA Tuning</strong></a></p>
<ul>
<li><a href="#1-binding-memory-to-numa-nodes"><strong>1. Binding Memory to NUMA Nodes</strong></a></li>
<li><a href="#2-optimizing-numa-aware-applications"><strong>2. Optimizing NUMA-Aware Applications</strong></a></li>
</ul>
</li>
<li>
<p><a href="#765-huge-pages"><strong>7.6.5 Huge Pages</strong></a></p>
<ul>
<li><a href="#1-enabling-huge-pages"><strong>1. Enabling Huge Pages</strong></a></li>
</ul>
</li>
<li>
<p><a href="#766-application-specific-tuning"><strong>7.6.6 Application-Specific Tuning</strong></a></p>
<ul>
<li><a href="#1-java-applications"><strong>1. Java Applications</strong></a></li>
<li><a href="#2-python-applications"><strong>2. Python Applications</strong></a></li>
<li><a href="#3-database-servers"><strong>3. Database Servers</strong></a></li>
</ul>
</li>
<li>
<p><a href="#767-monitoring-and-feedback"><strong>7.6.7 Monitoring and Feedback</strong></a></p>
<ul>
<li><a href="#1-monitoring-tools"><strong>1. Monitoring Tools</strong></a></li>
<li><a href="#2-feedback-loop"><strong>2. Feedback Loop</strong></a></li>
</ul>
</li>
<li>
<p><a href="#768-practical-examples"><strong>7.6.8 Practical Examples</strong></a></p>
<ul>
<li><a href="#example-1-reducing-swap-usage"><strong>Example 1: Reducing Swap Usage</strong></a></li>
<li><a href="#example-2-numa-tuning-in-high-performance-computing"><strong>Example 2: NUMA Tuning in High-Performance Computing</strong></a></li>
<li><a href="#example-3-optimizing-cache-pressure-for-a-file-server"><strong>Example 3: Optimizing Cache Pressure for a File Server</strong></a></li>
</ul>
</li>
<li>
<p><a href="#key-takeaways-8"><strong>Key Takeaways</strong></a></p>
</li>
</ul>
</li>
<li>
<p><a href="#77-practical-examples"><strong>7.7 Practical Examples</strong></a></p>
<ul>
<li>
<p><a href="#771-example-1-detecting-a-memory-leak-in-a-web-application"><strong>7.7.1 Example 1: Detecting a Memory Leak in a Web Application</strong></a></p>
<ul>
<li><a href="#problem"><strong>Problem</strong>:</a></li>
<li><a href="#diagnosis"><strong>Diagnosis</strong>:</a></li>
<li><a href="#solution"><strong>Solution</strong>:</a></li>
<li><a href="#result-1"><strong>Result</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#772-example-2-reducing-swap-usage-on-a-database-server"><strong>7.7.2 Example 2: Reducing Swap Usage on a Database Server</strong></a></p>
<ul>
<li><a href="#problem-1"><strong>Problem</strong>:</a></li>
<li><a href="#diagnosis-1"><strong>Diagnosis</strong>:</a></li>
<li><a href="#solution-1"><strong>Solution</strong>:</a></li>
<li><a href="#result-2"><strong>Result</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#773-example-3-optimizing-cache-for-a-file-server"><strong>7.7.3 Example 3: Optimizing Cache for a File Server</strong></a></p>
<ul>
<li><a href="#problem-2"><strong>Problem</strong>:</a></li>
<li><a href="#diagnosis-2"><strong>Diagnosis</strong>:</a></li>
<li><a href="#solution-2"><strong>Solution</strong>:</a></li>
<li><a href="#result-3"><strong>Result</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#774-example-4-numa-optimization-for-a-high-performance-application"><strong>7.7.4 Example 4: NUMA Optimization for a High-Performance Application</strong></a></p>
<ul>
<li><a href="#problem-3"><strong>Problem</strong>:</a></li>
<li><a href="#diagnosis-3"><strong>Diagnosis</strong>:</a></li>
<li><a href="#solution-3"><strong>Solution</strong>:</a></li>
<li><a href="#result-4"><strong>Result</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#775-example-5-tuning-a-java-application"><strong>7.7.5 Example 5: Tuning a Java Application</strong></a></p>
<ul>
<li><a href="#problem-4"><strong>Problem</strong>:</a></li>
<li><a href="#diagnosis-4"><strong>Diagnosis</strong>:</a></li>
<li><a href="#solution-4"><strong>Solution</strong>:</a></li>
<li><a href="#result-5"><strong>Result</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#776-example-6-reducing-memory-fragmentation"><strong>7.7.6 Example 6: Reducing Memory Fragmentation</strong></a></p>
<ul>
<li><a href="#problem-5"><strong>Problem</strong>:</a></li>
<li><a href="#diagnosis-5"><strong>Diagnosis</strong>:</a></li>
<li><a href="#solution-5"><strong>Solution</strong>:</a></li>
<li><a href="#result-6"><strong>Result</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#key-takeaways-for-practical-examples"><strong>Key Takeaways for practical examples</strong></a></p>
</li>
</ul>
</li>
<li>
<p><a href="#key-takeaways-for-memory-performance"><strong>Key Takeaways for memory performance</strong></a></p>
</li>
</ul>
</li>
<li>
<p><a href="#file-systems"><strong>File Systems</strong></a></p>
<ul>
<li><a href="#concepts-of-latency-caching-and-io-operations"><strong>Concepts of Latency, Caching, and I/O Operations</strong></a></li>
<li><a href="#observability-tools-for-file-systems"><strong>Observability Tools for File Systems</strong></a></li>
<li><a href="#tuning-for-performance-and-scalability"><strong>Tuning for Performance and Scalability</strong></a></li>
<li><a href="#examples-and-real-life-use-cases"><strong>Examples and Real-Life Use Cases</strong></a></li>
<li><a href="#key-highlights"><strong>Key Highlights</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#disks"><strong>Disks</strong></a></p>
<ul>
<li><a href="#storage-architecture-and-performance-concepts"><strong>Storage Architecture and Performance Concepts</strong></a></li>
<li><a href="#tools-for-disk-performance-monitoring"><strong>Tools for Disk Performance Monitoring</strong></a></li>
<li><a href="#tuning-techniques-for-disk-io-workloads"><strong>Tuning Techniques for Disk I/O Workloads</strong></a></li>
<li><a href="#examples-and-use-cases"><strong>Examples and Use Cases</strong></a></li>
<li><a href="#key-takeaways-9"><strong>Key Takeaways</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#networking"><strong>Networking</strong></a></p>
<ul>
<li><a href="#networking-concepts-protocols-latency-and-congestion"><strong>Networking Concepts: Protocols, Latency, and Congestion</strong></a></li>
<li><a href="#observability-tools-for-networking"><strong>Observability Tools for Networking</strong></a></li>
<li><a href="#network-performance-tuning-and-optimization"><strong>Network Performance Tuning and Optimization</strong></a></li>
<li><a href="#examples-and-case-studies"><strong>Examples and Case Studies</strong></a></li>
<li><a href="#key-highlights-1"><strong>Key Highlights</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#cloud-computing"><strong>Cloud Computing</strong></a></p>
<ul>
<li><a href="#virtualization-and-its-performance-implications"><strong>Virtualization and Its Performance Implications</strong></a></li>
<li><a href="#cloud-observability-techniques"><strong>Cloud Observability Techniques</strong></a></li>
<li><a href="#case-studies-on-virtualization-methods-like-containers"><strong>Case Studies on Virtualization Methods Like Containers</strong></a></li>
<li><a href="#key-highlights-2"><strong>Key Highlights</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#benchmarking"><strong>Benchmarking</strong></a></p>
<ul>
<li>
<p><a href="#121-purpose-of-benchmarking"><strong>12.1 Purpose of Benchmarking</strong></a></p>
<ul>
<li><a href="#definition-8"><strong>Definition</strong>:</a></li>
<li><a href="#key-goals"><strong>Key Goals</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#122-types-of-benchmarks"><strong>12.2 Types of Benchmarks</strong></a></p>
<ul>
<li>
<p><a href="#1221-synthetic-benchmarks"><strong>12.2.1 Synthetic Benchmarks</strong></a></p>
<ul>
<li><a href="#definition-9"><strong>Definition</strong>:</a></li>
<li><a href="#purpose-1"><strong>Purpose</strong>:</a></li>
<li><a href="#tools-9"><strong>Tools</strong>:</a></li>
<li><a href="#example-scenario"><strong>Example Scenario</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#1222-application-benchmarks"><strong>12.2.2 Application Benchmarks</strong></a></p>
<ul>
<li><a href="#definition-10"><strong>Definition</strong>:</a></li>
<li><a href="#purpose-2"><strong>Purpose</strong>:</a></li>
<li><a href="#tools-10"><strong>Tools</strong>:</a></li>
<li><a href="#example-scenario-1"><strong>Example Scenario</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#1223-microbenchmarks"><strong>12.2.3 Microbenchmarks</strong></a></p>
<ul>
<li><a href="#definition-11"><strong>Definition</strong>:</a></li>
<li><a href="#purpose-3"><strong>Purpose</strong>:</a></li>
<li><a href="#tools-11"><strong>Tools</strong>:</a></li>
<li><a href="#example-scenario-2"><strong>Example Scenario</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#1224-end-to-end-benchmarks"><strong>12.2.4 End-to-End Benchmarks</strong></a></p>
<ul>
<li><a href="#definition-12"><strong>Definition</strong>:</a></li>
<li><a href="#purpose-4"><strong>Purpose</strong>:</a></li>
<li><a href="#tools-12"><strong>Tools</strong>:</a></li>
<li><a href="#example-scenario-3"><strong>Example Scenario</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#1225-comparison-of-benchmark-types"><strong>12.2.5 Comparison of Benchmark Types</strong></a></p>
</li>
<li>
<p><a href="#key-takeaways-10"><strong>Key Takeaways</strong></a></p>
</li>
</ul>
</li>
<li>
<p><a href="#123-benchmarking-methodology"><strong>12.3 Benchmarking Methodology</strong></a></p>
<ul>
<li>
<p><a href="#1231-step-1-define-goals"><strong>12.3.1 Step 1: Define Goals</strong></a></p>
<ul>
<li><a href="#objective"><strong>Objective</strong>:</a></li>
<li><a href="#examples"><strong>Examples</strong>:</a></li>
<li><a href="#best-practices"><strong>Best Practices</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#1232-step-2-prepare-the-environment"><strong>12.3.2 Step 2: Prepare the Environment</strong></a></p>
<ul>
<li><a href="#objective-1"><strong>Objective</strong>:</a></li>
<li><a href="#key-actions"><strong>Key Actions</strong>:</a></li>
<li><a href="#example-11"><strong>Example</strong>:</a></li>
<li><a href="#best-practices-1"><strong>Best Practices</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#1233-step-3-select-workloads"><strong>12.3.3 Step 3: Select Workloads</strong></a></p>
<ul>
<li><a href="#objective-2"><strong>Objective</strong>:</a></li>
<li><a href="#types-of-workloads"><strong>Types of Workloads</strong>:</a></li>
<li><a href="#example-12"><strong>Example</strong>:</a></li>
<li><a href="#best-practices-2"><strong>Best Practices</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#1234-step-4-collect-baseline-metrics"><strong>12.3.4 Step 4: Collect Baseline Metrics</strong></a></p>
<ul>
<li><a href="#objective-3"><strong>Objective</strong>:</a></li>
<li><a href="#tools-13"><strong>Tools</strong>:</a></li>
<li><a href="#example-13"><strong>Example</strong>:</a></li>
<li><a href="#best-practices-3"><strong>Best Practices</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#1235-step-5-conduct-multiple-runs"><strong>12.3.5 Step 5: Conduct Multiple Runs</strong></a></p>
<ul>
<li><a href="#objective-4"><strong>Objective</strong>:</a></li>
<li><a href="#key-actions-1"><strong>Key Actions</strong>:</a></li>
<li><a href="#example-14"><strong>Example</strong>:</a></li>
<li><a href="#best-practices-4"><strong>Best Practices</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#1236-step-6-analyze-results"><strong>12.3.6 Step 6: Analyze Results</strong></a></p>
<ul>
<li><a href="#objective-5"><strong>Objective</strong>:</a></li>
<li><a href="#key-metrics"><strong>Key Metrics</strong>:</a></li>
<li><a href="#tools-14"><strong>Tools</strong>:</a></li>
<li><a href="#example-15"><strong>Example</strong>:</a></li>
<li><a href="#best-practices-5"><strong>Best Practices</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#key-takeaways-11"><strong>Key Takeaways</strong></a></p>
</li>
</ul>
</li>
<li>
<p><a href="#124-tools-for-benchmarking"><strong>12.4 Tools for Benchmarking</strong></a></p>
<ul>
<li>
<p><a href="#1241-cpu-benchmarking-tools"><strong>12.4.1 CPU Benchmarking Tools</strong></a></p>
<ul>
<li><a href="#purpose-5"><strong>Purpose</strong>:</a></li>
<li><a href="#key-tools"><strong>Key Tools</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#1242-memory-benchmarking-tools"><strong>12.4.2 Memory Benchmarking Tools</strong></a></p>
<ul>
<li><a href="#purpose-6"><strong>Purpose</strong>:</a></li>
<li><a href="#key-tools-1"><strong>Key Tools</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#1243-disk-io-benchmarking-tools"><strong>12.4.3 Disk I/O Benchmarking Tools</strong></a></p>
<ul>
<li><a href="#purpose-7"><strong>Purpose</strong>:</a></li>
<li><a href="#key-tools-2"><strong>Key Tools</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#1244-network-benchmarking-tools"><strong>12.4.4 Network Benchmarking Tools</strong></a></p>
<ul>
<li><a href="#purpose-8"><strong>Purpose</strong>:</a></li>
<li><a href="#key-tools-3"><strong>Key Tools</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#1245-application-benchmarking-tools"><strong>12.4.5 Application Benchmarking Tools</strong></a></p>
<ul>
<li><a href="#purpose-9"><strong>Purpose</strong>:</a></li>
<li><a href="#key-tools-4"><strong>Key Tools</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#1246-visualization-tools-for-benchmark-results"><strong>12.4.6 Visualization Tools for Benchmark Results</strong></a></p>
<ul>
<li><a href="#purpose-10"><strong>Purpose</strong>:</a></li>
<li><a href="#key-tools-5"><strong>Key Tools</strong>:</a></li>
<li><a href="#best-practices-6"><strong>Best Practices</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#key-takeaways-12"><strong>Key Takeaways</strong></a></p>
</li>
</ul>
</li>
<li>
<p><a href="#125-benchmarking-best-practices"><strong>12.5 Benchmarking Best Practices</strong></a></p>
<ul>
<li>
<p><a href="#1251-isolate-the-system"><strong>12.5.1 Isolate the System</strong></a></p>
<ul>
<li><a href="#purpose-11"><strong>Purpose</strong>:</a></li>
<li><a href="#strategies"><strong>Strategies</strong>:</a></li>
<li><a href="#real-world-example"><strong>Real-World Example</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#1252-use-realistic-workloads"><strong>12.5.2 Use Realistic Workloads</strong></a></p>
<ul>
<li><a href="#purpose-12"><strong>Purpose</strong>:</a></li>
<li><a href="#strategies-1"><strong>Strategies</strong>:</a></li>
<li><a href="#real-world-example-1"><strong>Real-World Example</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#1253-test-at-scale"><strong>12.5.3 Test at Scale</strong></a></p>
<ul>
<li><a href="#purpose-13"><strong>Purpose</strong>:</a></li>
<li><a href="#strategies-2"><strong>Strategies</strong>:</a></li>
<li><a href="#real-world-example-2"><strong>Real-World Example</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#1254-avoid-single-run-results"><strong>12.5.4 Avoid Single-Run Results</strong></a></p>
<ul>
<li><a href="#purpose-14"><strong>Purpose</strong>:</a></li>
<li><a href="#strategies-3"><strong>Strategies</strong>:</a></li>
<li><a href="#real-world-example-3"><strong>Real-World Example</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#1255-document-the-environment"><strong>12.5.5 Document the Environment</strong></a></p>
<ul>
<li><a href="#purpose-15"><strong>Purpose</strong>:</a></li>
<li><a href="#strategies-4"><strong>Strategies</strong>:</a></li>
<li><a href="#real-world-example-4"><strong>Real-World Example</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#1256-warm-up-the-system"><strong>12.5.6 Warm Up the System</strong></a></p>
<ul>
<li><a href="#purpose-16"><strong>Purpose</strong>:</a></li>
<li><a href="#strategies-5"><strong>Strategies</strong>:</a></li>
<li><a href="#real-world-example-5"><strong>Real-World Example</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#1257-visualize-results"><strong>12.5.7 Visualize Results</strong></a></p>
<ul>
<li><a href="#purpose-17"><strong>Purpose</strong>:</a></li>
<li><a href="#strategies-6"><strong>Strategies</strong>:</a></li>
<li><a href="#real-world-example-6"><strong>Real-World Example</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#1258-use-percentiles-for-analysis"><strong>12.5.8 Use Percentiles for Analysis</strong></a></p>
<ul>
<li><a href="#purpose-18"><strong>Purpose</strong>:</a></li>
<li><a href="#strategies-7"><strong>Strategies</strong>:</a></li>
<li><a href="#real-world-example-7"><strong>Real-World Example</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#key-takeaways-13"><strong>Key Takeaways</strong></a></p>
</li>
</ul>
</li>
<li>
<p><a href="#126-common-pitfalls-in-benchmarking"><strong>12.6 Common Pitfalls in Benchmarking</strong></a></p>
<ul>
<li>
<p><a href="#1261-ignoring-warm-up-periods"><strong>12.6.1 Ignoring Warm-Up Periods</strong></a></p>
<ul>
<li><a href="#pitfall"><strong>Pitfall</strong>:</a></li>
<li><a href="#impact"><strong>Impact</strong>:</a></li>
<li><a href="#example-16"><strong>Example</strong>:</a></li>
<li><a href="#solution-6"><strong>Solution</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#1262-overfitting-to-benchmarks"><strong>12.6.2 Overfitting to Benchmarks</strong></a></p>
<ul>
<li><a href="#pitfall-1"><strong>Pitfall</strong>:</a></li>
<li><a href="#impact-1"><strong>Impact</strong>:</a></li>
<li><a href="#example-17"><strong>Example</strong>:</a></li>
<li><a href="#solution-7"><strong>Solution</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#1263-misinterpreting-metrics"><strong>12.6.3 Misinterpreting Metrics</strong></a></p>
<ul>
<li><a href="#pitfall-2"><strong>Pitfall</strong>:</a></li>
<li><a href="#impact-2"><strong>Impact</strong>:</a></li>
<li><a href="#example-18"><strong>Example</strong>:</a></li>
<li><a href="#solution-8"><strong>Solution</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#1264-lack-of-reproducibility"><strong>12.6.4 Lack of Reproducibility</strong></a></p>
<ul>
<li><a href="#pitfall-3"><strong>Pitfall</strong>:</a></li>
<li><a href="#impact-3"><strong>Impact</strong>:</a></li>
<li><a href="#example-19"><strong>Example</strong>:</a></li>
<li><a href="#solution-9"><strong>Solution</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#1265-skipping-multiple-runs"><strong>12.6.5 Skipping Multiple Runs</strong></a></p>
<ul>
<li><a href="#pitfall-4"><strong>Pitfall</strong>:</a></li>
<li><a href="#impact-4"><strong>Impact</strong>:</a></li>
<li><a href="#example-20"><strong>Example</strong>:</a></li>
<li><a href="#solution-10"><strong>Solution</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#1266-testing-with-unrealistic-workloads"><strong>12.6.6 Testing with Unrealistic Workloads</strong></a></p>
<ul>
<li><a href="#pitfall-5"><strong>Pitfall</strong>:</a></li>
<li><a href="#impact-5"><strong>Impact</strong>:</a></li>
<li><a href="#example-21"><strong>Example</strong>:</a></li>
<li><a href="#solution-11"><strong>Solution</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#1267-overlooking-system-bottlenecks"><strong>12.6.7 Overlooking System Bottlenecks</strong></a></p>
<ul>
<li><a href="#pitfall-6"><strong>Pitfall</strong>:</a></li>
<li><a href="#impact-6"><strong>Impact</strong>:</a></li>
<li><a href="#example-22"><strong>Example</strong>:</a></li>
<li><a href="#solution-12"><strong>Solution</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#key-takeaways-14"><strong>Key Takeaways</strong></a></p>
</li>
</ul>
</li>
<li>
<p><a href="#127-practical-example-benchmarking-a-web-application"><strong>12.7 Practical Example: Benchmarking a Web Application</strong></a></p>
<ul>
<li>
<p><a href="#scenario-2"><strong>Scenario</strong></a></p>
</li>
<li>
<p><a href="#step-1-define-goals"><strong>Step 1: Define Goals</strong></a></p>
<ul>
<li><a href="#objectives"><strong>Objectives</strong>:</a></li>
<li><a href="#metrics-to-collect"><strong>Metrics to Collect</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#step-2-prepare-the-environment"><strong>Step 2: Prepare the Environment</strong></a></p>
<ul>
<li><a href="#test-environment"><strong>Test Environment</strong>:</a></li>
<li><a href="#baseline-configuration"><strong>Baseline Configuration</strong>:</a></li>
<li><a href="#warm-up"><strong>Warm-Up</strong>:</a></li>
<li><a href="#document-configuration"><strong>Document Configuration</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#step-3-select-workloads"><strong>Step 3: Select Workloads</strong></a></p>
<ul>
<li><a href="#workload-design"><strong>Workload Design</strong>:</a></li>
<li><a href="#tools-15"><strong>Tools</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#step-4-collect-baseline-metrics"><strong>Step 4: Collect Baseline Metrics</strong></a></p>
<ul>
<li><a href="#monitoring-tools"><strong>Monitoring Tools</strong>:</a></li>
<li><a href="#baseline-results"><strong>Baseline Results</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#step-5-conduct-benchmarks"><strong>Step 5: Conduct Benchmarks</strong></a></p>
<ul>
<li><a href="#load-test-1-moderate-traffic"><strong>Load Test 1: Moderate Traffic</strong></a></li>
<li><a href="#load-test-2-peak-traffic"><strong>Load Test 2: Peak Traffic</strong></a></li>
</ul>
</li>
<li>
<p><a href="#step-6-analyze-results"><strong>Step 6: Analyze Results</strong></a></p>
<ul>
<li><a href="#key-observations"><strong>Key Observations</strong>:</a></li>
<li><a href="#graph-results"><strong>Graph Results</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#step-7-apply-optimizations"><strong>Step 7: Apply Optimizations</strong></a></p>
</li>
<li>
<p><a href="#step-8-re-test-after-optimization"><strong>Step 8: Re-Test After Optimization</strong></a></p>
<ul>
<li><a href="#results"><strong>Results</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#key-takeaways-for-practical-examples-1"><strong>Key Takeaways for practical examples</strong></a></p>
</li>
</ul>
</li>
<li>
<p><a href="#key-takeaways-for-benchmarking"><strong>Key Takeaways for benchmarking</strong></a></p>
</li>
</ul>
</li>
<li>
<p><a href="#perf-the-linux-profiler"><strong><code class="language-text">perf</code>: The Linux Profiler</strong></a></p>
<ul>
<li><a href="#detailed-guide-to-the-linux-profiler-perf"><strong>Detailed Guide to the Linux Profiler <code class="language-text">perf</code></strong></a></li>
<li><a href="#commands-and-tools-for-event-tracing-and-cpu-profiling"><strong>Commands and Tools for Event Tracing and CPU Profiling</strong></a></li>
<li><a href="#advanced-use-cases-and-examples"><strong>Advanced Use Cases and Examples</strong></a></li>
<li><a href="#key-takeaways-15"><strong>Key Takeaways</strong></a></li>
</ul>
</li>
<li>
<p><a href="#ftrace-linux-kernel-tracing-framework"><strong><code class="language-text">Ftrace</code>: Linux Kernel Tracing Framework</strong></a></p>
<ul>
<li><a href="#what-is-ftrace"><strong>What is <code class="language-text">Ftrace</code>?</strong></a></li>
<li><a href="#core-components-of-ftrace"><strong>Core Components of <code class="language-text">Ftrace</code></strong></a></li>
<li><a href="#examples-of-using-ftrace-for-performance-analysis"><strong>Examples of Using <code class="language-text">Ftrace</code> for Performance Analysis</strong></a></li>
<li><a href="#real-world-applications-of-ftrace"><strong>Real-World Applications of <code class="language-text">Ftrace</code></strong></a></li>
<li><a href="#key-takeaways-16"><strong>Key Takeaways</strong></a></li>
</ul>
</li>
<li>
<p><a href="#bpf-berkeley-packet-filter"><strong>BPF (Berkeley Packet Filter)</strong></a></p>
<ul>
<li><a href="#overview-of-bpf-and-its-tools"><strong>Overview of BPF and Its Tools</strong></a></li>
<li><a href="#advanced-performance-analysis-using-bpf"><strong>Advanced Performance Analysis Using BPF</strong></a></li>
<li><a href="#key-highlights-3"><strong>Key Highlights</strong></a></li>
</ul>
</li>
<li>
<p><a href="#chapter-16-case-study"><strong>Chapter 16: Case Study</strong></a></p>
<ul>
<li>
<p><a href="#161-overview-of-the-case"><strong>16.1 Overview of the Case</strong></a></p>
<ul>
<li><a href="#scenario-3"><strong>Scenario</strong>:</a></li>
<li><a href="#symptoms"><strong>Symptoms</strong>:</a></li>
<li><a href="#environment"><strong>Environment</strong>:</a></li>
<li><a href="#objective-6"><strong>Objective</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#162-methodology"><strong>16.2 Methodology</strong></a></p>
<ul>
<li>
<p><a href="#1621-step-1-baseline-performance-measurement"><strong>16.2.1 Step 1: Baseline Performance Measurement</strong></a></p>
<ul>
<li>
<p><a href="#purpose-19"><strong>Purpose</strong>:</a></p>
</li>
<li>
<p><a href="#tools-and-techniques"><strong>Tools and Techniques</strong>:</a></p>
<ul>
<li><a href="#1-system-monitoring-tools"><strong>1. System Monitoring Tools</strong></a></li>
<li><a href="#2-application-specific-profiling"><strong>2. Application-Specific Profiling</strong></a></li>
</ul>
</li>
<li>
<p><a href="#deliverables"><strong>Deliverables</strong>:</a></p>
</li>
</ul>
</li>
<li>
<p><a href="#1622-step-2-identifying-the-bottleneck"><strong>16.2.2 Step 2: Identifying the Bottleneck</strong></a></p>
<ul>
<li>
<p><a href="#purpose-20"><strong>Purpose</strong>:</a></p>
</li>
<li>
<p><a href="#techniques-and-tools"><strong>Techniques and Tools</strong>:</a></p>
<ul>
<li><a href="#1-cpu-analysis"><strong>1. CPU Analysis</strong></a></li>
<li><a href="#2-memory-analysis"><strong>2. Memory Analysis</strong></a></li>
<li><a href="#3-database-query-profiling"><strong>3. Database Query Profiling</strong></a></li>
</ul>
</li>
<li>
<p><a href="#deliverables-1"><strong>Deliverables</strong>:</a></p>
</li>
</ul>
</li>
<li>
<p><a href="#1623-step-3-hypothesis-formation"><strong>16.2.3 Step 3: Hypothesis Formation</strong></a></p>
<ul>
<li><a href="#purpose-21"><strong>Purpose</strong>:</a></li>
<li><a href="#hypotheses"><strong>Hypotheses</strong>:</a></li>
<li><a href="#deliverables-2"><strong>Deliverables</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#key-takeaways-from-methodology"><strong>Key Takeaways from Methodology</strong></a></p>
</li>
</ul>
</li>
<li>
<p><a href="#163-applying-solutions"><strong>16.3 Applying Solutions</strong></a></p>
<ul>
<li>
<p><a href="#1631-solution-1-optimize-application-code"><strong>16.3.1 Solution 1: Optimize Application Code</strong></a></p>
<ul>
<li><a href="#problem-6"><strong>Problem</strong>:</a></li>
<li><a href="#action-plan"><strong>Action Plan</strong>:</a></li>
<li><a href="#result-7"><strong>Result</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#1632-solution-2-reduce-swapping"><strong>16.3.2 Solution 2: Reduce Swapping</strong></a></p>
<ul>
<li><a href="#problem-7"><strong>Problem</strong>:</a></li>
<li><a href="#action-plan-1"><strong>Action Plan</strong>:</a></li>
<li><a href="#result-8"><strong>Result</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#1633-solution-3-optimize-database-queries"><strong>16.3.3 Solution 3: Optimize Database Queries</strong></a></p>
<ul>
<li><a href="#problem-8"><strong>Problem</strong>:</a></li>
<li><a href="#action-plan-2"><strong>Action Plan</strong>:</a></li>
<li><a href="#result-9"><strong>Result</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#1634-validation"><strong>16.3.4 Validation</strong></a></p>
<ul>
<li><a href="#stress-testing"><strong>Stress Testing</strong>:</a></li>
<li><a href="#system-monitoring"><strong>System Monitoring</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#key-takeaways-17"><strong>Key Takeaways</strong></a></p>
</li>
</ul>
</li>
<li>
<p><a href="#164-validation"><strong>16.4 Validation</strong></a></p>
<ul>
<li>
<p><a href="#1641-performance-testing"><strong>16.4.1 Performance Testing</strong></a></p>
<ul>
<li><a href="#objective-7"><strong>Objective</strong>:</a></li>
<li><a href="#tools-16"><strong>Tools</strong>:</a></li>
<li><a href="#procedure"><strong>Procedure</strong>:</a></li>
<li><a href="#observations"><strong>Observations</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#1642-system-monitoring"><strong>16.4.2 System Monitoring</strong></a></p>
<ul>
<li><a href="#objective-8"><strong>Objective</strong>:</a></li>
<li><a href="#tools-17"><strong>Tools</strong>:</a></li>
<li><a href="#results-1"><strong>Results</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#1643-database-query-performance"><strong>16.4.3 Database Query Performance</strong></a></p>
<ul>
<li><a href="#objective-9"><strong>Objective</strong>:</a></li>
<li><a href="#tools-18"><strong>Tools</strong>:</a></li>
<li><a href="#results-2"><strong>Results</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#1644-regression-testing"><strong>16.4.4 Regression Testing</strong></a></p>
<ul>
<li><a href="#objective-10"><strong>Objective</strong>:</a></li>
<li><a href="#steps-3"><strong>Steps</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#1645-real-world-validation"><strong>16.4.5 Real-World Validation</strong></a></p>
<ul>
<li><a href="#scenario-4"><strong>Scenario</strong>:</a></li>
<li><a href="#outcome"><strong>Outcome</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#key-takeaways-18"><strong>Key Takeaways</strong></a></p>
</li>
</ul>
</li>
<li>
<p><a href="#165-lessons-learned"><strong>16.5 Lessons Learned</strong></a></p>
<ul>
<li>
<p><a href="#1651-the-importance-of-baseline-metrics"><strong>16.5.1 The Importance of Baseline Metrics</strong></a></p>
<ul>
<li><a href="#lesson"><strong>Lesson</strong>:</a></li>
<li><a href="#what-happened"><strong>What Happened</strong>:</a></li>
<li><a href="#example-23"><strong>Example</strong>:</a></li>
<li><a href="#best-practices-7"><strong>Best Practices</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#1652-structured-methodology-yields-better-results"><strong>16.5.2 Structured Methodology Yields Better Results</strong></a></p>
<ul>
<li><a href="#lesson-1"><strong>Lesson</strong>:</a></li>
<li><a href="#what-happened-1"><strong>What Happened</strong>:</a></li>
<li><a href="#example-24"><strong>Example</strong>:</a></li>
<li><a href="#best-practices-8"><strong>Best Practices</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#1653-the-power-of-the-right-tools"><strong>16.5.3 The Power of the Right Tools</strong></a></p>
<ul>
<li><a href="#lesson-2"><strong>Lesson</strong>:</a></li>
<li><a href="#what-happened-2"><strong>What Happened</strong>:</a></li>
<li><a href="#examples-1"><strong>Examples</strong>:</a></li>
<li><a href="#best-practices-9"><strong>Best Practices</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#1654-iterative-tuning-produces-sustainable-gains"><strong>16.5.4 Iterative Tuning Produces Sustainable Gains</strong></a></p>
<ul>
<li><a href="#lesson-3"><strong>Lesson</strong>:</a></li>
<li><a href="#what-happened-3"><strong>What Happened</strong>:</a></li>
<li><a href="#example-25"><strong>Example</strong>:</a></li>
<li><a href="#best-practices-10"><strong>Best Practices</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#1655-memory-tuning-can-eliminate-major-bottlenecks"><strong>16.5.5 Memory Tuning Can Eliminate Major Bottlenecks</strong></a></p>
<ul>
<li><a href="#lesson-4"><strong>Lesson</strong>:</a></li>
<li><a href="#what-happened-4"><strong>What Happened</strong>:</a></li>
<li><a href="#example-26"><strong>Example</strong>:</a></li>
<li><a href="#best-practices-11"><strong>Best Practices</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#1656-database-optimization-is-critical-for-scalability"><strong>16.5.6 Database Optimization is Critical for Scalability</strong></a></p>
<ul>
<li><a href="#lesson-5"><strong>Lesson</strong>:</a></li>
<li><a href="#what-happened-5"><strong>What Happened</strong>:</a></li>
<li><a href="#example-27"><strong>Example</strong>:</a></li>
<li><a href="#best-practices-12"><strong>Best Practices</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#1657-the-role-of-comprehensive-validation"><strong>16.5.7 The Role of Comprehensive Validation</strong></a></p>
<ul>
<li><a href="#lesson-6"><strong>Lesson</strong>:</a></li>
<li><a href="#what-happened-6"><strong>What Happened</strong>:</a></li>
<li><a href="#example-28"><strong>Example</strong>:</a></li>
<li><a href="#best-practices-13"><strong>Best Practices</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#1658-collaboration-across-teams"><strong>16.5.8 Collaboration Across Teams</strong></a></p>
<ul>
<li><a href="#lesson-7"><strong>Lesson</strong>:</a></li>
<li><a href="#what-happened-7"><strong>What Happened</strong>:</a></li>
<li><a href="#example-29"><strong>Example</strong>:</a></li>
<li><a href="#best-practices-14"><strong>Best Practices</strong>:</a></li>
</ul>
</li>
<li>
<p><a href="#key-takeaways-for-lessons-learned"><strong>Key Takeaways for lessons learned</strong></a></p>
</li>
</ul>
</li>
<li>
<p><a href="#key-takeaways-for-case-study"><strong>Key Takeaways for case study</strong></a></p>
</li>
</ul>
</li>
<li>
<p><a href="#questions">Questions</a></p>
</li>
<li>
<p><a href="#references">References</a></p>
</li>
</ul>
</div>
<h1 id="key-takeaways" style="position:relative;"><a href="#key-takeaways" aria-label="key takeaways permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>key takeaways</h1>
<h1 id="foundations-of-data-systems" style="position:relative;"><a href="#foundations-of-data-systems" aria-label="foundations of data systems permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Foundations of Data Systems</h1>
<h2 id="reliable-scalable-and-maintainable-applications" style="position:relative;"><a href="#reliable-scalable-and-maintainable-applications" aria-label="reliable scalable and maintainable applications permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Reliable, scalable, and maintainable applications</h2>
<p>A data-intensive application is typically built from standard building blocks. They usually need to:</p>
<ul>
<li>
<p>Store data (<em>databases</em>)</p>
</li>
<li>
<p>Speed up reads (<em>caches</em>)</p>
</li>
<li>
<p>Search data (<em>search indexes</em>)</p>
</li>
<li>
<p>Send a message to another process asynchronously (<em>stream processing</em>)</p>
</li>
<li>
<p>Periodically crunch data (<em>batch processing</em>)</p>
</li>
<li>
<p><strong>Reliability</strong>. To work <em>correctly</em> even in the face of <em>adversity</em>.</p>
</li>
<li>
<p><strong>Scalability</strong>. Reasonable ways of dealing with growth.</p>
</li>
<li>
<p><strong>Maintainability</strong>. Be able to work on it <em>productively</em>.</p>
</li>
</ul>
<h3 id="reliability" style="position:relative;"><a href="#reliability" aria-label="reliability permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Reliability</h3>
<p>Typical expectations:</p>
<ul>
<li>Application performs the function the user expected</li>
<li>Tolerate the user making mistakes</li>
<li>Its performance is good</li>
<li>The system prevents abuse</li>
</ul>
<p>Systems that anticipate faults and can cope with them are called <em>fault-tolerant</em> or <em>resilient</em>.</p>
<p><strong>A fault is usually defined as one component of the system deviating from its spec</strong>, whereas <em>failure</em> is when the system as a whole stops providing the required service to the user.</p>
<p>You should generally <strong>prefer tolerating faults over preventing faults</strong>.</p>
<ul>
<li><strong>Hardware faults</strong>. Until recently redundancy of hardware components was sufficient for most applications. As data volumes increase, more applications use a larger number of machines, proportionally increasing the rate of hardware faults. <strong>There is a move towards systems that tolerate the loss of entire machines</strong>. A system that tolerates machine failure can be patched one node at a time, without downtime of the entire system (<em>rolling upgrade</em>).</li>
<li><strong>Software errors</strong>. It is unlikely that a large number of hardware components will fail at the same time. Software errors are a systematic error within the system, they tend to cause many more system failures than uncorrelated hardware faults.</li>
<li><strong>Human errors</strong>. Humans are known to be unreliable. Configuration errors by operators are a leading cause of outages. You can make systems more reliable:
<ul>
<li>Minimising the opportunities for error, peg: with admin interfaces that make easy to do the “right thing” and discourage the “wrong thing”.</li>
<li>Provide fully featured non-production <em>sandbox</em> environments where people can explore and experiment safely.</li>
<li>Automated testing.</li>
<li>Quick and easy recovery from human error, fast to rollback configuration changes, roll out new code gradually and tools to recompute data.</li>
<li>Set up detailed and clear monitoring, such as performance metrics and error rates (<em>telemetry</em>).</li>
<li>Implement good management practices and training.</li>
</ul>
</li>
</ul>
<h3 id="scalability" style="position:relative;"><a href="#scalability" aria-label="scalability permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Scalability</h3>
<p>This is how do we cope with increased load. We need to succinctly describe the current load on the system; only then we can discuss growth questions.</p>
<hr>
<h4 id="twitter-example" style="position:relative;"><a href="#twitter-example" aria-label="twitter example permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Twitter example</h4>
<p>Twitter main operations</p>
<ul>
<li>Post tweet: a user can publish a new message to their followers (4.6k req/sec, over 12k req/sec peak)</li>
<li>Home timeline: a user can view tweets posted by the people they follow (300k req/sec)</li>
</ul>
<p>Two ways of implementing those operations:</p>
<ol>
<li>Posting a tweet simply inserts the new tweet into a global collection of tweets. When a user requests their home timeline, look up all the people they follow, find all the tweets for those users, and merge them (sorted by time). This could be done with a SQL <code class="language-text">JOIN</code>.</li>
<li>Maintain a cache for each user’s home timeline. When a user <em>posts a tweet</em>, look up all the people who follow that user, and insert the new tweet into each of their home timeline caches.</li>
</ol>
<p>Approach 1, systems struggle to keep up with the load of home timeline queries. So the company switched to approach 2. The average rate of published tweets is almost two orders of magnitude lower than the rate of home timeline reads.</p>
<p>Downside of approach 2 is that posting a tweet now requires a lot of extra work. Some users have over 30 million followers. A single tweet may result in over 30 million writes to home timelines.</p>
<p>Twitter moved to an hybrid of both approaches. Tweets continue to be fanned out to home timelines but a small number of users with a very large number of followers are fetched separately and merged with that user’s home timeline when it is read, like in approach 1.</p>
<hr>
<h4 id="describing-performance" style="position:relative;"><a href="#describing-performance" aria-label="describing performance permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Describing performance</h4>
<p>What happens when the load increases:</p>
<ul>
<li>How is the performance affected?</li>
<li>How much do you need to increase your resources?</li>
</ul>
<p>In a batch processing system such as Hadoop, we usually care about <em>throughput</em>, or the number of records we can process per second.</p>
<blockquote>
<h5 id="latency-and-response-time" style="position:relative;"><a href="#latency-and-response-time" aria-label="latency and response time permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Latency and response time</h5>
<p>The response time is what the client sees. Latency is the duration that a request is waiting to be handled.</p>
</blockquote>
<p>It’s common to see the <em>average</em> response time of a service reported. However, the mean is not very good metric if you want to know your “typical” response time, it does not tell you how many users actually experienced that delay.</p>
<p><strong>Better to use percentiles.</strong></p>
<ul>
<li><em>Median</em> (<em>50th percentile</em> or <em>p50</em>). Half of user requests are served in less than the median response time, and the other half take longer than the median</li>
<li>Percentiles <em>95th</em>, <em>99th</em> and <em>99.9th</em> (<em>p95</em>, <em>p99</em> and <em>p999</em>) are good to figure out how bad your outliners are.</li>
</ul>
<p>Amazon describes response time requirements for internal services in terms of the 99.9th percentile because the customers with the slowest requests are often those who have the most data. The most valuable customers.</p>
<p>On the other hand, optimising for the 99.99th percentile would be too expensive.</p>
<p><em>Service level objectives</em> (SLOs) and <em>service level agreements</em> (SLAs) are contracts that define the expected performance and availability of a service.
An SLA may state the median response time to be less than 200ms and a 99th percentile under 1s. <strong>These metrics set expectations for clients of the service and allow customers to demand a refund if the SLA is not met.</strong></p>
<p>Queueing delays often account for large part of the response times at high percentiles. <strong>It is important to measure times on the client side.</strong></p>
<p>When generating load artificially, the client needs to keep sending requests independently of the response time.</p>
<blockquote>
<h5 id="percentiles-in-practice" style="position:relative;"><a href="#percentiles-in-practice" aria-label="percentiles in practice permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Percentiles in practice</h5>
<p>Calls in parallel, the end-user request still needs to wait for the slowest of the parallel calls to complete.
The chance of getting a slow call increases if an end-user request requires multiple backend calls.</p>
</blockquote>
<h4 id="approaches-for-coping-with-load" style="position:relative;"><a href="#approaches-for-coping-with-load" aria-label="approaches for coping with load permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Approaches for coping with load</h4>
<ul>
<li><em>Scaling up</em> or <em>vertical scaling</em>: Moving to a more powerful machine</li>
<li><em>Scaling out</em> or <em>horizontal scaling</em>: Distributing the load across multiple smaller machines.</li>
<li><em>Elastic</em> systems: Automatically add computing resources when detected load increase. Quite useful if load is unpredictable.</li>
</ul>
<p>Distributing stateless services across multiple machines is fairly straightforward. Taking stateful data systems from a single node to a distributed setup can introduce a lot of complexity. Until recently it was common wisdom to keep your database on a single node.</p>
<h3 id="maintainability" style="position:relative;"><a href="#maintainability" aria-label="maintainability permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Maintainability</h3>
<p>The majority of the cost of software is in its ongoing maintenance. There are three design principles for software systems:</p>
<ul>
<li><strong>Operability</strong>. Make it easy for operation teams to keep the system running.</li>
<li><strong>Simplicity</strong>. Easy for new engineers to understand the system by removing as much complexity as possible.</li>
<li><strong>Evolvability</strong>. Make it easy for engineers to make changes to the system in the future.</li>
</ul>
<h4 id="operability-making-life-easy-for-operations" style="position:relative;"><a href="#operability-making-life-easy-for-operations" aria-label="operability making life easy for operations permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Operability: making life easy for operations</h4>
<p>A good operations team is responsible for</p>
<ul>
<li>Monitoring and quickly restoring service if it goes into bad state</li>
<li>Tracking down the cause of problems</li>
<li>Keeping software and platforms up to date</li>
<li>Keeping tabs on how different systems affect each other</li>
<li>Anticipating future problems</li>
<li>Establishing good practices and tools for development</li>
<li>Perform complex maintenance tasks, like platform migration</li>
<li>Maintaining the security of the system</li>
<li>Defining processes that make operations predictable</li>
<li>Preserving the organisation’s knowledge about the system</li>
</ul>
<p><strong>Good operability means making routine tasks easy.</strong></p>
<h4 id="simplicity-managing-complexity" style="position:relative;"><a href="#simplicity-managing-complexity" aria-label="simplicity managing complexity permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Simplicity: managing complexity</h4>
<p>When complexity makes maintenance hard, budget and schedules are often overrun. There is a greater risk of introducing bugs.</p>
<p>Making a system simpler means removing <em>accidental</em> complexity, as non inherent in the problem that the software solves (as seen by users).</p>
<p>One of the best tools we have for removing accidental complexity is <em>abstraction</em> that hides the implementation details behind clean and simple to understand APIs and facades.</p>
<h4 id="evolvability-making-change-easy" style="position:relative;"><a href="#evolvability-making-change-easy" aria-label="evolvability making change easy permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Evolvability: making change easy</h4>
<p><em>Agile</em> working patterns provide a framework for adapting to change.</p>
<hr>
<ul>
<li><em>Functional requirements</em>: what the application should do</li>
<li><em>Nonfunctional requirements</em>: general properties like security, reliability, compliance, scalability, compatibility and maintainability.</li>
</ul>
<hr>
<h2 id="data-models-and-query-language" style="position:relative;"><a href="#data-models-and-query-language" aria-label="data models and query language permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Data models and query language</h2>
<p>Most applications are built by layering one data model on top of another. Each layer hides the complexity of the layers below by providing a clean data model. These abstractions allow different groups of people to work effectively.</p>
<h3 id="relational-model-vs-document-model" style="position:relative;"><a href="#relational-model-vs-document-model" aria-label="relational model vs document model permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Relational model vs document model</h3>
<p>The roots of relational databases lie in <em>business data processing</em>, <em>transaction processing</em> and <em>batch processing</em>.</p>
<p>The goal was to hide the implementation details behind a cleaner interface.</p>
<p><em>Not Only SQL</em> has a few driving forces:</p>
<ul>
<li>Greater scalability</li>
<li>preference for free and open source software</li>
<li>Specialised query optimisations</li>
<li>Desire for a more dynamic and expressive data model</li>
</ul>
<p><strong>With a SQL model, if data is stored in a relational tables, an awkward translation layer is translated, this is called <em>impedance mismatch</em>.</strong></p>
<p>JSON model reduces the impedance mismatch and the lack of schema is often cited as an advantage.</p>
<p>JSON representation has better <em>locality</em> than the multi-table SQL schema. All the relevant information is in one place, and one query is sufficient.</p>
<p>In relational databases, it’s normal to refer to rows in other tables by ID, because joins are easy. In document databases, joins are not needed for one-to-many tree structures, and support for joins is often weak.</p>
<p>If the database itself does not support joins, you have to emulate a join in application code by making multiple queries.</p>
<p>The most popular database for business data processing in the 1970s was the IBM’s <em>Information Management System</em> (IMS).</p>
<p>IMS used a <em>hierarchical model</em> and like document databases worked well for one-to-many relationships, but it made many-to-,any relationships difficult, and it didn’t support joins.</p>
<h4 id="the-network-model" style="position:relative;"><a href="#the-network-model" aria-label="the network model permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>The network model</h4>
<p>Standardised by a committee called the Conference on Data Systems Languages (CODASYL) model was a generalisation of the hierarchical model. In the tree structure of the hierarchical model, every record has exactly one parent, while in the network model, a record could have multiple parents.</p>
<p>The links between records are like pointers in a programming language. The only way of accessing a record was to follow a path from a root record called <em>access path</em>.</p>
<p>A query in CODASYL was performed by moving a cursor through the database by iterating over a list of records. If you didn’t have a path to the data you wanted, you were in a difficult situation as it was difficult to make changes to an application’s data model.</p>
<h4 id="the-relational-model" style="position:relative;"><a href="#the-relational-model" aria-label="the relational model permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>The relational model</h4>
<p>By contrast, the relational model was a way to lay out all the data in the open” a relation (table) is simply a collection of tuples (rows), and that’s it.</p>
<p>The query optimiser automatically decides which parts of the query to execute in which order, and which indexes to use (the access path).</p>
<p>The relational model thus made it much easier to add new features to applications.</p>
<hr>
<p><strong>The main arguments in favour of the document data model are schema flexibility, better performance due to locality, and sometimes closer data structures to the ones used by the applications. The relation model counters by providing better support for joins, and many-to-one and many-to-many relationships.</strong></p>
<p>If the data in your application has a document-like structure, then it’s probably a good idea to use a document model. The relational technique of <em>shredding</em> can lead unnecessary complicated application code.</p>
<p>The poor support for joins in document databases may or may not be a problem.</p>
<p>If you application does use many-to-many relationships, the document model becomes less appealing. Joins can be emulated in application code by making multiple requests. Using the document model can lead to significantly more complex application code and worse performance.</p>
<h4 id="schema-flexibility" style="position:relative;"><a href="#schema-flexibility" aria-label="schema flexibility permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Schema flexibility</h4>
<p>Most document databases do not enforce any schema on the data in documents. Arbitrary keys and values can be added to a document, when reading, <strong>clients have no guarantees as to what fields the documents may contain.</strong></p>
<p>Document databases are sometimes called <em>schemaless</em>, but maybe a more appropriate term is <em>schema-on-read</em>, in contrast to <em>schema-on-write</em>.</p>
<p>Schema-on-read is similar to dynamic (runtime) type checking, whereas schema-on-write is similar to static (compile-time) type checking.</p>
<p>The schema-on-read approach if the items on the collection don’t have all the same structure (heterogeneous)</p>
<ul>
<li>Many different types of objects</li>
<li>Data determined by external systems</li>
</ul>
<h4 id="data-locality-for-queries" style="position:relative;"><a href="#data-locality-for-queries" aria-label="data locality for queries permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Data locality for queries</h4>
<p>If your application often needs to access the entire document, there is a performance advantage to this <em>storage locality</em>.</p>
<p>The database typically needs to load the entire document, even if you access only a small portion of it. On updates, the entire document usually needs to be rewritten, it is recommended that you keep documents fairly small.</p>
<h4 id="convergence-of-document-and-relational-databases" style="position:relative;"><a href="#convergence-of-document-and-relational-databases" aria-label="convergence of document and relational databases permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Convergence of document and relational databases</h4>
<p>PostgreSQL does support JSON documents. RethinkDB supports relational-like joins in its query language and some MongoDB drivers automatically resolve database references. Relational and document databases are becoming more similar over time.</p>
<h3 id="query-languages-for-data" style="position:relative;"><a href="#query-languages-for-data" aria-label="query languages for data permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Query languages for data</h3>
<p>SQL is a <em>declarative</em> query language. In an <em>imperative language</em>, you tell the computer to perform certain operations in order.</p>
<p>In a declarative query language you just specify the pattern of the data you want, but not <em>how</em> to achieve that goal.</p>
<p>A declarative query language hides implementation details of the database engine, making it possible for the database system to introduce performance improvements without requiring any changes to queries.</p>
<p>Declarative languages often lend themselves to parallel execution while imperative code is very hard to parallelise across multiple cores because it specifies instructions that must be performed in a particular order. Declarative languages specify only the pattern of the results, not the algorithm that is used to determine results.</p>
<h4 id="declarative-queries-on-the-web" style="position:relative;"><a href="#declarative-queries-on-the-web" aria-label="declarative queries on the web permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Declarative queries on the web</h4>
<p>In a web browser, using declarative CSS styling is much better than manipulating styles imperatively in JavaScript. Declarative languages like SQL turned out to be much better than imperative query APIs.</p>
<h4 id="mapreduce-querying" style="position:relative;"><a href="#mapreduce-querying" aria-label="mapreduce querying permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>MapReduce querying</h4>
<p><em>MapReduce</em> is a programming model for processing large amounts of data in bulk across many machines, popularised by Google.</p>
<p>Mongo offers a MapReduce solution.</p>
<div class="gatsby-highlight" data-language="js"><pre class="language-js"><code class="language-js">db<span class="token punctuation">.</span>observations<span class="token punctuation">.</span><span class="token function">mapReduce</span><span class="token punctuation">(</span>
    <span class="token keyword">function</span> <span class="token function">map</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token number">2</span>
        <span class="token keyword">var</span> year  <span class="token operator">=</span> <span class="token keyword">this</span><span class="token punctuation">.</span>observationTimestamp<span class="token punctuation">.</span><span class="token function">getFullYear</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">var</span> month <span class="token operator">=</span> <span class="token keyword">this</span><span class="token punctuation">.</span>observationTimestamp<span class="token punctuation">.</span><span class="token function">getMonth</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">;</span>
        <span class="token function">emit</span><span class="token punctuation">(</span>year <span class="token operator">+</span> <span class="token string">"-"</span> <span class="token operator">+</span> month<span class="token punctuation">,</span> <span class="token keyword">this</span><span class="token punctuation">.</span>numAnimals<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token number">3</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token keyword">function</span> <span class="token function">reduce</span><span class="token punctuation">(</span><span class="token parameter">key<span class="token punctuation">,</span> values</span><span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token number">4</span>
        <span class="token keyword">return</span> Array<span class="token punctuation">.</span><span class="token function">sum</span><span class="token punctuation">(</span>values<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token number">5</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{</span>
        <span class="token literal-property property">query</span><span class="token operator">:</span> <span class="token punctuation">{</span> <span class="token literal-property property">family</span><span class="token operator">:</span> <span class="token string">"Sharks"</span> <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token number">1</span>
        <span class="token literal-property property">out</span><span class="token operator">:</span> <span class="token string">"monthlySharkReport"</span> <span class="token number">6</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre></div>
<p>The <code class="language-text">map</code> and <code class="language-text">reduce</code> functions must be <em>pure</em> functions, they cannot perform additional database queries and they must not have any side effects. These restrictions allow the database to run the functions anywhere, in any order, and rerun them on failure.</p>
<p>A usability problem with MapReduce is that you have to write two carefully coordinated functions. A declarative language offers more opportunities for a query optimiser to improve the performance of a query. For there reasons, MongoDB 2.2 added support for a declarative query language called <em>aggregation pipeline</em></p>
<div class="gatsby-highlight" data-language="js"><pre class="language-js"><code class="language-js">db<span class="token punctuation">.</span>observations<span class="token punctuation">.</span><span class="token function">aggregate</span><span class="token punctuation">(</span><span class="token punctuation">[</span>
    <span class="token punctuation">{</span> <span class="token literal-property property">$match</span><span class="token operator">:</span> <span class="token punctuation">{</span> <span class="token literal-property property">family</span><span class="token operator">:</span> <span class="token string">"Sharks"</span> <span class="token punctuation">}</span> <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{</span> <span class="token literal-property property">$group</span><span class="token operator">:</span> <span class="token punctuation">{</span>
        <span class="token literal-property property">_id</span><span class="token operator">:</span> <span class="token punctuation">{</span>
            <span class="token literal-property property">year</span><span class="token operator">:</span>  <span class="token punctuation">{</span> <span class="token literal-property property">$year</span><span class="token operator">:</span>  <span class="token string">"$observationTimestamp"</span> <span class="token punctuation">}</span><span class="token punctuation">,</span>
            <span class="token literal-property property">month</span><span class="token operator">:</span> <span class="token punctuation">{</span> <span class="token literal-property property">$month</span><span class="token operator">:</span> <span class="token string">"$observationTimestamp"</span> <span class="token punctuation">}</span>
        <span class="token punctuation">}</span><span class="token punctuation">,</span>
        <span class="token literal-property property">totalAnimals</span><span class="token operator">:</span> <span class="token punctuation">{</span> <span class="token literal-property property">$sum</span><span class="token operator">:</span> <span class="token string">"$numAnimals"</span> <span class="token punctuation">}</span>
    <span class="token punctuation">}</span> <span class="token punctuation">}</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre></div>
<h3 id="graph-like-data-models" style="position:relative;"><a href="#graph-like-data-models" aria-label="graph like data models permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Graph-like data models</h3>
<p>If many-to-many relationships are very common in your application, it becomes more natural to start modelling your data as a graph.</p>
<p>A graph consists of <em>vertices</em> (<em>nodes</em> or <em>entities</em>) and <em>edges</em> (<em>relationships</em> or <em>arcs</em>).</p>
<p>Well-known algorithms can operate on these graphs, like the shortest path between two points, or popularity of a web page.</p>
<p>There are several ways of structuring and querying the data. The <em>property graph</em> model (implemented by Neo4j, Titan, and Infinite Graph) and the <em>triple-store</em> model (implemented by Datomic, AllegroGraph, and others). There are also three declarative query languages for graphs: Cypher, SPARQL, and Datalog.</p>
<h4 id="property-graphs" style="position:relative;"><a href="#property-graphs" aria-label="property graphs permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Property graphs</h4>
<p>Each vertex consists of:</p>
<ul>
<li>Unique identifier</li>
<li>Outgoing edges</li>
<li>Incoming edges</li>
<li>Collection of properties (key-value pairs)</li>
</ul>
<p>Each edge consists of:</p>
<ul>
<li>Unique identifier</li>
<li>Vertex at which the edge starts (<em>tail vertex</em>)</li>
<li>Vertex at which the edge ends (<em>head vertex</em>)</li>
<li>Label to describe the kind of relationship between the two vertices</li>
<li>A collection of properties (key-value pairs)</li>
</ul>
<p>Graphs provide a great deal of flexibility for data modelling. Graphs are good for evolvability.</p>
<hr>
<ul>
<li><em>Cypher</em> is a declarative language for property graphs created by Neo4j</li>
<li>Graph queries in SQL. In a relational database, you usually know in advance which joins you need in your query. In a graph query, the number if joins is not fixed in advance. In Cypher <code class="language-text">:WITHIN*0...</code> expresses “follow a <code class="language-text">WITHIN</code> edge, zero or more times” (like the <code class="language-text">*</code> operator in a regular expression). This idea of variable-length traversal paths in a query can be expressed using something called <em>recursive common table expressions</em> (the <code class="language-text">WITH RECURSIVE</code> syntax).</li>
</ul>
<hr>
<h4 id="triple-stores-and-sparql" style="position:relative;"><a href="#triple-stores-and-sparql" aria-label="triple stores and sparql permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Triple-stores and SPARQL</h4>
<p>In a triple-store, all information is stored in the form of very simple three-part statements: <em>subject</em>, <em>predicate</em>, <em>object</em> (peg: <em>Jim</em>, <em>likes</em>, <em>bananas</em>). A triple is equivalent to a vertex in graph.</p>
<h4 id="the-sparql-query-language" style="position:relative;"><a href="#the-sparql-query-language" aria-label="the sparql query language permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>The SPARQL query language</h4>
<p><em>SPARQL</em> is a query language for triple-stores using the RDF data model.</p>
<h4 id="the-foundation-datalog" style="position:relative;"><a href="#the-foundation-datalog" aria-label="the foundation datalog permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>The foundation: Datalog</h4>
<p><em>Datalog</em> provides the foundation that later query languages build upon. Its model is similar to the triple-store model, generalised a bit. Instead of writing a triple (<em>subject</em>, <em>predicate</em>, <em>object</em>), we write as <em>predicate(subject, object)</em>.</p>
<p>We define <em>rules</em> that tell the database about new predicates and rules can refer to other rules, just like functions can call other functions or recursively call themselves.</p>
<p>Rules can be combined and reused in different queries. It’s less convenient for simple one-off queries, but it can cope better if your data is complex.</p>
<h2 id="storage-and-retrieval" style="position:relative;"><a href="#storage-and-retrieval" aria-label="storage and retrieval permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Storage and retrieval</h2>
<p>Databases need to do two things: store the data and give the data back to you.</p>
<h3 id="data-structures-that-power-up-your-database" style="position:relative;"><a href="#data-structures-that-power-up-your-database" aria-label="data structures that power up your database permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Data structures that power up your database</h3>
<p>Many databases use a <em>log</em>, which is append-only data file. Real databases have more issues to deal with tho (concurrency control, reclaiming disk space so the log doesn’t grow forever and handling errors and partially written records).</p>
<blockquote>
<p>A <em>log</em> is an append-only sequence of records</p>
</blockquote>
<p>In order to efficiently find the value for a particular key, we need a different data structure: an <em>index</em>. An index is an <em>additional</em> structure that is derived from the primary data.</p>
<p>Well-chosen indexes speed up read queries but every index slows down writes. That’s why databases don’t index everything by default, but require you to choose indexes manually using your knowledge on typical query patterns.</p>
<h4 id="hash-indexes" style="position:relative;"><a href="#hash-indexes" aria-label="hash indexes permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Hash indexes</h4>
<p>Key-value stores are quite similar to the <em>dictionary</em> type (hash map or hash table).</p>
<p>Let’s say our storage consists only of appending to a file. The simplest indexing strategy is to keep an in-memory hash map where every key is mapped to a byte offset in the data file. Whenever you append a new key-value pair to the file, you also update the hash map to reflect the offset of the data you just wrote.</p>
<p>Bitcask (the default storage engine in Riak) does it like that. The only requirement it has is that all the keys fit in the available RAM. Values can use more space than there is available in memory, since they can be loaded from disk.</p>
<p>A storage engine like Bitcask is well suited to situations where the value for each key is updated frequently. There are a lot of writes, but there are too many distinct keys, you have a large number of writes per key, but it’s feasible to keep all keys in memory.</p>
<p>As we only ever append to a file, so how do we avoid eventually running out of disk space? <strong>A good solution is to break the log into segments of certain size by closing the segment file when it reaches a certain size, and making subsequent writes to a new segment file. We can then perform <em>compaction</em> on these segments.</strong> Compaction means throwing away duplicate keys in the log, and keeping only the most recent update for each key.</p>
<p>We can also merge several segments together at the sae time as performing the compaction. Segments are never modified after they have been written, so the merged segment is written to a new file. Merging and compaction of frozen segments can be done in a background thread. After the merging process is complete, we switch read requests to use the new merged segment instead of the old segments, and the old segment files can simply be deleted.</p>
<p>Each segment now has its own in-memory hash table, mapping keys to file offsets. In order to find a value for a key, we first check the most recent segment hash map; if the key is not present we check the second-most recent segment and so on. The merging process keeps the number of segments small, so lookups don’t need to check many hash maps.</p>
<p>Some issues that are important in a real implementation:</p>
<ul>
<li>File format. It is simpler to use binary format.</li>
<li>Deleting records. Append special deletion record to the data file (<em>tombstone</em>) that tells the merging process to discard previous values.</li>
<li>Crash recovery. If restarted, the in-memory hash maps are lost. You can recover from reading each segment but that would take long time. Bitcask speeds up recovery by storing a snapshot of each segment hash map on disk.</li>
<li>Partially written records. The database may crash at any time. Bitcask includes checksums allowing corrupted parts of the log to be detected and ignored.</li>
<li>Concurrency control. As writes are appended to the log in a strictly sequential order, a common implementation is to have a single writer thread. Segments are immutable, so they can be read concurrently by multiple threads.</li>
</ul>
<p>Append-only design turns out to be good for several reasons:</p>
<ul>
<li>Appending and segment merging are sequential write operations, much faster than random writes, especially on magnetic spinning-disks.</li>
<li>Concurrency and crash recovery are much simpler.</li>
<li>Merging old segments avoids files getting fragmented over time.</li>
</ul>
<p>Hash table has its limitations too:</p>
<ul>
<li>The hash table must fit in memory. It is difficult to make an on-disk hash map perform well.</li>
<li>Range queries are not efficient.</li>
</ul>
<h4 id="sstables-and-lsm-trees" style="position:relative;"><a href="#sstables-and-lsm-trees" aria-label="sstables and lsm trees permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>SSTables and LSM-Trees</h4>
<p>We introduce a new requirement to segment files: we require that the sequence of key-value pairs is <em>sorted by key</em>.</p>
<p>We call this <em>Sorted String Table</em>, or <em>SSTable</em>. We require that each key only appears once within each merged segment file (compaction already ensures that). SSTables have few big advantages over log segments with hash indexes</p>
<ol>
<li><strong>Merging segments is simple and efficient</strong> (we can use algorithms like <em>mergesort</em>). When multiple segments contain the same key, we can keep the value from the most recent segment and discard the values in older segments.</li>
<li><strong>You no longer need to keep an index of all the keys in memory.</strong> For a key like <code class="language-text">handiwork</code>, when you know the offsets for the keys <code class="language-text">handback</code> and <code class="language-text">handsome</code>, you know <code class="language-text">handiwork</code> must appear between those two. You can jump to the offset for <code class="language-text">handback</code> and scan from there until you find <code class="language-text">handiwork</code>, if not, the key is not present. You still need an in-memory index to tell you the offsets for some of the keys. One key for every few kilobytes of segment file is sufficient.</li>
<li>Since read requests need to scan over several key-value pairs in the requested range anyway, <strong>it is possible to group those records into a block and compress it</strong> before writing it to disk.</li>
</ol>
<p>How do we get the data sorted in the first place? With red-black trees or AVL trees, you can insert keys in any order and read them back in sorted order.</p>
<ul>
<li>When a write comes in, add it to an in-memory balanced tree structure (<em>memtable</em>).</li>
<li>When the memtable gets bigger than some threshold (megabytes), write it out to disk as an SSTable file. Writes can continue to a new memtable instance.</li>
<li>On a read request, try to find the key in the memtable, then in the most recent on-disk segment, then in the next-older segment, etc.</li>
<li>From time to time, run merging and compaction in the background to discard overwritten and deleted values.</li>
</ul>
<p>If the database crashes, the most recent writes are lost. We can keep a separate log on disk to which every write is immediately appended. That log is not in sorted order, but that doesn’t matter, because its only purpose is to restore the memtable after crash. Every time the memtable is written out to an SSTable, the log can be discarded.</p>
<p><strong>Storage engines that are based on this principle of merging and compacting sorted files are often called LSM structure engines (Log Structure Merge-Tree).</strong></p>
<p>Lucene, an indexing engine for full-text search used by Elasticsearch and Solr, uses a similar method for storing its <em>term dictionary</em>.</p>
<p>LSM-tree algorithm can be slow when looking up keys that don’t exist in the database. To optimise this, storage engines often use additional <em>Bloom filters</em> (a memory-efficient data structure for approximating the contents of a set).</p>
<p>There are also different strategies to determine the order and timing of how SSTables are compacted and merged. Mainly two <em>size-tiered</em> and <em>leveled</em> compaction. LevelDB and RocksDB use leveled compaction, HBase use size-tiered, and Cassandra supports both. In size-tiered compaction, newer and smaller SSTables are successively merged into older and larger SSTables. In leveled compaction, the key range is split up into smaller SSTables and older data is moved into separate “levels”, which allows the compaction to use less disk space.</p>
<h4 id="b-trees" style="position:relative;"><a href="#b-trees" aria-label="b trees permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>B-trees</h4>
<p>This is the most widely used indexing structure. B-tress keep key-value pairs sorted by key, which allows efficient key-value lookups and range queries.</p>
<p>The log-structured indexes break the database down into variable-size <em>segments</em> typically several megabytes or more. B-trees break the database down into fixed-size <em>blocks</em> or <em>pages</em>, traditionally 4KB.</p>
<p>One page is designated as the <em>root</em> and you start from there. The page contains several keys and references to child pages.</p>
<p>If you want to update the value for an existing key in a B-tree, you search for the leaf page containing that key, change the value in that page, and write the page back to disk. If you want to add new key, find the page and add it to the page. If there isn’t enough free space in the page to accommodate the new key, it is split in two half-full pages, and the parent page is updated to account for the new subdivision of key ranges.</p>
<p>Trees remain <em>balanced</em>. A B-tree with <em>n</em> keys always has a depth of <em>O</em>(log <em>n</em>).</p>
<p>The basic underlying write operation of a B-tree is to overwrite a page on disk with new data. It is assumed that the overwrite does not change the location of the page, all references to that page remain intact. This is a big contrast to log-structured indexes such as LSM-trees, which only append to files.</p>
<p>Some operations require several different pages to be overwritten. When you split a page, you need to write the two pages that were split, and also overwrite their parent. If the database crashes after only some of the pages have been written, you end up with a corrupted index.</p>
<p>It is common to include an additional data structure on disk: a <em>write-ahead log</em> (WAL, also know as the <em>redo log</em>).</p>
<p>Careful concurrency control is required if multiple threads are going to access, typically done protecting the tree internal data structures with <em>latches</em> (lightweight locks).</p>
<h4 id="b-trees-and-lsm-trees" style="position:relative;"><a href="#b-trees-and-lsm-trees" aria-label="b trees and lsm trees permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>B-trees and LSM-trees</h4>
<p>LSM-trees are typically faster for writes, whereas B-trees are thought to be faster for reads. Reads are typically slower on LSM-tress as they have to check several different data structures and SSTables at different stages of compaction.</p>
<p>Advantages of LSM-trees:</p>
<ul>
<li>LSM-trees are typically able to sustain higher write throughput than B-trees, party because they sometimes have lower write amplification: a write to the database results in multiple writes to disk. The more a storage engine writes to disk, the fewer writes per second it can handle.</li>
<li>LSM-trees can be compressed better, and thus often produce smaller files on disk than B-trees. B-trees tend to leave disk space unused due to fragmentation.</li>
</ul>
<p>Downsides of LSM-trees:</p>
<ul>
<li>Compaction process can sometimes interfere with the performance of ongoing reads and writes. B-trees can be more predictable. The bigger the database, the the more disk bandwidth is required for compaction. Compaction cannot keep up with the rate of incoming writes, if not configured properly you can run out of disk space.</li>
<li>On B-trees, each key exists in exactly one place in the index. This offers strong transactional semantics. Transaction isolation is implemented using locks on ranges of keys, and in a B-tree index, those locks can be directly attached to the tree.</li>
</ul>
<h4 id="other-indexing-structures" style="position:relative;"><a href="#other-indexing-structures" aria-label="other indexing structures permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Other indexing structures</h4>
<p>We’ve only discussed key-value indexes, which are like <em>primary key</em> index. There are also <em>secondary indexes</em>.</p>
<p>A secondary index can be easily constructed from a key-value index. The main difference is that in a secondary index, the indexed values are not necessarily unique. There are two ways of doing this: making each value in the index a list of matching row identifiers or by making a each entry unique by appending a row identifier to it.</p>
<h4 id="full-text-search-and-fuzzy-indexes" style="position:relative;"><a href="#full-text-search-and-fuzzy-indexes" aria-label="full text search and fuzzy indexes permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Full-text search and fuzzy indexes</h4>
<p>Indexes don’t allow you to search for <em>similar</em> keys, such as misspelled words. Such <em>fuzzy</em> querying requires different techniques.</p>
<p>Full-text search engines allow synonyms, grammatical variations, occurrences of words near each other.</p>
<p>Lucene uses SSTable-like structure for its term dictionary. Lucene, the in-memory index is a finite state automaton, similar to a <em>trie</em>.</p>
<h4 id="keeping-everything-in-memory" style="position:relative;"><a href="#keeping-everything-in-memory" aria-label="keeping everything in memory permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Keeping everything in memory</h4>
<p>Disks have two significant advantages: they are durable, and they have lower cost per gigabyte than RAM.</p>
<p>It’s quite feasible to keep them entirely in memory, this has lead to <em>in-memory</em> databases.</p>
<p>Key-value stores, such as Memcached are intended for cache only, it’s acceptable for data to be lost if the machine is restarted. Other in-memory databases aim for durability, with special hardware, writing a log of changes to disk, writing periodic snapshots to disk or by replicating in-memory sate to other machines.</p>
<p>When an in-memory database is restarted, it needs to reload its state, either from disk or over the network from a replica. The disk is merely used as an append-only log for durability, and reads are served entirely from memory.</p>
<p>Products such as VoltDB, MemSQL, and Oracle TimesTime are in-memory databases. Redis and Couchbase provide weak durability.</p>
<p>In-memory databases can be faster because they can avoid the overheads of encoding in-memory data structures in a form that can be written to disk.</p>
<p>Another interesting area is that in-memory databases may provide data models that are difficult to implement with disk-based indexes.</p>
<h3 id="transaction-processing-or-analytics" style="position:relative;"><a href="#transaction-processing-or-analytics" aria-label="transaction processing or analytics permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Transaction processing or analytics?</h3>
<p>A <em>transaction</em> is a group of reads and writes that form a logical unit, this pattern became known as <em>online transaction processing</em> (OLTP).</p>
<p><em>Data analytics</em> has very different access patterns. A query would need to scan over a huge number of records, only reading a few columns per record, and calculates aggregate statistics.</p>
<p>These queries are often written by business analysts, and fed into reports. This pattern became known for <em>online analytics processing</em> (OLAP).</p>
<h4 id="data-warehousing" style="position:relative;"><a href="#data-warehousing" aria-label="data warehousing permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Data warehousing</h4>
<p>A <em>data warehouse</em> is a separate database that analysts can query to their heart’s content without affecting OLTP operations. It contains read-only copy of the dat in all various OLTP systems in the company. Data is extracted out of OLTP databases (through periodic data dump or a continuous stream of update), transformed into an analysis-friendly schema, cleaned up, and then loaded into the data warehouse (process <em>Extract-Transform-Load</em> or ETL).</p>
<p>A data warehouse is most commonly relational, but the internals of the systems can look quite different.</p>
<p>Amazon RedShift is hosted version of ParAccel. Apache Hive, Spark SQL, Cloudera Impala, Facebook Presto, Apache Tajo, and Apache Drill. Some of them are based on ideas from Google’s Dremel.</p>
<p>Data warehouses are used in fairly formulaic style known as a <em>star schema</em>.</p>
<p>Facts are captured as individual events, because this allows maximum flexibility of analysis later. The fact table can become extremely large.</p>
<p>Dimensions represent the <em>who</em>, <em>what</em>, <em>where</em>, <em>when</em>, <em>how</em> and <em>why</em> of the event.</p>
<p>The name “star schema” comes from the fact than when the table relationships are visualised, the fact table is in the middle, surrounded by its dimension tables, like the rays of a star.</p>
<p>Fact tables often have over 100 columns, sometimes several hundred. Dimension tables can also be very wide.</p>
<h3 id="column-oriented-storage" style="position:relative;"><a href="#column-oriented-storage" aria-label="column oriented storage permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Column-oriented storage</h3>
<p>In a row-oriented storage engine, when you do a query that filters on a specific field, the engine will load all those rows with all their fields into memory, parse them and filter out the ones that don’t meet the requirement. This can take a long time.</p>
<p><em>Column-oriented storage</em> is simple: don’t store all the values from one row together, but store all values from each <em>column</em> together instead. If each column is stored in a separate file, a query only needs to read and parse those columns that are used in a query, which can save a lot of work.</p>
<p>Column-oriented storage often lends itself very well to compression as the sequences of values for each column look quite repetitive, which is a good sign for compression. A technique that is particularly effective in data warehouses is <em>bitmap encoding</em>.</p>
<p>Bitmap indexes are well suited for all kinds of queries that are common in a data warehouse.</p>
<blockquote>
<p>Cassandra and HBase have a concept of <em>column families</em>, which they inherited from Bigtable.</p>
</blockquote>
<p>Besides reducing the volume of data that needs to be loaded from disk, column-oriented storage layouts are also good for making efficient use of CPU cycles (<em>vectorised processing</em>).</p>
<p><strong>Column-oriented storage, compression, and sorting helps to make read queries faster and make sense in data warehouses, where most of the load consist on large read-only queries run by analysts. The downside is that writes are more difficult.</strong></p>
<p>An update-in-place approach, like B-tree use, is not possible with compressed columns. If you insert a row in the middle of a sorted table, you would most likely have to rewrite all column files.</p>
<p>It’s worth mentioning <em>materialised aggregates</em> as some cache of the counts ant the sums that queries use most often. A way of creating such a cache is with a <em>materialised view</em>, on a relational model this is usually called a <em>virtual view</em>: a table-like object whose contents are the results of some query. A materialised view is an actual copy of the query results, written in disk, whereas a virtual view is just a shortcut for writing queries.</p>
<p>When the underlying data changes, a materialised view needs to be updated, because it is denormalised copy of the data. Database can do it automatically, but writes would become more expensive.</p>
<p>A common special case of a materialised view is know as a <em>data cube</em> or <em>OLAP cube</em>, a grid of aggregates grouped by different dimensions.</p>
<h2 id="encoding-and-evolution" style="position:relative;"><a href="#encoding-and-evolution" aria-label="encoding and evolution permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Encoding and evolution</h2>
<p>Change to an application’s features also requires a change to data it stores.</p>
<p>Relational databases conforms to one schema although that schema can be changed, there is one schema in force at any point in time. <strong>Schema-on-read (or schemaless) contain a mixture of older and newer data formats.</strong></p>
<p>In large applications changes don’t happen instantaneously. You want to perform a <em>rolling upgrade</em> and deploy a new version to a few nodes at a time, gradually working your way through all the nodes without service downtime.</p>
<p>Old and new versions of the code, and old and new data formats, may potentially all coexist. We need to maintain compatibility in both directions</p>
<ul>
<li>Backward compatibility, newer code can read data that was written by older code.</li>
<li>Forward compatibility, older code can read data that was written by newer code.</li>
</ul>
<h3 id="formats-for-encoding-data" style="position:relative;"><a href="#formats-for-encoding-data" aria-label="formats for encoding data permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Formats for encoding data</h3>
<p>Two different representations:</p>
<ul>
<li>In memory</li>
<li>When you want to write data to a file or send it over the network, you have to encode it</li>
</ul>
<p>Thus, you need a translation between the two representations. In-memory representation to byte sequence is called <em>encoding</em> (<em>serialisation</em> or <em>marshalling</em>), and the reverse is called <em>decoding</em> (<em>parsing</em>, <em>deserialisation</em> or <em>unmarshalling</em>).</p>
<p>Programming languages come with built-in support for encoding in-memory objects into byte sequences, but is usually a bad idea to use them. Precisely because of a few problems.</p>
<ul>
<li>Often tied to a particular programming language.</li>
<li>The decoding process needs to be able to instantiate arbitrary classes and this is frequently a security hole.</li>
<li>Versioning</li>
<li>Efficiency</li>
</ul>
<p>Standardised encodings can be written and read by many programming languages.</p>
<p>JSON, XML, and CSV are human-readable and popular specially as data interchange formats, but they have some subtle problems:</p>
<ul>
<li>Ambiguity around the encoding of numbers and dealing with large numbers</li>
<li>Support of Unicode character strings, but no support for binary strings. People get around this by encoding binary data as Base64, which increases the data size by 33%.</li>
<li>There is optional schema support for both XML and JSON</li>
<li>CSV does not have any schema</li>
</ul>
<h4 id="binary-encoding" style="position:relative;"><a href="#binary-encoding" aria-label="binary encoding permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Binary encoding</h4>
<p>JSON is less verbose than XML, but both still use a lot of space compared to binary formats. There are binary encodings for JSON (MesagePack, BSON, BJSON, UBJSON, BISON and Smile), similar thing for XML (WBXML and Fast Infoset).</p>
<p><strong>Apache Thrift and Protocol Buffers (protobuf) are binary encoding libraries.</strong></p>
<p>Thrift offers two different protocols:</p>
<ul>
<li><strong>BinaryProtocol</strong>, there are no field names like <code class="language-text">userName</code>, <code class="language-text">favouriteNumber</code>. Instead the data contains <em>field tags</em>, which are numbers (<code class="language-text">1</code>, <code class="language-text">2</code>)</li>
<li><strong>CompactProtocol</strong>, which is equivalent to BinaryProtocol but it packs the same information in less space. It packs the field type and the tag number into the same byte.</li>
</ul>
<p>Protocol Buffers are very similar to Thrift’s CompactProtocol, bit packing is a bit different and that might allow smaller compression.</p>
<p>Schemas inevitable need to change over time (<em>schema evolution</em>), how do Thrift and Protocol Buffers handle schema changes while keeping backward and forward compatibility changes?</p>
<ul>
<li><strong>Forward compatible support</strong>. As with new fields you add new tag numbers, old code trying to read new code, it can simply ignore not recognised tags.</li>
<li><strong>Backwards compatible support</strong>. As long as each field has a unique tag number, new code can always read old data. Every field you add after initial deployment of schema must be optional or have a default value.</li>
</ul>
<p>Removing fields is just like adding a field with backward and forward concerns reversed. You can only remove a field that is optional, and you can never use the same tag again.</p>
<p>What about changing the data type of a field? There is a risk that values will lose precision or get truncated.</p>
<h5 id="avro" style="position:relative;"><a href="#avro" aria-label="avro permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Avro</h5>
<p>Apache Avro is another binary format that has two schema languages, one intended for human editing (Avro IDL), and one (based on JSON) that is more easily machine-readable.</p>
<p>You go go through the fields in the order they appear in the schema and use the schema to tell you the datatype of each field. Any mismatch in the schema between the reader and the writer would mean incorrectly decoded data.</p>
<p>What about schema evolution? When an application wants to encode some data, it encodes the data using whatever version of the schema it knows (<em>writer’s schema</em>).</p>
<p>When an application wants to decode some data, it is expecting the data to be in some schema (<em>reader’s schema</em>).</p>
<p>In Avro the writer’s schema and the reader’s schema <em>don’t have to be the same</em>. The Avro library resolves the differences by looking at the writer’s schema and the reader’s schema.</p>
<p>Forward compatibility means you can have a new version of the schema as writer and an old version of the schema as reader. Conversely, backward compatibility means that you can have a new version of the schema as reader and an old version as writer.</p>
<p>To maintain compatibility, you may only add or remove a field that has a default value.</p>
<p>If you were to add a field that has no default value, new readers wouldn’t be able to read data written by old writers.</p>
<p>Changing the datatype of a field is possible, provided that Avro can convert the type. Changing the name of a filed is tricky (backward compatible but not forward compatible).</p>
<p>The schema is identified encoded in the data. In a large file with lots of records, the writer of the file can just include the schema at the beginning of the file. On a database with individually written records, you cannot assume all the records will have the same schema, so you have to include a version number at the beginning of every encoded record. While sending records over the network, you can negotiate the schema version on connection setup.</p>
<p>Avro is friendlier to <em>dynamically generated schemas</em> (dumping into a file the database). You can fairly easily generate an Avro schema in JSON.</p>
<p>If the database schema changes, you can just generate a new Avro schema for the updated database schema and export data in the new Avro schema.</p>
<p>By contrast with Thrift and Protocol Buffers, every time the database schema changes, you would have to manually update the mappings from database column names to field tags.</p>
<hr>
<p>Although textual formats such as JSON, XML and CSV are widespread, binary encodings based on schemas are also a viable option. As they have nice properties:</p>
<ul>
<li>Can be much more compact, since they can omit field names from the encoded data.</li>
<li>Schema is a valuable form of documentation, required for decoding, you can be sure it is up to date.</li>
<li>Database of schemas allows you to check forward and backward compatibility changes.</li>
<li>Generate code from the schema is useful, since it enables type checking at compile time.</li>
</ul>
<h3 id="modes-of-dataflow" style="position:relative;"><a href="#modes-of-dataflow" aria-label="modes of dataflow permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Modes of dataflow</h3>
<p>Different process on how data flows between processes</p>
<h4 id="via-databases" style="position:relative;"><a href="#via-databases" aria-label="via databases permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Via databases</h4>
<p>The process that writes to the database encodes the data, and the process that reads from the database decodes it.</p>
<p>A value in the database may be written by a <em>newer</em> version of the code, and subsequently read by an <em>older</em> version of the code that is still running.</p>
<p>When a new version of your application is deployed, you may entirely replace the old version with the new version within a few minutes. The same is not true in databases, the five-year-old data will still be there, in the original encoding, unless you have explicitly rewritten it. <em>Data outlives code</em>.</p>
<p>Rewriting (<em>migrating</em>) is expensive, most relational databases allow simple schema changes, such as adding a new column with a <code class="language-text">null</code> default value without rewriting existing data. When an old row is read, the database fills in <code class="language-text">null</code>s for any columns that are missing.</p>
<h4 id="via-service-calls" style="position:relative;"><a href="#via-service-calls" aria-label="via service calls permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Via service calls</h4>
<p>You have processes that need to communicate over a network of <em>clients</em> and <em>servers</em>.</p>
<p>Services are similar to databases, each service should be owned by one team. and that team should be able to release versions of the service frequently, without having to coordinate with other teams. We should expect old and new versions of servers and clients to be running at the same time.</p>
<p><em>Remote procedure calls</em> (RPC) tries to make a request to a remote network service look the same as calling a function or method in your programming language, it seems convenient at first but the approach is flawed:</p>
<ul>
<li>A network request is unpredictable</li>
<li>A network request it may return without a result, due a <em>timeout</em></li>
<li>Retrying will cause the action to be performed multiple times, unless you build a mechanism for deduplication (<em>idempotence</em>).</li>
<li>A network request is much slower than a function call, and its latency is wildly variable.</li>
<li>Parameters need to be encoded into a sequence of bytes that can be sent over the network and becomes problematic with larger objects.</li>
<li>The RPC framework must translate datatypes from one language to another, not all languages have the same types.</li>
</ul>
<p><strong>There is no point trying to make a remote service look too much like a local object in your programming language, because it’s a fundamentally different thing.</strong></p>
<p>New generation of RPC frameworks are more explicit about the fact that a remote request is different from a local function call. Fiangle and Rest.li use <em>features</em> (<em>promises</em>) to encapsulate asyncrhonous actions.</p>
<p>RESTful API has some significant advantages like being good for experimentation and debugging.</p>
<p>REST seems to be the predominant style for public APIs. The main focus of RPC frameworks is on requests between services owned by the same organisation, typically within the same datacenter.</p>
<h4 id="via-asynchronous-message-passing" style="position:relative;"><a href="#via-asynchronous-message-passing" aria-label="via asynchronous message passing permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Via asynchronous message passing</h4>
<p>In an <em>asynchronous message-passing</em> systems, a client’s request (usually called a <em>message</em>) is delivered to another process with low latency. The message goes via an intermediary called a <em>message broker</em> (<em>message queue</em> or <em>message-oriented middleware</em>) which stores the message temporarily. This has several advantages compared to direct RPC:</p>
<ul>
<li>It can act as a buffer if the recipient is unavailable or overloaded</li>
<li>It can automatically redeliver messages to a process that has crashed and prevent messages from being lost</li>
<li>It avoids the sender needing to know the IP address and port number of the recipient (useful in a cloud environment)</li>
<li>It allows one message to be sent to several recipients</li>
<li><strong>Decouples the sender from the recipient</strong></li>
</ul>
<p>The communication happens only in one direction. The sender doesn’t wait for the message to be delivered, but simply sends it and then forgets about it (<em>asynchronous</em>).</p>
<p>Open source implementations for message brokers are RabbitMQ, ActiveMQ, HornetQ, NATS, and Apache Kafka.</p>
<p>One process sends a message to a named <em>queue</em> or <em>topic</em> and the broker ensures that the message is delivered to one or more <em>consumers</em> or <em>subscribers</em> to that queue or topic.</p>
<p>Message brokers typically don’t enforce a particular data model, you can use any encoding format.</p>
<p>An <em>actor model</em> is a programming model for concurrency in a single process. Rather than dealing with threads (and their complications), logic is encapsulated in <em>actors</em>. Each actor typically represent one client or entity, it may have some local state, and it communicates with other actors by sending and receiving asynchronous messages. Message deliver is not guaranteed. Since each actor processes only one message at a time, it doesn’t need to worry about threads.</p>
<p>In <em>distributed actor frameworks</em>, this programming model is used to scale an application across multiple nodes. It basically integrates a message broker and the actor model into a single framework.</p>
<ul>
<li><em>Akka</em> uses Java’s built-in serialisation by default, which does not provide forward or backward compatibility. You can replace it with something like Protocol Buffers and the ability to do rolling upgrades.</li>
<li><em>Orleans</em> by default uses custom data encoding format that does not support rolling upgrade deployments.</li>
<li>In <em>Erlang OTP</em> it is surprisingly hard to make changes to record schemas.</li>
</ul>
<hr>
<p>What happens if multiple machines are involved in storage and retrieval of data?</p>
<p>Reasons for distribute a database across multiple machines:</p>
<ul>
<li>Scalability</li>
<li>Fault tolerance/high availability</li>
<li>Latency, having servers at various locations worldwide</li>
</ul>
<h1 id="distributed-data" style="position:relative;"><a href="#distributed-data" aria-label="distributed data permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Distributed Data</h1>
<h2 id="replication" style="position:relative;"><a href="#replication" aria-label="replication permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Replication</h2>
<p>Reasons why you might want to replicate data:</p>
<ul>
<li>To keep data geographically close to your users</li>
<li>Increase availability</li>
<li>Increase read throughput</li>
</ul>
<p>The difficulty in replication lies in handling <em>changes</em> to replicated data. Popular algorithms for replicating changes between nodes: <em>single-leader</em>, <em>multi-leader</em>, and <em>leaderless</em> replication.</p>
<h3 id="leaders-and-followers" style="position:relative;"><a href="#leaders-and-followers" aria-label="leaders and followers permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Leaders and followers</h3>
<p>Each node that stores a copy of the database is called a <em>replica</em>.</p>
<p>Every write to the database needs to be processed by every replica. The most common solution for this is called <em>leader-based replication</em> (<em>active/passive</em> or <em>master-slave replication</em>).</p>
<ol>
<li>One of the replicas is designated the <em>leader</em> (<em>master</em> or <em>primary</em>). Writes to the database must send requests to the leader.</li>
<li>Other replicas are known as <em>followers</em> (<em>read replicas</em>, <em>slaves</em>, <em>secondaries</em> or <em>hot stanbys</em>). The leader sends the data change to all of its followers as part of a <em>replication log</em> or <em>change stream</em>.</li>
<li>Reads can be query the leader or any of the followers, while writes are only accepted on the leader.</li>
</ol>
<p>MySQL, Oracle Data Guard, SQL Server’s AlwaysOn Availability Groups, MongoDB, RethinkDB, Espresso, Kafka and RabbitMQ are examples of these kind of databases.</p>
<h4 id="synchronous-vs-asynchronous" style="position:relative;"><a href="#synchronous-vs-asynchronous" aria-label="synchronous vs asynchronous permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Synchronous vs asynchronous</h4>
<p><strong>The advantage of synchronous replication is that the follower is guaranteed to have an up-to-date copy of the data that is consistent with the leader. The disadvantage is that it the synchronous follower doesn’t respond, the write cannot be processed.</strong></p>
<p>It’s impractical for all followers to be synchronous. If you enable synchronous replication on a database, it usually means that <em>one</em> of the followers is synchronous, and the others are asynchronous. This guarantees up-to-date copy of the data on at least two nodes (this is sometimes called <em>semi-synchronous</em>).</p>
<p>Often, leader-based replication is asynchronous. Writes are not guaranteed to be durable, the main advantage of this approach is that the leader can continue processing writes.</p>
<h4 id="setting-up-new-followers" style="position:relative;"><a href="#setting-up-new-followers" aria-label="setting up new followers permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Setting up new followers</h4>
<p>Copying data files from one node to another is typically not sufficient.</p>
<p>Setting up a follower can usually be done without downtime. The process looks like:</p>
<ol>
<li>Take a snapshot of the leader’s database</li>
<li>Copy the snapshot to the follower node</li>
<li>Follower requests data changes that have happened since the snapshot was taken</li>
<li>Once follower processed the backlog of data changes since snapshot, it has <em>caught up</em>.</li>
</ol>
<h4 id="handling-node-outages" style="position:relative;"><a href="#handling-node-outages" aria-label="handling node outages permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Handling node outages</h4>
<p>How does high availability works with leader-based replication?</p>
<h4 id="follower-failure-catchup-recovery" style="position:relative;"><a href="#follower-failure-catchup-recovery" aria-label="follower failure catchup recovery permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Follower failure: catchup recovery</h4>
<p>Follower can connect to the leader and request all the data changes that occurred during the time when the follower was disconnected.</p>
<h4 id="leader-failure-failover" style="position:relative;"><a href="#leader-failure-failover" aria-label="leader failure failover permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Leader failure: failover</h4>
<p>One of the followers needs to be promoted to be the new leader, clients need to be reconfigured to send their writes to the new leader and followers need to start consuming data changes from the new leader.</p>
<p>Automatic failover consists:</p>
<ol>
<li>Determining that the leader has failed. If a node does not respond in a period of time it’s considered dead.</li>
<li>Choosing a new leader. The best candidate for leadership is usually the replica with the most up-to-date changes from the old leader.</li>
<li>Reconfiguring the system to use the new leader. The system needs to ensure that the old leader becomes a follower and recognises the new leader.</li>
</ol>
<p>Things that could go wrong:</p>
<ul>
<li>If asynchronous replication is used, the new leader may have received conflicting writes in the meantime.</li>
<li>Discarding writes is especially dangerous if other storage systems outside of the database need to be coordinated with the database contents.</li>
<li>It could happen that two nodes both believe that they are the leader (<em>split brain</em>). Data is likely to be lost or corrupted.</li>
<li>What is the right time before the leader is declared dead?</li>
</ul>
<p>For these reasons, some operation teams prefer to perform failovers manually, even if the software supports automatic failover.</p>
<h4 id="implementation-of-replication-logs" style="position:relative;"><a href="#implementation-of-replication-logs" aria-label="implementation of replication logs permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Implementation of replication logs</h4>
<h5 id="statement-based-replication" style="position:relative;"><a href="#statement-based-replication" aria-label="statement based replication permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Statement-based replication</h5>
<p>The leader logs every <em>statement</em> and sends it to its followers (every <code class="language-text">INSERT</code>, <code class="language-text">UPDATE</code> or <code class="language-text">DELETE</code>).</p>
<p>This type of replication has some problems:</p>
<ul>
<li>Non-deterministic functions such as <code class="language-text">NOW()</code> or <code class="language-text">RAND()</code> will generate different values on replicas.</li>
<li>Statements that depend on existing data, like auto-increments, must be executed in the same order in each replica.</li>
<li>Statements with side effects may result on different results on each replica.</li>
</ul>
<p>A solution to this is to replace any nondeterministic function with a fixed return value in the leader.</p>
<h5 id="write-ahead-log-wal-shipping" style="position:relative;"><a href="#write-ahead-log-wal-shipping" aria-label="write ahead log wal shipping permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Write-ahead log (WAL) shipping</h5>
<p>The log is an append-only sequence of bytes containing all writes to the database. The leader can send it to its followers. This way of replication is used in PostgresSQL and Oracle.</p>
<p>The main disadvantage is that the log describes the data at a very low level (like which bytes were changed in which disk blocks), coupling it to the storage engine.</p>
<p>Usually is not possible to run different versions of the database in leaders and followers. This can have a big operational impact, like making it impossible to have a zero-downtime upgrade of the database.</p>
<h5 id="logical-row-based-log-replication" style="position:relative;"><a href="#logical-row-based-log-replication" aria-label="logical row based log replication permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Logical (row-based) log replication</h5>
<p>Basically a sequence of records describing writes to database tables at the granularity of a row:</p>
<ul>
<li>For an inserted row, the new values of all columns.</li>
<li>For a deleted row, the information that uniquely identifies that column.</li>
<li>For an updated row, the information to uniquely identify that row and all the new values of the columns.</li>
</ul>
<p>A transaction that modifies several rows, generates several of such logs, followed by a record indicating that the transaction was committed. MySQL binlog uses this approach.</p>
<p>Since logical log is decoupled from the storage engine internals, it’s easier to make it backwards compatible.</p>
<p>Logical logs are also easier for external applications to parse, useful for data warehouses, custom indexes and caches (<em>change data capture</em>).</p>
<h5 id="trigger-based-replication" style="position:relative;"><a href="#trigger-based-replication" aria-label="trigger based replication permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Trigger-based replication</h5>
<p>There are some situations were you may need to move replication up to the application layer.</p>
<p>A trigger lets you register custom application code that is automatically executed when a data change occurs. This is a good opportunity to log this change into a separate table, from which it can be read by an external process.</p>
<p>Main disadvantages is that this approach has greater overheads, is more prone to bugs but it may be useful due to its flexibility.</p>
<h3 id="problems-with-replication-lag" style="position:relative;"><a href="#problems-with-replication-lag" aria-label="problems with replication lag permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Problems with replication lag</h3>
<p>Node failures is just one reason for wanting replication. Other reasons are scalability and latency.</p>
<p>In a <em>read-scaling</em> architecture, you can increase the capacity for serving read-only requests simply by adding more followers. However, this only realistically works on asynchronous replication. The more nodes you have, the likelier is that one will be down, so a fully synchronous configuration would be unreliable.</p>
<p>With an asynchronous approach, a follower may fall behind, leading to inconsistencies in the database (<em>eventual consistency</em>).</p>
<p>The <em>replication lag</em> could be a fraction of a second or several seconds or even minutes.</p>
<p>The problems that may arise and how to solve them.</p>
<h4 id="reading-your-own-writes" style="position:relative;"><a href="#reading-your-own-writes" aria-label="reading your own writes permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Reading your own writes</h4>
<p><em>Read-after-write consistency</em>, also known as <em>read-your-writes consistency</em> is a guarantee that if the user reloads the page, they will always see any updates they submitted themselves.</p>
<p>How to implement it:</p>
<ul>
<li><strong>When reading something that the user may have modified, read it from the leader.</strong> For example, user profile information on a social network is normally only editable by the owner. A simple rule is always read the user’s own profile from the leader.</li>
<li>You could track the time of the latest update and, for one minute after the last update, make all reads from the leader.</li>
<li>The client can remember the timestamp of the most recent write, then the system can ensure that the replica serving any reads for that user reflects updates at least until that timestamp.</li>
<li>If your replicas are distributed across multiple datacenters, then any request needs to be routed to the datacenter that contains the leader.</li>
</ul>
<p>Another complication is that the same user is accessing your service from multiple devices, you may want to provide <em>cross-device</em> read-after-write consistency.</p>
<p>Some additional issues to consider:</p>
<ul>
<li>Remembering the timestamp of the user’s last update becomes more difficult. The metadata will need to be centralised.</li>
<li>If replicas are distributed across datacenters, there is no guarantee that connections from different devices will be routed to the same datacenter. You may need to route requests from all of a user’s devices to the same datacenter.</li>
</ul>
<h4 id="monotonic-reads" style="position:relative;"><a href="#monotonic-reads" aria-label="monotonic reads permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Monotonic reads</h4>
<p>Because of followers falling behind, it’s possible for a user to see things <em>moving backward in time</em>.</p>
<p>When you read data, you may see an old value; monotonic reads only means that if one user makes several reads in sequence, they will not see time go backward.</p>
<p>Make sure that each user always makes their reads from the same replica. The replica can be chosen based on a hash of the user ID. If the replica fails, the user’s queries will need to be rerouted to another replica.</p>
<h4 id="consistent-prefix-reads" style="position:relative;"><a href="#consistent-prefix-reads" aria-label="consistent prefix reads permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Consistent prefix reads</h4>
<p>If a sequence of writes happens in a certain order, then anyone reading those writes will see them appear in the same order.</p>
<p>This is a particular problem in partitioned (sharded) databases as there is no global ordering of writes.</p>
<p>A solution is to make sure any writes casually related to each other are written to the same partition.</p>
<h4 id="solutions-for-replication-lag" style="position:relative;"><a href="#solutions-for-replication-lag" aria-label="solutions for replication lag permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Solutions for replication lag</h4>
<p><em>Transactions</em> exist so there is a way for a database to provide stronger guarantees so that the application can be simpler.</p>
<h3 id="multi-leader-replication" style="position:relative;"><a href="#multi-leader-replication" aria-label="multi leader replication permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Multi-leader replication</h3>
<p>Leader-based replication has one major downside: there is only one leader, and all writes must go through it.</p>
<p>A natural extension is to allow more than one node to accept writes (<em>multi-leader</em>, <em>master-master</em> or <em>active/active</em> replication) where each leader simultaneously acts as a follower to the other leaders.</p>
<h4 id="use-cases-for-multi-leader-replication" style="position:relative;"><a href="#use-cases-for-multi-leader-replication" aria-label="use cases for multi leader replication permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Use cases for multi-leader replication</h4>
<p>It rarely makes sense to use multi-leader setup within a single datacenter.</p>
<h5 id="multi-datacenter-operation" style="position:relative;"><a href="#multi-datacenter-operation" aria-label="multi datacenter operation permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Multi-datacenter operation</h5>
<p>You can have a leader in <em>each</em> datacenter. Within each datacenter, regular leader-follower replication is used. Between datacenters, each datacenter leader replicates its changes to the leaders in other datacenters.</p>
<p>Compared to a single-leader replication model deployed in multi-datacenters</p>
<ul>
<li><strong>Performance.</strong> With single-leader, every write must go across the internet to wherever the leader is, adding significant latency. In multi-leader every write is processed in the local datacenter and replicated asynchronously to other datacenters. The network delay is hidden from users and perceived performance may be better.</li>
<li><strong>Tolerance of datacenter outages.</strong> In single-leader if the datacenter with the leader fails, failover can promote a follower in another datacenter. In multi-leader, each datacenter can continue operating independently from others.</li>
<li><strong>Tolerance of network problems.</strong> Single-leader is very sensitive to problems in this inter-datacenter link as writes are made synchronously over this link. Multi-leader with asynchronous replication can tolerate network problems better.</li>
</ul>
<p>Multi-leader replication is implemented with Tungsten Replicator for MySQL, BDR for PostgreSQL or GoldenGate for Oracle.</p>
<p>It’s common to fall on subtle configuration pitfalls. Autoincrementing keys, triggers and integrity constraints can be problematic. Multi-leader replication is often considered dangerous territory and avoided if possible.</p>
<h5 id="clients-with-offline-operation" style="position:relative;"><a href="#clients-with-offline-operation" aria-label="clients with offline operation permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Clients with offline operation</h5>
<p>If you have an application that needs to continue to work while it is disconnected from the internet, every device that has a local database can act as a leader, and there will be some asynchronous multi-leader replication process (imagine, a Calendar application).</p>
<p>CouchDB is designed for this mode of operation.</p>
<h4 id="collaborative-editing" style="position:relative;"><a href="#collaborative-editing" aria-label="collaborative editing permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Collaborative editing</h4>
<p><em>Real-time collaborative editing</em> applications allow several people to edit a document simultaneously. Like Etherpad or Google Docs.</p>
<p>The user edits a document, the changes are instantly applied to their local replica and asynchronously replicated to the server and any other user.</p>
<p>If you want to avoid editing conflicts, you must the lock the document before a user can edit it.</p>
<p>For faster collaboration, you may want to make the unit of change very small (like a keystroke) and avoid locking.</p>
<h4 id="handling-write-conflicts" style="position:relative;"><a href="#handling-write-conflicts" aria-label="handling write conflicts permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Handling write conflicts</h4>
<p>The biggest problem with multi-leader replication is when conflict resolution is required. This problem does not happen in a single-leader database.</p>
<h5 id="synchronous-vs-asynchronous-conflict-detection" style="position:relative;"><a href="#synchronous-vs-asynchronous-conflict-detection" aria-label="synchronous vs asynchronous conflict detection permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Synchronous vs asynchronous conflict detection</h5>
<p>In single-leader the second writer can be blocked and wait the first one to complete, forcing the user to retry the write. On multi-leader if both writes are successful, the conflict is only detected asynchronously later in time.</p>
<p>If you want synchronous conflict detection, you might as well use single-leader replication.</p>
<h5 id="conflict-avoidance" style="position:relative;"><a href="#conflict-avoidance" aria-label="conflict avoidance permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Conflict avoidance</h5>
<p>The simplest strategy for dealing with conflicts is to avoid them. If all writes for a particular record go through the sae leader, then conflicts cannot occur.</p>
<p>On an application where a user can edit their own data, you can ensure that requests from a particular user are always routed to the same datacenter and use the leader in that datacenter for reading and writing.</p>
<h5 id="converging-toward-a-consistent-state" style="position:relative;"><a href="#converging-toward-a-consistent-state" aria-label="converging toward a consistent state permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Converging toward a consistent state</h5>
<p>On single-leader, the last write determines the final value of the field.</p>
<p>In multi-leader, it’s not clear what the final value should be.</p>
<p>The database must resolve the conflict in a <em>convergent</em> way, all replicas must arrive a the same final value when all changes have been replicated.</p>
<p>Different ways of achieving convergent conflict resolution.</p>
<ul>
<li>Five each write a unique ID (timestamp, long random number, UUID, or a has of the key and value), pick the write with the highest ID as the <em>winner</em> and throw away the other writes. This is known as <em>last write wins</em> (LWW) and it is dangerously prone to data loss.</li>
<li>Give each replica a unique ID, writes that originated at a higher-numbered replica always take precedence. This approach also implies data loss.</li>
<li>Somehow merge the values together.</li>
<li>Record the conflict and write application code that resolves it a to some later time (perhaps prompting the user).</li>
</ul>
<h5 id="custom-conflict-resolution" style="position:relative;"><a href="#custom-conflict-resolution" aria-label="custom conflict resolution permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Custom conflict resolution</h5>
<p>Multi-leader replication tools let you write conflict resolution logic using application code.</p>
<ul>
<li><strong>On write.</strong> As soon as the database system detects a conflict in the log of replicated changes, it calls the conflict handler.</li>
<li><strong>On read.</strong> All the conflicting writes are stored. On read, multiple versions of the data are returned to the application. The application may prompt the user or automatically resolve the conflict. CouchDB works this way.</li>
</ul>
<h4 id="multi-leader-replication-topologies" style="position:relative;"><a href="#multi-leader-replication-topologies" aria-label="multi leader replication topologies permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Multi-leader replication topologies</h4>
<p>A <em>replication topology</em> describes the communication paths along which writes are propagated from one node to another.</p>
<p>The most general topology is <em>all-to-all</em> in which every leader sends its writes to every other leader. MySQL uses <em>circular topology</em>, where each nodes receives writes from one node and forwards those writes to another node. Another popular topology has the shape of a <em>star</em>, one designated node forwards writes to all of the other nodes.</p>
<p>In circular and star topologies a write might need to pass through multiple nodes before they reach all replicas. To prevent infinite replication loops each node is given a unique identifier and the replication log tags each write with the identifiers of the nodes it has passed through. When a node fails it can interrupt the flow of replication messages.</p>
<p>In all-to-all topology fault tolerance is better as messages can travel along different paths avoiding a single point of failure. It has some issues too, some network links may be faster than others and some replication messages may “overtake” others. To order events correctly. there is a technique called <em>version vectors</em>. PostgresSQL BDR does not provide casual ordering of writes, and Tungsten Replicator for MySQL doesn’t even try to detect conflicts.</p>
<h3 id="leaderless-replication" style="position:relative;"><a href="#leaderless-replication" aria-label="leaderless replication permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Leaderless replication</h3>
<p>Simply put, any replica can directly accept writes from clients. Databases like look like Amazon’s in-house <em>Dynamo</em> datastore. <em>Riak</em>, <em>Cassandra</em> and <em>Voldemort</em> follow the <em>Dynamo style</em>.</p>
<p>In a leaderless configuration, failover does not exist. Clients send the write to all replicas in parallel.</p>
<p><em>Read requests are also sent to several nodes in parallel</em>. The client may get different responses. Version numbers are used to determine which value is newer.</p>
<p>Eventually, all the data is copied to every replica. After a unavailable node come back online, it has two different mechanisms to catch up:</p>
<ul>
<li><strong>Read repair.</strong> When a client detect any stale responses, write the newer value back to that replica.</li>
<li><strong>Anti-entropy process.</strong> There is a background process that constantly looks for differences in data between replicas and copies any missing data from one replica to he other. It does not copy writes in any particular order.</li>
</ul>
<h4 id="quorums-for-reading-and-writing" style="position:relative;"><a href="#quorums-for-reading-and-writing" aria-label="quorums for reading and writing permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Quorums for reading and writing</h4>
<p>If there are <em>n</em> replicas, every write must be confirmed by <em>w</em> nodes to be considered successful, and we must query at least <em>r</em> nodes for each read. As long as <em>w</em> + <em>r</em> > <em>n</em>, we expect to get an up-to-date value when reading. <em>r</em> and <em>w</em> values are called <em>quorum</em> reads and writes. Are the minimum number of votes required for the read or write to be valid.</p>
<p>A common choice is to make <em>n</em> and odd number (typically 3 or 5) and to set <em>w</em> = <em>r</em> = (<em>n</em> + 1)/2 (rounded up).</p>
<p>Limitations:</p>
<ul>
<li>Sloppy quorum, the <em>w</em> writes may end up on different nodes than the <em>r</em> reads, so there is no longer a guaranteed overlap.</li>
<li>If two writes occur concurrently, and is not clear which one happened first, the only safe solution is to merge them. Writes can be lost due to clock skew.</li>
<li>If a write happens concurrently with a read, the write may be reflected on only some of the replicas.</li>
<li>If a write succeeded on some replicas but failed on others, it is not rolled back on the replicas where it succeeded. Reads may or may not return the value from that write.</li>
<li>If a node carrying a new value fails, and its data is restored from a replica carrying an old value, the number of replicas storing the new value may break the quorum condition.</li>
</ul>
<p><strong>Dynamo-style databases are generally optimised for use cases that can tolerate eventual consistency.</strong></p>
<h4 id="sloppy-quorums-and-hinted-handoff" style="position:relative;"><a href="#sloppy-quorums-and-hinted-handoff" aria-label="sloppy quorums and hinted handoff permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Sloppy quorums and hinted handoff</h4>
<p>Leaderless replication may be appealing for use cases that require high availability and low latency, and that can tolerate occasional stale reads.</p>
<p>It’s likely that the client won’t be able to connect to <em>some</em> database nodes during a network interruption.</p>
<ul>
<li>Is it better to return errors to all requests for which we cannot reach quorum of <em>w</em> or <em>r</em> nodes?</li>
<li>Or should we accept writes anyway, and write them to some nodes that are reachable but aren’t among the <em>n</em> nodes on which the value usually lives?</li>
</ul>
<p>The latter is known as <em>sloppy quorum</em>: writes and reads still require <em>w</em> and <em>r</em> successful responses, but those may include nodes that are not among the designated <em>n</em> “home” nodes for a value.</p>
<p>Once the network interruption is fixed, any writes are sent to the appropriate “home” nodes (<em>hinted handoff</em>).</p>
<p>Sloppy quorums are useful for increasing write availability: as long as any <em>w</em> nodes are available, the database can accept writes. This also means that you cannot be sure to read the latest value for a key, because it may have been temporarily written to some nodes outside of <em>n</em>.</p>
<h5 id="multi-datacenter-operation-1" style="position:relative;"><a href="#multi-datacenter-operation-1" aria-label="multi datacenter operation 1 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Multi-datacenter operation</h5>
<p>Each write from a client is sent to all replicas, regardless of datacenter, but the client usually only waits for acknowledgement from a quorum of nodes within its local datacenter so that it is unaffected by delays and interruptions on cross-datacenter link.</p>
<h4 id="detecting-concurrent-writes" style="position:relative;"><a href="#detecting-concurrent-writes" aria-label="detecting concurrent writes permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Detecting concurrent writes</h4>
<p>In order to become eventually consistent, the replicas should converge toward the same value. If you want to avoid losing data, you application developer, need to know a lot about the internals of your database’s conflict handling.</p>
<ul>
<li><strong>Last write wins (discarding concurrent writes).</strong> Even though the writes don’ have a natural ordering, we can force an arbitrary order on them. We can attach a timestamp to each write and pick the most recent. There are some situations such caching on which lost writes are acceptable. If losing data is not acceptable, LWW is a poor choice for conflict resolution.</li>
<li><strong>The “happens-before” relationship and concurrency.</strong> Whether one operation happens before another operation is the key to defining what concurrency means. <strong>We can simply say that to operations are <em>concurrent</em> if neither happens before the other.</strong> Either A happened before B, or B happened before A, or A and B are concurrent.</li>
</ul>
<h5 id="capturing-the-happens-before-relationship" style="position:relative;"><a href="#capturing-the-happens-before-relationship" aria-label="capturing the happens before relationship permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Capturing the happens-before relationship</h5>
<p>The server can determine whether two operations are concurrent by looking at the version numbers.</p>
<ul>
<li>The server maintains a version number for every key, increments the version number every time that key is written, and stores the new version number along the value written.</li>
<li>Client reads a key, the server returns all values that have not been overwrite, as well as the latest version number. A client must read a key before writing.</li>
<li>Client writes a key, it must include the version number from the prior read, and it must merge together all values that it received in the prior read.</li>
<li>Server receives a write with a particular version number, it can overwrite all values with that version number or below, but it must keep all values with a higher version number.</li>
</ul>
<h5 id="merging-concurrently-written-values" style="position:relative;"><a href="#merging-concurrently-written-values" aria-label="merging concurrently written values permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Merging concurrently written values</h5>
<p>No data is silently dropped. It requires clients do some extra work, they have to clean up afterward by merging the concurrently written values. Riak calls these concurrent values <em>siblings</em>.</p>
<p>Merging sibling values is the same problem as conflict resolution in multi-leader replication. A simple approach is to just pick one of the values on a version number or timestamp (last write wins). You may need to do something more intelligent in application code to avoid losing data.</p>
<p>If you want to allow people to <em>remove</em> things, union of siblings may not yield the right result. An item cannot simply be deleted from the database when it is removed, the system must leave a marker with an appropriate version number to indicate that the item has been removed when merging siblings (<em>tombstone</em>).</p>
<p>Merging siblings in application code is complex and error-prone, there are efforts to design data structures that can perform this merging automatically (CRDTs).</p>
<h4 id="version-vectors" style="position:relative;"><a href="#version-vectors" aria-label="version vectors permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Version vectors</h4>
<p>We need a version number <em>per replica</em> as well as per key. Each replica increments its own version number when processing a write, and also keeps track of the version numbers it has seen from each of the other replicas.</p>
<p>The collection of version numbers from all the replicas is called a <em>version vector</em>.</p>
<p>Version vector are sent from the database replicas to clients when values are read, and need to be sent back to the database when a value is subsequently written. Riak calls this <em>casual context</em>. Version vectors allow the database to distinguish between overwrites and concurrent writes.</p>
<h2 id="partitioning" style="position:relative;"><a href="#partitioning" aria-label="partitioning permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Partitioning</h2>
<p>Replication, for very large datasets or very high query throughput is not sufficient, we need to break the data up into <em>partitions</em> (<em>sharding</em>).</p>
<p>Basically, each partition is a small database of its own.</p>
<p>The main reason for wanting to partition data is <em>scalability</em>, query load can be load cabe distributed across many processors. Throughput can be scaled by adding more nodes.</p>
<h3 id="partitioning-and-replication" style="position:relative;"><a href="#partitioning-and-replication" aria-label="partitioning and replication permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Partitioning and replication</h3>
<p>Each record belongs to exactly one partition, it may still be stored on several nodes for fault tolerance.</p>
<p>A node may store more than one partition.</p>
<h3 id="partition-of-key-value-data" style="position:relative;"><a href="#partition-of-key-value-data" aria-label="partition of key value data permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Partition of key-value data</h3>
<p>Our goal with partitioning is to spread the data and the query load evenly across nodes.</p>
<p>If partition is unfair, we call it <em>skewed</em>. It makes partitioning much less effective. A partition with disproportionately high load is called a <em>hot spot</em>.</p>
<p>The simplest approach is to assign records to nodes randomly. The main disadvantage is that if you are trying to read a particular item, you have no way of knowing which node it is on, so you have to query all nodes in parallel.</p>
<h4 id="partition-by-key-range" style="position:relative;"><a href="#partition-by-key-range" aria-label="partition by key range permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Partition by key range</h4>
<p>Assign a continuous range of keys, like the volumes of a paper encyclopaedia. Boundaries might be chose manually by an administrator, or the database can choose them automatically. On each partition, keys are in sorted order so scans are easy.</p>
<p>The downside is that certain access patterns can lead to hot spots.</p>
<h4 id="partitioning-by-hash-of-key" style="position:relative;"><a href="#partitioning-by-hash-of-key" aria-label="partitioning by hash of key permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Partitioning by hash of key</h4>
<p>A good hash function takes skewed data and makes it uniformly distributed. There is no need to be cryptographically strong (MongoDB uses MD5 and Cassandra uses Murmur3). You can assign each partition a range of hashes. The boundaries can be evenly spaced or they can be chosen pseudorandomly (<em>consistent hashing</em>).</p>
<p>Unfortunately we lose the ability to do efficient range queries. Keys that were once adjacent are now scattered across all the partitions. Any range query has to be sent to all partitions.</p>
<h4 id="skewed-workloads-and-relieving-hot-spots" style="position:relative;"><a href="#skewed-workloads-and-relieving-hot-spots" aria-label="skewed workloads and relieving hot spots permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Skewed workloads and relieving hot spots</h4>
<p>You can’t avoid hot spots entirely. For example, you may end up with large volume of writes to the same key.</p>
<p>It’s the responsibility of the application to reduce the skew. A simple technique is to add a random number to the beginning or end of the key.</p>
<p>Splitting writes across different keys, makes reads now to do some extra work and combine them.</p>
<h3 id="partitioning-and-secondary-indexes" style="position:relative;"><a href="#partitioning-and-secondary-indexes" aria-label="partitioning and secondary indexes permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Partitioning and secondary indexes</h3>
<p>The situation gets more complicated if secondary indexes are involved. A secondary index usually doesn’t identify the record uniquely. They don’t map neatly to partitions.</p>
<h4 id="partitioning-secondary-indexes-by-document" style="position:relative;"><a href="#partitioning-secondary-indexes-by-document" aria-label="partitioning secondary indexes by document permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Partitioning secondary indexes by document</h4>
<p>Each partition maintains its secondary indexes, covering only the documents in that partition (<em>local index</em>).</p>
<p>You need to send the query to <em>all</em> partitions, and combine all the results you get back (<em>scatter/gather</em>). This is prone to tail latency amplification and is widely used in MongoDB, Riak, Cassandra, Elasticsearch, SolrCloud and VoltDB.</p>
<h4 id="partitioning-secondary-indexes-by-term" style="position:relative;"><a href="#partitioning-secondary-indexes-by-term" aria-label="partitioning secondary indexes by term permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Partitioning secondary indexes by term</h4>
<p>We construct a <em>global index</em> that covers data in all partitions. The global index must also be partitioned so it doesn’t become the bottleneck.</p>
<p>It is called the <em>term-partitioned</em> because the term we’re looking for determines the partition of the index.</p>
<p>Partitioning by term can be useful for range scans, whereas partitioning on a hash of the term gives a more even distribution load.</p>
<p>The advantage is that it can make reads more efficient: rather than doing scatter/gather over all partitions, a client only needs to make a request to the partition containing the term that it wants. The downside of a global index is that writes are slower and complicated.</p>
<h3 id="rebalancing-partitions" style="position:relative;"><a href="#rebalancing-partitions" aria-label="rebalancing partitions permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Rebalancing partitions</h3>
<p>The process of moving load from one node in the cluster to another.</p>
<p>Strategies for rebalancing:</p>
<ul>
<li><strong>How not to do it: Hash mod n.</strong> The problem with <em>mod N</em> is that if the number of nodes <em>N</em> changes, most of the keys will need to be moved from one node to another.</li>
<li><strong>Fixed number of partitions.</strong> Create many more partitions than there are nodes and assign several partitions to each node. If a node is added to the cluster, we can <em>steal</em> a few partitions from every existing node until partitions are fairly distributed once again. The number of partitions does not change, nor does the assignment of keys to partitions. The only thing that change is the assignment of partitions to nodes. This is used in Riak, Elasticsearch, Couchbase, and Voldemport. <strong>You need to choose a high enough number of partitions to accomodate future growth.</strong> Neither too big or too small.</li>
<li><strong>Dynamic partitioning.</strong> The number of partitions adapts to the total data volume. An empty database starts with an empty partition. While the dataset is small, all writes have to processed by a single node while the others nodes sit idle. HBase and MongoDB allow an initial set of partitions to be configured (<em>pre-splitting</em>).</li>
<li><strong>Partitioning proportionally to nodes.</strong> Cassandra and Ketama make the number of partitions proportional to the number of nodes. Have a fixed number of partitions <em>per node</em>. This approach also keeps the size of each partition fairly stable.</li>
</ul>
<h4 id="automatic-versus-manual-rebalancing" style="position:relative;"><a href="#automatic-versus-manual-rebalancing" aria-label="automatic versus manual rebalancing permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Automatic versus manual rebalancing</h4>
<p>Fully automated rebalancing may seem convenient but the process can overload the network or the nodes and harm the performance of other requests while the rebalancing is in progress.</p>
<p>It can be good to have a human in the loop for rebalancing. You may avoid operational surprises.</p>
<h3 id="request-routing" style="position:relative;"><a href="#request-routing" aria-label="request routing permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Request routing</h3>
<p>This problem is also called <em>service discovery</em>. There are different approaches:</p>
<ol>
<li>Allow clients to contact any node and make them handle the request directly, or forward the request to the appropriate node.</li>
<li>Send all requests from clients to a routing tier first that acts as a partition-aware load balancer.</li>
<li>Make clients aware of the partitioning and the assignment of partitions to nodes.</li>
</ol>
<p>In many cases the problem is: how does the component making the routing decision learn about changes in the assignment of partitions to nodes?</p>
<p>Many distributed data systems rely on a separate coordination service such as ZooKeeper to keep track of this cluster metadata. Each node registers itself in ZooKeeper, and ZooKeeper maintains the authoritative mapping of partitions to nodes. The routing tier or the partitioning-aware client, can subscribe to this information in ZooKeeper. HBase, SolrCloud and Kafka use ZooKeeper to track partition assignment. MongoDB relies on its own <em>config server</em>. Cassandra and Riak take a different approach: they use a <em>gossip protocol</em>.</p>
<h4 id="parallel-query-execution" style="position:relative;"><a href="#parallel-query-execution" aria-label="parallel query execution permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Parallel query execution</h4>
<p><em>Massively parallel processing</em> (MPP) relational database products are much more sophisticated in the types of queries they support.</p>
<h2 id="transactions" style="position:relative;"><a href="#transactions" aria-label="transactions permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Transactions</h2>
<p>Implementing fault-tolerant mechanisms is a lot of work.</p>
<h3 id="the-slippery-concept-of-a-transaction" style="position:relative;"><a href="#the-slippery-concept-of-a-transaction" aria-label="the slippery concept of a transaction permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>The slippery concept of a transaction</h3>
<p><em>Transactions</em> have been the mechanism of choice for simplifying these issues. Conceptually, all the reads and writes in a transaction are executed as one operation: either the entire transaction succeeds (<em>commit</em>) or it fails (<em>abort</em>, <em>rollback</em>).</p>
<p>The application is free to ignore certain potential error scenarios and concurrency issues (<em>safety guarantees</em>).</p>
<h4 id="acid" style="position:relative;"><a href="#acid" aria-label="acid permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>ACID</h4>
<ul>
<li><strong>Atomicity.</strong> Is <em>not</em> about concurrency. It is what happens if a client wants to make several writes, but a fault occurs after some of the writes have been processed. <em>Abortability</em> would have been a better term than <em>atomicity</em>.</li>
<li><strong>Consistency.</strong> <em>Invariants</em> on your data must always be true. The idea of consistency depends on the application’s notion of invariants. Atomicity, isolation, and durability are properties of the database, whereas consistency (in an ACID sense) is a property of the application.</li>
<li><strong>Isolation.</strong> Concurrently executing transactions are isolated from each other. It’s also called <em>serializability</em>, each transaction can pretend that it is the only transaction running on the entire database, and the result is the same as if they had run <em>serially</em> (one after the other).</li>
<li><strong>Durability.</strong> Once a transaction has committed successfully, any data it has written will not be forgotten, even if there is a hardware fault or the database crashes. In a single-node database this means the data has been written to nonvolatile storage. In a replicated database it means the data has been successfully copied to some number of nodes.</li>
</ul>
<p>Atomicity can be implemented using a log for crash recovery, and isolation can be implemented using a lock on each object, allowing only one thread to access an object at any one time.</p>
<p><strong>A transaction is a mechanism for grouping multiple operations on multiple objects into one unit of execution.</strong></p>
<h4 id="handling-errors-and-aborts" style="position:relative;"><a href="#handling-errors-and-aborts" aria-label="handling errors and aborts permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Handling errors and aborts</h4>
<p>A key feature of a transaction is that it can be aborted and safely retried if an error occurred.</p>
<p>In datastores with leaderless replication is the application’s responsibility to recover from errors.</p>
<p>The whole point of aborts is to enable safe retries.</p>
<h3 id="weak-isolation-levels" style="position:relative;"><a href="#weak-isolation-levels" aria-label="weak isolation levels permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Weak isolation levels</h3>
<p>Concurrency issues (race conditions) come into play when one transaction reads data that is concurrently modified by another transaction, or when two transactions try to simultaneously modify the same data.</p>
<p>Databases have long tried to hide concurrency issues by providing <em>transaction isolation</em>.</p>
<p>In practice, is not that simple. Serializable isolation has a performance cost. It’s common for systems to use weaker levels of isolation, which protect against <em>some</em> concurrency issues, but not all.</p>
<p>Weak isolation levels used in practice:</p>
<h4 id="read-committed" style="position:relative;"><a href="#read-committed" aria-label="read committed permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Read committed</h4>
<p>It makes two guarantees:</p>
<ol>
<li>When reading from the database, you will only see data that has been committed (no <em>dirty reads</em>). Writes by a transaction only become visible to others when that transaction commits.</li>
<li>When writing to the database, you will only overwrite data that has been committed (no <em>dirty writes</em>). Dirty writes are prevented usually by delaying the second write until the first write’s transaction has committed or aborted.</li>
</ol>
<p>Most databases prevent dirty writes by using row-level locks that hold the lock until the transaction is committed or aborted. Only one transaction can hold the lock for any given object.</p>
<p>On dirty reads, requiring read locks does not work well in practice as one long-running write transaction can force many read-only transactions to wait. For every object that is written, the database remembers both the old committed value and the new value set by the transaction that currently holds the write lock. While the transaction is ongoing, any other transactions that read the object are simply given the old value.</p>
<h4 id="snapshot-isolation-and-repeatable-read" style="position:relative;"><a href="#snapshot-isolation-and-repeatable-read" aria-label="snapshot isolation and repeatable read permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Snapshot isolation and repeatable read</h4>
<p>There are still plenty of ways in which you can have concurrency bugs when using this isolation level.</p>
<p><em>Nonrepeatable read</em> or <em>read skew</em>, when you read at the same time you committed a change you may see temporal and inconsistent results.</p>
<p>There are some situations that cannot tolerate such temporal inconsistencies:</p>
<ul>
<li><strong>Backups.</strong> During the time that the backup process is running, writes will continue to be made to the database. If you need to restore from such a backup, inconsistencies can become permanent.</li>
<li><strong>Analytic queries and integrity checks.</strong> You may get nonsensical results if they observe parts of the database at different points in time.</li>
</ul>
<p><em>Snapshot isolation</em> is the most common solution. Each transaction reads from a <em>consistent snapshot</em> of the database.</p>
<p>The implementation of snapshots typically use write locks to prevent dirty writes.</p>
<p>The database must potentially keep several different committed versions of an object (<em>multi-version concurrency control</em> or MVCC).</p>
<p>Read committed uses a separate snapshot for each query, while snapshot isolation uses the same snapshot for an entire transaction.</p>
<p>How do indexes work in a multi-version database? One option is to have the index simply point to all versions of an object and require an index query to filter out any object versions that are not visible to the current transaction.</p>
<p>Snapshot isolation is called <em>serializable</em> in Oracle, and <em>repeatable read</em> in PostgreSQL and MySQL.</p>
<h4 id="preventing-lost-updates" style="position:relative;"><a href="#preventing-lost-updates" aria-label="preventing lost updates permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Preventing lost updates</h4>
<p>This might happen if an application reads some value from the database, modifies it, and writes it back. If two transactions do this concurrently, one of the modifications can be lost (later write <em>clobbers</em> the earlier write).</p>
<h5 id="atomic-write-operations" style="position:relative;"><a href="#atomic-write-operations" aria-label="atomic write operations permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Atomic write operations</h5>
<p>A solution for this it to avoid the need to implement read-modify-write cycles and provide atomic operations such us</p>
<div class="gatsby-highlight" data-language="sql"><pre class="language-sql"><code class="language-sql"><span class="token keyword">UPDATE</span> counters <span class="token keyword">SET</span> <span class="token keyword">value</span> <span class="token operator">=</span> <span class="token keyword">value</span> <span class="token operator">+</span> <span class="token number">1</span> <span class="token keyword">WHERE</span> <span class="token keyword">key</span> <span class="token operator">=</span> <span class="token string">'foo'</span><span class="token punctuation">;</span></code></pre></div>
<p>MongoDB provides atomic operations for making local modifications, and Redis provides atomic operations for modifying data structures.</p>
<h5 id="explicit-locking" style="position:relative;"><a href="#explicit-locking" aria-label="explicit locking permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Explicit locking</h5>
<p>The application explicitly lock objects that are going to be updated.</p>
<h5 id="automatically-detecting-lost-updates" style="position:relative;"><a href="#automatically-detecting-lost-updates" aria-label="automatically detecting lost updates permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Automatically detecting lost updates</h5>
<p>Allow them to execute in parallel, if the transaction manager detects a lost update, abort the transaction and force it to retry its read-modify-write cycle.</p>
<p>MySQL/InnoDB’s repeatable read does not detect lost updates.</p>
<h5 id="compare-and-set" style="position:relative;"><a href="#compare-and-set" aria-label="compare and set permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Compare-and-set</h5>
<p>If the current value does not match with what you previously read, the update has no effect.</p>
<div class="gatsby-highlight" data-language="sql"><pre class="language-sql"><code class="language-sql"><span class="token keyword">UPDATE</span> wiki_pages <span class="token keyword">SET</span> content <span class="token operator">=</span> <span class="token string">'new content'</span>
  <span class="token keyword">WHERE</span> id <span class="token operator">=</span> <span class="token number">1234</span> <span class="token operator">AND</span> content <span class="token operator">=</span> <span class="token string">'old content'</span><span class="token punctuation">;</span></code></pre></div>
<h5 id="conflict-resolution-and-replication" style="position:relative;"><a href="#conflict-resolution-and-replication" aria-label="conflict resolution and replication permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Conflict resolution and replication</h5>
<p>With multi-leader or leaderless replication, compare-and-set do not apply.</p>
<p>A common approach in replicated databases is to allow concurrent writes to create several conflicting versions of a value (also know as <em>siblings</em>), and to use application code or special data structures to resolve and merge these versions after the fact.</p>
<h4 id="write-skew-and-phantoms" style="position:relative;"><a href="#write-skew-and-phantoms" aria-label="write skew and phantoms permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Write skew and phantoms</h4>
<p>Imagine Alice and Bob are two on-call doctors for a particular shift. Imagine both the request to leave because they are feeling unwell. Unfortunately they happen to click the button to go off call at approximately the same time.</p>
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">ALICE                                   BOB

┌─ BEGIN TRANSACTION                    ┌─ BEGIN TRANSACTION
│                                       │
├─ currently_on_call = (                ├─ currently_on_call = (
│   select count(*) from doctors        │    select count(*) from doctors
│   where on_call = true                │    where on_call = true
│   and shift_id = 1234                 │    and shift_id = 1234
│  )                                    │  )
│  // now currently_on_call = 2         │  // now currently_on_call = 2
│                                       │
├─ if (currently_on_call  2) {          │
│    update doctors                     │
│    set on_call = false                │
│    where name = 'Alice'               │
│    and shift_id = 1234                ├─ if (currently_on_call >= 2) {
│  }                                    │    update doctors
│                                       │    set on_call = false
└─ COMMIT TRANSACTION                   │    where name = 'Bob'  
                                        │    and shift_id = 1234
                                        │  }
                                        │
                                        └─ COMMIT TRANSACTION</code></pre></div>
<p>Since database is using snapshot isolation, both checks return 2. Both transactions commit, and now no doctor is on call. The requirement of having at least one doctor has been violated.</p>
<p>Write skew can occur if two transactions read the same objects, and then update some of those objects. You get a dirty write or lost update anomaly.</p>
<p>Ways to prevent write skew are a bit more restricted:</p>
<ul>
<li>Atomic operations don’t help as things involve more objects.</li>
<li>Automatically prevent write skew requires true serializable isolation.</li>
<li>The second-best option in this case is probably to explicitly lock the rows that the transaction depends on.
<div class="gatsby-highlight" data-language="sql"><pre class="language-sql"><code class="language-sql"><span class="token keyword">BEGIN</span> <span class="token keyword">TRANSACTION</span><span class="token punctuation">;</span>

<span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> doctors
<span class="token keyword">WHERE</span> on_call <span class="token operator">=</span> <span class="token boolean">true</span>
<span class="token operator">AND</span> shift_id <span class="token operator">=</span> <span class="token number">1234</span> <span class="token keyword">FOR</span> <span class="token keyword">UPDATE</span><span class="token punctuation">;</span>

<span class="token keyword">UPDATE</span> doctors
<span class="token keyword">SET</span> on_call <span class="token operator">=</span> <span class="token boolean">false</span>
<span class="token keyword">WHERE</span> name <span class="token operator">=</span> <span class="token string">'Alice'</span>
<span class="token operator">AND</span> shift_id <span class="token operator">=</span> <span class="token number">1234</span><span class="token punctuation">;</span>

<span class="token keyword">COMMIT</span><span class="token punctuation">;</span></code></pre></div>
</li>
</ul>
<h3 id="serializability" style="position:relative;"><a href="#serializability" aria-label="serializability permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Serializability</h3>
<p>This is the strongest isolation level. It guarantees that even though transactions may execute in parallel, the end result is the same as if they had executed one at a time, <em>serially</em>, without concurrency. Basically, the database prevents <em>all</em> possible race conditions.</p>
<p>There are three techniques for achieving this:</p>
<ul>
<li>Executing transactions in serial order</li>
<li>Two-phase locking</li>
<li>Serializable snapshot isolation.</li>
</ul>
<h4 id="actual-serial-execution" style="position:relative;"><a href="#actual-serial-execution" aria-label="actual serial execution permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Actual serial execution</h4>
<p>The simplest way of removing concurrency problems is to remove concurrency entirely and execute only one transaction at a time, in serial order, on a single thread. This approach is implemented by VoltDB/H-Store, Redis and Datomic.</p>
<h5 id="encapsulating-transactions-in-stored-procedures" style="position:relative;"><a href="#encapsulating-transactions-in-stored-procedures" aria-label="encapsulating transactions in stored procedures permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Encapsulating transactions in stored procedures</h5>
<p>With interactive style of transaction, a lot of time is spent in network communication between the application and the database.</p>
<p>For this reason, systems with single-threaded serial transaction processing don’t allow interactive multi-statement transactions. The application must submit the entire transaction code to the database ahead of time, as a <em>stored procedure</em>, so all the data required by the transaction is in memory and the procedure can execute very fast.</p>
<p>There are a few pros and cons for stored procedures:</p>
<ul>
<li>Each database vendor has its own language for stored procedures. They usually look quite ugly and archaic from today’s point of view, and they lack the ecosystem of libraries.</li>
<li>It’s harder to debug, more awkward to keep in version control and deploy, trickier to test, and difficult to integrate with monitoring.</li>
</ul>
<p>Modern implementations of stored procedures include general-purpose programming languages instead: VoltDB uses Java or Groovy, Datomic uses Java or Clojure, and Redis uses Lua.</p>
<h5 id="partitioning-1" style="position:relative;"><a href="#partitioning-1" aria-label="partitioning 1 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Partitioning</h5>
<p>Executing all transactions serially limits the transaction throughput to the speed of a single CPU.</p>
<p>In order to scale to multiple CPU cores you can potentially partition your data and each partition can have its own transaction processing thread. You can give each CPU core its own partition.</p>
<p>For any transaction that needs to access multiple partitions, the database must coordinate the transaction across all the partitions. They will be vastly slower than single-partition transactions.</p>
<h4 id="two-phase-locking-2pl" style="position:relative;"><a href="#two-phase-locking-2pl" aria-label="two phase locking 2pl permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Two-phase locking (2PL)</h4>
<blockquote>
<p>Two-phase locking (2PL) sounds similar to two-phase <em>commit</em> (2PC) but be aware that they are completely different things.</p>
</blockquote>
<p>Several transactions are allowed to concurrently read the same object as long as nobody is writing it. When somebody wants to write (modify or delete) an object, exclusive access is required.</p>
<p>Writers don’t just block other writers; they also block readers and vice versa. It protects against all the race conditions discussed earlier.</p>
<p>Blocking readers and writers is implemented by a having lock on each object in the database. The lock is used as follows:</p>
<ul>
<li>if a transaction want sot read an object, it must first acquire a lock in shared mode.</li>
<li>If a transaction wants to write to an object, it must first acquire the lock in exclusive mode.</li>
<li>If a transaction first reads and then writes an object, it may upgrade its shared lock to an exclusive lock.</li>
<li>After a transaction has acquired the lock, it must continue to hold the lock until the end of the transaction (commit or abort). <strong>First phase is when the locks are acquired, second phase is when all the locks are released.</strong></li>
</ul>
<p>It can happen that transaction A is stuck waiting for transaction B to release its lock, and vice versa (<em>deadlock</em>).</p>
<p><strong>The performance for transaction throughput and response time of queries are significantly worse under two-phase locking than under weak isolation.</strong></p>
<p>A transaction may have to wait for several others to complete before it can do anything.</p>
<p>Databases running 2PL can have unstable latencies, and they can be very slow at high percentiles. One slow transaction, or one transaction that accesses a lot of data and acquires many locks can cause the rest of the system to halt.</p>
<h5 id="predicate-locks" style="position:relative;"><a href="#predicate-locks" aria-label="predicate locks permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Predicate locks</h5>
<p>With <em>phantoms</em>, one transaction may change the results of another transaction’s search query.</p>
<p>In order to prevent phantoms, we need a <em>predicate lock</em>. Rather than a lock belonging to a particular object, it belongs to all objects that match some search condition.</p>
<p>Predicate locks applies even to objects that do not yet exist in the database, but which might be added in the future (phantoms).</p>
<h5 id="index-range-locks" style="position:relative;"><a href="#index-range-locks" aria-label="index range locks permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Index-range locks</h5>
<p>Predicate locks do not perform well. Checking for matching locks becomes time-consuming and for that reason most databases implement <em>index-range locking</em>.</p>
<p>It’s safe to simplify a predicate by making it match a greater set of objects.</p>
<p>These locks are not as precise as predicate locks would be, but since they have much lower overheads, they are a good compromise.</p>
<h4 id="serializable-snapshot-isolation-ssi" style="position:relative;"><a href="#serializable-snapshot-isolation-ssi" aria-label="serializable snapshot isolation ssi permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Serializable snapshot isolation (SSI)</h4>
<p>It provides full serializability and has a small performance penalty compared to snapshot isolation. SSI is fairly new and might become the new default in the future.</p>
<h5 id="pesimistic-versus-optimistic-concurrency-control" style="position:relative;"><a href="#pesimistic-versus-optimistic-concurrency-control" aria-label="pesimistic versus optimistic concurrency control permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Pesimistic versus optimistic concurrency control</h5>
<p>Two-phase locking is called <em>pessimistic</em> concurrency control because if anything might possibly go wrong, it’s better to wait.</p>
<p>Serial execution is also <em>pessimistic</em> as is equivalent to each transaction having an exclusive lock on the entire database.</p>
<p>Serializable snapshot isolation is <em>optimistic</em> concurrency control technique. Instead of blocking if something potentially dangerous happens, transactions continue anyway, in the hope that everything will turn out all right. The database is responsible for checking whether anything bad happened. If so, the transaction is aborted and has to be retried.</p>
<p>If there is enough spare capacity, and if contention between transactions is not too high, optimistic concurrency control techniques tend to perform better than pessimistic ones.</p>
<p>SSI is based on snapshot isolation, reads within a transaction are made from a consistent snapshot of the database. On top of snapshot isolation, SSI adds an algorithm for detecting serialization conflicts among writes and determining which transactions to abort.</p>
<p>The database knows which transactions may have acted on an outdated premise and need to be aborted by:</p>
<ul>
<li><strong>Detecting reads of a stale MVCC object version.</strong> The database needs to track when a transaction ignores another transaction’s writes due to MVCC visibility rules. When a transaction wants to commit, the database checks whether any of the ignored writes have now been committed. If so, the transaction must be aborted.</li>
<li><strong>Detecting writes that affect prior reads.</strong> As with two-phase locking, SSI uses index-range locks except that it does not block other transactions. When a transaction writes to the database, it must look in the indexes for any other transactions that have recently read the affected data. It simply notifies the transactions that the data they read may no longer be up to date.</li>
</ul>
<h5 id="performance-of-serializable-snapshot-isolation" style="position:relative;"><a href="#performance-of-serializable-snapshot-isolation" aria-label="performance of serializable snapshot isolation permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Performance of serializable snapshot isolation</h5>
<p>Compared to two-phase locking, the big advantage of SSI is that one transaction doesn’t need to block waiting for locks held by another transaction. Writers don’t block readers, and vice versa.</p>
<p>Compared to serial execution, SSI is not limited to the throughput of a single CPU core. Transactions can read and write data in multiple partitions while ensuring serializable isolation.</p>
<p>The rate of aborts significantly affects the overall performance of SSI. SSI requires that read-write transactions be fairly short (long-running read-only transactions may be okay).</p>
<h2 id="the-trouble-with-distributed-systems" style="position:relative;"><a href="#the-trouble-with-distributed-systems" aria-label="the trouble with distributed systems permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>The trouble with distributed systems</h2>
<h3 id="faults-and-partial-failures" style="position:relative;"><a href="#faults-and-partial-failures" aria-label="faults and partial failures permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Faults and partial failures</h3>
<p>A program on a single computer either works or it doesn’t. There is no reason why software should be flaky (non deterministic).</p>
<p>In a distributed systems we have no choice but to confront the messy reality of the physical world. There will be parts that are broken in an unpredictable way, while others work. Partial failures are <em>nondeterministic</em>. Things will unpredicably fail.</p>
<p>We need to accept the possibility of partial failure and build fault-tolerant mechanism into the software. <strong>We need to build a reliable system from unreliable components.</strong></p>
<h3 id="unreliable-networks" style="position:relative;"><a href="#unreliable-networks" aria-label="unreliable networks permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Unreliable networks</h3>
<p>Focusing on <em>shared-nothing systems</em> the network is the only way machines communicate.</p>
<p>The internet and most internal networks are <em>asynchronous packet networks</em>. A message is sent and the network gives no guarantees as to when it will arrive, or whether it will arrive at all. Things that could go wrong:</p>
<ol>
<li>Request lost</li>
<li>Request waiting in a queue to be delivered later</li>
<li>Remote node may have failed</li>
<li>Remote node may have temporarily stoped responding</li>
<li>Response has been lost on the network</li>
<li>The response has been delayed and will be delivered later</li>
</ol>
<p>If you send a request to another node and don’t receive a response, it is <em>impossible</em> to tell why.</p>
<p><strong>The usual way of handling this issue is a <em>timeout</em></strong>: after some time you give up waiting and assume that the response is not going to arrive.</p>
<p>Nobody is immune to network problems. You do need to know how your software reacts to network problems to ensure that the system can recover from them. It may make sense to deliberately trigger network problems and test the system’s response.</p>
<p>If you want to be sure that a request was successful, you need a positive response from the application itself.</p>
<p>If something has gone wrong, you have to assume that you will get no response at all.</p>
<h4 id="timeouts-and-unbounded-delays" style="position:relative;"><a href="#timeouts-and-unbounded-delays" aria-label="timeouts and unbounded delays permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Timeouts and unbounded delays</h4>
<p>A long timeout means a long wait until a node is declared dead. A short timeout detects faults faster, but carries a higher risk of incorrectly declaring a node dead (when it could be a slowdown).</p>
<p>Premature declaring a node is problematic, if the node is actually alive the action may end up being performed twice.</p>
<p>When a node is declared dead, its responsibilities need to be transferred to other nodes, which places additional load on other nodes and the network.</p>
<h4 id="network-congestion-and-queueing" style="position:relative;"><a href="#network-congestion-and-queueing" aria-label="network congestion and queueing permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Network congestion and queueing</h4>
<ul>
<li>Different nodes try to send packets simultaneously to the same destination, the network switch must queue them and feed them to the destination one by one. The switch will discard packets when filled up.</li>
<li>If CPU cores are busy, the request is queued by the operative system, until applications are ready to handle it.</li>
<li>In virtual environments, the operative system is often paused while another virtual machine uses a CPU core. The VM queues the incoming data.</li>
<li>TCP performs <em>flow control</em>, in which a node limits its own rate of sending in order to avoid overloading a network link or the receiving node. This means additional queuing at the sender.</li>
</ul>
<p>You can choose timeouts experimentally by measuring the distribution of network round-trip times over an extended period.</p>
<p>Systems can continually measure response times and their variability (<em>jitter</em>), and automatically adjust timeouts according to the observed response time distribution.</p>
<h4 id="synchronous-vs-ashynchronous-networks" style="position:relative;"><a href="#synchronous-vs-ashynchronous-networks" aria-label="synchronous vs ashynchronous networks permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Synchronous vs ashynchronous networks</h4>
<p>A telephone network estabilishes a <em>circuit</em>, we say is <em>synchronous</em> even as the data passes through several routers as it does not suffer from queing. The maximum end-to-end latency of the network is fixed (<em>bounded delay</em>).</p>
<p>A circuit is a fixed amount of reserved bandwidth which nobody else can use while the circuit is established, whereas packets of a TCP connection opportunistically use whatever network bandwidth is available.</p>
<p><strong>Using circuits for bursty data transfers wastes network capacity and makes transfer unnecessary slow. By contrast, TCP dinamycally adapts the rate of data transfer to the available network capacity.</strong></p>
<p>We have to assume that network congestion, queueing, and unbounded delays will happen. Consequently, there’s no “correct” value for timeouts, they need to be determined experimentally.</p>
<h3 id="unreliable-clocks" style="position:relative;"><a href="#unreliable-clocks" aria-label="unreliable clocks permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Unreliable clocks</h3>
<p>The time when a message is received is always later than the time when it is sent, we don’t know how much later due to network delays. This makes difficult to determine the order of which things happened when multiple machines are involved.</p>
<p>Each machine on the network has its own clock, slightly faster or slower than the other machines. It is possible to synchronise clocks with Network Time Protocol (NTP).</p>
<ul>
<li><strong>Time-of-day clocks</strong>. Return the current date and time according to some calendar (<em>wall-clock time</em>). If the local clock is toof ar ahead of the NTP server, it may be forcibly reset and appear to jump back to a previous point in time. <strong>This makes it is unsuitable for measuring elapsed time.</strong></li>
<li><strong>Monotonic clocks</strong>. Peg: <code class="language-text">System.nanoTime()</code>. They are guaranteed to always move forward. The difference between clock reads can tell you how much time elapsed beween two checks. <strong>The <em>absolute</em> value of the clock is meaningless.</strong> NTP allows the clock rate to be speeded up or slowed down by up to 0.05%, but <strong>NTP cannot cause the monotonic clock to jump forward or backward</strong>. <strong>In a distributed system, using a monotonic clock for measuring elapsed time (peg: timeouts), is usually fine</strong>.</li>
</ul>
<p>If some piece of sofware is relying on an accurately synchronised clock, the result is more likely to be silent and subtle data loss than a dramatic crash.</p>
<p>You need to carefully monitor the clock offsets between all the machines.</p>
<h4 id="timestamps-for-ordering-events" style="position:relative;"><a href="#timestamps-for-ordering-events" aria-label="timestamps for ordering events permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Timestamps for ordering events</h4>
<p><strong>It is tempting, but dangerous to rely on clocks for ordering of events across multiple nodes.</strong> This usually imply that <em>last write wins</em> (LWW), often used in both multi-leader replication and leaderless databases like Cassandra and Riak, and data-loss may happen.</p>
<p>The definition of “recent” also depends on local time-of-day clock, which may well be incorrect.</p>
<p><em>Logical clocks</em>, based on counters instead of oscillating quartz crystal, are safer alternative for ordering events. Logical clocks do not measure time of the day or elapsed time, only relative ordering of events. This contrasts with time-of-the-day and monotic clocks (also known as <em>physical clocks</em>).</p>
<h4 id="clock-readings-have-a-confidence-interval" style="position:relative;"><a href="#clock-readings-have-a-confidence-interval" aria-label="clock readings have a confidence interval permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Clock readings have a confidence interval</h4>
<p>It doesn’t make sense to think of a clock reading as a point in time, it is more like a range of times, within a confidence internval: for example, 95% confident that the time now is between 10.3 and 10.5.</p>
<p>The most common implementation of snapshot isolation requires a monotonically increasing transaction ID.</p>
<p>Spanner implements snapshot isolation across datacenters by using clock’s confidence interval. If you have two confidence internvals where</p>
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">A = [A earliest, A latest]
B = [B earliest, B latest]</code></pre></div>
<p>And those two intervals do not overlap (<code class="language-text">A earliest</code> &#x3C; <code class="language-text">A latest</code> &#x3C; <code class="language-text">B earliest</code> &#x3C; <code class="language-text">B latest</code>), then B definetively happened after A.</p>
<p>Spanner deliberately waits for the length of the confidence interval before commiting a read-write transaction, so their confidence intervals do not overlap.</p>
<p>Spanner needs to keep the clock uncertainty as small as possible, that’s why Google deploys a GPS receiver or atomic clock in each datacenter.</p>
<h4 id="process-pauses" style="position:relative;"><a href="#process-pauses" aria-label="process pauses permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Process pauses</h4>
<p>How does a node know that it is still leader?</p>
<p>One option is for the leader to obtain a <em>lease</em> from other nodes (similar ot a lock with a timeout). It will be the leader until the lease expires; to remain leader, the node must periodically renew the lease. If the node fails, another node can takeover when it expires.</p>
<p>We have to be very careful making assumptions about the time that has passed for processing requests (and holding the lease), as there are many reasons a process would be paused:</p>
<ul>
<li>Garbage collector (stop the world)</li>
<li>Virtual machine can be suspended</li>
<li>In laptops execution may be suspended</li>
<li>Operating system context-switches</li>
<li>Synchronous disk access</li>
<li>Swapping to disk (paging)</li>
<li>Unix process can be stopped (<code class="language-text">SIGSTOP</code>)</li>
</ul>
<p><strong>You cannot assume anything about timing</strong></p>
<h5 id="response-time-guarantees" style="position:relative;"><a href="#response-time-guarantees" aria-label="response time guarantees permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Response time guarantees</h5>
<p>There are systems that require software to respond before a specific <em>deadline</em> (<em>real-time operating system, or RTOS</em>).</p>
<p>Library functions must document their worst-case execution times; dynamic memory allocation may be restricted or disallowed and enormous amount of testing and measurement must be done.</p>
<p>Garbage collection could be treated like brief planned outages. If the runtime can warn the application that a node soon requires a GC pause, the application can stop sending new requests to that node and perform GC while no requests are in progress.</p>
<p>A variant of this idea is to use the garbage collector only for short-lived objects and to restart the process periodically.</p>
<h3 id="knowledge-truth-and-lies" style="position:relative;"><a href="#knowledge-truth-and-lies" aria-label="knowledge truth and lies permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Knowledge, truth and lies</h3>
<p>A node cannot necessarily trust its own judgement of a situation. Many distributed systems rely on a <em>quorum</em> (voting among the nodes).</p>
<p>Commonly, the quorum is an absolute majority of more than half of the nodes.</p>
<h4 id="fencing-tokens" style="position:relative;"><a href="#fencing-tokens" aria-label="fencing tokens permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Fencing tokens</h4>
<p>Assume every time the lock server grant sa lock or a lease, it also returns a <em>fencing token</em>, which is a number that increases every time a lock is granted (incremented by the lock service). Then we can require every time a client sends a write request to the storage service, it must include its current fencing token.</p>
<p>The storage server remembers that it has already processed a write with a higher token number, so it rejects the request with the last token.</p>
<p>If ZooKeeper is used as lock service, the transaciton ID <code class="language-text">zcid</code> or the node version <code class="language-text">cversion</code> can be used as a fencing token.</p>
<h4 id="byzantine-faults" style="position:relative;"><a href="#byzantine-faults" aria-label="byzantine faults permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Byzantine faults</h4>
<p>Fencing tokens can detect and block a node that is <em>inadvertently</em> acting in error.</p>
<p>Distributed systems become much harder if there is a risk that nodes may “lie” (<em>byzantine fault</em>).</p>
<p>A system is <em>Byzantine fault-tolerant</em> if it continues to operate correctly even if some of the nodes are malfunctioning.</p>
<ul>
<li>Aerospace environments</li>
<li>Multiple participating organisations, some participants may attempt ot cheat or defraud others</li>
</ul>
<h2 id="consistency-and-consensus" style="position:relative;"><a href="#consistency-and-consensus" aria-label="consistency and consensus permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Consistency and consensus</h2>
<p>The simplest way of handling faults is to simply let the entire service fail. We need to find ways of <em>tolerating</em> faults.</p>
<h3 id="consistency-guarantees" style="position:relative;"><a href="#consistency-guarantees" aria-label="consistency guarantees permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Consistency guarantees</h3>
<p>Write requests arrive on different nodes at different times.</p>
<p>Most replicated databases provide at least <em>eventual consistency</em>. The inconsistency is temporary, and eventually resolves itself (<em>convergence</em>).</p>
<p>With weak guarantees, you need to be constantly aware of its limitations. Systems with stronger guarantees may have worse performance or be less fault-tolerant than systems with weaker guarantees.</p>
<h3 id="linearizability" style="position:relative;"><a href="#linearizability" aria-label="linearizability permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Linearizability</h3>
<p>Make a system appear as if there were only one copy of the data, and all operaitons on it are atomic.</p>
<ul>
<li><code class="language-text">read(x) => v</code> Read from register <em>x</em>, database returns value <em>v</em>.</li>
<li><code class="language-text">write(x,v) => r</code> <em>r</em> could be <em>ok</em> or <em>error</em>.</li>
</ul>
<p>If one client read returns the new value, all subsequent reads must also return the new value.</p>
<ul>
<li><code class="language-text">cas(x_old, v_old, v_new) => r</code> an atomic <em>compare-and-set</em> operation. If the value of the register <em>x</em> equals <em>v_old</em>, it is atomically set to <em>v_new</em>. If <code class="language-text">x != v_old</code> the registers is unchanged and it returns an error.</li>
</ul>
<p><strong>Serializability</strong>: Transactions behave the same as if they had executed <em>some</em> serial order.</p>
<p><strong>Linearizability</strong>: Recency guarantee on reads and writes of a register (individual object).</p>
<h4 id="locking-and-leader-election" style="position:relative;"><a href="#locking-and-leader-election" aria-label="locking and leader election permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Locking and leader election</h4>
<p>To ensure that there is indeed only one leader, a lock is used. It must be linearizable: all nodes must agree which nodes owns the lock; otherwise is useless.</p>
<p>Apache ZooKeepr and etcd are often used for distributed locks and leader election.</p>
<h4 id="constraints-and-uniqueness-guarantees" style="position:relative;"><a href="#constraints-and-uniqueness-guarantees" aria-label="constraints and uniqueness guarantees permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Constraints and uniqueness guarantees</h4>
<p>Unique constraints, like a username or an email address require a situation similiar to a lock.</p>
<p>A hard uniqueness constraint in relational databases requires linearizability.</p>
<h4 id="implementing-linearizable-systems" style="position:relative;"><a href="#implementing-linearizable-systems" aria-label="implementing linearizable systems permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Implementing linearizable systems</h4>
<p>The simplest approach would be to have a single copy of the data, but this would not be able to tolerate faults.</p>
<ul>
<li>Single-leader repolication is potentially linearizable.</li>
<li>Consensus algorithms is linearizable.</li>
<li>Multi-leader replication is not linearizable.</li>
<li>Leaderless replication is probably not linearizable.</li>
</ul>
<p>Multi-leader replication is often a good choice for multi-datacenter replication. On a network interruption betwen data-centers will force a choice between linearizability and availability.</p>
<p>With multi-leader configuraiton, each data center can operate normally with interruptions.</p>
<p>With single-leader replication, the leader must be in one of the datacenters. If the application requires linearizable reads and writes, the network interruption causes the application to become unavailable.</p>
<ul>
<li>
<p>If your applicaiton <em>requires</em> linearizability, and some replicas are disconnected from the other replicas due to a network problem, the some replicas cannot process request while they are disconnected (unavailable).</p>
</li>
<li>
<p>If your application <em>does not require</em>, then it can be written in a way tha each replica can process requests independently, even if it is disconnected from other replicas (peg: multi-leader), becoming <em>available</em>.</p>
</li>
</ul>
<p><strong>If an application does not require linearizability it can be more tolerant of network problems.</strong></p>
<h4 id="the-unhelpful-cap-theorem" style="position:relative;"><a href="#the-unhelpful-cap-theorem" aria-label="the unhelpful cap theorem permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>The unhelpful CAP theorem</h4>
<p>CAP is sometimes presented as <em>Consistency, Availability, Partition tolerance: pick 2 out of 3</em>. Or being said in another way <em>either Consistency or Available when Partitioned</em>.</p>
<p>CAP only considers one consistency model (linearizability) and one kind of fault (<em>network partitions</em>, or nodes that are alive but disconnected from each other). It doesn’t say anything about network delays, dead nodes, or other trade-offs. CAP has been historically influential, but nowadays has little practical value for designing systems.</p>
<hr>
<p>The main reason for dropping linearizability is <em>performance</em>, not fault tolerance. Linearizabilit is slow and this is true all the time, not on only during a network fault.</p>
<h3 id="ordering-guarantees" style="position:relative;"><a href="#ordering-guarantees" aria-label="ordering guarantees permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Ordering guarantees</h3>
<p>Cause comes before the effect. Causal order in the system is what happened before what (<em>causally consistent</em>).</p>
<p><em>Total order</em> allows any two elements to be compared. Peg, natural numbers are totally ordered.</p>
<p>Some cases one set is greater than another one.</p>
<p>Different consistency models:</p>
<ul>
<li>Linearizablity. <em>total order</em> of operations: if the system behaves as if there is only a single copy of the data.</li>
<li>Causality. Two events are ordered if they are causally related. Causality defines <em>a partial order</em>, not a total one (incomparable if they are concurrent).</li>
</ul>
<p>Linearizability is not the only way of preserving causality. <strong>Causal consistency is the strongest possible consistency model that does not slow down due to network delays, and remains available in the face of network failures.</strong></p>
<p>You need to know which operation <em>happened before</em>.</p>
<p>In order to determine the causal ordering, the database needs to know which version of the data was read by the application. <strong>The version number from the prior operation is passed back to the database on a write.</strong></p>
<p>We can create sequence numbers in a total order that is <em>consistent with causality</em>.</p>
<p>With a single-leader replication, the leader can simply increment a counter for each operation, and thus assign a monotonically increasing sequence number to each operation in the replication log.</p>
<p>If there is not a single leader (multi-leader or leaderless database):</p>
<ul>
<li>Each node can generate its own independent set of sequence numbers. One node can generate only odd numbers and the other only even numbers.</li>
<li>Attach a timestamp from a time-of-day clock.</li>
<li>Preallocate blocks of sequence numbers.</li>
</ul>
<p>The only problem is that the sequence numbers they generate are <em>not consistent with causality</em>. They do not correctly capture ordering of operations across different nodes.</p>
<p>There is simple method for generating sequence numbers that <em>is</em> consistent with causality: <em>Lamport timestamps</em>.</p>
<p>Each node has a unique identifier, and each node keeps a counter of the number of operations it has processed. The lamport timestamp is then simply a pair of (<em>counter</em>, <em>node ID</em>). It provides total order, as if you have two timestamps one with a greater counter value is the greater timestamp. If the counter values are the same, the one with greater node ID is the greater timestamp.</p>
<p>Every node and every client keeps track of the <em>maximum</em> counter value it has seen so far, and includes that maximum on every request. When a node receives a request of response with a maximum counter value greater than its own counter value, it inmediately increases its own counter to that maximum.</p>
<p>As long as the maximum counter value is carried along with every operation, this scheme  ensure that the ordering from the lamport timestamp is consistent with causality.</p>
<p>Total order of oepration only emerges after you have collected all of the operations.</p>
<p>Total order broadcast:</p>
<ul>
<li>Reliable delivery: If a message is delivered to one node, it is delivered to all nodes.</li>
<li>Totally ordered delivery: Mesages are delivered to every node in the same order.</li>
</ul>
<p>ZooKeeper and etcd implement total order broadcast.</p>
<p>If every message represents a write to the database, and every replica processes the same writes in the same order, then the replcias will remain consistent with each other (<em>state machine replication</em>).</p>
<p>A node is not allowed to retroactgively insert a message into an earlier position in the order if subsequent messages have already been dlivered.</p>
<p>Another way of looking at total order broadcast is that it is a way of creating a <em>log</em>. Delivering a message is like appending to the log.</p>
<p>If you have total order broadcast, you can build linearizable storage on top of it.</p>
<p>Because log entries are delivered to all nodes in the same order, if therer are several concurrent writes, all nodes will agree on which one came first. Choosing the first of the conflicting writes as the winner and aborting later ones ensures that all nodes agree on whether a write was commited or aborted.</p>
<p>This procedure ensures linearizable writes, it doesn’t guarantee linearizable reads.</p>
<p>To make reads linearizable:</p>
<ul>
<li>You can sequence reads through the log by appending a message, reading the log, and performing the actual read when the message is delivered back to you (etcd works something like this).</li>
<li>Fetch the position of the latest log message in a linearizable way, you can query that position to be delivered to you, and then perform the read (idea behind ZooKeeper’s <code class="language-text">sync()</code>).</li>
<li>You can make your read from a replica that is synchronously updated on writes.</li>
</ul>
<p>For every message you want to send through total order broadcast, you increment-and-get the linearizable integer and then attach the value you got from the register as a sequence number to the message. YOu can send the message to all nodes, and the recipients will deliver the message consecutively by sequence number.</p>
<h3 id="distributed-transactions-and-consensus" style="position:relative;"><a href="#distributed-transactions-and-consensus" aria-label="distributed transactions and consensus permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Distributed transactions and consensus</h3>
<p>Basically <em>getting several nodes to agree on something</em>.</p>
<p>There are situations in which it is important for nodes to agree:</p>
<ul>
<li>Leader election: All nodes need to agree on which node is the leader.</li>
<li>Atomic commit: Get all nodes to agree on the outcome of the transacction, either they all abort or roll back.</li>
</ul>
<h4 id="atomic-commit-and-two-phase-commit-2pc" style="position:relative;"><a href="#atomic-commit-and-two-phase-commit-2pc" aria-label="atomic commit and two phase commit 2pc permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Atomic commit and two-phase commit (2PC)</h4>
<p>A transaction either succesfully <em>commit</em>, or <em>abort</em>. Atomicity prevents half-finished results.</p>
<p>On a single node, transaction commitment depends on the <em>order</em> in which data is writen to disk: first the data, then the commit record.</p>
<p>2PC uses a coordinartor (<em>transaction manager</em>). When the application is ready to commit, the coordinator begins phase 1: it sends a <em>prepare</em> request to each of the nodes, asking them whether are able to commit.</p>
<ul>
<li>If all participants reply “yes”, the coordinator sends out a <em>commit</em> request in phase 2, and the commit takes place.</li>
<li>If any of the participants replies “no”, the coordinator sends an <em>abort</em> request to all nodes in phase 2.</li>
</ul>
<p>When a participant votes “yes”, it promises that it will definitely be able to commit later; and once the coordiantor decides, that decision is irrevocable. Those promises ensure the atomicity of 2PC.</p>
<p>If one of the participants or the network fails during 2PC (prepare requests fail or time out), the coordinator aborts the transaction. If any of the commit or abort request fail, the coordinator retries them indefinitely.</p>
<p>If the coordinator fails before sending the prepare requests, a participant can safely abort the transaction.</p>
<p>The only way 2PC can complete is by waiting for the coordinator to revover in case of failure. This is why the coordinator must write its commit or abort decision to a transaction log on disk before sending commit or abort requests to participants.</p>
<h4 id="three-phase-commit" style="position:relative;"><a href="#three-phase-commit" aria-label="three phase commit permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Three-phase commit</h4>
<p>2PC is also called a <em>blocking</em> atomic commit protocol, as 2Pc can become stuck waiting for the coordinator to recover.</p>
<p>There is an alternative called <em>three-phase commit</em> (3PC) that requires a <em>perfect failure detector</em>.</p>
<hr>
<p>Distributed transactions carry a heavy performance penalty due the disk forcing in 2PC required for crash recovery and additional network round-trips.</p>
<p>XA (X/Open XA for eXtended Architecture) is a standard for implementing two-phase commit across heterogeneous technologies. Supported by many traditional relational databases (PostgreSQL, MySQL, DB2, SQL Server, and Oracle) and message brokers (ActiveMQ, HornetQ, MSQMQ, and IBM MQ).</p>
<p>The problem with <em>locking</em> is that database transactions usually take a row-level exclusive lock on any rows they modify, to prevent dirty writes.</p>
<p>While those locks are held, no other transaction can modify those rows.</p>
<p>When a coordinator fails, <em>orphaned</em> in-doubt transactions do ocurr, and the only way out is for an administrator to manually decide whether to commit or roll back the transaction.</p>
<h4 id="fault-tolerant-consensus" style="position:relative;"><a href="#fault-tolerant-consensus" aria-label="fault tolerant consensus permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Fault-tolerant consensus</h4>
<p>One or more nodes may <em>propose</em> values, and the consensus algorithm <em>decides</em> on those values.</p>
<p>Consensus algorithm must satisfy the following properties:</p>
<ul>
<li>Uniform agreement: No two nodes decide differently.</li>
<li>Integrity: No node decides twice.</li>
<li>Validity: If a node decides the value <em>v</em>, then <em>v</em> was proposed by some node.</li>
<li>Termination: Every node that does not crash eventually decides some value.</li>
</ul>
<p>If you don’t care about fault tolerance, then satisfying the first three properties is easy: you can just hardcode one node to be the “dictator” and let that node make all of the decisions.</p>
<p>The termination property formalises the idea of fault tolerance. Even if some nodes fail, the other nodes must still reach a decision. Termination is a liveness property, whereas the other three are safety properties.</p>
<p><strong>The best-known fault-tolerant consensus algorithms are Viewstamped Replication (VSR), Paxos, Raft and Zab.</strong></p>
<p>Total order broadcast requires messages to be delivered exactly once, in the same order, to all nodes.</p>
<p>So total order broadcast is equivalent to repeated rounds of consensus:</p>
<ul>
<li>Due to agreement property, all nodes decide to deliver the same messages in the same order.</li>
<li>Due to integrity, messages are not duplicated.</li>
<li>Due to validity, messages are not corrupted.</li>
<li>Due to termination, messages are not lost.</li>
</ul>
<h5 id="single-leader-replication-and-consensus" style="position:relative;"><a href="#single-leader-replication-and-consensus" aria-label="single leader replication and consensus permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Single-leader replication and consensus</h5>
<p>All of the consensus protocols dicussed so far internally use a leader, but they don’t guarantee that the lader is unique. Protocols define an <em>epoch number</em> (<em>ballot number</em> in Paxos, <em>view number</em> in Viewstamped Replication, and <em>term number</em> in Raft). Within each epoch, the leader is unique.</p>
<p>Every time the current leader is thought to be dead, a vote is started among the nodes to elect a new leader. This election is given an incremented epoch number, and thus epoch numbers are totallly ordered and monotonically increasing. If there is a conflic, the leader with the higher epoch number prevails.</p>
<p>A node cannot trust its own judgement. It must collect votes from a <em>quorum</em> of nodes. For every decision that a leader wants to make, it must send the proposed value to the other nodes and wait for a quorum of nodes to respond in favor of the proposal.</p>
<p>There are two rounds of voting, once to choose a leader, and second time to vote on a leader’s proposal. The quorums for those two votes must overlap.</p>
<p>The biggest difference with 2PC, is that 2PC requires a “yes” vote for <em>every</em> participant.</p>
<p>The benefits of consensus come at a cost. The process by which nodes vote on proposals before they are decided is kind of synchronous replication.</p>
<p>Consensus always require a strict majority to operate.</p>
<p>Most consensus algorithms assume a fixed set of nodes that participate in voting, which means that you can’t just add or remove nodes in the cluster. <em>Dynamic membership</em> extensions are much less well understood than static membership algorithms.</p>
<p>Consensus systems rely on timeouts to detect failed nodes. In geographically distributed systems, it often happens that a node falsely believes the leader to have failed due to a network issue. This implies frequest leader elecctions resulting in terrible performance, spending more time choosing a leader than doing any useful work.</p>
<h4 id="membership-and-coordination-services" style="position:relative;"><a href="#membership-and-coordination-services" aria-label="membership and coordination services permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Membership and coordination services</h4>
<p>ZooKeeper or etcd are often described as “distributed key-value stores” or “coordination and configuration services”.</p>
<p>They are designed to hold small amounts of data that can fit entirely in memory, you wouldn’t want to store all of your application’s data here. Data is replicated across all the nodes using a fault-tolerant total order broadcast algorithm.</p>
<p>ZooKeeper is modeled after Google’s Chubby lock service and it provides some useful features:</p>
<ul>
<li>Linearizable atomic operations: Usuing an atomic compare-and-set operation, you can implement a lock.</li>
<li>Total ordering of operations: When some resource is protected by a lock or lease, you need a <em>fencing token</em> to prevent clients from conflicting with each other in the case of a process pause. The fencing token is some number that monotonically increases every time the lock is acquired.</li>
<li>Failure detection: Clients maintain a long-lived session on ZooKeeper servers. When a ZooKeeper node fails, the session remains active. When ZooKeeper declares the session to be dead all locks held are automatically released.</li>
<li>Change notifications: Not only can one client read locks and values, it can also watch them for changes.</li>
</ul>
<p>ZooKeeper is super useful for distributed coordination.</p>
<p>ZooKeeper/Chubby model works well when you have several instances of a process or service, and one of them needs to be chosen as a leader or primary. If the leader fails, one of the other nodes should take over. This is useful for single-leader databases and for job schedulers and similar stateful systems.</p>
<p>ZooKeeper runs on a fixed number of nodes, and performs its majority votes among those nodes while supporting a potentially large number of clients.</p>
<p>The kind of data managed by ZooKeeper is quite slow-changing like “the node running on 10.1.1.23 is the leader for partition 7”. It is not intended for storing the runtime state of the application. If application state needs to be replicated there are other tools (like Apache BookKeeper).</p>
<p>ZooKeeper, etcd, and Consul are also often used for <em>service discovery</em>, find out which IP address you need to connect to in order to reach a particular service. In cloud environments, it is common for virtual machines to continually come an go, you often don’t know the IP addresses of your services ahead of time. Your services when they start up they register their network endpoints ina  service registry, where they can then be found by other services.</p>
<p>ZooKeeper and friends can be seen as part of a long history of research into <em>membership services</em>, determining which nodes are currently active and live members of a cluster.</p>
<h1 id="derived-data" style="position:relative;"><a href="#derived-data" aria-label="derived data permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Derived Data</h1>
<h2 id="batch-processing" style="position:relative;"><a href="#batch-processing" aria-label="batch processing permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Batch processing</h2>
<ul>
<li>Service (online): waits for a request, sends a response back</li>
<li>Batch processing system (offline): takes a large amount of input data, runs a <em>job</em> to process it, and produces some output.</li>
<li>Stream processing systems (near-real-time): a stream processor consumes input and produces outputs. A stream job operates on events shortly after they happen.</li>
</ul>
<h3 id="batch-processing-with-unix-tools" style="position:relative;"><a href="#batch-processing-with-unix-tools" aria-label="batch processing with unix tools permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Batch processing with Unix tools</h3>
<p>We can build a simple log analysis job to get the five most popular pages on your site</p>
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">cat /var/log/nginx/access.log |
  awk '{print $7}' |
  sort             |
  uniq -c          |
  sort -r -n       |
  head -n 5        |</code></pre></div>
<p>You could write the same thing with a simpel program.</p>
<p>The difference is that with Unix commands automatically handle larger-than-memory datasets and automatically paralelizes sorting across multiple CPU cores.</p>
<p>Programs must have the same data format to pass information to one another. In Unix, that interface is a file (file descriptor), an ordered sequence of bytes.</p>
<p>By convention Unix programs treat this sequence of bytes as ASCII text.</p>
<p>The unix approach works best if a program simply uses <code class="language-text">stdin</code> and <code class="language-text">stdout</code>. This allows a shell user to wire up the input and output in whatever way they want; the program doesn’t know or care where the input is coming from and where the output is going to.</p>
<p>Part of what makes Unix tools so successful is that they make it quite easy to see what is going on.</p>
<h3 id="map-reduce-and-distributed-filesystems" style="position:relative;"><a href="#map-reduce-and-distributed-filesystems" aria-label="map reduce and distributed filesystems permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Map reduce and distributed filesystems</h3>
<p>A single MapReduce job is comparable to a single Unix process.</p>
<p>Running a MapReduce job normally does not modify the input and does not have any side effects other than producing the output.</p>
<p>While Unix tools use <code class="language-text">stdin</code> and <code class="language-text">stdout</code> as input and output, MapReduce jobs read and write files on a distributed filesystem. In Hadoop, that filesystem is called HDFS (Haddoop Distributed File System).</p>
<p>HDFS is based on the <em>shared-nothing</em> principe. Implemented by centralised storage appliance, often using custom hardware and special network infrastructure.</p>
<p>HDFS consists of a daemon process running on each machine, exposing a network service that allows other nodes to access files stored on that machine. A central server called the <em>NameNode</em> keeps track of which file blocks are stored on which machine.</p>
<p>File blocks are replciated on multiple machines. Reaplication may mean simply several copies of the same data on multiple machines, or an <em>erasure coding</em> scheme such as Reed-Solomon codes, which allow lost data to be recovered.</p>
<p>MapReduce is a programming framework with which you can write code to process large datasets in a distributed filesystem like HDFS.</p>
<ol>
<li>Read a set of input files, and break it up into <em>records</em>.</li>
<li>Call the mapper function to extract a key and value from each input record.</li>
<li>Sort all of the key-value pairs by key.</li>
<li>Call the reducer function to iterate over the sorted key-value pairs.</li>
</ol>
<ul>
<li>Mapper: Called once for every input record, and its job is to extract the key and value from the input record.</li>
<li>Reducer: Takes the key-value pairs produced by the mappers, collects all the values belonging to the same key, and calls the reducer with an interator over that collection of vaues.</li>
</ul>
<p>MapReduce can parallelise a computation across many machines, without you having ot write code to explicitly handle the parallelism. THe mapper and reducer only operate on one record at a time; they don’t need to know where their input is coming from or their output is going to.</p>
<p>In Hadoop MapReduce, the mapper and reducer are each a Java class that implements a particular interface.</p>
<p>The MapReduce scheduler tries to run each mapper on one of the machines that stores a replica of the input file, <em>putting the computation near the data</em>.</p>
<p>The reduce side of the computation is also partitioned. While the number of map tasks is determined by the number of input file blocks, the number of reduce tasks is configured by the job author. To ensure that all key-value pairs with the same key end up in the same reducer, the framework uses a hash of the key.</p>
<p>The dataset is likely too large to be sorted with a conventional sorting algorithm on a single machine. Sorting is performed in stages.</p>
<p>Whenever a mapper finishes reading its input file and writing its sorted output files, the MapReduce scheduler notifies the reducers that they can start fetching the output files from that mapper. The reducers connect to each of the mappers and download the files of sorted key-value pairs for their partition. Partitioning by reducer, sorting and copying data partitions from mappers to reducers is called <em>shuffle</em>.</p>
<p>The reduce task takes the files from the mappers and merges them together, preserving the sort order.</p>
<p>MapReduce jobs can be chained together into <em>workflows</em>, the output of one job becomes the input to the next job. In Hadoop this chaining is done implicitly by directory name: the first job writes its output to a designated directory in HDFS, the second job reads that same directory name as its input.</p>
<p>Compared with the Unix example, it could be seen as in each sequence of commands each command output is written to a temporary file, and the next command reads from the temporary file.</p>
<p>It is common in datasets for one record to have an association with another record: a <em>foreign key</em> in a relational model, a <em>document reference</em> in a document model, or an <em>edge</em> in graph model.</p>
<p>If the query involves joins, it may require multiple index lookpus. MapReduce has no concept of indexes.</p>
<p>When a MapReduce job is given a set of files as input, it reads the entire content of all of those files, like a <em>full table scan</em>.</p>
<p>In analytics it is common to want to calculate aggregates over a large number of records. Scanning the entire input might be quite reasonable.</p>
<p>In order to achieve good throughput in a batch process, the computation must be local to one machine. Requests over the network are too slow and nondeterministic. Queries to other database for example would be prohibitive.</p>
<p>A better approach is to take a copy of the data (peg: the database) and put it in the same distributed filesystem.</p>
<p>MapReduce programming model has separated the physical network communication aspects of the computation (getting the data to the right machine) from the application logic (processing the data once you have it).</p>
<p>In an example of a social network, small number of celebrities may have many millions of followers. Such disproportionately active database records are known as <em>linchpin objects</em> or <em>hot keys</em>.</p>
<p>A single reducer can lead to significant <em>skew</em> that is, one reducer that must process significantly more records than the others.</p>
<p>The <em>skewed join</em> method in Pig first runs a sampling job to determine which keys are hot and then records related to the hot key need to be replicated to <em>all</em> reducers handling that key.</p>
<p>Handling the hot key over several reducers is called <em>shared join</em> method. In Crunch is similar but requires the hot keys to be specified explicitly.</p>
<p>Hive’s skewed join optimisation requries hot keys to be specified explicitly and it uses map-side join. If you <em>can</em> make certain assumptions about your input data, it is possible to make joins faster. A MapReducer job with no reducers and no sorting, each mapper simply reads one input file and writes one output file.</p>
<p>The output of a batch process is often not a report, but some other kind of structure.</p>
<p>Google’s original use of MapReduce was to build indexes for its search engine. Hadoop MapReduce remains a good way of building indexes for Lucene/Solr.</p>
<p>If you need to perform a full-text search, a batch process is very effective way of building indexes: the mappers partition the set of documents as needed, each reducer builds the index for its partition, and the index files are written to the distributed filesystem. It pararellises very well.</p>
<p>Machine learning systems such as clasifiers and recommendation systems are a common use for batch processing.</p>
<h4 id="key-value-stores-as-batch-process-output" style="position:relative;"><a href="#key-value-stores-as-batch-process-output" aria-label="key value stores as batch process output permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Key-value stores as batch process output</h4>
<p>The output of those batch jobs is often some kind of database.</p>
<p>So, how does the output from the batch process get back into a database?</p>
<p>Writing from the batch job directly to the database server is a bad idea:</p>
<ul>
<li>Making a network request for every single record is magnitude slower than the normal throughput of a batch task.</li>
<li>Mappers or reducers concurrently write to the same output database an it can be easily overwhelmed.</li>
<li>You have to worry about the results from partially completed jobs being visible to other systems.</li>
</ul>
<p>A much better solution is to build a brand-new database <em>inside</em> the batch job an write it as files to the job’s output directory, so it can be loaded in bulk into servers that handle read-only queries. Various key-value stores support building database files in MapReduce including Voldemort, Terrapin, ElephanDB and HBase bulk loading.</p>
<hr>
<p>By treating inputs as immutable and avoiding side effects (such as writing to external databases), batch jobs not only achieve good performance but also become much easier to maintain.</p>
<p>Design principles that worked well for Unix also seem to be working well for Hadoop.</p>
<p>The MapReduce paper was not at all new. The sections we’ve seen had been already implemented in so-called <em>massively parallel processing</em> (MPP) databases.</p>
<p>The biggest difference is that MPP databases focus on parallel execution of analytic SQL queries on a cluster of machines, while the combination of MapReduce and a distributed filesystem provides something much more like a general-purpose operating system that can run arbitraty programs.</p>
<p>Hadoop opened up the possibility of indiscriminately dumpint data into HDFS. MPP databases typically require careful upfront modeling of the data and query patterns before importing data into the database’s proprietary storage format.</p>
<p>In MapReduce instead of forcing the producer of a dataset to bring it into a standarised format, the interpretation of the data becomes the consumer’s problem.</p>
<p>If you have HDFS and MapReduce, you <em>can</em> build a SQL query execution engine on top of it, and indeed this is what the Hive project did.</p>
<p>If a node crashes while a query is executing, most MPP databases abort the entire query. MPP databases also prefer to keep as much data as possible in memory.</p>
<p>MapReduce can tolerate the failure of a map or reduce task without it affecting the job. It is also very eager to write data to disk, partly for fault tolerance, and partly because the dataset might not fit in memory anyway.</p>
<p>MapReduce is more appropriate for larger jobs.</p>
<p>At Google, a MapReduce task that runs for an hour has an approximately 5% risk of being terminated to make space for higher-priority process.</p>
<p>Ths is why MapReduce is designed to tolerate frequent unexpected task termination.</p>
<h3 id="beyond-mapreduce" style="position:relative;"><a href="#beyond-mapreduce" aria-label="beyond mapreduce permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Beyond MapReduce</h3>
<p>In response to the difficulty of using MapReduce directly, various higher-level programming models emerged on top of it: Pig, Hive, Cascading, Crunch.</p>
<p>MapReduce has poor performance for some kinds of processing. It’s very robust, you can use it to process almost arbitrarily large quantities of data on an unreliable multi-tenant system with frequent task terminations, and it will still get the job done.</p>
<p>The files on the distributed filesystem are simply <em>intermediate state</em>: a means of passing data from one job to the next.</p>
<p>The process of writing out the intermediate state to files is called <em>materialisation</em>.</p>
<p>MapReduce’s approach of fully materialising state has some downsides compared to Unix pipes:</p>
<ul>
<li>A MapReduce job can only start when all tasks in the preceding jobs have completed, whereas rocesses connected by a Unix pipe are started at the same time.</li>
<li>Mappers are often redundant: they just read back the same file that was just written by a reducer.</li>
<li>Files are replicated across several nodes, which is often overkill for such temporary data.</li>
</ul>
<p>To fix these problems with MapReduce, new execution engines for distributed batch computations were developed, Spark, Tez and Flink. These new ones can handle an entire workflow as one job, rather than breaking it up into independent subjobs (<em>dataflow engines</em>).</p>
<p>These functions need not to take the strict roles of alternating map and reduce, they are assembled in flexible ways, in functions called <em>operators</em>.</p>
<p>Spark, Flink, and Tex avoid writing intermediate state to HDFS, so they take a different approach to tolerating faults: if a machine fails and the intermediate state on that machine is lost, it is recomputed from other data that is still available.</p>
<p>The framework must keep track of how a given piece of data was computed. Spark uses the resilient distributed dataset (RDD) to track ancestry data, while Flink checkpoints operator state, allowing it to resume running an operator that ran into a fault during its execution.</p>
<h4 id="graphs-and-iterative-processing" style="position:relative;"><a href="#graphs-and-iterative-processing" aria-label="graphs and iterative processing permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Graphs and iterative processing</h4>
<p>It’s interesting to look at graphs in batch processing context, where the goal is to perform some kind of offline processing or analysis on an entire graph. This need often arises in machine learning applications such as recommednation engines, or in ranking systems.</p>
<p>“repeating until done” cannot be expressed in plain MapReduce as it runs in a single pass over the data and some extra trickery is necessary.</p>
<p>An optimisation for batch processing graphs, the <em>bulk synchronous parallel</em> (BSP) has become popular. It is implemented by Apache Giraph, Spark’s GraphX API, and Flink’s Gelly API (_Pregel model, as Google Pregel paper popularised it).</p>
<p>One vertex can “send a message” to another vertex, and typically those messages are sent along the edges in a graph.</p>
<p>The difference from MapReduce is that a vertex remembers its state in memory from one iteration to the next.</p>
<p>The fact that vertices can only communicate by message passing helps improve the performance of Pregel jobs, since messages can be batched.</p>
<p>Fault tolerance is achieved by periodically checkpointing the state of all vertices at the end of an interation.</p>
<p>The framework may partition the graph in arbitrary ways.</p>
<p>Graph algorithms often have a lot of cross-machine communication overhead, and the intermediate state is often bigger than the original graph.</p>
<p>If your graph can fit into memory on a single computer, it’s quite likely that a single-machine algorithm will outperform a distributed batch process. If the graph is too big to fit on a single machine, a distributed approach such as Pregel is unavoidable.</p>
<h2 id="stream-processing" style="position:relative;"><a href="#stream-processing" aria-label="stream processing permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Stream processing</h2>
<p>We can run the processing continuously, abandoning the fixed time slices entirely and simply processing every event as it happens, that’s the idea behind <em>stream processing</em>. Data that is incrementally made available over time.</p>
<h3 id="transmitting-event-streams" style="position:relative;"><a href="#transmitting-event-streams" aria-label="transmitting event streams permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Transmitting event streams</h3>
<p>A record is more commonly known as an <em>event</em>. Something that happened at some point in time, it usually contains a timestamp indicating when it happened acording to a time-of-day clock.</p>
<p>An event is generated once by a <em>producer</em> (<em>publisher</em> or <em>sender</em>), and then potentially processed by multiple <em>consumers</em> (<em>subcribers</em> or <em>recipients</em>). Related events are usually grouped together into a <em>topic</em> or a <em>stream</em>.</p>
<p>A file or a database is sufficient to connect producers and consumers: a producer writes every event that it generates to the datastore, and each consumer periodically polls the datastore to check for events that have appeared since it last ran.</p>
<p>However, when moving toward continual processing, polling becomes expensive. It is better for consumers to be notified when new events appear.</p>
<p>Databases offer <em>triggers</em> but they are limited, so specialised tools have been developed for the purpose of delivering event notifications.</p>
<h4 id="messaging-systems" style="position:relative;"><a href="#messaging-systems" aria-label="messaging systems permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Messaging systems</h4>
<h5 id="direct-messaging-from-producers-to-consumers" style="position:relative;"><a href="#direct-messaging-from-producers-to-consumers" aria-label="direct messaging from producers to consumers permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Direct messaging from producers to consumers</h5>
<p>Within the <em>publish</em>/<em>subscribe</em> model, we can differentiate the systems by asking two questions:</p>
<ol>
<li><em>What happens if the producers send messages faster than the consumers can process them?</em> The system can drop messages, buffer the messages in a queue, or apply <em>backpressure</em> (<em>flow control</em>, blocking the producer from sending more messages).</li>
<li><em>What happens if nodes crash or temporarily go offline, are any messages lost?</em> Durability may require some combination of writing to disk and/or replication.</li>
</ol>
<p>A number of messaging systems use direct communication between producers and consumers without intermediary nodes:</p>
<ul>
<li>UDP multicast, where low latency is important, application-level protocols can recover lost packets.</li>
<li>Brokerless messaging libraries such as ZeroMQ</li>
<li>StatsD and Brubeck use unreliable UDP messaging for collecting metrics</li>
<li>If the consumer expose a service on the network, producers can make a direct HTTP or RPC request to push messages to the consumer. This is the idea behind webhooks, a callback URL of one service is registered with another service, and makes a request to that URL whenever an event occurs</li>
</ul>
<p>These direct messaging systems require the application code to be aware of the possibility of message loss. The faults they can tolerate are quite limited as they assume that producers and consumers are constantly online.</p>
<p>If a consumer if offline, it may miss messages. Some protocols allow the producer to retry failed message deliveries, but it may break down if the producer crashes losing the buffer or messages.</p>
<h5 id="message-brokers" style="position:relative;"><a href="#message-brokers" aria-label="message brokers permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Message brokers</h5>
<p>An alternative is to send messages via a <em>message broker</em> (or <em>message queue</em>), which is a kind of database that is optimised for handling message streams. It runs as a server, with producers and consumers connecting to it as clients. Producers write messages to the broker, and consumers receive them by reading them from the broker.</p>
<p>By centralising the data, these systems can easily tolerate clients that come and go, and the question of durability is moved to the broker instead. Some brokers only keep messages in memory, while others write them down to disk so that they are not lost inc ase of a broker crash.</p>
<p>A consequence of queueing is that consuemrs are generally <em>asynchronous</em>: the producer only waits for the broker to confirm that it has buffered the message and does not wait for the message to be processed by consumers.</p>
<p>Some brokers can even participate in two-phase commit protocols using XA and JTA. This makes them similar to databases, aside some practical differences:</p>
<ul>
<li>Most message brokers automatically delete a message when it has been successfully delivered to its consumers. This makes them not suitable for long-term storage.</li>
<li>Most message brokers assume that their working set is fairly small. If the broker needs to buffer a lot of messages, each individual message takes longer to process, and the overall throughput may degrade.</li>
<li>Message brokers often support some way of subscribing to a subset of topics matching some pattern.</li>
<li>Message brokers do not support arbitrary queries, but they do notify clients when data changes.</li>
</ul>
<p>This is the traditional view of message brokers, encapsulated in standards like JMS and AMQP, and implemented in RabbitMQ, ActiveMQ, HornetQ, Qpid, TIBCO Enterprise Message Service, IBM MQ, Azure Service Bus, and Google Cloud Pub/Sub.</p>
<p>When multiple consumers read messages in the same topic, to main patterns are used:</p>
<ul>
<li>Load balancing: Each message is delivered to <em>one</em> of the consumers. The broker may assign messages to consumers arbitrarily.</li>
<li>Fan-out: Each message is delivered to <em>all</em> of the consumers.</li>
</ul>
<p>In order to ensure that the message is not lost, message brokers use <em>acknowledgements</em>: a client must explicitly tell the broker when it has finished processing a message so that the broker can remove it from the queue.</p>
<p>The combination of laod balancing with redelivery inevitably leads to messages being reordered. To avoid this issue, youc an use a separate queue per consumer (not use the load balancing feature).</p>
<h5 id="partitioned-logs" style="position:relative;"><a href="#partitioned-logs" aria-label="partitioned logs permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Partitioned logs</h5>
<p>A key feature of barch process is that you can run them repeatedly without the risk of damaging the input. This is not the case with AMQP/JMS-style messaging: receiving a message is destructive if the acknowledgement causes it to be deleted from the broker.</p>
<p>If you add a new consumer to a messaging system, any prior messages are already gone and cannot be recovered.</p>
<p>We can have a hybrid, combining the durable storage approach of databases with the low-latency notifications facilities of messaging, this is the idea behind <em>log-based message brokers</em>.</p>
<p>A log is simply an append-only sequence of records on disk. The same structure can be used to implement a message broker: a producer sends a message by appending it to the end of the log, and consumer receives messages by reading the log sequentially. If a consumer reaches the end of the log, it waits for a notification that a new message has been appended.</p>
<p>To scale to higher throughput than a single disk can offer, the log can be <em>partitioned</em>. Different partitions can then be hosted on different machines. A topic can then be defined as a group of partitions that all carry messages of the same type.</p>
<p>Within each partition, the broker assigns monotonically increasing sequence number, or <em>offset</em>, to every message.</p>
<p>Apache Kafka, Amazon Kinesis Streams, and Twitter’s DistributedLog, are log-based message brokers that work like this.</p>
<p>The log-based approach trivially supports fan-out messaging, as several consumers can independently read the log reading without affecint each other. Reading a message does not delete it from the log. To eachieve load balancing the broker can assign entire partitions to nodes in the consumer group. Each client then consumes <em>all</em> the messages in the partition it has been assigned. This approach has some downsides.</p>
<ul>
<li>The number of nodes sharing the work of consuming a topic can be at most the number of log partitions in that topic.</li>
<li>If a single message is slow to process, it holds up the processing of subsequent messages in that partition.</li>
</ul>
<p>In situations where messages may be expensive to process and you want to pararellise processing on a message-by-message basis, and where message ordering is not so important, the JMS/AMQP style of message broker is preferable. In situations with high message throughput, where each message is fast to process and where message ordering is important, the log-based approach works very well.</p>
<p>It is easy to tell which messages have been processed: al messages with an offset less than a consumer current offset have already been processed, and all messages with a greater offset have not yet been seen.</p>
<p>The offset is very similar to the <em>log sequence number</em> that is commonly found in single-leader database replication. The message broker behaves like a leader database, and the consumer like a follower.</p>
<p>If a consumer node fails, another node in the consumer group starts consuming messages at the last recorded offset. If the consumer had processed subsequent messages but not yet recorded their offset, those messages will be processed a second time upon restart.</p>
<p>If you only ever append the log, you will eventually run out of disk space. From time to time old segments are deleted or moved to archive.</p>
<p>If a slow consumer cannot keep with the rate of messages, and it falls so far behind that its consumer offset poitns to a deleted segment, it will miss some of the messages.</p>
<p>The throughput of a log remains more or less constant, since every message is written to disk anyway. This is in contrast to messaging systems that keep messages in memory by default and only write them to disk if the queue grows too large: systems are fast when queues are short and become much slower when they start writing to disk, throughput depends on the amount of history retained.</p>
<p>If a consumer cannot keep up with producers, the consumer can drop messages, buffer them or applying backpressure.</p>
<p>You can monitor how far a consumer is behind the head of the log, and raise an alert if it falls behind significantly.</p>
<p>If a consumer does fall too far behind and start missing messages, only that consumer is affected.</p>
<p>With AMQP and JMS-style message brokers, processing and acknowledging messages is a destructive operation, since it causes the messages to be deleted on the broker. In a log-based message broker, consuming messages is more like reading from a file.</p>
<p>The offset is under the consumer’s control, so you can easily be manipulated if necessary, like for replaying old messages.</p>
<h3 id="databases-and-streams" style="position:relative;"><a href="#databases-and-streams" aria-label="databases and streams permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Databases and streams</h3>
<p>A replciation log is a stream of a database write events, produced by the leader as it processes transactions. Followers apply that stream of writes to their own copy of the database and thus end up with an accurate copy of the same data.</p>
<p>If periodic full database dumps are too slow, an alternative that is sometimes used is <em>dual writes</em>. For example, writing to the database, then updating the search index, then invalidating the cache.</p>
<p>Dual writes have some serious problems, one of which is race conditions. If you have concurrent writes, one value will simply silently overwrite another value.</p>
<p>One of the writes may fail while the other succeeds and two systems will become inconsistent.</p>
<p>The problem with most databases replication logs is that they are considered an internal implementation detail, not a public API.</p>
<p>Recently there has been a growing interest in <em>change data capture</em> (CDC), which is the process of observing all data changes written to a database and extracting them in a form in which they can be replicated to other systems.</p>
<p>For example, you can capture the changes in a database and continually apply the same changes to a search index.</p>
<p>We can call log consumers <em>derived data systems</em>: the data stored in the search index and the data warehouse is just another view. Change data capture is a mechanism for ensuring that all changes made to the system of record are also reflected in the derived data systems.</p>
<p>Change data capture makes one database the leader, and turns the others into followers.</p>
<p>Database triggers can be used to implement change data capture, but they tend to be fragile and have significant performance overheads. Parsing the replication log can be a more robust approach.</p>
<p>LinkedIn’s Databus, Facebook’s Wormhole, and Yahoo!‘s Sherpa use this idea at large scale. Bottled Watter implements CDC for PostgreSQL decoding the write-ahead log, Maxwell and Debezium for something similar for MySQL by parsing the binlog, Mongoriver reads the MongoDB oplog, and GoldenGate provide similar facilities for Oracle.</p>
<p>Keeping all changes forever would require too much disk space, and replaying it would take too long, so the log needs to be truncated.</p>
<p>You can start with a consistent snapshot of the database, and it must correspond to a known position or offset in the change log.</p>
<p>The storage engine periodically looks for log records with the same key, throws away any duplicates, and keeps only the most recent update for each key.</p>
<p>An update with a special null value (a <em>tombstone</em>) indicates that a key was deleted.</p>
<p>The same idea works in the context of log-based mesage brokers and change data capture.</p>
<p>RethinkDB allows queries to subscribe to notifications, Firebase and CouchDB provide data synchronisation based on change feed.</p>
<p>Kafka Connect integrates change data capture tools for a wide range of database systems with Kafka.</p>
<h4 id="event-sourcing" style="position:relative;"><a href="#event-sourcing" aria-label="event sourcing permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Event sourcing</h4>
<p>There are some parallels between the ideas we’ve discussed here and <em>event sourcing</em>.</p>
<p>Similarly to change data capture, event sourcing involves storing all changes to the application state as a log of change events. Event sourcing applyies the idea at a different level of abstraction.</p>
<p>Event sourcing makes it easier to evolve applications over time, helps with debugging by making it easier to understand after the fact why something happened, and guards against application bugs.</p>
<p>Specialised databases such as Event Store have been developed to support applications using event sourcing.</p>
<p>Applications that use event sourcing need to take the log of evetns and transform it into application state that is suitable for showing to a user.</p>
<p>Replying the event log allows you to reconstruct the current state of the system.</p>
<p>Applications that use event sourcing typically have some mechanism for storing snapshots.</p>
<p>Event sourcing philosophy is careful to distinguis between <em>events</em> and <em>commands</em>. When a request from a user first arrives, it is initially a command: it may still fail (like some integrity condition is violated). If the validation is successful, it becomes an event, which is durable and immutable.</p>
<p>A consumer of the event stream is not allowed to reject an event: Any validation of a command needs to happen synchronously, before it becomes an event. For example, by using a serializable transaction that atomically validates the command and publishes the event.</p>
<p>Alternatively, the user request to serve a seat could be split into two events: first a tentative reservation, and then a separate confirmation event once the reservation has been validated. This split allows the validation to take place in an asynchronous process.</p>
<p>Whenever you have state changes, that state is the result of the events that mutated it over time.</p>
<p>Mutable state and an append-only log of immutable events do not contradict each other.</p>
<p>As an example, financial bookkeeping is recorded as an append-only <em>ledger</em>. It is a log of events describing money, good, or services that have changed hands. Profit and loss or the balance sheet are derived from the ledger by adding them up.</p>
<p>If a mistake is made, accountants don’t erase or change the incorrect transaction, instead, they add another transaction that compensates for the mistake.</p>
<p>If buggy code writes bad data to a database, recovery is much harder if the code is able to destructively overwrite data.</p>
<p>Immutable events also capture more information than just the current state. If you persisted a cart into a regular database, deleting an item would effectively loose that event.</p>
<p>You can derive views from the same event log, Druid ingests directly from Kafka, Pistachio is a distributed key-value sotre that uses Kafka as a commit log, Kafka Connect sinks can export data from Kafka to various different databases and indexes.</p>
<p>Storing data is normally quite straightforward if you don’t have to worry about how it is going to be queried and accessed. You gain a lot of flexibility by separating the form in which data is written from the form it is read, this idea is known as <em>command query responsibility segregation</em> (CQRS).</p>
<p>There is this fallacy that data must be written in the same form as it will be queried.</p>
<p>The biggest downside of event sourcing and change data capture is that consumers of the event log are usually asynchronous, a user may make a write to the log, then read from a log derived view and find that their write has not yet been reflected.</p>
<p>The limitations on immutable event history depends on the amount of churn in the dataset. Some workloads mostly add data and rarely update or delete; they are wasy to make immutable. Other workloads have a high rate of updates and deletes on a comparaively small dataset; in these cases immutable history becomes an issue because of fragmentation, performance compaction and garbage collection.</p>
<p>There may also be circumstances in which you need data to be deleted for administrative reasons.</p>
<p>Sometimes you may want to rewrite history, Datomic calls this feature <em>excision</em>.</p>
<h3 id="processing-streams" style="position:relative;"><a href="#processing-streams" aria-label="processing streams permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Processing Streams</h3>
<p>What you can do with the stream once you have it:</p>
<ol>
<li>You can take the data in the events and write it to the database, cache, search index, or similar storage system, from where it can thenbe queried by other clients.</li>
<li>You can push the events to users in some way, for example by sending email alerts or push notifications, or to a real-time dashboard.</li>
<li>You can process one or more input streams to produce one or more output streams.</li>
</ol>
<p>Processing streams to produce other, derived streams is what an <em>operator job</em> does. The one crucial difference to batch jobs is that a stream never ends.</p>
<p><em>Complex event processing</em> (CEP) is an approach for analising event streams where you can specify rules to search for certain patterns of events in them.</p>
<p>When a match is found, the engine emits a <em>complex event</em>.</p>
<p>Queries are stored long-term, and events from the input streams continuously flow past them in search of a query that matches an event pattern.</p>
<p>Implementations of CEP include Esper, IBM InfoSphere Streams, Apama, TIBCO StreamBase, and SQLstream.</p>
<p>The boundary between CEP and stream analytics is blurry, analytics tends to be less interested in finding specific event sequences and is more oriented toward aggregations and statistical metrics.</p>
<p>Frameworks with analytics in mind are: Apache Storm, Spark Streaming, Flink, Concord, Samza, and Kafka Streams. Hosted services include Google Cloud Dataflow and Azure Stream Analytics.</p>
<p>Sometimes there is a need to search for individual events continually, such as full-text search queries over streams.</p>
<p>Message-passing ystems are also based on messages and events, we normally don’t think of them as stream processors.</p>
<p>There is some crossover area between RPC-like systems and stream processing. Apache Storm has a feature called <em>distributed RPC</em>.</p>
<p>In a batch process, the time at which the process is run has nothing to do with the time at which the events actually occurred.</p>
<p>Many stream processing frameworks use the local system clock on the processing machine (<em>processing time</em>) to determine windowing. It is a simple approach that breaks down if there is any significant processing lag.</p>
<p>Confusing event time and processing time leads to bad data. Processing time may be unreliable as the stream processor may queue events, restart, etc. It’s better to take into account the original event time to count rates.</p>
<p>You can never be sure when you have received all the events.</p>
<p>You can time out and declare a window ready after you have not seen any new events for a while, but it could still happen that some events are delayed due a network interruption. You need to be able to handle such <em>stranggler</em> events that arrive after the window has already been declared complete.</p>
<ol>
<li>You can ignore the stranggler events, tracking the number of dropped events as a metric.</li>
<li>Publish a <em>correction</em>, an updated value for the window with stranglers included. You may also need to retrat the previous output.</li>
</ol>
<p>To adjust for incofrrect device clocks, one approach is to log three timestamps:</p>
<ul>
<li>The time at which the event occurred, according to the device clock</li>
<li>The time at which the event was sent to the server, according to the device clock</li>
<li>The time at which the event was received by the server, according to the server clock.</li>
</ul>
<p>You can estimate the offset between the device clock and the server clock, then apply that offset to the event timestamp, and thus estimate the true time at which the event actually ocurred.</p>
<p>Several types of windows are in common use:</p>
<ul>
<li>Tumbling window: Fixed length. If you have a 1-minute tumbling window, all events between 10:03:00 and 10:03:59 will be grouped in one window, next window would be 10:04:00-10:04:59</li>
<li>Hopping window: Fixed length, but allows windows to overlap in order to provide some smoothing. If you have a 5-minute window with a hop size of 1 minute, it would contain the events between 10:03:00 and 10:07:59, next window would cover 10:04:00-10:08:59</li>
<li>Sliding window: Events that occur within some interval of each other. For example, a 5-minute sliding window would cover 10:03:39 and 10:08:12 because they are less than 4 minutes apart.</li>
<li>Session window: No fixed duration. All events for the same user, the window ends when the user has been inactive for some time (30 minutes). Common in website analytics</li>
</ul>
<p>The fact that new events can appear anytime on a stream makes joins on stream challenging.</p>
<h4 id="stream-stream-joins" style="position:relative;"><a href="#stream-stream-joins" aria-label="stream stream joins permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Stream-stream joins</h4>
<p>You want to detect recent trends in searched-for URLs. You log an event containing the query. Someone clicks one of the search results, you log another event recording the click. You need to bring together the events for the search action and the click action.</p>
<p>For this type of join, a stream processor needs to maintain <em>state</em>: All events that occurred in the last hour, indexed by session ID. Whenever a search event or click event occurs, it is added to the appropriate index, and the stream processor also checks the other index to see if another event for the same session ID has already arrived. If there is a matching event, you emit an event saying search result was clicked.</p>
<h4 id="stream-table-joins" style="position:relative;"><a href="#stream-table-joins" aria-label="stream table joins permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Stream-table joins</h4>
<p>Sometimes know as <em>enriching</em> the activity events with information from the database.</p>
<p>Imagine two datasets: a set of usr activity events, and a database of user profiles. Activity events include the user ID, and the the resulting stream should have the augmented profile information based upon the user ID.</p>
<p>The stream process needs to look at one activity event at a time, look up the event’s user ID in the database, and add the profile information to the activity event. THe database lookup could be implemented by querying a remote database., however this would be slow and risk overloading the database.</p>
<p>Another approach is to load a copy of the database into the stream processor so that it can be queried locally without a network round-trip. The stream processor’s local copy of the database needs to be kept up to date; this can be solved with change data capture.</p>
<h4 id="table-table-join" style="position:relative;"><a href="#table-table-join" aria-label="table table join permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Table-table join</h4>
<p>The stream process needs to maintain a database containing the set of followers for each user so it knows which timelines need to be updated when a new tweet arrives.</p>
<h4 id="time-dependence-join" style="position:relative;"><a href="#time-dependence-join" aria-label="time dependence join permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Time-dependence join</h4>
<p>The previous three types of join require the stream processor to maintain some state.</p>
<p>If state changes over time, and you join with some state, what point in time do you use for the join?</p>
<p>If the ordering of events across streams is undetermined, the join becomes nondeterministic.</p>
<p>This issue is known as <em>slowly changing dimension</em> (SCD), often addressed by using a unique identifier for a particular version of the joined record. For example, we can turn the system deterministic if every time the tax rate changes, it is given a new identifier, and the invoice includes the identifier for the tax rate at the time of sale. But as a consequence makes log compation impossible.</p>
<h4 id="fault-tolerance" style="position:relative;"><a href="#fault-tolerance" aria-label="fault tolerance permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Fault tolerance</h4>
<p>Batch processing frameworks can tolerate faults fairly easy:if a task in a MapReduce job fails, it can simply be started again on another machine, input files are immutable and the output is written to a separate file.</p>
<p>Even though restarting tasks means records can be processed multiple times, the visible effect in the output is as if they had only been processed once (<em>exactly-once-semantics</em> or <em>effectively-once</em>).</p>
<p>With stream processing waiting until a tasks if finished before making its ouput visible is not an option, stream is infinite.</p>
<p>One solution is to break the stream into small blocks, and treat each block like a minuature batch process (<em>micro-batching</em>). This technique is used in Spark Streaming, and the batch size is typically around one second.</p>
<p>An alternative approach, used in Apache Flint, is to periodically generate rolling checkpoints of state and write them to durable storage. If a stream operator crashes, it can restart from its most recent checkpoint.</p>
<p>Microbatching and chekpointing approaches provide the same exactly-once semantics as batch processing. However, as soon as output leaves the stream processor, the framework is no longer able to discard the output of a failed batch.</p>
<p>In order to give appearance of exactly-once processing, things either need to happen atomically or none of must happen. Things should not go out of sync of each other. Distributed transactions and two-phase commit can be used.</p>
<p>This approach is used in Google Cloud Dataflow and VoltDB, and there are plans to add similar features to Apache Kafka.</p>
<p>Our goal is to discard the partial output of failed tasks so that they can be safely retired without taking effect twice. Distributed transactions are one way of achieving that goal, but another way is to rely on <em>idempotence</em>.</p>
<p>An idempotent operation is one that you can perform multiple times, and it has the same effect as if you performed it only once.</p>
<p>Even if an operation is not naturally idempotent, it can often be made idempotent with a bit of extra metadata. You can tell wether an update has already been applied.</p>
<p>Idempotent operations can be an effective way of achieving exactly-once semantics with only a small overhead.</p>
<p>Any stream process that requires state must ensure tha this state can be recovered after a failure.</p>
<p>One option is to keep the state in a remote datastore and replicate it, but it is slow.</p>
<p>An alternative is to keep state local to the stream processor and replicate it periodically.</p>
<p>Flink periodically captures snapshots and writes them to durable storage such as HDFS; Samza and Kafka Streams replicate state changes by sending them to a dedicated Kafka topic with log compaction. VoltDB replicates state by redundantly processing each input message on several nodes.</p>
<h2 id="the-future-of-data-systems" style="position:relative;"><a href="#the-future-of-data-systems" aria-label="the future of data systems permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>The future of data systems</h2>
<h3 id="data-integration" style="position:relative;"><a href="#data-integration" aria-label="data integration permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Data integration</h3>
<p>Updating a derived data system based on an event log can often be made determinisitic and idempotent.</p>
<p>Distributed transactions decide on an ordering of writes by using locks for mutual exclusion, while CDC and event sourcing use a log for ordering. Distributed transactions use atomic commit to ensure exactly once semantics, while log-based systems are based on deterministic retry and idempotence.</p>
<p>Transaction systems provide linearizability, useful guarantees as reading your own writes. On the other hand, derived systems are often updated asynchronously, so they do not by default offer the same timing guarantees.</p>
<p>In the absence of widespread support for a good distributed transaction protocol, log-based derived data is the most promising approach for integrating different data systems.</p>
<p>However, as systems are scaled towards bigger and more coplex worloads, limitiations emerge:</p>
<ul>
<li>Constructing a totally ordered log requires all events to pass through a <em>single leader node</em> that decides on the ordering.</li>
<li>An undefined ordering of events that originate on multiple datacenters.</li>
<li>When two events originate in different services, there is no defined order for those events.</li>
<li>Some applications maintain client-side state. Clients and servers are very likely to see events in different orders.</li>
</ul>
<p>Deciding on a total order of events is known as <em>total order broadcast</em>, which is equivalent to consensus. It is still an open research problem to design consensus algorithms that can scale beyond the throughput of a single node.</p>
<h4 id="batch-and-stream-processing" style="position:relative;"><a href="#batch-and-stream-processing" aria-label="batch and stream processing permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Batch and stream processing</h4>
<p>The fundamental difference between batch processors and batch processes is that the stream processors operate on unbounded datasets whereas batch processes inputs are of a known finite size.</p>
<p>Spark performs stream processing on top of batch processing. Apache Flink performs batch processing in top of stream processing.</p>
<p>Batch processing has a quite strong functional flavour. The output depends only on the input, there are no side-effects. Stream processing is similar but it allows managed, fault-tolerant state.</p>
<p>Derived data systems could be maintained synchronously. However, asynchrony is what makes systems based on event logs robust: it allows a fault in one part of the system to be contained locally.</p>
<p>Stream processing allows changes in the input to be reflected in derived views with low delay, whereas batch processing allows large amounts of accumulated historical data to be reprocessed in order to derive new views onto an existing dataset.</p>
<p>Derived views allow <em>gradual</em> evolution. If you want to restructure a dataset, you do not need to perform the migration as a sudden switch. Instead, you can maintain the old schema and the new schema side by side as two independent derived views onto the same underlying data, eventually you can drop the old view.</p>
<h4 id="lambda-architecture" style="position:relative;"><a href="#lambda-architecture" aria-label="lambda architecture permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Lambda architecture</h4>
<p>The whole idea behind lambda architecture is that incoming data should be recorded by appending immutable events to an always-growing dataset, similarly to event sourcing. From these events, read-optimised vuews are derived. Lambda architecture proposes running two different systems in parallel: a batch processing system such as Hadoop MapReduce, and a stream-processing system as Storm.</p>
<p>The stream processor produces an approximate update to the view: the batch processor produces a corrected version of the derived view.</p>
<p>The stream process can use fast approximation algorithms while the batch process uses slower exact algorithms.</p>
<h3 id="unbundling-databases" style="position:relative;"><a href="#unbundling-databases" aria-label="unbundling databases permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Unbundling databases</h3>
<h4 id="creating-an-index" style="position:relative;"><a href="#creating-an-index" aria-label="creating an index permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Creating an index</h4>
<p>Batch and stream processors are like elaborate implementations of triggers, stored procedures, and materialised view maintenance routines. The derived data systems they maintain are like different index types.</p>
<p>There are two avenues by which different storate and processing tools can nevertheless be composed into a cohesive system:</p>
<ul>
<li>Federated databases: unifying reads. It is possible to provide a unified query interface to a wide variety of underlying storate engines and processing methods, this is known as <em>federated database</em> or <em>polystore</em>. An example is PostgreSQL’s <em>foreign data wrapper</em>.</li>
<li>Unbundled databases: unifying writes. When we compose several storage systems, we need to ensure that all data changes end up in all the right places, even in the face of faults, it is like <em>unbundling</em> a database’s index-maintenance features in a way that can synchronise writes across disparate technologies.</li>
</ul>
<p>Keeping the writes to several storage systems in sync is the harder engineering problem.</p>
<p>Synchronising writes requires distributed transactions across heterogeneous storage systems which may be the wrong solution. An asynchronous event log with idempotent writes is a much more robust and practical approach.</p>
<p>The big advantage is <em>loose coupling</em> between various components:</p>
<ol>
<li>Asynchronous event streams make the system as a whole more robust to outages or performance degradation of individual components.</li>
<li>Unbundling data systems allows different software components and services to be developed, improved and maintained independently from each other by different teams.</li>
</ol>
<p>If there is a single technology that does everything you need, you’re most likely best off simply using that product rather than trying to reimplement it yourself from lower-level components. The advantages of unbundling and composition only come into the picture when there is no single piece of software that satisfies all your requirements.</p>
<h4 id="separation-of-application-code-and-state" style="position:relative;"><a href="#separation-of-application-code-and-state" aria-label="separation of application code and state permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Separation of application code and state</h4>
<p>It makes sense to have some parts of a system that specialise in durable data storage, and other parts that specialise in running application code. The two can interact while still remaining independent.</p>
<p>The trend has been to keep stateless application logic separate from state management (databases): not putting application logic in the database and not putting persistent state in the application.</p>
<h4 id="dataflow-interplay-between-state-changes-and-application-code" style="position:relative;"><a href="#dataflow-interplay-between-state-changes-and-application-code" aria-label="dataflow interplay between state changes and application code permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Dataflow, interplay between state changes and application code</h4>
<p>Instead of treating the database as a passive variable that is manipulated by the application, application code responds to state changes in one place by triggering state changes in another place.</p>
<h4 id="stream-processors-and-services" style="position:relative;"><a href="#stream-processors-and-services" aria-label="stream processors and services permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Stream processors and services</h4>
<p>A customer is purchasing an item that is priced in one currency but paid in another currency. In order to perform the currency conversion, you need to know the current exchange rate.</p>
<p>This could be implemented in two ways:</p>
<ul>
<li>Microservices approach, the code that processes the purchase would probably wuery an exchange-rate service or a database in order to obtain the current rate for a particular currency.</li>
<li>Dataflow approach, the code that processes purchases would subscribe to a stream of exchange rate updates ahead of time, and record the current rate in a local database whenever it changes. When it comes to processing the purchase, it only needs to query the local database.</li>
</ul>
<p>The dataflow is not only faster, but it is also more robust to the failure of another service.</p>
<h4 id="observing-derived-state" style="position:relative;"><a href="#observing-derived-state" aria-label="observing derived state permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Observing derived state</h4>
<h5 id="materialised-views-and-caching" style="position:relative;"><a href="#materialised-views-and-caching" aria-label="materialised views and caching permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Materialised views and caching</h5>
<p>A full-text search index is a good example: the write path updates the index, and the read path searches the index for keywords.</p>
<p>If you don’t have an index, a search query would have to scan over all documents, which is very expensive. No index means less work on the write path (no index to update), but a lot more work on the read path.</p>
<p>Another option would be to precompute the search results for only a fixed set of the most common queries. The uncommon queries can still be served from the inxed. This is what we call a <em>cache</em> although it could also be called a materialised view.</p>
<h5 id="read-are-events-too" style="position:relative;"><a href="#read-are-events-too" aria-label="read are events too permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Read are events too</h5>
<p>It is also possible to represent read requests as streams of events, and send both the read events and write events through a stream processor; the processor responds to read events by emiting the result of the read to an output stream.</p>
<p>It would allow you to reconstruct what the user saw before they made a particular decision.</p>
<p>Enables better tracking of casual dependencies.</p>
<h3 id="aiming-for-correctness" style="position:relative;"><a href="#aiming-for-correctness" aria-label="aiming for correctness permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Aiming for correctness</h3>
<p>If your application can tolerate occasionally corrupting or losing data in unpredictable ways, life is a lot simpler. If you need stronger assurances of correctness, the serializability and atomic commit are established approaches.</p>
<p>While traditional transaction approach is not going away, there are some ways of thinking about correctness in the context of dataflow architectures.</p>
<h4 id="the-end-to-end-argument-for-databases" style="position:relative;"><a href="#the-end-to-end-argument-for-databases" aria-label="the end to end argument for databases permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>The end-to-end argument for databases</h4>
<p>Bugs occur, and people make mistakes. Favour of immutable and append-only data, because it is easier to recover from such mistakes.</p>
<p>We’ve seen the idea of <em>exactly-once</em> (or <em>effectively-once</em>) semantics. If something goes wrong while processing a message, you can either give up or try again. If you try again, there is the risk that it actually succeeded the first time, the message ends up being processed twice.</p>
<p><em>Exactly-once</em> means arranging the computation such that the final effect is the same as if no faults had occurred.</p>
<p>One of the most effective approaches is to make the operation <em>idempotent</em>, to ensure that it has the same effect, no matter whether it is executed once or multiple times. Idempotence requires some effort and care: you may need to maintain some additional metadata (operation IDs), and ensure fencing when failing over from one node to another.</p>
<p>Two-phase commit unfortunately is not sufficient to ensure that the transaction will only be executed once.</p>
<p>You need to consider <em>end-to-end</em> flow of the request.</p>
<p>You can generate a unique identifier for an operation (such as a UUID) and include it as a hidden form field in the client application, or calculate a hash of all the relevant form fields to derive the operation ID. If the web browser submits the POST request twice, the two requests will have the same operation ID. You can then pass that operation ID all the way through to the database and check that you only ever execute one operation with a given ID. You can then save those requests to be processed, uniquely identified by the operation ID.</p>
<p>Is not enough to prevent a user from submitting a duplicate request if the first one times out. Solving the problem requires an end-to-end solution: a transaction indentifier that is passed all the way from the end-user client to the database.</p>
<p>Low-level reliability mechanisms such as those in TCP, work quite well, and so the remaining higher-level faults occur fairly rarely.</p>
<p>Transactions have long been seen as a good abstraction, they are useful but not enough.</p>
<p>It is worth exploring F=fault-tolerance abstractions that make it easy to provide application-specific end-to-end correctness properties, but also maintain good performance and good operational characteristics.</p>
<h4 id="enforcing-constraints" style="position:relative;"><a href="#enforcing-constraints" aria-label="enforcing constraints permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Enforcing constraints</h4>
<h5 id="uniqueness-constraints-require-consensus" style="position:relative;"><a href="#uniqueness-constraints-require-consensus" aria-label="uniqueness constraints require consensus permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Uniqueness constraints require consensus</h5>
<p>The most common way of achieving consensus is to make a single node the leadder, and put it in charge of making all decisions. If you need to tolerate the leader failing, you’re back at the consensus problem again.</p>
<p>Uniqueness checking can be scaled out by partitioning based on the value that needs to be unique. For example, if you need usernames to be unique, you can partition by hash or username.</p>
<p>Asynchronous multi-master replication is ruled out as different masters concurrently may accept conflicting writes, so values are no longer unique. If you want to be able to immediately reject any writes that would violate the constraint, synchronous coordination is unavoidable.</p>
<h5 id="uniqueness-in-log-based-messaging" style="position:relative;"><a href="#uniqueness-in-log-based-messaging" aria-label="uniqueness in log based messaging permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Uniqueness in log-based messaging</h5>
<p>A stream processor consumes all the messages in a log partition sequentially on a single thread. A stream processor can unambiguously and deterministically decide which one of several conflicting operations came first.</p>
<ol>
<li>Every request for a username is encoded as a message.</li>
<li>A stream processor sequentially reads the requests in the log. For every request for a username tht is available, it records the name as taken and emits a success message to an output stream. For every request for a username that is already taken, it emits a rejection message to an output stream.</li>
<li>The client waits for a success or rejection message corresponding to its request.</li>
</ol>
<p>The approach works not only for uniqueness constraints, but also for many other kinds of constraints.</p>
<h5 id="multi-partition-request-processing" style="position:relative;"><a href="#multi-partition-request-processing" aria-label="multi partition request processing permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Multi-partition request processing</h5>
<p>There are potentially three partitions: the one containing the request ID, the one containing the payee account, and one containing the payer account.</p>
<p>The traditional approach to databases, executing this transaction would require an atomic commit across all three partitions.</p>
<p>Equivalent correctness can be achieved with partitioned logs, and without an atomic commit.</p>
<ol>
<li>The request to transfer money from account A to account B is given a unique request ID by the client, and appended to a log partition based on the request ID.</li>
<li>A stream processor reads the log of requests. For each request message it emits two messages to output streams: a debit instruction to the payer account A (partitioned by A), and a credit instruction to the payee account B (partitioned by B). The original request ID is included in those emitted messages.</li>
<li>Further processors consume the streams of credit and debit instructions, deduplicate by request ID, and apply the chagnes to the account balances.</li>
</ol>
<h4 id="timeliness-and-integrity" style="position:relative;"><a href="#timeliness-and-integrity" aria-label="timeliness and integrity permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Timeliness and integrity</h4>
<p>Consumers of a log are asynchronous by design, so a sender does not wait until its message has been proccessed by consumers. However, it is possible for a client to wait for a message to appear on an output stream.</p>
<p><em>Consistency</em> conflates two different requirements:</p>
<ul>
<li>Timeliness: users observe the system in an up-to-date state.</li>
<li>Integrity: Means absence of corruption. No data loss, no contradictory or false data. The derivation must be correct.</li>
</ul>
<p>Violations of timeless are “eventual consistency” whereas violations of integrity are “perpetual inconsistency”.</p>
<h4 id="correctness-and-dataflow-systems" style="position:relative;"><a href="#correctness-and-dataflow-systems" aria-label="correctness and dataflow systems permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Correctness and dataflow systems</h4>
<p>When processing event streams asynchronously, there is no guarantee of timeliness, unless you explicitly build consumers that wait for a message to arrive before returning. But integrity is in fact central to streaming systems.</p>
<p><em>Exactly-once</em> or <em>effectively-once</em> semantics is a mechanism for preserving integrity. Fault-tolerant message delivery and duplicate supression are important for maintaining the integrity of a data system in the face of faults.</p>
<p>Stream processing systems can preserve integrity without requireing distributed transactions and an atomic commit protocol, which means they can potentially achieve comparable correctness with much better performance and operational robustness. Integrity can be achieved through a combination of mechanisms:</p>
<ul>
<li>Representing the content of the write operation as a single message, this fits well with event-sourcing</li>
<li>Deriving all other state updates from that single message using deterministic derivation functions</li>
<li>Passing a client-generated request ID, enabling end-to-end duplicate supression and idempotence</li>
<li>Making messages immutable and allowing derived data to be reprocessed from time to time</li>
</ul>
<p>In many businesses contexts, it is actually acceptable to temporarily violate a constraint and fix it up later apologising. The cost of the apology (money or reputation), it is often quite low.</p>
<h4 id="coordination-avoiding-data-systems" style="position:relative;"><a href="#coordination-avoiding-data-systems" aria-label="coordination avoiding data systems permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Coordination-avoiding data-systems</h4>
<ol>
<li>Dataflow systems can maintain integrity guarantees on derived data without atomic commit, linearizability, or synchronous cross-partition coordination.</li>
<li>Although strict uniqueness constraints require timeliness and coordination, many applications are actually fine with loose constraints than may be temporarily violated and fixed up later.</li>
</ol>
<p>Dataflow systems can provide the data management services for many applications without requiring coordination, while still giving strong integrity guarantees. <em>Coordination-avoiding</em> data systems can achieve better performance and fault tolerance than systems that need to perform synchronous coordination.</p>
<h4 id="trust-but-verify" style="position:relative;"><a href="#trust-but-verify" aria-label="trust but verify permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Trust, but verify</h4>
<p>Checking the integrity of data is know as <em>auditing</em>.</p>
<p>If you want to be sure that your data is still there, you have to actually read it and check. It is important to try restoring from your backups from time to time. Don’t just blindly trust that it is working.</p>
<p><em>Self-validating</em> or <em>self-auditing</em> systems continually check their own integrity.</p>
<p>ACID databases has led us toward developing applications on the basis of blindly trusting technology, neglecting any sort of auditability in the process.</p>
<p>By contrast, event-based systems can provide better auditability (like with event sourcing).</p>
<p>Cryptographic auditing and integrity checking often relies on <em>Merkle trees</em>. Outside of the hype for cryptocurrencies, <em>certificate transparency</em> is a security technology that relies on Merkle trees to check the validity of TLS/SSL certificates.</p>
<h3 id="doing-the-right-thing" style="position:relative;"><a href="#doing-the-right-thing" aria-label="doing the right thing permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Doing the right thing</h3>
<p>Many datasets are about people: their behaviour, their interests, their identity. We must treat such data with humanity and respect. Users are humans too, and human dignitity is paramount.</p>
<p>There are guidelines to navigate these issues such as ACM’s Software Engineering Code of Ethics and Professional Practice</p>
<p>It is not sufficient for software engineers to focus exclusively on the technology and ignore its consequences: the ethical responsibility is ours to bear also.</p>
<p>In countries that respect human rights, the criminal justice system presumes innocence until proven guilty; on the other hand, automated systems can systematically and artbitrarily exclude a person from participating in society without any proof of guilt, and with little chance of appeal.</p>
<p>If there is a systematic bias in the input to an algorithm, the system will most likely learn and amplify bias in its output.</p>
<p>It seems ridiculous to believe that an algorithm could somehow take biased data as input and produce fair and impartial output from it. Yet this believe often seems to be implied by proponents of data-driven decision making.</p>
<p>If we want the future to be better than the past, moral imagination is required, and that’s something only humans can provide. Data and models should be our tools, not our masters.</p>
<p>If a human makes a mistake, they can be held accountable. Algorithms make mistakes too, but who is accountable if they go wrong?</p>
<p>A credit score summarises “How did you behave in the past?” whereas predictive analytics usually work on the basis of “Who is similar to you, and how did people like you behave in the past?” Drawing parallels to others’ behaviour implies stereotyping people.</p>
<p>We will also need to figure outhow to prevent data being used to harm people, and realise its positive potential instead, this power could be used to focus aid an support to help people who most need it.</p>
<p>When services become good at predicting what content users want to se, they may end up showing people only opinions they already agree with, leading to echo chambers in which stereotypes, misinformation and polaristaion can breed.</p>
<p>Many consequences can be predicted by thinking about the entire system (not just the computerised parts), an approach known as <em>systems thinking</em>.</p>
<h4 id="privacy-and-tracking" style="position:relative;"><a href="#privacy-and-tracking" aria-label="privacy and tracking permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Privacy and tracking</h4>
<p>When a system only stores data that a user has explicitly entered, because they want the system to store and process it in a certain way, the system is performing a service for the user: the user is the customer.</p>
<p>But when a user’s activity is tracked and logged as a side effect of other things they are doing, the relationship is less clear. The service no longer just does what the users tells it to do, but it takes on interests of its own, which may conflict with the user’s interest.</p>
<p>If the service is funded through advertising, the advertirsers are the actual customers, and the users’ interests take second place.</p>
<p>The user is given a free service and is coaxed into engaging with it as much as possible. The tracking of the user serves the needs of the advertirses who are funding the service. This is basically <em>surveillance</em>.</p>
<p>As a thougt experiment, try replacing the word <em>data</em> with <em>surveillance</em>.</p>
<p>Even themost totalitarian and repressive regimes could only dream of putting a microphone in every room and forcing every person to constantly carry a device capable of tracking their location and movements. Yet we apparently voluntarily, even enthusiastically, throw ourselves into this world of total surveillance. The difference is just that the data is being collected by corporations rather than government agencies.</p>
<p>Perhaps you feel you have nothing to hide, you are totally in line with existing power structures, you are not a marginalised minority, and you needn’t fear persecution. Not everyone is so fortunate.</p>
<p>Without understanding what happens to their data, users cannot give any meaningful consent. Often, data from one user also says things about other people who are not users of the service and who have not agreed to any terms.</p>
<p>For a user who does not consent to surveillance, the only real alternative is simply to not user the service. But this choice is not free either: if a service is so popular that it is “regarded by most people as essential for basic social participation”, then it is not reasonable to expect people to opt out of this service. Especially when a service has network effects, there is a social cost to people choosing <em>not</em> to use it.</p>
<p>Declining to use a service due to its tracking of users is only an option for the small number of people who are priviledged enough to have the time and knowledge to understand its privacy policy, and who can affort to potentially miss out on social participation or professional opportunities that may have arisen if they ahd participated in the service. For people in a less priviledged position, there is no meaningful freedom of choice: surveillance becomes inescapable.</p>
<p>Having privacy does not mean keeping everything secret; it means having the freedom to choose which things to reveal to whom, what to make public, and what to keep secret.</p>
<p>Companies that acquire data essentially say “trust us to do the right thing with your data” which means that the right to decide what to reveal and what to keep secret is transferred from the individual to the company.</p>
<p>Even if the service promises not to sell the data to third parties, it usually grants itself unrestricted rights to process and analyse the data internally, often going much further than what is overtly visible to users.</p>
<p>If targeted advertising is what pays for a service, then behavioral data about people is the service’s core asset.</p>
<p>When collecting data, we need to consider not just today’s political environment, but also future governments too. There is no guarantee that every government elected in the future will respect human rights and civil liberties, so “it is poor civic hygiene to install technologies that could someday facilitate a police state”.</p>
<p>To scrutinise others while avoiding scrutiny oneself is one of the most important forms of power.</p>
<p>In the industrial revolution tt took a long time before safeguards were established, such as environmental protection regulations, safety protocols for workplaces, outlawing child labor, and health inspections for food. Undoubtedly the cost of doing business increased when factories could no longer dump their waste into rivers, sell tainted foods, or exploit workers. But society as a whole benefited hugely, and few of us would want to return to a time before those regulations.</p>
<p>We should stop regarding users as metrics to be optimised, and remember that they are humans who deserve respect, dignity, and agency. We should self-regulate our data collection and processing practices in order to establish an maintain the trust of the people who depend on our software. And we should take it upon ourselves to educate end users about how their data is used, rather than keeping them in the dark.</p>
<p>We should allow each individual to maintain their privacy, their control over their own data, and not steal that control from them through surveillance.</p>
<p>We should not retain data forever, but purge it as soon as it is no longer needed.</p>
<h1 id="introduction-of-systems-performance-enterprise-and-the-cloud" style="position:relative;"><a href="#introduction-of-systems-performance-enterprise-and-the-cloud" aria-label="introduction of systems performance enterprise and the cloud permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Introduction of “Systems Performance: Enterprise and the Cloud”</strong></h1>
<p>The introduction of “Systems Performance: Enterprise and the Cloud” by Brendan Gregg sets the foundation for understanding the complex field of systems performance. It covers key concepts, methodologies, and examples that lay the groundwork for the rest of the book. Below is an in-depth breakdown of the content found in the Introduction chapter:</p>
<h3 id="11-systems-performance" style="position:relative;"><a href="#11-systems-performance" aria-label="11 systems performance permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>1.1 Systems Performance</strong></h3>
<ul>
<li><strong>Definition and Scope</strong>: Systems performance is defined as the study of the performance of an entire computer system, including all major software and hardware components. This can include any component within the data path, from storage devices to application software, or even a collection of servers in a distributed system.</li>
<li><strong>End-to-End Analysis</strong>: Emphasis is placed on understanding the relationships between components across the entire system stack. For distributed systems, this often means analyzing multiple servers and applications that contribute to a common user experience.</li>
<li><strong>Goals</strong>: The two primary goals of systems performance are improving end-user experience by reducing latency and reducing computing costs by eliminating inefficiencies and improving throughput.</li>
</ul>
<h3 id="12-roles" style="position:relative;"><a href="#12-roles" aria-label="12 roles permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>1.2 Roles</strong></h3>
<ul>
<li><strong>Who Does Systems Performance?</strong>: A variety of roles are involved, including system administrators, site reliability engineers (SREs), network engineers, database administrators, and more. Each of these roles may focus on specific aspects of systems performance, such as network health, application efficiency, or resource allocation.</li>
<li><strong>Performance Engineers</strong>: Dedicated performance engineers may work across multiple teams to conduct a holistic study of the entire system, coordinate efforts, and identify bottlenecks that require multidisciplinary expertise to resolve. Gregg provides an example from Netflix, where a cloud performance team assists multiple teams with performance analysis.</li>
</ul>
<h3 id="13-activities" style="position:relative;"><a href="#13-activities" aria-label="13 activities permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>1.3 Activities</strong></h3>
<ul>
<li><strong>Performance Lifecycle</strong>: Systems performance encompasses a wide range of activities, which can be organized as steps in the lifecycle of a software project. These activities include:
<ol>
<li>Setting <strong>performance objectives</strong> and creating performance models.</li>
<li><strong>Characterizing</strong> the performance of prototype software and hardware.</li>
<li><strong>Analyzing</strong> the performance of in-development products in a controlled environment.</li>
<li><strong>Non-regression testing</strong> for verifying the performance of new versions.</li>
<li><strong>Benchmarking</strong> to measure and validate performance metrics.</li>
<li><strong>Proof-of-concept testing</strong> in production environments.</li>
<li><strong>Performance tuning</strong> in real-world production.</li>
<li><strong>Monitoring</strong> systems while in production.</li>
<li><strong>Analyzing performance issues</strong> in production.</li>
<li>Conducting <strong>incident reviews</strong> for performance problems, looking for ways to prevent similar issues in the future.</li>
</ol>
</li>
</ul>
<h3 id="14-perspectives" style="position:relative;"><a href="#14-perspectives" aria-label="14 perspectives permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>1.4 Perspectives</strong></h3>
<ul>
<li><strong>Two Primary Perspectives</strong>: Systems performance analysis can be approached from two perspectives:
<ul>
<li><strong>Resource Analysis</strong>: Analyzing system resources like CPU, memory, disk, and network from the bottom up. This is the typical approach taken by system administrators.</li>
<li><strong>Workload Analysis</strong>: Analyzing workloads, including applications, from the top down. This perspective is used by developers who focus on application performance and seek to optimize how the workload utilizes underlying resources.</li>
</ul>
</li>
<li><strong>Full Stack Approach</strong>: Performance engineers often combine both perspectives to conduct a thorough analysis of a system, providing insights that are sometimes missed when only one perspective is used.</li>
</ul>
<h3 id="15-performance-is-challenging" style="position:relative;"><a href="#15-performance-is-challenging" aria-label="15 performance is challenging permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>1.5 Performance is Challenging</strong></h3>
<ul>
<li><strong>Subjectivity</strong>: Performance is often subjective, meaning that a “good” performance level for one user might be “bad” for another. Gregg discusses how setting objective goals, such as specific latency targets, can help eliminate subjectivity.</li>
<li><strong>Complexity</strong>: Systems are inherently complex. Performance issues can be influenced by cascading failures between components, making analysis difficult. Performance engineers must understand the interactions between all components and often adopt a holistic approach to analysis.</li>
<li><strong>Multiple Causes and Issues</strong>: Performance problems can arise from multiple, simultaneous causes rather than a single issue. Understanding and quantifying the magnitude of various issues is essential to identifying the highest impact opportunities for improvement.</li>
</ul>
<h3 id="16-latency" style="position:relative;"><a href="#16-latency" aria-label="16 latency permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>1.6 Latency</strong></h3>
<ul>
<li><strong>Key Metric for Performance</strong>: Latency is one of the most important metrics for measuring performance. It measures the time taken to complete operations such as an application request or database query.</li>
<li><strong>Estimating Speedup</strong>: The use of latency as a metric can help estimate potential speedups by analyzing time spent in different operations. For example, identifying latency in disk reads can help quantify the benefit of improving or caching those reads.</li>
<li><strong>Ambiguity</strong>: The term “latency” can be ambiguous without additional context. In the context of systems performance, latency may refer to the time required for connection setup, data transfer, or other operations. The chapter provides definitions to clarify such ambiguities.</li>
</ul>
<h3 id="17-observability" style="position:relative;"><a href="#17-observability" aria-label="17 observability permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>1.7 Observability</strong></h3>
<ul>
<li><strong>Understanding Through Observation</strong>: Observability refers to understanding a system by observing its external outputs. The chapter introduces the concepts of counters, metrics, profiling, and tracing.</li>
<li><strong>Types of Observability</strong>:
<ul>
<li><strong>Counters, Statistics, and Metrics</strong>: Basic numerical outputs that give insight into system behavior.</li>
<li><strong>Profiling</strong>: Capturing snapshots of resource usage over time, which is useful for understanding periodic resource bottlenecks.</li>
<li><strong>Tracing</strong>: Tracking the flow of requests through components to understand bottlenecks.</li>
</ul>
</li>
</ul>
<h3 id="18-experimentation" style="position:relative;"><a href="#18-experimentation" aria-label="18 experimentation permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>1.8 Experimentation</strong></h3>
<ul>
<li><strong>The Importance of Experimentation</strong>: Performance tuning is an iterative process involving trial and error. Experimentation is often essential to gain insights and validate assumptions.</li>
</ul>
<h3 id="19-cloud-computing" style="position:relative;"><a href="#19-cloud-computing" aria-label="19 cloud computing permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>1.9 Cloud Computing</strong></h3>
<ul>
<li><strong>Unique Challenges of Cloud</strong>: The chapter introduces cloud computing and the specific challenges it presents for systems performance. Cloud environments are highly dynamic, with frequent scaling and resource sharing. These factors affect observability and optimization efforts.</li>
</ul>
<h3 id="110-methodologies" style="position:relative;"><a href="#110-methodologies" aria-label="110 methodologies permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>1.10 Methodologies</strong></h3>
<ul>
<li>
<p><strong>Linux Perf Analysis in 60 Seconds</strong>: Brendan Gregg provides a practical checklist to quickly assess the performance of a Linux system in under 60 seconds. This rapid analysis method is particularly useful for time-critical scenarios, such as troubleshooting performance issues in production environments. The checklist involves running a series of quick commands to gather an overview of system health:</p>
<ol>
<li><strong>uptime</strong>: Checks system load averages to identify if the system is currently overloaded.</li>
<li><strong>dmesg | tail</strong>: Reviews recent kernel messages to check for errors or warnings.</li>
<li><strong>vmstat 1 5</strong>: Provides a quick summary of CPU, memory, and I/O activity over a short period. This helps identify CPU saturation, swapping, or I/O bottlenecks.</li>
<li><strong>mpstat -P ALL 1 5</strong>: Shows CPU usage for all processors to help identify if the workload is balanced across CPU cores.</li>
<li><strong>pidstat 1 5</strong>: Displays per-process resource usage, including CPU, memory, and I/O, which can help identify processes using the most resources.</li>
<li><strong>iostat -xz 1 5</strong>: Provides detailed disk I/O statistics, which can indicate if any disks are saturated or experiencing high latency.</li>
<li><strong>free -m</strong>: Checks memory usage, including available memory and swap usage, to determine if the system is experiencing memory pressure.</li>
<li><strong>sar -n DEV 1 5</strong>: Monitors network interface statistics to identify potential network bottlenecks.</li>
<li><strong>top</strong>: Provides a real-time view of system activity, including CPU, memory, and process information, useful for identifying resource-hungry processes.</li>
</ol>
</li>
<li>
<p><strong>Objective</strong>: The goal is to gather a high-level snapshot of system performance quickly, enabling the performance engineer to identify any glaring issues and determine where more detailed analysis is needed.</p>
</li>
<li>
<p><strong>Performance Analysis Techniques</strong>: Key methodologies for analyzing systems performance are introduced here, including ways to identify and resolve common performance issues.</p>
</li>
</ul>
<h3 id="111-case-studies" style="position:relative;"><a href="#111-case-studies" aria-label="111 case studies permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>1.11 Case Studies</strong></h3>
<ul>
<li><strong>Real-World Examples</strong>: The chapter concludes with case studies to illustrate common performance problems and solutions, including slow disks, software changes, and more complex scenarios. These examples demonstrate how performance analysis works in practice and serve as practical guides for dealing with similar challenges.</li>
</ul>
<h3 id="112-references" style="position:relative;"><a href="#112-references" aria-label="112 references permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>1.12 References</strong></h3>
<ul>
<li><strong>Sources for Further Reading</strong>: The introduction provides references to help readers learn more about the topics covered in the chapter and to deepen their understanding of performance analysis.</li>
</ul>
<h1 id="methodologies" style="position:relative;"><a href="#methodologies" aria-label="methodologies permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Methodologies</strong></h1>
<ul>
<li>
<p><strong>Modeling</strong></p>
<ul>
<li>Explores theoretical models and practical applications for predicting performance under different scenarios:
<ul>
<li><strong>Enterprise vs. Cloud</strong>: Compares traditional enterprise systems with cloud systems, highlighting differences in scalability and performance characteristics.</li>
<li><strong>Visual Identification</strong>: Stresses visual methods like diagrams to understand system structure and data flow.</li>
<li><strong>Amdahl’s Law of Scalability</strong>: Describes the law’s implications on system performance, particularly in highlighting diminishing returns as parallel processing increases.</li>
<li><strong>Universal Scalability Law</strong>: A model that predicts performance gains and limitations of scaling by addressing contention and coherence issues.</li>
<li><strong>Queueing Theory</strong>: Introduces queueing models as they apply to performance, helping predict delays based on resource usage and wait times.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Capacity Planning</strong></p>
<ul>
<li><strong>Resource Limits</strong>: Identifies maximum resource thresholds and the implications of exceeding them.</li>
<li><strong>Factor Analysis</strong>: Details the factors impacting performance, such as hardware constraints, software configurations, and workload types.</li>
<li><strong>Scaling Solutions</strong>: Examines strategies to scale resources to meet demand without degrading performance.</li>
</ul>
</li>
<li>
<p><strong>Statistics</strong></p>
<ul>
<li>Covers statistical methods for quantifying performance characteristics:
<ul>
<li><strong>Quantifying Performance Gains</strong>: Provides ways to calculate improvements objectively.</li>
<li><strong>Averages</strong>: Cautions against relying solely on averages and suggests using additional metrics like percentiles.</li>
<li><strong>Standard Deviation, Percentiles, Median</strong>: Discusses variability measures and their importance for understanding performance consistency.</li>
<li><strong>Coefficient of Variation</strong>: Examines relative variability, particularly for understanding performance stability.</li>
<li><strong>Multimodal Distributions</strong>: Recognizes patterns with multiple peaks, indicating varied workload behaviors.</li>
<li><strong>Outliers</strong>: Advises on interpreting outliers as potential indicators of performance bottlenecks or anomalies.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Terminology</strong></p>
<ul>
<li>Establishes key definitions that set a shared understanding across performance topics.</li>
<li>Terms like latency, throughput, utilization, saturation, profiling, and tracing are clarified to ensure consistency and precision in analysis.</li>
</ul>
</li>
<li>
<p><strong>Models</strong></p>
<ul>
<li><strong>System Under Test (SUT)</strong>: Describes how a performance engineer should define the boundaries of the system or component being analyzed.</li>
<li><strong>Queueing System</strong>: Introduces the concept of systems as queueing models where resources (e.g., CPU, disk) serve requests that may arrive faster than they can be processed, causing queues.
<ul>
<li>The queueing model aids in understanding delays and bottlenecks that occur when demand exceeds resource capacity.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="concepts" style="position:relative;"><a href="#concepts" aria-label="concepts permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Concepts</h2>
<ul>
<li>
<p><strong>Latency</strong></p>
<ul>
<li><strong>Definition</strong>: Latency is the time taken for a single operation to complete, from start to end. This can apply to a wide range of operations, from CPU cycles and disk I/O to network requests.</li>
<li><strong>Types of Latency</strong>:
<ul>
<li><strong>Response Time</strong>: The end-to-end delay perceived by a user or system component.</li>
<li><strong>Queueing Delay</strong>: The time a request waits before it can be processed due to resource saturation.</li>
</ul>
</li>
<li><strong>Importance</strong>: Latency is a key performance metric, as it directly affects user experience. High latency in critical paths can lead to slow application performance or dissatisfied users.</li>
<li><strong>Measurement</strong>: Measured in milliseconds (ms) or microseconds (µs), with tools like <code class="language-text">perf</code>, <code class="language-text">tcpdump</code>, or application logs providing insights into latency at various stages.</li>
<li><strong>Application</strong>: In performance tuning, reducing latency often means optimizing resources (e.g., CPU, memory) and addressing bottlenecks.</li>
</ul>
</li>
<li>
<p><strong>Time Scales</strong></p>
<ul>
<li><strong>Definition</strong>: Time scales refer to the different temporal levels at which performance metrics and events are examined.</li>
<li><strong>Levels</strong>:
<ul>
<li><strong>Microsecond and Millisecond</strong>: Useful for analyzing short-duration events like CPU instructions, system calls, or high-performance network requests.</li>
<li><strong>Second</strong>: Often used for observing resource utilization patterns, like CPU or disk utilization over time.</li>
<li><strong>Long-Term (Minutes to Days)</strong>: Important for trend analysis, identifying recurring patterns, or observing workload behavior changes over days or weeks.</li>
</ul>
</li>
<li><strong>Importance</strong>: Different time scales reveal different performance characteristics. For example, microsecond granularity may expose CPU contention in a highly parallel application, while daily patterns could reveal peak and off-peak load times.</li>
<li><strong>Application</strong>: Analysts select the appropriate time scale based on the performance question being investigated, ensuring insights match the relevant time frame of the observed issue.</li>
</ul>
</li>
<li>
<p><strong>Trade-Offs</strong></p>
<ul>
<li><strong>Definition</strong>: Trade-offs in system performance involve balancing conflicting resource demands to optimize overall efficiency.</li>
<li><strong>Examples of Common Trade-Offs</strong>:
<ul>
<li><strong>Memory vs. CPU Usage</strong>: Algorithms that save memory might use more CPU and vice versa.</li>
<li><strong>Throughput vs. Latency</strong>: Increasing throughput might raise latency if resources become saturated.</li>
<li><strong>Resource Usage vs. Power Consumption</strong>: High CPU utilization can improve processing speed but consumes more power, which can be a concern in power-sensitive environments.</li>
</ul>
</li>
<li><strong>Importance</strong>: Trade-offs guide decision-making in tuning and resource allocation, ensuring that gains in one area don’t lead to unacceptable losses in another.</li>
<li><strong>Application</strong>: Analysts weigh trade-offs to find optimal configurations, often needing to compromise based on system requirements or priorities.</li>
</ul>
</li>
<li>
<p><strong>Tuning Efforts</strong></p>
<ul>
<li><strong>Definition</strong>: Tuning efforts refer to the time and resources invested in optimizing a system, with the goal of achieving measurable performance improvements.</li>
<li><strong>Diminishing Returns</strong>: Initial tuning often yields significant gains, but further tuning may have limited impact, requiring increasingly complex and costly interventions.</li>
<li><strong>Importance</strong>: Helps analysts decide when to stop optimizing and when further efforts are not justified by the potential gains.</li>
<li><strong>Application</strong>: Tuning is balanced against available resources and deadlines, ensuring that time and effort are spent where they provide maximum impact.</li>
</ul>
</li>
<li>
<p><strong>Level of Appropriateness</strong></p>
<ul>
<li><strong>Definition</strong>: Refers to selecting the right level of detail in performance analysis, tailored to the scope and complexity of the problem.</li>
<li><strong>Granularity Choices</strong>:
<ul>
<li><strong>High-Level (System-Wide)</strong>: Suitable for general performance monitoring and identifying overarching bottlenecks.</li>
<li><strong>Low-Level (Component or Process-Level)</strong>: Essential for diagnosing specific issues within a particular application or resource.</li>
</ul>
</li>
<li><strong>Importance</strong>: Choosing the appropriate level prevents unnecessary complexity and focuses efforts where they are most likely to yield insights.</li>
<li><strong>Application</strong>: Analysts balance detail levels, starting broad and drilling down as needed, depending on the complexity of the issue.</li>
</ul>
</li>
<li>
<p><strong>When to Stop Analysis</strong></p>
<ul>
<li><strong>Definition</strong>: Establishing a threshold at which performance analysis is considered complete or when further analysis may yield minimal returns.</li>
<li><strong>Stopping Criteria</strong>:
<ul>
<li><strong>Performance Goals Met</strong>: If objectives like response time or utilization targets are achieved.</li>
<li><strong>Resource Constraints</strong>: If further analysis is too costly or resource-intensive.</li>
<li><strong>Plateauing Improvements</strong>: If tuning and troubleshooting reach diminishing returns.</li>
</ul>
</li>
<li><strong>Importance</strong>: Prevents wasted effort and resources, allowing teams to allocate time effectively and focus on pressing issues.</li>
<li><strong>Application</strong>: Used in iterative performance tuning cycles, where each cycle is evaluated for the necessity of further efforts.</li>
</ul>
</li>
<li>
<p><strong>Point-in-Time Recommendations</strong></p>
<ul>
<li><strong>Definition</strong>: Recommendations are based on current system state and workload, acknowledging that performance requirements and system configuration may change over time.</li>
<li><strong>Importance</strong>: Recognizes that performance tuning is a moving target; as workloads evolve, so too must optimizations.</li>
<li><strong>Application</strong>: Analysts document the rationale for tuning choices, noting that they may need adjustment as the system or application grows or changes.</li>
</ul>
</li>
<li>
<p><strong>Load vs. Architecture</strong></p>
<ul>
<li><strong>Definition</strong>: Differentiates between the system’s workload (load) and its design or capabilities (architecture).
<ul>
<li><strong>Load</strong>: The volume and type of demand placed on a system at any given time.</li>
<li><strong>Architecture</strong>: The underlying design, such as hardware capacity, software configuration, and resource distribution.</li>
</ul>
</li>
<li><strong>Importance</strong>: Analyzing load helps in understanding if performance issues are due to demand outpacing capacity, while architecture analysis evaluates if the system design supports the workload efficiently.</li>
<li><strong>Application</strong>: Analysts determine if performance improvements should focus on scaling the architecture (e.g., adding servers) or adjusting the workload (e.g., throttling requests).</li>
</ul>
</li>
<li>
<p><strong>Scalability</strong></p>
<ul>
<li><strong>Definition</strong>: Scalability is the system’s ability to handle increased load by proportionally increasing resources or optimizing current resources.</li>
<li><strong>Scalability Models</strong>:
<ul>
<li><strong>Vertical Scaling</strong>: Adding more power to an existing machine (e.g., more CPU cores).</li>
<li><strong>Horizontal Scaling</strong>: Adding more machines to distribute load.</li>
</ul>
</li>
<li><strong>Importance</strong>: Ensures the system can adapt to growth without major redesigns.</li>
<li><strong>Application</strong>: Analysts often simulate increased load or benchmark scenarios to evaluate if the current system scales efficiently or if new solutions are required.</li>
</ul>
</li>
<li>
<p><strong>Metrics</strong></p>
<ul>
<li><strong>Definition</strong>: Metrics are quantitative measurements that provide insight into system performance.</li>
<li><strong>Types of Metrics</strong>:
<ul>
<li><strong>Throughput</strong>: Volume of operations completed per unit time (e.g., requests per second).</li>
<li><strong>Utilization</strong>: Percentage of time a resource is actively in use.</li>
<li><strong>Error Rate</strong>: Frequency of errors or faults.</li>
</ul>
</li>
<li><strong>Importance</strong>: Reliable metrics form the backbone of performance analysis, enabling data-driven decisions.</li>
<li><strong>Application</strong>: Analysts collect, monitor, and analyze these metrics to identify trends, issues, and bottlenecks.</li>
</ul>
</li>
<li>
<p><strong>Utilization and Saturation</strong></p>
<ul>
<li><strong>Utilization</strong>:
<ul>
<li><strong>Definition</strong>: The percentage of time a resource is in use, showing how busy it is.</li>
<li><strong>Importance</strong>: High utilization indicates heavy use, which could signal impending bottlenecks.</li>
</ul>
</li>
<li><strong>Saturation</strong>:
<ul>
<li><strong>Definition</strong>: The extent to which a resource is overused, resulting in queuing and delays.</li>
<li><strong>Importance</strong>: High saturation levels are a strong indicator of bottlenecks and degraded performance.</li>
</ul>
</li>
<li><strong>Application</strong>: Both metrics are used in concert to assess resource availability and identify overtaxed components.</li>
</ul>
</li>
<li>
<p><strong>Profiling</strong></p>
<ul>
<li><strong>Definition</strong>: Profiling is the process of collecting detailed data on system performance, often focusing on specific components (e.g., CPU, memory).</li>
<li><strong>Purpose</strong>: Identifies which parts of the system or application consume the most resources.</li>
<li><strong>Tools</strong>: <code class="language-text">perf</code>, <code class="language-text">gprof</code>, <code class="language-text">bpftrace</code>, among others, can capture profiling data.</li>
<li><strong>Application</strong>: Profiling is used to optimize hotspots, or areas consuming disproportionate resources.</li>
</ul>
</li>
<li>
<p><strong>Caching</strong></p>
<ul>
<li><strong>Definition</strong>: Caching temporarily stores frequently accessed data in a faster storage area to reduce access latency.</li>
<li><strong>Types of Caches</strong>:
<ul>
<li><strong>Memory Cache</strong>: Stores data in RAM for quicker access.</li>
<li><strong>Disk Cache</strong>: Stores data in faster storage for disk I/O efficiency.</li>
<li><strong>Web Cache</strong>: Stores web resources closer to end users.</li>
</ul>
</li>
<li><strong>Importance</strong>: Caching significantly improves response times by reducing latency on repeated data requests.</li>
<li><strong>Application</strong>: Analysts often tune cache sizes and policies to strike a balance between memory usage and cache hit rate.</li>
</ul>
</li>
<li>
<p><strong>Known-Unknowns</strong></p>
<ul>
<li><strong>Definition</strong>: Known-unknowns are areas of the system that might impact performance but lack sufficient visibility.</li>
<li><strong>Examples</strong>:
<ul>
<li>Areas without monitoring or logging (blind spots).</li>
<li>Components where full performance impact is uncertain.</li>
</ul>
</li>
<li><strong>Importance</strong>: Recognizing known-unknowns helps analysts identify blind spots where performance issues may be lurking.</li>
<li><strong>Application</strong>: Analysts continuously assess and expand observability to reduce known-unknown, such as adding monitoring tools to unmonitored components.</li>
</ul>
</li>
<li>
<p><strong>Perspectives</strong></p>
<ul>
<li>Introduces two primary analysis perspectives:
<ul>
<li><strong>Resource Analysis</strong>: Focuses on understanding each resource (e.g., CPU, memory) independently to identify constraints and inefficiencies.</li>
<li><strong>Workload Analysis</strong>: Involves characterizing the demand that applications and processes place on system resources to see how they affect performance.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="methodology" style="position:relative;"><a href="#methodology" aria-label="methodology permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Methodology</strong></h2>
<ul>
<li>
<p><strong>Anti-Methods</strong></p>
<ul>
<li>Streetlight Anti-Method: This involves focusing on what is easy to observe or measure rather than investigating areas that may actually need attention. The name comes from the “streetlight effect,” where someone looks for a lost item under a streetlight simply because it’s brighter there, even if the item was lost elsewhere.
<ul>
<li>Pitfall: Limits the analyst’s scope and may miss the root cause, as easy-to-observe metrics are not always the relevant metrics.</li>
</ul>
</li>
<li>Random Change Anti-Method: Here, changes are applied randomly without a scientific basis or understanding of the system’s behavior.
<ul>
<li>Pitfall: Can create new issues, making troubleshooting harder. This method often lacks controlled testing and documentation, so changes and their effects are not fully understood.</li>
</ul>
</li>
<li>Blame-Someone-Else Anti-Method: Rather than analyzing the system comprehensively, blame is shifted to other teams or components without sufficient evidence.
<ul>
<li>Pitfall: Leads to misdiagnosis and delays in issue resolution. Effective analysis requires collaboration rather than assumption.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Ad Hoc Checklist Method</strong></p>
<ul>
<li>This involves using a quick, often experience-based checklist of typical performance checks and fixes.</li>
<li>Application: Useful for addressing known performance problems rapidly, especially in high-pressure situations.</li>
<li>Pitfall: Lacks thoroughness and can miss complex or novel issues. Often reactive rather than proactive.</li>
</ul>
</li>
<li>
<p><strong>Scientific Method</strong></p>
<ul>
<li>Steps: Hypothesis formation, experiment design, data collection, analysis, and conclusion.</li>
<li>Purpose: A rigorous, repeatable approach where hypotheses are tested against observations and adjusted based on results.</li>
<li>Advantages: Reduces guesswork by grounding findings in empirical data, allowing for evidence-based solutions.</li>
<li>Application: Ideal for complex issues that require in-depth understanding and a high degree of accuracy.</li>
</ul>
</li>
<li>
<p><strong>Diagnosis Cycle</strong></p>
<ul>
<li>Involves an iterative approach to performance analysis where the analyst forms hypotheses, tests them, and refines the understanding of the problem with each cycle.</li>
<li>Steps: Problem identification → Hypothesis generation → Testing and data collection → Adjustment of hypothesis.</li>
<li>Purpose: Allows performance issues to be systematically narrowed down through repeated analysis.</li>
<li>Application: Suitable for complex, multi-faceted problems where direct observation does not reveal clear causes.</li>
</ul>
</li>
<li>
<p><strong>Tools Method</strong></p>
<ul>
<li>Focuses on using specific tools and their outputs to address and analyze performance.</li>
<li>Example: Using CPU profilers (e.g., perf), memory tools (e.g., vmstat), and network monitors (e.g., tcpdump) to identify resource bottlenecks.</li>
<li>Pitfall: Tool-centric analysis can lead to over-reliance on certain metrics or types of data, potentially overlooking the broader context or interactions between system components.</li>
</ul>
</li>
<li>
<p><strong>The USE Method (Utilization, Saturation, Errors)</strong></p>
<ul>
<li>Steps: Examine each resource in a system (e.g., CPU, memory, disk, network) for:</li>
<li>Utilization: The percentage of resource use, identifying how busy the resource is.</li>
<li>Saturation: The demand exceeding the resource’s capacity, leading to queuing and delays.</li>
<li>Errors: Faults or abnormal behaviors impacting resource performance.</li>
<li>Purpose: Provides a comprehensive view by systematically examining the key factors affecting each resource.</li>
<li>Advantages: Helps quickly locate bottlenecks and provides a structured approach to address them.</li>
<li>Application: Effective for diagnosing common performance issues, especially in complex systems where multiple resources are used.</li>
</ul>
</li>
<li>
<p><strong>The RED Method (Rate, Errors, Duration)</strong></p>
<ul>
<li>Primarily applied to microservices and request-driven architectures:</li>
<li>Rate: Frequency of requests.</li>
<li>Errors: Error rate per unit time or request.</li>
<li>Duration: Time taken per request (latency).</li>
<li>Purpose: Focuses on user-facing services and provides a user-centered perspective.</li>
<li>Advantages: Ideal for web services and microservices, helping quickly identify service-level bottlenecks.</li>
<li>Application: Effective in customer-centric systems where request handling is crucial, such as e-commerce and cloud services.</li>
</ul>
</li>
<li>
<p><strong>Workload Characterization</strong></p>
<ul>
<li>Involves understanding the nature of the workload being run on the system: how it demands CPU, memory, I/O, and network resources.</li>
<li>Elements: Identify types (e.g., batch processing, real-time requests), frequency, intensity, and resource distribution of workloads.</li>
<li>Purpose: Provides context for performance metrics by relating them to actual workload demands.</li>
<li>Application: Essential for accurate benchmarking, capacity planning, and understanding how different workloads impact performance.</li>
</ul>
</li>
<li>
<p><strong>Drill-Down Analysis</strong></p>
<ul>
<li>A technique to focus progressively deeper on a specific metric or subsystem.</li>
<li>Steps: Start with high-level metrics and drill down into details (e.g., from system-level CPU usage to per-thread CPU usage).</li>
<li>Purpose: Isolates the exact layer or component contributing to a performance issue.</li>
<li>Application: Useful when initial indicators suggest an issue in a particular area, but detailed analysis is needed to locate the exact source.</li>
</ul>
</li>
<li>
<p><strong>Latency Analysis</strong></p>
<ul>
<li>Examines response times, queuing delays, and processing times at various stages in the system.</li>
<li>Steps: Measure latency at key points (e.g., application, network, storage) and plot latency distribution to identify outliers.</li>
<li>Purpose: Helps to identify components or processes with excessive delay.</li>
<li>Application: Particularly valuable in user-facing systems where response time directly impacts user experience.</li>
</ul>
</li>
<li>
<p><strong>Method R</strong></p>
<ul>
<li>Objective: Reducing response times by focusing on critical paths and delays within applications.</li>
<li>Steps: Identify critical paths, focus on optimizing slow segments, and estimate the maximum potential speedup.</li>
<li>Purpose: Focuses on maximizing system responsiveness, especially important in user-interactive systems.</li>
<li>Application: Commonly used in database and application performance tuning where response time is critical.</li>
</ul>
</li>
<li>
<p><strong>Event Tracing</strong></p>
<ul>
<li>Uses trace events within the system (e.g., function calls, context switches) to monitor detailed operations and interactions.</li>
<li>Tools: Event tracers like perf, Ftrace, bpftrace.</li>
<li>Purpose: Provides insight into fine-grained activities, revealing interactions and performance at the microsecond level.</li>
<li>Application: Helpful for diagnosing intricate issues in application performance, kernel operations, or system resource contention.</li>
</ul>
</li>
<li>
<p><strong>Baseline Statistics</strong></p>
<ul>
<li>Involves gathering data over time to establish a baseline of normal performance.</li>
<li>Purpose: Baselines provide context for identifying deviations and anomalies.</li>
<li>Application: Useful in long-term monitoring, enabling early detection of problems by comparing current performance to historical averages.</li>
</ul>
</li>
<li>
<p><strong>Static Performance Tuning</strong></p>
<ul>
<li>Pre-emptive adjustments made to configurations based on known best practices, tuning known bottlenecks.</li>
<li>Purpose: Optimizes resource usage without requiring real-time troubleshooting.</li>
<li>Application: Commonly applied in database, memory, and CPU resource allocation.</li>
</ul>
</li>
<li>
<p><strong>Cache Tuning</strong></p>
<ul>
<li>Focuses on optimizing cache behavior to reduce access times and improve hit ratios.</li>
<li>Purpose: Ensures frequently accessed data is stored closer to the processing units, minimizing latency.</li>
<li>Application: Used extensively in memory, file system, and application-level caches.</li>
</ul>
</li>
<li>
<p><strong>Micro-Benchmarking</strong></p>
<ul>
<li>Involves running small, controlled tests to evaluate the impact of specific changes.</li>
<li>Purpose: Provides precise measurements in an isolated environment.</li>
<li>Application: Ideal for testing hardware upgrades, configuration changes, or new algorithms on performance-sensitive tasks.</li>
</ul>
</li>
<li>
<p><strong>Performance Mantras</strong></p>
<ul>
<li>Examples: “Measure, don’t guess,” “Optimize the common case,” “Make it work, make it right, make it fast.”</li>
<li>Purpose: These simplified principles serve as reminders to follow best practices and avoid common pitfalls.</li>
<li>Application: Applied as guiding rules to improve analysis focus and efficiency.</li>
</ul>
</li>
</ul>
<h2 id="monitoring" style="position:relative;"><a href="#monitoring" aria-label="monitoring permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Monitoring</h2>
<h3 id="time-based-patterns" style="position:relative;"><a href="#time-based-patterns" aria-label="time based patterns permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Time-Based Patterns</strong></h3>
<ul>
<li><strong>Definition</strong>: Time-based patterns refer to the cyclical or recurring behaviors in system performance metrics observed over different time intervals.</li>
<li><strong>Examples of Time-Based Patterns</strong>:
<ul>
<li><strong>Daily Patterns</strong>: Systems often have predictable cycles, like increased usage during business hours and reduced usage at night.</li>
<li><strong>Weekly Patterns</strong>: Some systems, particularly those related to business operations, may have lower activity on weekends and peak activity during weekdays.</li>
<li><strong>Seasonal Patterns</strong>: E-commerce platforms might see spikes during holiday seasons or special events.</li>
</ul>
</li>
<li><strong>Importance</strong>: Recognizing these patterns is crucial for identifying what is “normal” versus what is a potential anomaly. Understanding time-based patterns also assists in capacity planning and helps avoid false alerts due to expected load changes.</li>
<li><strong>Application</strong>:
<ul>
<li>Monitoring tools typically provide dashboards and reports with historical data, helping visualize these patterns.</li>
<li>Analysts can use time-based patterns to set baseline expectations, improving anomaly detection and alerting accuracy by differentiating expected cyclic behavior from true performance issues.</li>
</ul>
</li>
</ul>
<h3 id="monitoring-products" style="position:relative;"><a href="#monitoring-products" aria-label="monitoring products permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Monitoring Products</strong></h3>
<ul>
<li><strong>Definition</strong>: Monitoring products are specialized tools designed to gather, process, and present system performance metrics in real time and over historical periods.</li>
<li><strong>Types of Monitoring Products</strong>:
<ul>
<li><strong>Infrastructure Monitoring</strong>: Focuses on system-level metrics (e.g., CPU, memory, disk I/O) using tools like <code class="language-text">Nagios</code>, <code class="language-text">Zabbix</code>, <code class="language-text">Prometheus</code>, and <code class="language-text">Grafana</code>.</li>
<li><strong>Application Performance Monitoring (APM)</strong>: Tracks application-specific metrics (e.g., request rates, error rates, response times) using tools like <code class="language-text">New Relic</code>, <code class="language-text">AppDynamics</code>, and <code class="language-text">Datadog</code>.</li>
<li><strong>Log Aggregation and Analysis</strong>: Collects and analyzes logs to uncover insights, using tools like <code class="language-text">Elasticsearch</code>, <code class="language-text">Splunk</code>, and <code class="language-text">Graylog</code>.</li>
</ul>
</li>
<li><strong>Purpose</strong>: Monitoring products provide observability into different layers of the stack and enable continuous, real-time insights into system performance.</li>
<li><strong>Application</strong>:
<ul>
<li>Analysts configure monitoring products to capture relevant metrics for each critical component.</li>
<li>These tools are typically integrated into alerting systems that notify operators when performance deviates from normal thresholds, allowing for quick response.</li>
</ul>
</li>
</ul>
<h3 id="summary-since-boot" style="position:relative;"><a href="#summary-since-boot" aria-label="summary since boot permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Summary-Since-Boot</strong></h3>
<ul>
<li><strong>Definition</strong>: A summary-since-boot metric provides cumulative performance data from the time the system last restarted. It aggregates usage data over a long period, helping analysts understand the overall load and resource consumption.</li>
<li><strong>Examples</strong>:
<ul>
<li><strong>CPU Utilization</strong>: The percentage of time the CPU has been busy since boot.</li>
<li><strong>Disk I/O</strong>: Total read and write operations performed since the system started.</li>
<li><strong>Network Throughput</strong>: Total bytes sent and received since the last restart.</li>
</ul>
</li>
<li><strong>Importance</strong>: This cumulative data provides a broad view of system activity, making it easier to identify long-term resource usage trends and avoid short-term spikes that might distort typical usage patterns.</li>
<li><strong>Application</strong>:
<ul>
<li>Analysts use summary-since-boot metrics as a baseline to understand typical workload patterns, which can be particularly valuable for planning, capacity assessment, and identifying slow-burning issues that develop over long periods.</li>
<li>Tools like <code class="language-text">sar</code> and <code class="language-text">vmstat</code> can be configured to log data periodically, providing a cumulative view of system metrics.</li>
</ul>
</li>
</ul>
<h3 id="real-time-vs-historical-monitoring" style="position:relative;"><a href="#real-time-vs-historical-monitoring" aria-label="real time vs historical monitoring permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Real-Time vs. Historical Monitoring</strong></h3>
<ul>
<li><strong>Real-Time Monitoring</strong>:
<ul>
<li><strong>Definition</strong>: Capturing and displaying system performance data as it happens, often with second-to-minute granularity.</li>
<li><strong>Importance</strong>: Essential for detecting and responding to immediate issues. Real-time monitoring allows quick identification of sudden spikes or drops in performance, helping mitigate outages and bottlenecks.</li>
<li><strong>Tools</strong>: <code class="language-text">top</code>, <code class="language-text">htop</code>, <code class="language-text">nload</code>, and dashboards in APM tools (e.g., Datadog, New Relic).</li>
<li><strong>Application</strong>: Real-time monitoring is particularly useful during incident response, providing an up-to-date view of the system’s health.</li>
</ul>
</li>
<li><strong>Historical Monitoring</strong>:
<ul>
<li><strong>Definition</strong>: Storing and analyzing data over extended periods to identify trends, patterns, and changes in system performance.</li>
<li><strong>Importance</strong>: Enables trend analysis, anomaly detection, and long-term capacity planning. Historical data helps correlate performance issues with external events, seasonal trends, or recurring issues.</li>
<li><strong>Tools</strong>: <code class="language-text">Prometheus</code> with <code class="language-text">Grafana</code>, <code class="language-text">Elasticsearch</code>, and <code class="language-text">Splunk</code> for log-based analysis.</li>
<li><strong>Application</strong>: Historical monitoring helps performance engineers understand how changes impact performance over time and can inform capacity planning and scaling decisions.</li>
</ul>
</li>
</ul>
<h3 id="anomaly-detection" style="position:relative;"><a href="#anomaly-detection" aria-label="anomaly detection permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Anomaly Detection</strong></h3>
<ul>
<li><strong>Definition</strong>: Anomaly detection involves identifying deviations from the established baseline or expected behavior.</li>
<li><strong>Types of Anomalies</strong>:
<ul>
<li><strong>Sudden Spikes or Drops</strong>: Large, immediate changes in a metric, which could indicate incidents like a DDoS attack or hardware failure.</li>
<li><strong>Gradual Trend Shifts</strong>: Slower changes over time, often indicative of resource leaks or slow memory saturation.</li>
</ul>
</li>
<li><strong>Importance</strong>: Early detection of anomalies helps avoid more severe issues by allowing analysts to respond quickly before an anomaly turns into a service-impacting incident.</li>
<li><strong>Application</strong>:
<ul>
<li>Modern monitoring systems often include built-in anomaly detection algorithms, such as threshold-based, moving averages, or machine learning-based models.</li>
<li>Analysts can fine-tune anomaly detection thresholds based on historical patterns to reduce false positives.</li>
</ul>
</li>
</ul>
<h3 id="alerting" style="position:relative;"><a href="#alerting" aria-label="alerting permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Alerting</strong></h3>
<ul>
<li><strong>Definition</strong>: Alerting is the process of notifying the operations team of performance or health issues as they occur.</li>
<li><strong>Types of Alerts</strong>:
<ul>
<li><strong>Threshold-Based Alerts</strong>: Triggered when metrics exceed or fall below a defined limit (e.g., CPU utilization above 80%).</li>
<li><strong>Anomaly-Based Alerts</strong>: Triggered based on deviations from expected patterns or baseline behavior.</li>
<li><strong>Composite Alerts</strong>: Combine multiple metrics (e.g., high CPU and memory usage) to reduce noise and focus on critical issues.</li>
</ul>
</li>
<li><strong>Importance</strong>: Effective alerting enables proactive response to performance issues, minimizing downtime and improving system reliability.</li>
<li><strong>Application</strong>:
<ul>
<li>Analysts configure alert thresholds carefully to strike a balance between avoiding unnecessary noise (alert fatigue) and catching important issues.</li>
<li>Alert systems are often configured with different urgency levels, such as warning alerts for monitoring and critical alerts for immediate action.</li>
</ul>
</li>
</ul>
<h3 id="visualization-techniques" style="position:relative;"><a href="#visualization-techniques" aria-label="visualization techniques permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Visualization Techniques</strong></h3>
<ul>
<li><strong>Definition</strong>: Visualization techniques present monitoring data graphically to make it easier to understand and analyze patterns, trends, and anomalies.</li>
<li><strong>Common Visualization Types</strong>:
<ul>
<li><strong>Line Graphs</strong>: Show metric changes over time, highlighting trends and periodic patterns.</li>
<li><strong>Heat Maps</strong>: Visualize data density, useful for identifying hot spots or patterns in high-frequency events.</li>
<li><strong>Stacked Area Charts</strong>: Show cumulative usage, useful for understanding how resource consumption is distributed across different applications or services.</li>
<li><strong>Histograms</strong>: Display distributions (e.g., latency distributions) to reveal performance outliers and assess consistency.</li>
</ul>
</li>
<li><strong>Importance</strong>: Visualizations transform raw data into interpretable insights, which support quicker and more accurate analysis.</li>
<li><strong>Application</strong>: Analysts use visualization tools like Grafana, Kibana, and custom dashboards to explore and present data meaningfully, helping both technical and non-technical stakeholders understand system performance.</li>
</ul>
<h3 id="monitoring-granularity" style="position:relative;"><a href="#monitoring-granularity" aria-label="monitoring granularity permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Monitoring Granularity</strong></h3>
<ul>
<li><strong>Definition</strong>: Monitoring granularity refers to the detail and frequency at which performance data is collected.</li>
<li><strong>Levels of Granularity</strong>:
<ul>
<li><strong>High Granularity</strong>: Frequent sampling intervals (e.g., per second) providing a detailed view of system behavior, often used for troubleshooting specific incidents.</li>
<li><strong>Low Granularity</strong>: Longer sampling intervals (e.g., per minute or per hour) useful for high-level trend analysis and reducing data storage costs.</li>
</ul>
</li>
<li><strong>Importance</strong>: Choosing the right granularity balances the need for detail with resource and storage constraints.</li>
<li><strong>Application</strong>:
<ul>
<li>High granularity monitoring is configured for critical resources or systems requiring rapid detection of performance changes.</li>
<li>Low granularity monitoring is typically applied for long-term historical analysis and capacity planning.</li>
</ul>
</li>
</ul>
<h3 id="metric-aggregation-and-data-retention" style="position:relative;"><a href="#metric-aggregation-and-data-retention" aria-label="metric aggregation and data retention permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Metric Aggregation and Data Retention</strong></h3>
<ul>
<li><strong>Definition</strong>: Metric aggregation combines data points to reduce the volume of data, while data retention policies determine how long monitoring data is stored.</li>
<li><strong>Purpose of Aggregation</strong>: Reduces storage needs and improves visualization performance by summarizing data over time.
<ul>
<li><strong>Examples</strong>: Averaging CPU usage per minute instead of storing each second’s data; summarizing network traffic by hourly totals.</li>
</ul>
</li>
<li><strong>Purpose of Data Retention</strong>: Determines the historical depth available for analysis and long-term trend recognition.
<ul>
<li><strong>Application</strong>: Short-term high granularity data (e.g., last 24 hours) for detailed analysis and aggregated long-term data (e.g., last year) for trend and capacity analysis.</li>
</ul>
</li>
</ul>
<h3 id="synthetic-monitoring" style="position:relative;"><a href="#synthetic-monitoring" aria-label="synthetic monitoring permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Synthetic Monitoring</strong></h3>
<ul>
<li><strong>Definition</strong>: Synthetic monitoring simulates user transactions or operations by periodically running tests from external or internal points to validate system performance and availability.</li>
<li><strong>Examples of Synthetic Checks</strong>:
<ul>
<li><strong>HTTP Pings</strong>: Monitoring a website’s availability and response time by sending requests from different locations.</li>
<li><strong>API Tests</strong>: Sending sample requests to APIs to measure response times and detect service degradation.</li>
</ul>
</li>
<li><strong>Importance</strong>: Synthetic monitoring provides a consistent benchmark and proactive insight into user experience, even if real users are not active on the system.</li>
<li><strong>Application</strong>:
<ul>
<li>Synthetic checks are often run periodically from multiple locations to validate uptime and performance from diverse network conditions.</li>
</ul>
</li>
</ul>
<h3 id="end-user-experience-monitoring-eum" style="position:relative;"><a href="#end-user-experience-monitoring-eum" aria-label="end user experience monitoring eum permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>End-User Experience Monitoring (EUM)</strong></h3>
<ul>
<li><strong>Definition</strong>: End-user experience monitoring focuses on the actual performance as experienced by users, tracking metrics such as page load time, application responsiveness, and error rates.</li>
<li><strong>Types of EUM</strong>:
<ul>
<li><strong>Real User Monitoring (RUM)</strong>: Collects data from real user interactions, providing insights into geographic and demographic-based performance.</li>
<li><strong>Session Replay</strong>: Captures and replays user interactions, allowing a detailed analysis of user experience issues.</li>
</ul>
</li>
<li><strong>Importance</strong>: Ensures that performance meets user expectations, especially in applications where responsiveness and reliability are critical.</li>
<li><strong>Application</strong>: EUM tools like Google Analytics, Splunk Real User Monitoring, or New Relic Browser help developers and performance analysts optimize user experience by providing insights into actual usage conditions.</li>
</ul>
<h2 id="visualizations" style="position:relative;"><a href="#visualizations" aria-label="visualizations permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Visualizations</h2>
<h3 id="1-line-charts" style="position:relative;"><a href="#1-line-charts" aria-label="1 line charts permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>1. <strong>Line Charts</strong></h3>
<ul>
<li><strong>Purpose</strong>: Line charts are used to show trends over time. In systems performance, they are ideal for visualizing metrics like CPU usage, memory consumption, and network bandwidth over time.</li>
<li><strong>Example</strong>: A line chart might show CPU utilization over the course of 24 hours, revealing high usage during business hours and lower usage at night.</li>
<li><strong>Advantages</strong>:
<ul>
<li>Excellent for identifying trends, cyclic behaviors, and seasonality in data.</li>
<li>Helps in observing gradual increases or spikes in resource usage.</li>
</ul>
</li>
<li><strong>Limitations</strong>: Can become cluttered with too many metrics or data points.</li>
</ul>
<hr>
<h3 id="2-scatter-plots" style="position:relative;"><a href="#2-scatter-plots" aria-label="2 scatter plots permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>2. <strong>Scatter Plots</strong></h3>
<ul>
<li><strong>Purpose</strong>: Scatter plots display the relationship between two variables, often helping in identifying correlations or outliers.</li>
<li><strong>Example</strong>: A scatter plot might show the correlation between network latency and CPU usage to see if high CPU load impacts network performance.</li>
<li><strong>Advantages</strong>:
<ul>
<li>Useful for spotting patterns, clusters, and potential correlations.</li>
<li>Ideal for outlier detection where data deviates from expected trends.</li>
</ul>
</li>
<li><strong>Limitations</strong>: Doesn’t provide time-sequence insights unless combined with time-based color coding.</li>
<li><strong>Image</strong>:
<ul>
<li><img src="https://upload.wikimedia.org/wikipedia/commons/a/af/Scatter_diagram_for_quality_characteristic_XXX.svg" alt="Scatter Plot"></li>
<li><em>Illustration</em>: Displays network latency against CPU usage, where a cluster of high-latency points with high CPU usage might suggest a correlation.</li>
</ul>
</li>
</ul>
<hr>
<h3 id="3-heat-maps" style="position:relative;"><a href="#3-heat-maps" aria-label="3 heat maps permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>3. <strong>Heat Maps</strong></h3>
<ul>
<li><strong>Purpose</strong>: Heat maps use color intensity to show the density or value of data across a matrix, making it easy to spot hot spots and bottlenecks.</li>
<li><strong>Example</strong>: A time-based heat map can show CPU utilization per hour, with darker colors representing higher utilization.</li>
<li><strong>Advantages</strong>:
<ul>
<li>Excellent for spotting high-density areas, such as peak usage times.</li>
<li>Effective for visualizing large data volumes compactly.</li>
</ul>
</li>
<li><strong>Limitations</strong>: Provides less precise data values, more suitable for pattern recognition than exact measurements.</li>
<li><strong>Image</strong>:
<ul>
<li><img src="https://upload.wikimedia.org/wikipedia/commons/f/fc/Heatmap.png" alt="Heat Map"></li>
<li><em>Illustration</em>: CPU usage intensity across a 24-hour period, where darker areas indicate peak usage hours.</li>
</ul>
</li>
</ul>
<hr>
<h3 id="4-timeline-charts" style="position:relative;"><a href="#4-timeline-charts" aria-label="4 timeline charts permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>4. <strong>Timeline Charts</strong></h3>
<ul>
<li><strong>Purpose</strong>: Timeline charts focus on sequencing events over time, making it clear when specific actions or events occurred relative to each other.</li>
<li><strong>Example</strong>: A timeline chart can show server restarts, application deployments, and peak usage times, helping correlate events with performance changes.</li>
<li><strong>Advantages</strong>:
<ul>
<li>Effective for understanding the sequence and overlap of events.</li>
<li>Useful for root cause analysis by correlating system changes with performance shifts.</li>
</ul>
</li>
<li><strong>Limitations</strong>: Limited in displaying quantitative data; best for qualitative insights.</li>
<li><strong>Image</strong>:
<ul>
<li><img src="https://upload.wikimedia.org/wikipedia/commons/2/2d/Timeline_example_3.png" alt="Timeline Chart"></li>
<li><em>Illustration</em>: Event timeline showing application deployments, outages, and configuration changes.</li>
</ul>
</li>
</ul>
<hr>
<h3 id="5-surface-plots" style="position:relative;"><a href="#5-surface-plots" aria-label="5 surface plots permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>5. <strong>Surface Plots</strong></h3>
<ul>
<li><strong>Purpose</strong>: Surface plots display three-dimensional data on a two-dimensional plane, with colors or elevations representing values.</li>
<li><strong>Example</strong>: Used to show CPU usage and memory consumption over time, revealing how these metrics change together.</li>
<li><strong>Advantages</strong>:
<ul>
<li>Provides insight into complex interactions between three variables.</li>
<li>Allows identification of trends across a surface that may not be visible in 2D graphs.</li>
</ul>
</li>
<li><strong>Limitations</strong>: Interpretation can be difficult, especially in static views without interactive features.</li>
</ul>
<hr>
<h3 id="6-flame-graphs" style="position:relative;"><a href="#6-flame-graphs" aria-label="6 flame graphs permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>6. <strong>Flame Graphs</strong></h3>
<ul>
<li><strong>Purpose</strong>: Flame graphs visualize stack traces, showing which functions or processes use the most CPU time.</li>
<li><strong>Example</strong>: Used in profiling to identify hot spots in code by showing functions where most time is spent.</li>
<li><strong>Advantages</strong>:
<ul>
<li>Very effective for identifying CPU-intensive functions in code.</li>
<li>Helps pinpoint “hot paths” that are prime candidates for optimization.</li>
</ul>
</li>
<li><strong>Limitations</strong>: Specific to code profiling; not suited for general system monitoring.</li>
</ul>
<hr>
<h3 id="7-stacked-area-charts" style="position:relative;"><a href="#7-stacked-area-charts" aria-label="7 stacked area charts permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>7. <strong>Stacked Area Charts</strong></h3>
<ul>
<li><strong>Purpose</strong>: Stacked area charts are used to display cumulative data, showing how different components contribute to a total.</li>
<li><strong>Example</strong>: A stacked area chart can show memory usage per application over time, revealing which applications use the most memory.</li>
<li><strong>Advantages</strong>:
<ul>
<li>Clearly shows distribution of resources across different components.</li>
<li>Useful for identifying dominant contributors to total resource usage.</li>
</ul>
</li>
<li><strong>Limitations</strong>: Harder to interpret when there are many categories, as the chart can become cluttered.</li>
</ul>
<hr>
<h3 id="8-histograms" style="position:relative;"><a href="#8-histograms" aria-label="8 histograms permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>8. <strong>Histograms</strong></h3>
<ul>
<li><strong>Purpose</strong>: Histograms show frequency distributions by dividing data into bins, with each bin representing the frequency of data within a range.</li>
<li><strong>Example</strong>: Used to display latency distributions to understand the spread and consistency of response times.</li>
<li><strong>Advantages</strong>:
<ul>
<li>Effective for understanding data distributions and spotting outliers.</li>
<li>Ideal for summarizing data spread, such as latency or response times.</li>
</ul>
</li>
<li><strong>Limitations</strong>: Sensitive to bin size; too many bins can create noise, while too few can oversimplify.</li>
</ul>
<hr>
<h3 id="9-box-plots" style="position:relative;"><a href="#9-box-plots" aria-label="9 box plots permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>9. <strong>Box Plots</strong></h3>
<ul>
<li><strong>Purpose</strong>: Box plots summarize data by displaying median, quartiles, and outliers, providing a quick view of distribution and variability.</li>
<li><strong>Example</strong>: Used to compare response times across servers, helping identify servers with higher latency.</li>
<li><strong>Advantages</strong>:
<ul>
<li>Provides a compact summary of data variability, ideal for quick comparison.</li>
<li>Useful for detecting outliers and understanding consistency.</li>
</ul>
</li>
<li><strong>Limitations</strong>: Not intuitive for all users, as interpreting quartiles and whiskers can be complex.</li>
<li><strong>Image</strong>:
<ul>
<li><img src="https://upload.wikimedia.org/wikipedia/commons/1/1a/Boxplot_vs_PDF.svg" alt="Box Plot"></li>
<li><em>Illustration</em>: Compares latency distributions across servers, with outliers clearly visible.</li>
</ul>
</li>
</ul>
<hr>
<h3 id="10-sunburst-diagrams" style="position:relative;"><a href="#10-sunburst-diagrams" aria-label="10 sunburst diagrams permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>10. <strong>Sunburst Diagrams</strong></h3>
<ul>
<li><strong>Purpose</strong>: Sunburst diagrams visualize hierarchical data in concentric circles, where each ring represents a deeper level.</li>
<li><strong>Example</strong>: Used in performance profiling to show hierarchical function calls and their contributions to total time.</li>
<li><strong>Advantages</strong>:
<ul>
<li>Excellent for displaying hierarchical relationships visually, making it easy to understand nested structures.</li>
<li>Useful for identifying major contributors within a hierarchy.</li>
</ul>
</li>
<li><strong>Limitations</strong>: Best suited for hierarchical data; less effective for non-hierarchical datasets.</li>
</ul>
<hr>
<h3 id="11-treemaps" style="position:relative;"><a href="#11-treemaps" aria-label="11 treemaps permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>11. <strong>Treemaps</strong></h3>
<ul>
<li><strong>Purpose</strong>: Treemaps use nested rectangles to display hierarchical data, with each rectangle representing a component’s size relative to others.</li>
<li><strong>Example</strong>: Used to visualize disk usage across directories, where each rectangle’s size represents the space used.</li>
<li><strong>Advantages</strong>:
<ul>
<li>Effective for visualizing proportions in hierarchical data, such as storage or memory usage.</li>
<li>Helps identify large components quickly within nested structures.</li>
</ul>
</li>
<li><strong>Limitations</strong>: Can become cluttered with too many small components, making details hard to interpret.</li>
</ul>
<hr>
<h3 id="12-sparkline-charts" style="position:relative;"><a href="#12-sparkline-charts" aria-label="12 sparkline charts permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>12. <strong>Sparkline Charts</strong></h3>
<ul>
<li><strong>Purpose</strong>: Sparklines are compact, minimalist charts without axes, used to show trends in a small amount of space.</li>
<li><strong>Example</strong>: In</li>
</ul>
<p>a performance monitoring dashboard, sparklines can show recent CPU or memory usage trends next to a list of processes.</p>
<ul>
<li><strong>Advantages</strong>:
<ul>
<li>Very space-efficient, useful for inline trend analysis within tables.</li>
<li>Excellent for showing recent data trends without occupying much visual space.</li>
</ul>
</li>
<li><strong>Limitations</strong>: Limited detail; designed for quick reference rather than in-depth analysis.</li>
</ul>
<h1 id="chapter-4-observability-tools" style="position:relative;"><a href="#chapter-4-observability-tools" aria-label="chapter 4 observability tools permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Chapter 4: Observability Tools</strong></h1>
<p>Observability tools are the cornerstone of understanding system behavior. These tools enable engineers to observe and analyze systems, identifying bottlenecks and optimizing performance across the stack. The chapter is structured to introduce key tool types, data sources, and examples of their practical application.</p>
<hr>
<h2 id="41-tool-coverage" style="position:relative;"><a href="#41-tool-coverage" aria-label="41 tool coverage permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>4.1 Tool Coverage</strong></h2>
<h3 id="static-performance-tools" style="position:relative;"><a href="#static-performance-tools" aria-label="static performance tools permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Static Performance Tools</strong></h3>
<ul>
<li><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; "
    >
      <a
    class="gatsby-resp-image-link"
    href="/static/be676d820ce53bc85cf71c7efb6df069/31198/linux-static-performance-tuning-tools.png"
    style="display: block"
    target="_blank"
    rel="noopener"
  >
    <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 69.62025316455697%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAsTAAALEwEAmpwYAAACxklEQVR42m1Ua3OaQBT1//+UTj80mdgm0SbWRw1ixGgAHwEfQBSQNyoienqXaJ12cmeW2V2Ws+fecy6F4/EIFuv1GrP5HLbj4EDrjPZdz4Nl27BWK2zTNH/HIggCGj52ux2m0ykMw8Bms8nfFfLnCTSwTKzexkgW74i0GZbDAczRCGtDo/UcFq0jusD1XMRxjBVdxHEcBEGATfsXQIqQDgSzGVYtDl63A6fThlJ5xLRahdlqQWs0YPMtGJKElesiDMOcIcuMzbMs+xdwl2ZYagqWioBhtw75uYZWrYjm4zVeuBI8rQdn0oGmSudP4BKwLMs0BlBV9QJ4OBzyxUDR8Ngeo/RbRLOnoPF8j7vqFfrDBgy1CVWuYKEPT3BHsPonSQLP85Gm+wvgWZjuq4IvN0/4WnzCfe0FglTNQYXeA+YSpf9ahm8qJECCZLullFOsFgq0Nx77/e4DkLHTdR2B70FSDRSbMq6rPdzxEor1nzQv4+ZXCV2xA77Xwlyf5ASiKCJh1jCmEnSljX26uzBkxWWHvDDGcKZDt11YNF/YK5iOB21hYrp0oDtBvpdl+1xVm1SOQp+Eif6WrcCk14hhSj5jt4SBl9cnyQ7gJws0xhp6ugPbJEvZFo6HIwF8eO5Ac41EHPcfsF0HH4A50D6lQzH8MIIfZ1hYAQYTE9/5EW65LhqSDGNBlvJMBLGDIPRICI+ckSKOAkzUMWGcRGEuF0UR08kEurHEj6qKb2URV2UZnDDHOxlcHHGo8DdoCCXUhVvoBG5ZVk6Cqew4LpXhlPKYOqPF8ySKi46oo9R4Q5Wfodae4K6uECsPvFhBn5Tsjzm0xRp6Mp8L8lkUGFWWNot4k8INtgjXe1LTxHNXxobsEa09RJsAmyTCu6lBGojwyXtny51tlwOypmbtw2oS+D6J4lNdQuoC+iFsN5+yYG12VvV/hn8AJDYTgXg96dQAAAAASUVORK5CYII='); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="linux static performance tuning tools"
        title=""
        src="/static/be676d820ce53bc85cf71c7efb6df069/f058b/linux-static-performance-tuning-tools.png"
        srcset="/static/be676d820ce53bc85cf71c7efb6df069/c26ae/linux-static-performance-tuning-tools.png 158w,
/static/be676d820ce53bc85cf71c7efb6df069/6bdcf/linux-static-performance-tuning-tools.png 315w,
/static/be676d820ce53bc85cf71c7efb6df069/f058b/linux-static-performance-tuning-tools.png 630w,
/static/be676d820ce53bc85cf71c7efb6df069/31198/linux-static-performance-tuning-tools.png 694w"
        sizes="(max-width: 630px) 100vw, 630px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
        decoding="async"
      />
  </a>
    </span></li>
<li><strong>Definition</strong>: Tools that collect metrics without requiring live interaction or dynamic data manipulation.</li>
<li><strong>Examples</strong>:
<ul>
<li><code class="language-text">vmstat</code>: Provides a high-level view of system performance, including CPU, memory, and I/O activity. Example usage:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">vmstat</span> <span class="token number">1</span></code></pre></div>
<ul>
<li>Output includes columns for processes (runnable), memory usage, and disk I/O, making it an excellent quick diagnostic tool.</li>
</ul>
</li>
<li><code class="language-text">iostat</code>: Focuses on disk and CPU utilization.
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">iostat <span class="token parameter variable">-x</span> <span class="token number">1</span></code></pre></div>
<ul>
<li>Reports extended statistics like average queue size (<code class="language-text">avgqu-sz</code>) and disk utilization (<code class="language-text">%util</code>).</li>
</ul>
</li>
<li><code class="language-text">mpstat</code>: Analyzes per-CPU utilization, showing bottlenecks on specific cores.
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">mpstat <span class="token parameter variable">-P</span> ALL <span class="token number">1</span></code></pre></div>
</li>
</ul>
</li>
</ul>
<h3 id="crisis-tools" style="position:relative;"><a href="#crisis-tools" aria-label="crisis tools permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Crisis Tools</strong></h3>
<ul>
<li><strong>Definition</strong>: Tools used during active performance crises to diagnose and resolve issues.</li>
<li><strong>Examples</strong>:
<ul>
<li><code class="language-text">top</code>: Real-time process monitoring tool that shows resource usage per process.</li>
<li><code class="language-text">perf top</code>: Provides a live view of the hottest functions (based on CPU usage) in the system.</li>
<li><code class="language-text">iotop</code>: Monitors disk I/O usage by process in real time.</li>
<li><code class="language-text">strace</code> and <code class="language-text">lsof</code>: Useful during application-level troubleshooting to inspect system calls and file descriptor usage.</li>
</ul>
</li>
</ul>
<hr>
<h2 id="42-tool-types" style="position:relative;"><a href="#42-tool-types" aria-label="42 tool types permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>4.2 Tool Types</strong></h2>
<ul>
<li><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; "
    >
      <a
    class="gatsby-resp-image-link"
    href="/static/48d37c23194e67d7280bacad487d06ad/83b75/linux-workload-obserability-tools.png"
    style="display: block"
    target="_blank"
    rel="noopener"
  >
    <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 68.9873417721519%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAsTAAALEwEAmpwYAAAC7UlEQVR42m1TiW7bOBTM/3/JAlts10Wao24dxU7io46i2zptibIuS3J8O06cTB+ZttgFSuCJlEQO582bd/L29obtdov1eo0oijArS5RVhXo+x/zxEUmaIs9zPNJ6miRi33a7QUV7np+fEYYhNE0T3/k42e/34qfn+2Cui7k9QjmykBs6UopYVbBnERJNwXjQQx1OUNU11qsV4pjBtCzUdYXlcvEOuNvt4DgOhrKMyDJR3fdRK0PE3Q48qYWgLSG8acO5aiEnQEYX5EUByzSREnueXVnORAY825MsSynVULBkoQ9DvoGpdHHfkzDsXqDb+UxxCn34FVkwQBqZJEOGRuNf2LYtgDo3N4KUYPjwICMIAvHiBDEuOhYuOybuNIaB3sHF9Uc02w04egszxgEN0rRAv98XgFy7knTn7ASgRRp4nof9fgfdCvD3aRf/nA/w4XMbQ+MafaWJ9t0n+OoXBMo50omCzXaHLMtEAYskwMSUcNhv3gHTNBG3PZCG6sjH5dCBpIc47+k4u+ug0W7honcL2TYwHJlQLR0FaajrumC4WVWYjmXU1ewdkGugktBB4ONxsUSU5ZhME7jjCRRVQ0zr8SSCG8Yw/RCm4wkbyUSAszy+HKBSEW1yxusrFYV7icUxXLIMr9jx+QmvFFuS4PzexF/XA7RthllRwtR0GJqBgjRUNRVJkqLOPDC7jfWieGc4JwNLkoRm84tgmFZPCFgN2WRoqQyyH6NLdnLGBqLEQ1pGGJMbptMp+TAm/y2FSzgZAXg8HjGbzTCf19QJBZpdhtMrD42vNvpqLjYFTENHPkNP/4Zb9ZIkcelMSZkxrMjgvMqr1c9O4Y9fJdfdHGfSCFc9H7f3EYGaKOolhuYVNKcPxb7Dd6q84X0XEvi+B07ov+N/gAXdao1Iy90TlqsNtZUjmLg+zVVB79SKCYPr2ViQPL8GP//bh7z1NpsNbViIbqmIfk29yrU9HA5UuVfBgs8vLy+/Zx5/Gj8AqDL8EEz5DL0AAAAASUVORK5CYII='); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="linux workload observability-tools"
        title=""
        src="/static/48d37c23194e67d7280bacad487d06ad/f058b/linux-workload-obserability-tools.png"
        srcset="/static/48d37c23194e67d7280bacad487d06ad/c26ae/linux-workload-obserability-tools.png 158w,
/static/48d37c23194e67d7280bacad487d06ad/6bdcf/linux-workload-obserability-tools.png 315w,
/static/48d37c23194e67d7280bacad487d06ad/f058b/linux-workload-obserability-tools.png 630w,
/static/48d37c23194e67d7280bacad487d06ad/83b75/linux-workload-obserability-tools.png 695w"
        sizes="(max-width: 630px) 100vw, 630px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
        decoding="async"
      />
  </a>
    </span></li>
</ul>
<h3 id="fixed-counters" style="position:relative;"><a href="#fixed-counters" aria-label="fixed counters permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Fixed Counters</strong></h3>
<ul>
<li><strong>Definition</strong>: Predefined metrics in hardware or software that measure performance events.</li>
<li><strong>Hardware Counters</strong>:
<ul>
<li><strong>Examples</strong>:
<ul>
<li>Cache hits/misses: Useful for diagnosing memory hierarchy inefficiencies.</li>
<li>Branch mispredictions: Can indicate poor code or compiler optimizations.</li>
</ul>
</li>
<li><strong>Tool</strong>: <code class="language-text">perf stat</code> to measure counters:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">perf <span class="token function">stat</span> <span class="token parameter variable">-e</span> cache-misses,branches ./app</code></pre></div>
<ul>
<li>Reports the number of cache misses and branches during application execution.</li>
</ul>
</li>
</ul>
</li>
<li><strong>Software Counters</strong>:
<ul>
<li><strong>Examples</strong>: Process context switches, memory page faults.</li>
</ul>
</li>
</ul>
<h3 id="profiling" style="position:relative;"><a href="#profiling" aria-label="profiling permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Profiling</strong></h3>
<ul>
<li><strong>Definition</strong>: Focuses on collecting and analyzing aggregate data over time.</li>
<li><strong>Example Use Case</strong>:
<ul>
<li>Profiling a web server to identify slow endpoints:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">perf record <span class="token parameter variable">-a</span> <span class="token parameter variable">-g</span> -- <span class="token function">sleep</span> <span class="token number">10</span>
perf report</code></pre></div>
<ul>
<li>Captures stack traces system-wide for 10 seconds and generates a report of the hottest paths.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="tracing" style="position:relative;"><a href="#tracing" aria-label="tracing permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Tracing</strong></h3>
<ul>
<li><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; "
    >
      <a
    class="gatsby-resp-image-link"
    href="/static/6e16641737ef44b6222d63befd8985e8/82158/linux-tracing-sources.png"
    style="display: block"
    target="_blank"
    rel="noopener"
  >
    <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 63.92405063291139%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsTAAALEwEAmpwYAAACe0lEQVR42l1TaXOiQBD1//+e/ZKq3Zi45hAxIEYH5BBU5Ba8AI/4tmdc4tZOVTMX/aa7X79WURSI4xin0wl8XC4XnMn4qOsaxWYj1qfzGdfrVazP59P3mv+TZSm+vr7EvsUB83yNqqpwJaDQ87B0bNTbDYokRhYE2NDs8zP6t9wU2G63ApCD8Ifquvp+oMU/ZVlidzigynPUOkOqfqAydISyBL/fw0rqwSdLlQEWqgKfHln5vgCOowiMTQSGADwejwiCFQq6rCnS2hijnjICHJMxrDUV7lsX+tMjZi8d2H0JynAIy7Kw2+0ouwIeZXVpUm7qECcp4nCJPGRkOqWtwGavMEYdWJMuimCEQzKGOelBlgcYyDIS8qmpVHme3VPmdeDhFhSd5ycYTHO8jQKoVo6R8wFp1MZg0kHkSVgv+lTjIWauh8VijihKkAQuUvcF5T6/AVZVCdtxBDGGNcePtoaH3wxPfQe6q0FhHUjDR0SuhMDsYuUqUNQhntpthGGEqtwReR5Ox+qeMmd6U+T4ZDYeXqf4+W6i8+FhaKmQWRc97RnGZweMgFW5TSTokPt9TKcm0miOeMnuEfLP8XhCmiQYmw56doDO2EGXzfA80vFLGdHMIJkuZGeBPjOxXC4wNU3q3wR5uhT1LvfZHZCPLMugEXu8NvO5R8y5WK1W5OwTozZ0wxCR8TQDaptb/+bUOjss/YCa/SaGFlcGt+1uS0BzzGYz+NRjXD18b5pTsbcoott5RKChsEYU/GEuDAHI6ebGpRdRk67XGbL1+ltKzcydbdumWhciA03TkKapuGsw/rJc4UAq4V2/3++FNSD/j8ap8eGi+PecA/4BFo3Jpr8u7CYAAAAASUVORK5CYII='); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="linux tracing sources"
        title=""
        src="/static/6e16641737ef44b6222d63befd8985e8/f058b/linux-tracing-sources.png"
        srcset="/static/6e16641737ef44b6222d63befd8985e8/c26ae/linux-tracing-sources.png 158w,
/static/6e16641737ef44b6222d63befd8985e8/6bdcf/linux-tracing-sources.png 315w,
/static/6e16641737ef44b6222d63befd8985e8/f058b/linux-tracing-sources.png 630w,
/static/6e16641737ef44b6222d63befd8985e8/82158/linux-tracing-sources.png 696w"
        sizes="(max-width: 630px) 100vw, 630px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
        decoding="async"
      />
  </a>
    </span></li>
<li><strong>Static Tracing</strong>:
<ul>
<li>Example: Kernel tracepoints for file system events.
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token builtin class-name">echo</span> <span class="token string">'1'</span> <span class="token operator">></span> /sys/kernel/debug/tracing/events/ext4/ext4_read_start/enable</code></pre></div>
<ul>
<li>Enables tracing for <code class="language-text">ext4_read_start</code>.</li>
</ul>
</li>
</ul>
</li>
<li><strong>Dynamic Tracing</strong>:
<ul>
<li><strong>Tools</strong>: <code class="language-text">kprobes</code> (kernel), <code class="language-text">uprobes</code> (user-space).
<ul>
<li>Example: Attach a probe to the <code class="language-text">open</code> system call.
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token builtin class-name">echo</span> <span class="token string">'p:open_probe do_sys_open'</span> <span class="token operator">></span> /sys/kernel/debug/tracing/kprobe_events
<span class="token builtin class-name">echo</span> <span class="token string">'1'</span> <span class="token operator">></span> /sys/kernel/debug/tracing/events/kprobes/open_probe/enable</code></pre></div>
</li>
<li>Captures every invocation of <code class="language-text">do_sys_open</code>.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="monitoring-1" style="position:relative;"><a href="#monitoring-1" aria-label="monitoring 1 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Monitoring</strong></h3>
<ul>
<li><strong>Definition</strong>: Periodically collects metrics to visualize trends over time.</li>
<li><strong>Examples</strong>:
<ul>
<li>Grafana and Prometheus for long-term monitoring.</li>
<li>Basic Linux tools like <code class="language-text">sar</code> for quick metric collection.</li>
</ul>
</li>
</ul>
<hr>
<h2 id="43-observability-sources" style="position:relative;"><a href="#43-observability-sources" aria-label="43 observability sources permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>4.3 Observability Sources</strong></h2>
<h3 id="proc-filesystem" style="position:relative;"><a href="#proc-filesystem" aria-label="proc filesystem permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong><code class="language-text">/proc</code> Filesystem</strong></h3>
<ul>
<li><strong>Definition</strong>: A virtual filesystem exposing kernel data structures.</li>
<li><strong>Examples</strong>:
<ul>
<li><code class="language-text">/proc/stat</code>: Reports CPU usage statistics, including time spent in various modes (user, system, idle).</li>
<li><code class="language-text">/proc/meminfo</code>: Provides memory utilization details like free memory, buffers, and cache sizes.</li>
<li><code class="language-text">/proc/diskstats</code>: Displays I/O statistics for block devices.</li>
</ul>
</li>
</ul>
<h3 id="sys-filesystem" style="position:relative;"><a href="#sys-filesystem" aria-label="sys filesystem permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong><code class="language-text">/sys</code> Filesystem</strong></h3>
<ul>
<li><strong>Definition</strong>: Exposes kernel objects for tuning and monitoring.</li>
<li><strong>Examples</strong>:
<ul>
<li><code class="language-text">/sys/block/sda/stat</code>: Reports I/O statistics for the <code class="language-text">sda</code> block device.</li>
<li><code class="language-text">/sys/class/net/eth0/statistics</code>: Provides networking counters for the <code class="language-text">eth0</code> interface.</li>
</ul>
</li>
</ul>
<h3 id="tracepoints" style="position:relative;"><a href="#tracepoints" aria-label="tracepoints permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Tracepoints</strong></h3>
<ul>
<li><strong>Definition</strong>: Static instrumentation points in the kernel for observing specific events.</li>
<li><strong>Example</strong>:
<ul>
<li>Enable a tracepoint for <code class="language-text">sched:sched_switch</code> to monitor context switches:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token builtin class-name">echo</span> <span class="token string">'1'</span> <span class="token operator">></span> /sys/kernel/debug/tracing/events/sched/sched_switch/enable</code></pre></div>
</li>
</ul>
</li>
</ul>
<h3 id="kprobes-and-uprobes" style="position:relative;"><a href="#kprobes-and-uprobes" aria-label="kprobes and uprobes permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>kprobes and uprobes</strong></h3>
<ul>
<li><strong>kprobes</strong>:
<ul>
<li>Attach to kernel functions for tracing and debugging.</li>
<li>Example: Monitor every <code class="language-text">do_exit</code> call.
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token builtin class-name">echo</span> <span class="token string">'p:probe_exit do_exit'</span> <span class="token operator">></span> /sys/kernel/debug/tracing/kprobe_events</code></pre></div>
</li>
</ul>
</li>
<li><strong>uprobes</strong>:
<ul>
<li>Attach to user-space functions for application-level tracing.</li>
<li>Example: Trace <code class="language-text">main</code> in a binary.
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">bpftrace <span class="token parameter variable">-e</span> <span class="token string">'uprobe:/path/to/app:main { printf("main called\n"); }'</span></code></pre></div>
</li>
</ul>
</li>
</ul>
<h3 id="usdt-user-level-statically-defined-tracing" style="position:relative;"><a href="#usdt-user-level-statically-defined-tracing" aria-label="usdt user level statically defined tracing permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>USDT (User-Level Statically Defined Tracing)</strong></h3>
<ul>
<li>Often used in database systems like MySQL or PostgreSQL.</li>
<li>Example: Monitor MySQL queries using USDT probes.</li>
</ul>
<hr>
<h2 id="44-tool-summaries" style="position:relative;"><a href="#44-tool-summaries" aria-label="44 tool summaries permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>4.4 Tool Summaries</strong></h2>
<h3 id="sar-system-activity-reporter" style="position:relative;"><a href="#sar-system-activity-reporter" aria-label="sar system activity reporter permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong><code class="language-text">sar</code> (System Activity Reporter)</strong></h3>
<ul>
<li><span
      class="gatsby-resp-image-wrapper"
      style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; "
    >
      <a
    class="gatsby-resp-image-link"
    href="/static/b006c8c85582042a330acf3abd60bfa8/394f7/linux-sar-observability.png"
    style="display: block"
    target="_blank"
    rel="noopener"
  >
    <span
    class="gatsby-resp-image-background-image"
    style="padding-bottom: 67.72151898734178%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAsTAAALEwEAmpwYAAACeUlEQVR42pWTfXOaQBDG/f7fpk2mzWgzVo2JNr6QQNSAUXwFlFNAEAzgk92bMkmav3ozOwcc99vnnt0r5XkOy7KwXq+RpilWqxXCMITneRBCwPd9BIcDgiDAgWb+xmO/38v4d5TyPCPYCuPxGK7rYjAYSBiH4zgSuNvtZMxmpkzMI80yvKavX4EZLWRphiRO5KZCCcM4CavnRLxWzLZtY7vdSsD5fP4KjOMYURRJiGXZUFUV3W4HyoOCdrsFwzAIJGhtLaH8PyvnvV8UcjYGsLIH7RnqwICi6ag1qyhXv6FSu4TSr2Kut6H1qqTMkRvZ++PxSL5n+ChSKuTFKIpRafRx8auFy+t7dJ56aPauUGlewBjVMR/+hjmswfcEFS2SAvjY6+kjQs9CwSwVHkTHBFfVLkEVNO511Nt3aP6p0HyN0dMd5uMOdO0Wjr2W9jBMCBezYR2b5fAv7oxSIZVbxXFsaoUdtpsNOp0OJpOJ9NWhdy6QoRvynYGFf1EU0rHfqy2BvMh+8JxmKR3LI4CBDYHYfK66aZoyuCAyqSsgthZ0tY7FRPkM5AZNkoT6KkdySnEIY6ytLR5VDaqmwhUb+h5TwpQSvspWYQGHwIcvVgi8zWfg8RgjPHh4GDn4UZ/i+7WGnzcmhHfCIdqh2S/jVqmgqZShvXRkEVn1crmAM+vB25jvHhYld8UeVw0dN10T9fspyjc6hi8ulo5BFW+gP2pSwhY917D3dxDU4HzDPEdHsFu9A/P8zO2OY3zCk2FjshCYLvdo9Q0Mnuekku75dibDdheUYII4ieUV5Fske/JDI5a4YtxTbH4SR3R0H3y/2a/TKaE5x/+MN5XrG+905uh1AAAAAElFTkSuQmCC'); background-size: cover; display: block;"
  ></span>
  <img
        class="gatsby-resp-image-image"
        alt="linux sar observability"
        title=""
        src="/static/b006c8c85582042a330acf3abd60bfa8/f058b/linux-sar-observability.png"
        srcset="/static/b006c8c85582042a330acf3abd60bfa8/c26ae/linux-sar-observability.png 158w,
/static/b006c8c85582042a330acf3abd60bfa8/6bdcf/linux-sar-observability.png 315w,
/static/b006c8c85582042a330acf3abd60bfa8/f058b/linux-sar-observability.png 630w,
/static/b006c8c85582042a330acf3abd60bfa8/394f7/linux-sar-observability.png 707w"
        sizes="(max-width: 630px) 100vw, 630px"
        style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;"
        loading="lazy"
        decoding="async"
      />
  </a>
    </span></li>
<li><strong>Features</strong>:
<ul>
<li>Collects CPU, memory, disk, and network metrics.</li>
<li>Allows historical analysis.</li>
</ul>
</li>
<li><strong>Examples</strong>:
<ul>
<li>CPU monitoring:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">sar <span class="token parameter variable">-u</span> <span class="token number">1</span> <span class="token number">10</span></code></pre></div>
<ul>
<li>Captures CPU usage every second for 10 seconds.</li>
</ul>
</li>
<li>Disk I/O monitoring:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">sar <span class="token parameter variable">-d</span> <span class="token number">1</span> <span class="token number">10</span></code></pre></div>
</li>
</ul>
</li>
</ul>
<h3 id="tracing-utilities" style="position:relative;"><a href="#tracing-utilities" aria-label="tracing utilities permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Tracing Utilities</strong></h3>
<ul>
<li><strong>Ftrace</strong>:
<ul>
<li>Built into Linux for kernel function tracing.</li>
<li>Example: Enable function graph tracing:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token builtin class-name">echo</span> <span class="token string">'function_graph'</span> <span class="token operator">></span> /sys/kernel/debug/tracing/current_tracer</code></pre></div>
</li>
</ul>
</li>
<li><strong>BPF Tools</strong>:
<ul>
<li>Example: Use <code class="language-text">bpftrace</code> to capture file open calls.
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">bpftrace <span class="token parameter variable">-e</span> <span class="token string">'tracepoint:syscalls:sys_enter_open { printf("File opened: %s\n", str(args->filename)); }'</span></code></pre></div>
</li>
</ul>
</li>
</ul>
<h3 id="visualization-tools" style="position:relative;"><a href="#visualization-tools" aria-label="visualization tools permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Visualization Tools</strong></h3>
<ul>
<li><strong>Line Charts</strong>:
<ul>
<li>Ideal for visualizing time-series metrics like CPU or memory usage.</li>
</ul>
</li>
<li><strong>Flame Graphs</strong>:
<ul>
<li>Show the hierarchical breakdown of CPU usage, making hotspots easily identifiable.</li>
<li>Generate using <code class="language-text">perf</code> or <code class="language-text">bpftrace</code>.</li>
</ul>
</li>
</ul>
<hr>
<h2 id="45-observing-observability" style="position:relative;"><a href="#45-observing-observability" aria-label="45 observing observability permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>4.5 Observing Observability</strong></h2>
<ul>
<li><strong>“Review the gaps in your metrics.”</strong></li>
<li>Example:
<ul>
<li>Ensure tools like <code class="language-text">sar</code> and <code class="language-text">perf</code> are configured to collect relevant data, such as detailed I/O latency distributions.</li>
</ul>
</li>
</ul>
<hr>
<h2 id="exercises" style="position:relative;"><a href="#exercises" aria-label="exercises permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Exercises</strong></h2>
<ul>
<li><strong>Static Analysis</strong>: Use <code class="language-text">vmstat</code> to analyze CPU bottlenecks.</li>
<li><strong>Dynamic Tracing</strong>: Create a custom BPF trace to monitor file access patterns.</li>
<li><strong>Flame Graphs</strong>: Profile an application using <code class="language-text">perf</code> and generate a flame graph.</li>
</ul>
<p>Here’s a much more detailed and in-depth expansion of <strong>Chapter 5: Applications</strong> from <em>Systems Performance: Enterprise and the Cloud, Second Edition</em>. This version includes detailed concepts, in-depth explanations, and additional examples for every section.</p>
<hr>
<h1 id="chapter-5-applications" style="position:relative;"><a href="#chapter-5-applications" aria-label="chapter 5 applications permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Chapter 5: Applications</strong></h1>
<p>Applications are the most visible layer of a system to end-users, and their performance directly affects user satisfaction and system efficiency. This chapter provides a comprehensive view of application performance, profiling, and optimization techniques, along with the potential pitfalls to avoid.</p>
<hr>
<h2 id="51-application-level-performance-concepts" style="position:relative;"><a href="#51-application-level-performance-concepts" aria-label="51 application level performance concepts permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>5.1 Application-Level Performance Concepts</strong></h2>
<h3 id="511-objectives" style="position:relative;"><a href="#511-objectives" aria-label="511 objectives permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>5.1.1 Objectives</strong></h3>
<ul>
<li><strong>“Applications should aim to optimize the common case.”</strong>
<ul>
<li>Focus on high-frequency operations first. For instance:
<ul>
<li>In a web application, optimize the rendering of a frequently visited homepage rather than a rarely accessed admin panel.</li>
<li>Example: E-commerce platforms prioritize checkout process speed over back-office administrative tools.</li>
</ul>
</li>
<li><strong>Prioritizing Resources</strong>:
<ul>
<li>Profile the system to identify hotspots (e.g., slow database queries, inefficient loops).</li>
<li>Use A/B testing or telemetry data to understand the most accessed features or code paths.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="512-observability" style="position:relative;"><a href="#512-observability" aria-label="512 observability permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>5.1.2 Observability</strong></h3>
<ul>
<li><strong>“Effective observability is key to diagnosing and improving application performance.”</strong>
<ul>
<li>Track:
<ul>
<li><strong>Internal Metrics</strong>:
<ul>
<li>Function execution times.</li>
<li>Memory usage by module.</li>
<li>Latency of in-memory data structures (e.g., hash lookups).</li>
</ul>
</li>
<li><strong>External Metrics</strong>:
<ul>
<li>API call latency.</li>
<li>Database query durations.</li>
<li>System calls (e.g., read/write operations).</li>
</ul>
</li>
</ul>
</li>
<li>Example Tools:
<ul>
<li>Application-level metrics: Prometheus or OpenTelemetry.</li>
<li>API monitoring: Postman monitors or custom scripts to track API performance.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="513-big-o-notation" style="position:relative;"><a href="#513-big-o-notation" aria-label="513 big o notation permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>5.1.3 Big O Notation</strong></h3>
<ul>
<li><strong>“Big O notation determines scalability under growing input sizes.”</strong>
<ul>
<li>Analyze algorithmic complexity to predict performance bottlenecks.</li>
<li>Examples:
<ul>
<li><strong>O(1)</strong>: Hash table lookups (constant time).</li>
<li><strong>O(n log n)</strong>: Sorting algorithms like quicksort.</li>
<li><strong>O(n²)</strong>: Nested loops for pairwise comparisons.</li>
</ul>
</li>
<li><strong>Real-World Example</strong>:
<ul>
<li>Analyzing search functionality:
<ul>
<li>Linear search (O(n)) vs. binary search (O(log n)).</li>
<li>Use sorted data with binary search for faster lookups.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h2 id="52-application-performance-techniques" style="position:relative;"><a href="#52-application-performance-techniques" aria-label="52 application performance techniques permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>5.2 Application Performance Techniques</strong></h2>
<h3 id="521-selecting-io-sizes" style="position:relative;"><a href="#521-selecting-io-sizes" aria-label="521 selecting io sizes permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>5.2.1 Selecting I/O Sizes</strong></h3>
<ul>
<li><strong>“Appropriate I/O sizes balance throughput and memory usage.”</strong>
<ul>
<li>Example: A file-processing application:
<ul>
<li>Small buffer sizes: Increased system calls and overhead.</li>
<li>Large buffer sizes: Reduced system calls but higher memory usage.</li>
</ul>
</li>
<li><strong>Practical Guidelines</strong>:
<ul>
<li>For disk I/O, test with typical block sizes (e.g., 4 KB, 8 KB, 64 KB).</li>
<li>For network I/O, use larger packets to reduce the number of transmissions.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="522-caching" style="position:relative;"><a href="#522-caching" aria-label="522 caching permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>5.2.2 Caching</strong></h3>
<ul>
<li><strong>“Caching reduces redundant work and improves response times.”</strong>
<ul>
<li>Examples:
<ul>
<li>Web server caching (e.g., caching static assets using CDNs).</li>
<li>Application caching:
<ul>
<li>Redis or Memcached for database query results.</li>
</ul>
</li>
<li>Local caching:
<ul>
<li>Use local memory to store intermediate results during complex computations.</li>
</ul>
</li>
</ul>
</li>
<li><strong>Challenges</strong>:
<ul>
<li>Cache invalidation: Ensuring outdated data is removed.</li>
<li>Cache thrashing: Frequent evictions due to insufficient memory.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="523-buffering" style="position:relative;"><a href="#523-buffering" aria-label="523 buffering permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>5.2.3 Buffering</strong></h3>
<ul>
<li><strong>“Buffering smooths data processing by batching operations.”</strong>
<ul>
<li>Examples:
<ul>
<li>Logging: Batch log entries and write to disk periodically.</li>
<li>Network Communication: Use send/receive buffers to manage data transfer efficiently.</li>
</ul>
</li>
<li><strong>Trade-offs</strong>:
<ul>
<li>Increased latency (data waits in the buffer).</li>
<li>Potential data loss if buffers are not flushed during application crashes.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="524-polling" style="position:relative;"><a href="#524-polling" aria-label="524 polling permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>5.2.4 Polling</strong></h3>
<ul>
<li><strong>“Polling continuously checks for conditions, often wasting CPU cycles.”</strong>
<ul>
<li><strong>Example</strong>:
<ul>
<li>Inefficient: A program repeatedly checks a queue for new messages.</li>
<li>Efficient: Use event-driven mechanisms like <code class="language-text">select</code>, <code class="language-text">poll</code>, or <code class="language-text">epoll</code> in Linux.</li>
</ul>
</li>
<li><strong>Event-Driven Design</strong>:
<ul>
<li>React to signals, callbacks, or interrupts instead of polling.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="525-concurrency-and-parallelism" style="position:relative;"><a href="#525-concurrency-and-parallelism" aria-label="525 concurrency and parallelism permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>5.2.5 Concurrency and Parallelism</strong></h3>
<ul>
<li><strong>“Concurrency improves responsiveness; parallelism increases throughput.”</strong>
<ul>
<li>Examples:
<ul>
<li><strong>Concurrency</strong>: A web server handling multiple connections using threads.</li>
<li><strong>Parallelism</strong>: A rendering application using multiple cores to process image fragments.</li>
</ul>
</li>
<li><strong>Best Practices</strong>:
<ul>
<li>Use thread-safe data structures.</li>
<li>Avoid shared mutable state to reduce contention.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="526-non-blocking-io" style="position:relative;"><a href="#526-non-blocking-io" aria-label="526 non blocking io permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>5.2.6 Non-Blocking I/O</strong></h3>
<ul>
<li><strong>“Non-blocking I/O allows an application to continue processing while waiting for I/O.”</strong>
<ul>
<li>Examples:
<ul>
<li><strong>Traditional blocking call</strong>:
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python">data <span class="token operator">=</span> socket<span class="token punctuation">.</span>recv<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">)</span>  <span class="token comment"># Blocks until data arrives</span></code></pre></div>
</li>
<li><strong>Non-blocking alternative</strong>:
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python">socket<span class="token punctuation">.</span>setblocking<span class="token punctuation">(</span><span class="token boolean">False</span><span class="token punctuation">)</span></code></pre></div>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="527-processor-binding" style="position:relative;"><a href="#527-processor-binding" aria-label="527 processor binding permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>5.2.7 Processor Binding</strong></h3>
<ul>
<li><strong>“Binding processes or threads to specific cores (CPU affinity) improves cache locality.”</strong>
<ul>
<li>Example:
<ul>
<li>Database workloads benefit from binding threads to cores to prevent cache thrashing.</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h2 id="53-programming-languages-and-environments" style="position:relative;"><a href="#53-programming-languages-and-environments" aria-label="53 programming languages and environments permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>5.3 Programming Languages and Environments</strong></h2>
<h3 id="531-compiled-languages" style="position:relative;"><a href="#531-compiled-languages" aria-label="531 compiled languages permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>5.3.1 Compiled Languages</strong></h3>
<ul>
<li><strong>“Compiled languages like C/C++ offer better performance at the cost of longer build times.”</strong>
<ul>
<li>Example:
<ul>
<li>C++ applications use compiler optimizations (e.g., <code class="language-text">-O2</code>, <code class="language-text">-O3</code>) to improve runtime efficiency.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="532-interpreted-languages" style="position:relative;"><a href="#532-interpreted-languages" aria-label="532 interpreted languages permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>5.3.2 Interpreted Languages</strong></h3>
<ul>
<li><strong>“Interpreted languages like Python are slower but easier to develop and debug.”</strong>
<ul>
<li>Example:
<ul>
<li>Optimize Python applications with compiled libraries like NumPy for matrix operations.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="533-virtual-machines" style="position:relative;"><a href="#533-virtual-machines" aria-label="533 virtual machines permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>5.3.3 Virtual Machines</strong></h3>
<ul>
<li><strong>“Languages like Java or C# use virtual machines to provide portability and runtime optimizations.”</strong>
<ul>
<li>Example:
<ul>
<li>The Java HotSpot VM uses Just-In-Time (JIT) compilation to improve performance dynamically.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="534-garbage-collection" style="position:relative;"><a href="#534-garbage-collection" aria-label="534 garbage collection permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>5.3.4 Garbage Collection</strong></h3>
<ul>
<li><strong>“Garbage collection automates memory management but introduces pauses.”</strong>
<ul>
<li>Example:
<ul>
<li>Tuning the JVM garbage collector for latency-sensitive applications.</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h2 id="54-observability-and-profiling-methods" style="position:relative;"><a href="#54-observability-and-profiling-methods" aria-label="54 observability and profiling methods permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>5.4 Observability and Profiling Methods</strong></h2>
<p>Effective application-level performance analysis requires robust observability and profiling methods to identify bottlenecks, inefficiencies, and resource misuse. This section outlines critical profiling techniques and tools.</p>
<hr>
<h3 id="541-cpu-profiling" style="position:relative;"><a href="#541-cpu-profiling" aria-label="541 cpu profiling permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>5.4.1 CPU Profiling</strong></h3>
<ul>
<li>
<p><strong>Definition</strong>: CPU profiling identifies parts of the application consuming the most CPU resources. It highlights “hotspots,” functions or threads spending excessive time on the CPU.</p>
</li>
<li>
<p><strong>Tools and Techniques</strong>:</p>
<ul>
<li><strong><code class="language-text">perf</code></strong>:
<ul>
<li>Example: Profile an application for 10 seconds:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">perf record <span class="token parameter variable">-p</span> <span class="token operator">&lt;</span>pid<span class="token operator">></span> -- <span class="token function">sleep</span> <span class="token number">10</span>
perf report</code></pre></div>
<ul>
<li>This captures stack traces for the specified process ID and generates a report showing CPU usage by function.</li>
</ul>
</li>
<li>Use <code class="language-text">perf</code> to compare performance before and after optimizations.</li>
</ul>
</li>
<li><strong>Flame Graphs</strong>:
<ul>
<li>Visualize CPU usage hierarchically:
<ul>
<li>Use <code class="language-text">perf</code> or a similar tool to collect data.</li>
<li>Generate a Flame Graph to identify where most CPU time is spent.</li>
<li>Example: A Flame Graph might show that 40% of CPU time is spent in a specific sorting function, indicating a potential bottleneck.</li>
</ul>
</li>
</ul>
</li>
<li><strong>Language-Specific Profilers</strong>:
<ul>
<li>Python: <code class="language-text">cProfile</code>:
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> cProfile
cProfile<span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token string">'main()'</span><span class="token punctuation">)</span></code></pre></div>
</li>
<li>Java: Java Mission Control (JMC) and VisualVM.</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h3 id="542-off-cpu-analysis" style="position:relative;"><a href="#542-off-cpu-analysis" aria-label="542 off cpu analysis permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>5.4.2 Off-CPU Analysis</strong></h3>
<ul>
<li>
<p><strong>Definition</strong>: Off-CPU analysis examines the time an application spends waiting for resources (e.g., disk I/O, network, or locks), rather than executing on the CPU.</p>
</li>
<li>
<p><strong>Use Cases</strong>:</p>
<ul>
<li>Diagnose I/O-bound applications, such as a database waiting for disk reads.</li>
<li>Identify contention for shared resources (e.g., mutex locks).</li>
</ul>
</li>
<li>
<p><strong>Tools</strong>:</p>
<ul>
<li><strong><code class="language-text">offcputime</code> (BCC tool)</strong>:
<ul>
<li>Captures stack traces during waiting periods:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">offcputime-bpfcc <span class="token parameter variable">-p</span> <span class="token operator">&lt;</span>pid<span class="token operator">></span></code></pre></div>
<ul>
<li>Output reveals where the application is stalled.</li>
</ul>
</li>
<li>Example: Analyze a database application with frequent disk I/O delays to identify which queries or processes are waiting the most.</li>
</ul>
</li>
<li><strong><code class="language-text">bpftrace</code></strong>:
<ul>
<li>Write a custom script to capture waiting threads:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">bpftrace <span class="token parameter variable">-e</span> <span class="token string">'tracepoint:sched:sched_stat_sleep { printf("Off-CPU time: %d ms\n", args->delta); }'</span></code></pre></div>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h3 id="543-syscall-analysis" style="position:relative;"><a href="#543-syscall-analysis" aria-label="543 syscall analysis permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>5.4.3 Syscall Analysis</strong></h3>
<ul>
<li>
<p><strong>Definition</strong>: System calls (syscalls) are the primary interface between user applications and the operating system. Analyzing syscalls helps understand application-OS interactions.</p>
</li>
<li>
<p><strong>Tools</strong>:</p>
<ul>
<li><strong><code class="language-text">strace</code></strong>:
<ul>
<li>Monitors and logs system calls:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">strace</span> <span class="token parameter variable">-c</span> ./app</code></pre></div>
<ul>
<li>Output includes the number of syscalls, execution time, and frequency.</li>
</ul>
</li>
<li>Example: A web server spending excessive time in <code class="language-text">read()</code> syscalls might indicate poor I/O batching.</li>
</ul>
</li>
<li><strong>Use Case</strong>:
<ul>
<li>Monitor file access:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">strace</span> <span class="token parameter variable">-e</span> open,read,write ./app</code></pre></div>
<ul>
<li>Captures all file-related system calls.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h3 id="544-use-method-utilization-saturation-errors" style="position:relative;"><a href="#544-use-method-utilization-saturation-errors" aria-label="544 use method utilization saturation errors permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>5.4.4 USE Method (Utilization, Saturation, Errors)</strong></h3>
<ul>
<li>
<p><strong>Definition</strong>: A systematic approach to analyze performance across resources:</p>
<ul>
<li><strong>Utilization</strong>: How much of a resource is being used (e.g., CPU utilization at 80%).</li>
<li><strong>Saturation</strong>: Are resources overburdened (e.g., CPU run queues)?</li>
<li><strong>Errors</strong>: Any error conditions affecting performance (e.g., disk read failures).</li>
</ul>
</li>
<li>
<p><strong>Example</strong>:</p>
<ul>
<li>Analyze a server’s CPU:
<ul>
<li>Utilization: <code class="language-text">mpstat</code> shows 85% user time.</li>
<li>Saturation: Run queue length >2 indicates contention.</li>
<li>Errors: Check for system logs indicating hardware issues.</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h3 id="545-thread-state-analysis" style="position:relative;"><a href="#545-thread-state-analysis" aria-label="545 thread state analysis permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>5.4.5 Thread State Analysis</strong></h3>
<ul>
<li>
<p><strong>Definition</strong>: Analyzing thread states (e.g., running, waiting, blocked) helps identify inefficiencies like lock contention, idle threads, or excessive context switching.</p>
</li>
<li>
<p><strong>Tools</strong>:</p>
<ul>
<li><strong>Native Threads</strong>:
<ul>
<li>Use <code class="language-text">pstack</code> to capture thread stack traces:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">pstack <span class="token operator">&lt;</span>pid<span class="token operator">></span></code></pre></div>
<ul>
<li>Example: Identify threads blocked on a mutex.</li>
</ul>
</li>
</ul>
</li>
<li><strong>Java Applications</strong>:
<ul>
<li>Use <code class="language-text">jstack</code>:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">jstack <span class="token operator">&lt;</span>pid<span class="token operator">></span></code></pre></div>
<ul>
<li>Output shows threads and their states (e.g., <code class="language-text">BLOCKED</code>, <code class="language-text">WAITING</code>).</li>
</ul>
</li>
<li>Example:
<ul>
<li>A web application with many threads in the <code class="language-text">BLOCKED</code> state may have lock contention in the database connection pool.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h3 id="546-lock-analysis" style="position:relative;"><a href="#546-lock-analysis" aria-label="546 lock analysis permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>5.4.6 Lock Analysis</strong></h3>
<ul>
<li>
<p><strong>Definition</strong>: Locks can degrade application performance by causing threads to serialize execution or wait indefinitely.</p>
</li>
<li>
<p><strong>Tools</strong>:</p>
<ul>
<li><strong><code class="language-text">bpftrace</code></strong>:
<ul>
<li>Monitor contention for locks:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">bpftrace <span class="token parameter variable">-e</span> <span class="token string">'tracepoint:locking:lock_acquire { printf("Lock acquired: %s\n", comm); }'</span></code></pre></div>
</li>
<li>Output identifies frequent lock acquisitions.</li>
</ul>
</li>
<li><strong>Java Lock Analysis</strong>:
<ul>
<li>Java Flight Recorder (JFR) captures lock contention events.</li>
</ul>
</li>
<li><strong>Metrics to Monitor</strong>:
<ul>
<li>Lock hold time.</li>
<li>Contention rate (threads waiting for a lock).</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h3 id="547-distributed-tracing" style="position:relative;"><a href="#547-distributed-tracing" aria-label="547 distributed tracing permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>5.4.7 Distributed Tracing</strong></h3>
<ul>
<li>
<p><strong>Definition</strong>: Distributed tracing tracks a request as it traverses multiple services, identifying latency sources in a microservices architecture.</p>
</li>
<li>
<p><strong>Tools</strong>:</p>
<ul>
<li><strong>OpenTelemetry</strong>:
<ul>
<li>Integrates with services to collect traces and visualize latencies.</li>
<li>Example: Identify a slow database query causing delays in a web application.</li>
</ul>
</li>
<li><strong>Jaeger/Zipkin</strong>:
<ul>
<li>Visualize request flow through services.</li>
<li>Example: Trace a single request across an API gateway, authentication service, and database.</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h3 id="548-static-performance-tuning" style="position:relative;"><a href="#548-static-performance-tuning" aria-label="548 static performance tuning permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>5.4.8 Static Performance Tuning</strong></h3>
<ul>
<li><strong>Definition</strong>: Identifies inefficiencies and applies preemptive optimizations.</li>
<li>Examples:
<ul>
<li>Optimize algorithms (e.g., replace O(n²) algorithms with O(n log n)).</li>
<li>Precompute results when possible.</li>
</ul>
</li>
</ul>
<hr>
<h3 id="549-micro-benchmarking" style="position:relative;"><a href="#549-micro-benchmarking" aria-label="549 micro benchmarking permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>5.4.9 Micro-Benchmarking</strong></h3>
<ul>
<li><strong>Definition</strong>: Measures the performance of small, isolated code blocks.</li>
<li>Tools:
<ul>
<li><strong>Google Benchmark (C++):</strong>
<ul>
<li>Example:
<div class="gatsby-highlight" data-language="cpp"><pre class="language-cpp"><code class="language-cpp"><span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">BM_Sort</span><span class="token punctuation">(</span>benchmark<span class="token double-colon punctuation">::</span>State<span class="token operator">&amp;</span> state<span class="token punctuation">)</span> <span class="token punctuation">{</span>
    std<span class="token double-colon punctuation">::</span>vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> <span class="token function">v</span><span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">auto</span> _ <span class="token operator">:</span> state<span class="token punctuation">)</span> std<span class="token double-colon punctuation">::</span><span class="token function">sort</span><span class="token punctuation">(</span>v<span class="token punctuation">.</span><span class="token function">begin</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> v<span class="token punctuation">.</span><span class="token function">end</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
<span class="token function">BENCHMARK</span><span class="token punctuation">(</span>BM_Sort<span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre></div>
</li>
</ul>
</li>
<li><strong><code class="language-text">time</code> Command</strong>:
<ul>
<li>Example:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">time</span> ./app</code></pre></div>
<ul>
<li>Measures total runtime, useful for simple comparisons.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h3 id="5410-performance-monitoring-tools" style="position:relative;"><a href="#5410-performance-monitoring-tools" aria-label="5410 performance monitoring tools permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>5.4.10 Performance Monitoring Tools</strong></h3>
<ul>
<li><strong>Definition</strong>: Continuous tracking of application metrics to identify trends and anomalies.</li>
<li>Tools:
<ul>
<li><strong>Prometheus/Grafana</strong>:
<ul>
<li>Monitor CPU, memory, and custom application metrics.</li>
</ul>
</li>
<li><strong>ELK Stack</strong>:
<ul>
<li>Collect and visualize logs, providing insights into errors and usage patterns.</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<p>Let’s take a deep dive into <strong>Sections 5.5 (Observability Tools)</strong> and <strong>5.6 (Gotchas)</strong> with expanded details, in-depth explanations, and practical examples for each subsection:</p>
<hr>
<h2 id="55-observability-tools" style="position:relative;"><a href="#55-observability-tools" aria-label="55 observability tools permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>5.5 Observability Tools</strong></h2>
<p>This section introduces essential tools for application performance analysis on Linux. These tools provide critical insights into CPU usage, system calls, I/O performance, and application bottlenecks.</p>
<hr>
<h3 id="551-perf" style="position:relative;"><a href="#551-perf" aria-label="551 perf permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>5.5.1 <code class="language-text">perf</code></strong></h3>
<ul>
<li>
<p><strong>Purpose</strong>: <code class="language-text">perf</code> is a comprehensive tool for profiling and tracing Linux systems. It provides detailed insights into CPU usage, system calls, and hardware events.</p>
</li>
<li>
<p><strong>Capabilities</strong>:</p>
<ul>
<li><strong>CPU Flame Graphs</strong>:
<ul>
<li>Use <code class="language-text">perf</code> to capture stack traces:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">perf record <span class="token parameter variable">-F</span> <span class="token number">99</span> <span class="token parameter variable">-p</span> <span class="token operator">&lt;</span>pid<span class="token operator">></span> -- <span class="token function">sleep</span> <span class="token number">10</span>
perf script <span class="token operator">|</span> stackcollapse-perf.pl <span class="token operator">|</span> flamegraph.pl <span class="token operator">></span> out.svg</code></pre></div>
</li>
<li>Flame Graphs visualize CPU usage hierarchically, highlighting hot functions.</li>
<li>Example: A web server might show heavy CPU usage in <code class="language-text">handle_request()</code> due to inefficient parsing logic.</li>
</ul>
</li>
<li><strong>System-Wide Profiling</strong>:
<ul>
<li>Profile all processes:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">perf record <span class="token parameter variable">-a</span> -- <span class="token function">sleep</span> <span class="token number">5</span></code></pre></div>
</li>
<li>Use this for high-level performance trends across the system.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Advanced Example</strong>:</p>
<ul>
<li>Trace and measure latency for a specific syscall (e.g., <code class="language-text">read</code>):
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">perf trace <span class="token parameter variable">-e</span> <span class="token builtin class-name">read</span></code></pre></div>
</li>
</ul>
</li>
</ul>
<hr>
<h3 id="552-profile" style="position:relative;"><a href="#552-profile" aria-label="552 profile permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>5.5.2 <code class="language-text">profile</code></strong></h3>
<ul>
<li><strong>Purpose</strong>: Part of the BPF Compiler Collection (BCC), <code class="language-text">profile</code> captures stack traces at specified intervals.</li>
<li><strong>Advantages</strong>:
<ul>
<li>Lower overhead compared to sampling-based profilers like <code class="language-text">strace</code>.</li>
</ul>
</li>
<li><strong>Use Case</strong>:
<ul>
<li>Identify CPU hotspots in a Python application:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">profile <span class="token parameter variable">-F</span> <span class="token number">49</span> <span class="token parameter variable">-p</span> <span class="token variable"><span class="token variable">$(</span>pidof python<span class="token variable">)</span></span></code></pre></div>
<ul>
<li>Output: Stack traces showing the most CPU-intensive functions in the Python process.</li>
</ul>
</li>
<li>This tool is especially useful for profiling production workloads due to minimal disruption.</li>
</ul>
</li>
</ul>
<hr>
<h3 id="553-offcputime" style="position:relative;"><a href="#553-offcputime" aria-label="553 offcputime permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>5.5.3 <code class="language-text">offcputime</code></strong></h3>
<ul>
<li>
<p><strong>Purpose</strong>: Measures the time threads spend waiting (off-CPU) rather than executing (on-CPU). This is crucial for diagnosing I/O latency, lock contention, and synchronization issues.</p>
</li>
<li>
<p><strong>Example</strong>:</p>
<ul>
<li>Analyze a database application waiting for disk reads:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">offcputime-bpfcc <span class="token parameter variable">-p</span> <span class="token operator">&lt;</span>pid<span class="token operator">></span></code></pre></div>
<ul>
<li>Output: A stack trace showing functions stalled waiting for file I/O or mutex locks.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Use Case</strong>:</p>
<ul>
<li>A Redis server exhibits high latency. <code class="language-text">offcputime</code> reveals that threads are waiting on slow disk writes.</li>
</ul>
</li>
</ul>
<hr>
<h3 id="554-strace" style="position:relative;"><a href="#554-strace" aria-label="554 strace permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>5.5.4 <code class="language-text">strace</code></strong></h3>
<ul>
<li>
<p><strong>Purpose</strong>: Monitors system calls made by a process. Ideal for debugging syscall-related performance issues.</p>
</li>
<li>
<p><strong>Capabilities</strong>:</p>
<ul>
<li>Count and summarize syscalls:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">strace</span> <span class="token parameter variable">-c</span> <span class="token parameter variable">-p</span> <span class="token operator">&lt;</span>pid<span class="token operator">></span></code></pre></div>
</li>
<li>Trace specific syscalls:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">strace</span> <span class="token parameter variable">-e</span> open,read,write ./app</code></pre></div>
<ul>
<li>Output: Calls to <code class="language-text">open()</code>, <code class="language-text">read()</code>, and <code class="language-text">write()</code> with arguments.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Example</strong>:</p>
<ul>
<li>Analyze a file-opening bottleneck:
<ul>
<li>A script opens files unnecessarily. <code class="language-text">strace</code> reveals repeated calls to <code class="language-text">open()</code>.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Considerations</strong>:</p>
<ul>
<li>High overhead; avoid using in production environments.</li>
</ul>
</li>
</ul>
<hr>
<h3 id="555-execsnoop" style="position:relative;"><a href="#555-execsnoop" aria-label="555 execsnoop permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>5.5.5 <code class="language-text">execsnoop</code></strong></h3>
<ul>
<li><strong>Purpose</strong>: Tracks new process executions, including short-lived processes that might go unnoticed in other tools.</li>
<li><strong>Example</strong>:
<ul>
<li>Monitor processes on a database server:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">execsnoop</code></pre></div>
<ul>
<li>Output: Shows commands executed, such as backup scripts or cron jobs.</li>
</ul>
</li>
</ul>
</li>
<li><strong>Use Case</strong>:
<ul>
<li>Identify a rogue process consuming significant resources.</li>
</ul>
</li>
</ul>
<hr>
<h3 id="556-syscount" style="position:relative;"><a href="#556-syscount" aria-label="556 syscount permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>5.5.6 <code class="language-text">syscount</code></strong></h3>
<ul>
<li><strong>Purpose</strong>: Counts and categorizes system calls, providing insight into syscall frequency and patterns.</li>
<li><strong>Example</strong>:
<ul>
<li>Trace syscalls system-wide:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">syscount <span class="token parameter variable">-P</span></code></pre></div>
<ul>
<li>Output: A table showing the most frequent syscalls (<code class="language-text">read()</code>, <code class="language-text">poll()</code>, etc.).</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h3 id="557-bpftrace" style="position:relative;"><a href="#557-bpftrace" aria-label="557 bpftrace permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>5.5.7 <code class="language-text">bpftrace</code></strong></h3>
<ul>
<li><strong>Purpose</strong>: A powerful tool for custom tracing scripts using eBPF.</li>
<li><strong>Capabilities</strong>:
<ul>
<li><strong>Trace Signals</strong>:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">bpftrace <span class="token parameter variable">-e</span> <span class="token string">'tracepoint:syscalls:sys_enter_kill { printf("%d sent SIG to %d\n", pid, args->pid); }'</span></code></pre></div>
<ul>
<li>Output: Tracks processes sending signals (e.g., <code class="language-text">kill</code>).</li>
</ul>
</li>
<li><strong>Trace I/O Latency</strong>:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">bpftrace <span class="token parameter variable">-e</span> <span class="token string">'tracepoint:block:block_rq_issue { printf("%d %s\n", pid, comm); }'</span></code></pre></div>
<ul>
<li>Output: Identifies slow block I/O operations.</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h2 id="56-gotchas" style="position:relative;"><a href="#56-gotchas" aria-label="56 gotchas permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>5.6 Gotchas</strong></h2>
<p>This section highlights common challenges encountered during profiling and strategies to overcome them.</p>
<hr>
<h3 id="561-missing-symbols" style="position:relative;"><a href="#561-missing-symbols" aria-label="561 missing symbols permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>5.6.1 Missing Symbols</strong></h3>
<ul>
<li><strong>Problem</strong>: Profilers fail to map memory addresses to function names due to missing debug symbols.</li>
<li><strong>Example</strong>:
<ul>
<li>A Flame Graph shows <code class="language-text">[unknown]</code> frames for an application compiled without <code class="language-text">-g</code>.</li>
</ul>
</li>
<li><strong>Solution</strong>:
<ul>
<li>Compile with debug symbols:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">gcc <span class="token parameter variable">-g</span> <span class="token parameter variable">-o</span> app app.c</code></pre></div>
</li>
<li>For JIT runtimes (Java, Node.js), use symbol-dumping tools like <code class="language-text">perf-map-agent</code>.</li>
</ul>
</li>
</ul>
<hr>
<h3 id="562-missing-stacks" style="position:relative;"><a href="#562-missing-stacks" aria-label="562 missing stacks permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>5.6.2 Missing Stacks</strong></h3>
<ul>
<li><strong>Problem</strong>: Incomplete stack traces obscure the root cause of performance issues.</li>
<li><strong>Example</strong>:
<ul>
<li>An off-CPU analysis shows <code class="language-text">pthread_cond_timedwait()</code> but not the calling function.</li>
</ul>
</li>
<li><strong>Solution</strong>:
<ul>
<li>Compile with <code class="language-text">-fno-omit-frame-pointer</code>.</li>
<li>Use DWARF-based stack-walking tools for better trace completeness.</li>
</ul>
</li>
</ul>
<hr>
<h3 id="563-overhead-from-profiling-tools" style="position:relative;"><a href="#563-overhead-from-profiling-tools" aria-label="563 overhead from profiling tools permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>5.6.3 Overhead from Profiling Tools</strong></h3>
<ul>
<li><strong>Problem</strong>: Profiling tools, especially tracing ones like <code class="language-text">strace</code>, introduce significant latency.</li>
<li><strong>Solution</strong>:
<ul>
<li>Use low-overhead tools like <code class="language-text">perf</code> or eBPF-based profilers.</li>
<li>Limit tracing to specific processes or syscalls.</li>
</ul>
</li>
</ul>
<hr>
<h3 id="564-sampling-bias" style="position:relative;"><a href="#564-sampling-bias" aria-label="564 sampling bias permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>5.6.4 Sampling Bias</strong></h3>
<ul>
<li><strong>Problem</strong>: Sampling-based tools may miss rare or transient events.</li>
<li><strong>Example</strong>:
<ul>
<li>A profiling session misses infrequent database timeouts.</li>
</ul>
</li>
<li><strong>Solution</strong>:
<ul>
<li>Increase sampling frequency cautiously:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">perf record <span class="token parameter variable">-F</span> <span class="token number">1000</span> <span class="token parameter variable">-p</span> <span class="token operator">&lt;</span>pid<span class="token operator">></span></code></pre></div>
</li>
<li>Combine sampling with event-based tracing.</li>
</ul>
</li>
</ul>
<hr>
<h3 id="565-ignoring-distributed-context" style="position:relative;"><a href="#565-ignoring-distributed-context" aria-label="565 ignoring distributed context permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>5.6.5 Ignoring Distributed Context</strong></h3>
<ul>
<li><strong>Problem</strong>: Profiling a single service may overlook issues caused by upstream/downstream dependencies.</li>
<li><strong>Example</strong>:
<ul>
<li>A web app’s latency is attributed to CPU usage but is actually caused by slow database queries.</li>
</ul>
</li>
<li><strong>Solution</strong>:
<ul>
<li>Use distributed tracing tools like OpenTelemetry or Jaeger to capture the full request lifecycle.</li>
</ul>
</li>
</ul>
<hr>
<h2 id="advanced-examples" style="position:relative;"><a href="#advanced-examples" aria-label="advanced examples permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Advanced Examples</strong></h2>
<h3 id="example-1-diagnosing-high-io-latency" style="position:relative;"><a href="#example-1-diagnosing-high-io-latency" aria-label="example 1 diagnosing high io latency permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example 1: Diagnosing High I/O Latency</strong></h3>
<ul>
<li>Tools: <code class="language-text">offcputime</code> and <code class="language-text">bpftrace</code>.</li>
<li>Scenario: A database exhibits high response times.</li>
<li>Steps:
<ol>
<li>Use <code class="language-text">offcputime</code> to identify threads waiting on disk reads.</li>
<li>Drill down with <code class="language-text">bpftrace</code> to trace I/O operations:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">bpftrace <span class="token parameter variable">-e</span> <span class="token string">'tracepoint:block:block_rq_complete { printf("%d %d\n", args->sector, args->delta); }'</span></code></pre></div>
</li>
</ol>
</li>
</ul>
<h3 id="example-2-investigating-lock-contention" style="position:relative;"><a href="#example-2-investigating-lock-contention" aria-label="example 2 investigating lock contention permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example 2: Investigating Lock Contention</strong></h3>
<ul>
<li>Tools: <code class="language-text">perf</code> and <code class="language-text">bpftrace</code>.</li>
<li>Scenario: A multithreaded application experiences high CPU usage.</li>
<li>Steps:
<ol>
<li>Use <code class="language-text">perf</code> to capture stack traces:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">perf record <span class="token parameter variable">-p</span> <span class="token operator">&lt;</span>pid<span class="token operator">></span> -- <span class="token function">sleep</span> <span class="token number">10</span></code></pre></div>
</li>
<li>Generate a Flame Graph to identify locking bottlenecks.</li>
<li>Use <code class="language-text">bpftrace</code> for mutex tracing:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">bpftrace <span class="token parameter variable">-e</span> <span class="token string">'tracepoint:locking:lock_acquire { printf("%s\n", comm); }'</span></code></pre></div>
</li>
</ol>
</li>
</ul>
<hr>
<h2 id="exercises-1" style="position:relative;"><a href="#exercises-1" aria-label="exercises 1 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Exercises</strong></h2>
<ul>
<li><strong>Flame Graphs</strong>:
<ul>
<li>Profile an application using <code class="language-text">perf</code> and generate a Flame Graph.</li>
</ul>
</li>
<li><strong>Off-CPU Analysis</strong>:
<ul>
<li>Use <code class="language-text">offcputime</code> to analyze a database under load.</li>
</ul>
</li>
<li><strong>Distributed Tracing</strong>:
<ul>
<li>Set up OpenTelemetry to trace requests across multiple microservices.</li>
</ul>
</li>
</ul>
<p>Here’s a <strong>detailed outline of Chapter 6: CPUs</strong> from <em>Systems Performance: Enterprise and the Cloud (Second Edition)</em>, including a breakdown of all sections, subtopics, and relevant examples for clarity.</p>
<hr>
<h1 id="chapter-6-cpus" style="position:relative;"><a href="#chapter-6-cpus" aria-label="chapter 6 cpus permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Chapter 6: CPUs</strong></h1>
<p>The chapter provides a comprehensive analysis of CPU performance in enterprise and cloud environments, focusing on architecture, metrics, tools, visualization, and tuning. Each section is designed to provide insights into optimizing CPU usage, identifying bottlenecks, and applying performance improvements.</p>
<hr>
<h2 id="61-terminology" style="position:relative;"><a href="#61-terminology" aria-label="61 terminology permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>6.1 Terminology</strong></h2>
<p>Key terms and definitions essential for understanding CPU performance:</p>
<ol>
<li>
<p><strong>Clock Rate</strong>:</p>
<ul>
<li>The speed at which the CPU executes instructions (e.g., 3 GHz = 3 billion cycles per second).</li>
<li>Example: A workload achieving 1 instruction per cycle on a 3 GHz CPU executes 3 billion instructions per second.</li>
</ul>
</li>
<li>
<p><strong>Utilization</strong>:</p>
<ul>
<li>Percentage of time the CPU is actively executing instructions.</li>
<li>Example: A 90% CPU utilization rate indicates near-full resource use.</li>
</ul>
</li>
<li>
<p><strong>Instructions Per Cycle (IPC)</strong>:</p>
<ul>
<li>Measures efficiency by calculating the average number of instructions executed per cycle.</li>
<li>Example: Higher IPC indicates better resource utilization.</li>
</ul>
</li>
<li>
<p><strong>Cycles Per Instruction (CPI)</strong>:</p>
<ul>
<li>The inverse of IPC, showing how many clock cycles each instruction takes on average.</li>
<li>Example: Lower CPI is desirable as it indicates faster execution.</li>
</ul>
</li>
<li>
<p><strong>Run Queue</strong>:</p>
<ul>
<li>The number of processes waiting for CPU time.</li>
<li>Example: A high run queue indicates contention for CPU resources.</li>
</ul>
</li>
</ol>
<hr>
<h2 id="62-models" style="position:relative;"><a href="#62-models" aria-label="62 models permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>6.2 Models</strong></h2>
<p>Conceptual and practical models for understanding CPU performance:</p>
<ol>
<li>
<p><strong>Hardware Architecture</strong>:</p>
<ul>
<li>Multi-core processors with shared and private caches.</li>
<li>Example: A quad-core CPU with shared L3 cache.</li>
</ul>
</li>
<li>
<p><strong>Pipelines</strong>:</p>
<ul>
<li>Instruction pipelines split execution into fetch, decode, execute, memory access, and write-back stages.</li>
</ul>
</li>
<li>
<p><strong>Caches</strong>:</p>
<ul>
<li>Hierarchical storage (L1, L2, L3) for reducing memory access latency.</li>
<li>Example: High cache hit rates correlate to faster program execution.</li>
</ul>
</li>
<li>
<p><strong>NUMA (Non-Uniform Memory Access)</strong>:</p>
<ul>
<li>Memory latency depends on whether data is local or remote to the CPU core.</li>
</ul>
</li>
</ol>
<hr>
<h2 id="63-concepts" style="position:relative;"><a href="#63-concepts" aria-label="63 concepts permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>6.3 Concepts</strong></h2>
<ol>
<li>
<p><strong>Clock Cycles</strong>:</p>
<ul>
<li>Basic unit of CPU work tied to its clock rate.</li>
</ul>
</li>
<li>
<p><strong>Pipeline Stalls</strong>:</p>
<ul>
<li>Occur when dependencies or resource limitations delay execution.</li>
</ul>
</li>
<li>
<p><strong>Hyper-Threading</strong>:</p>
<ul>
<li>Executes multiple threads per core to improve throughput.</li>
</ul>
</li>
<li>
<p><strong>Branch Prediction and Speculative Execution</strong>:</p>
<ul>
<li>Techniques to improve performance by guessing instruction outcomes.</li>
</ul>
</li>
</ol>
<hr>
<h2 id="64-architecture" style="position:relative;"><a href="#64-architecture" aria-label="64 architecture permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>6.4 Architecture</strong></h2>
<ol>
<li>
<p><strong>Core Design</strong>:</p>
<ul>
<li>Out-of-order execution to maximize instruction throughput.</li>
</ul>
</li>
<li>
<p><strong>Simultaneous Multi-Threading (SMT)</strong>:</p>
<ul>
<li>Efficient use of CPU resources by running multiple threads on a single core.</li>
</ul>
</li>
<li>
<p><strong>Cache Design</strong>:</p>
<ul>
<li>Faster access at higher levels (L1) versus larger storage in shared caches (L3).</li>
</ul>
</li>
<li>
<p><strong>CPU Frequency Scaling</strong>:</p>
<ul>
<li>Dynamic adjustment of clock speeds based on workload.</li>
</ul>
</li>
</ol>
<hr>
<p>Here’s a <strong>comprehensive and in-depth expansion of Section 6.5: Methodology</strong> from Chapter 6 of <em>Systems Performance: Enterprise and the Cloud</em>. This section focuses on strategies and methods to analyze, diagnose, and troubleshoot CPU performance effectively.</p>
<hr>
<h2 id="65-methodology" style="position:relative;"><a href="#65-methodology" aria-label="65 methodology permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>6.5 Methodology</strong></h2>
<p>Effective CPU performance analysis requires a structured approach to identify bottlenecks, inefficiencies, and potential areas for optimization. Section 6.5 explores key methodologies for assessing CPU performance.</p>
<hr>
<h3 id="651-use-method" style="position:relative;"><a href="#651-use-method" aria-label="651 use method permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>6.5.1 USE Method</strong></h3>
<p>The <strong>USE Method</strong> (Utilization, Saturation, and Errors) is a systematic way to analyze resource performance, including CPUs.</p>
<h4 id="utilization" style="position:relative;"><a href="#utilization" aria-label="utilization permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Utilization</strong></h4>
<ul>
<li><strong>Definition</strong>: Measures the percentage of time a resource (CPU in this case) is actively used.</li>
<li><strong>Why It Matters</strong>:
<ul>
<li>High utilization indicates heavy use but doesn’t necessarily imply a problem.</li>
<li>Low utilization might indicate underutilization or inefficiencies in workloads.</li>
</ul>
</li>
<li><strong>Example</strong>:
<ul>
<li>A server running at 90% CPU utilization could be performing optimally for a batch processing workload.</li>
<li>Conversely, 90% utilization in a real-time application might cause delays in critical tasks.</li>
</ul>
</li>
</ul>
<h4 id="saturation" style="position:relative;"><a href="#saturation" aria-label="saturation permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Saturation</strong></h4>
<ul>
<li><strong>Definition</strong>: Indicates whether a resource is overburdened, often seen in high run queue lengths.</li>
<li><strong>Symptoms</strong>:
<ul>
<li>Threads waiting for CPU time.</li>
<li>Increased response times due to contention.</li>
</ul>
</li>
<li><strong>Example</strong>:
<ul>
<li>A run queue length greater than the number of cores (e.g., 16 threads on an 8-core CPU) indicates saturation.</li>
</ul>
</li>
<li><strong>Tools</strong>:
<ul>
<li>Use <code class="language-text">sar -q</code> to monitor run queues:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">sar <span class="token parameter variable">-q</span> <span class="token number">1</span> <span class="token number">5</span></code></pre></div>
</li>
</ul>
</li>
</ul>
<h4 id="errors" style="position:relative;"><a href="#errors" aria-label="errors permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Errors</strong></h4>
<ul>
<li><strong>Definition</strong>: Measures failure rates, such as context switch errors or task migration issues.</li>
<li><strong>Example</strong>:
<ul>
<li>A high rate of context switches might suggest improper thread handling.</li>
</ul>
</li>
</ul>
<hr>
<h3 id="652-cycle-analysis" style="position:relative;"><a href="#652-cycle-analysis" aria-label="652 cycle analysis permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>6.5.2 Cycle Analysis</strong></h3>
<h4 id="cpu-cycle-categories" style="position:relative;"><a href="#cpu-cycle-categories" aria-label="cpu cycle categories permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>CPU Cycle Categories</strong></h4>
<p>Understanding how CPU cycles are spent helps identify performance bottlenecks:</p>
<ol>
<li><strong>Execution Cycles</strong>:
<ul>
<li>Cycles used for actual instruction execution.</li>
</ul>
</li>
<li><strong>Memory Stalls</strong>:
<ul>
<li>Cycles waiting for data from memory (e.g., due to cache misses).</li>
</ul>
</li>
<li><strong>Branch Mispredictions</strong>:
<ul>
<li>Cycles wasted due to incorrect branch predictions.</li>
</ul>
</li>
</ol>
<h4 id="tool-example" style="position:relative;"><a href="#tool-example" aria-label="tool example permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Tool Example</strong>:</h4>
<ul>
<li>Use <code class="language-text">perf stat</code> to analyze CPU cycle distribution:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">perf <span class="token function">stat</span> <span class="token parameter variable">-e</span> cycles,instructions,cache-misses,branch-misses ./app</code></pre></div>
</li>
<li><strong>Output Example</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">Performance counter stats for './app':
    1,000,000 cycles
      800,000 instructions
        2,000 cache-misses
          500 branch-misses</code></pre></div>
<ul>
<li><strong>Interpretation</strong>:
<ul>
<li>High cache misses suggest poor memory locality.</li>
<li>High branch misses indicate inefficient branching logic.</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h3 id="653-profiling-workloads" style="position:relative;"><a href="#653-profiling-workloads" aria-label="653 profiling workloads permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>6.5.3 Profiling Workloads</strong></h3>
<p>Profiling involves measuring application behavior under different workloads to pinpoint inefficiencies.</p>
<h4 id="steps" style="position:relative;"><a href="#steps" aria-label="steps permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Steps</strong>:</h4>
<ol>
<li>
<p><strong>Baseline Measurement</strong>:</p>
<ul>
<li>Profile the application under normal conditions to establish performance baselines.</li>
<li>Example:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">perf record ./app
perf report</code></pre></div>
</li>
</ul>
</li>
<li>
<p><strong>Stress Testing</strong>:</p>
<ul>
<li>Simulate high-load conditions to uncover bottlenecks.</li>
<li>Use <code class="language-text">sysbench</code> for CPU stress tests:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">sysbench cpu <span class="token parameter variable">--threads</span><span class="token operator">=</span><span class="token number">8</span> run</code></pre></div>
</li>
</ul>
</li>
<li>
<p><strong>Dynamic Workload Profiling</strong>:</p>
<ul>
<li>Profile applications with fluctuating workloads (e.g., cloud services).</li>
<li>Tool: <code class="language-text">bpftrace</code> for real-time profiling.</li>
</ul>
</li>
</ol>
<hr>
<h3 id="654-run-queue-analysis" style="position:relative;"><a href="#654-run-queue-analysis" aria-label="654 run queue analysis permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>6.5.4 Run Queue Analysis</strong></h3>
<p>The <strong>run queue</strong> represents the number of threads waiting for CPU resources.</p>
<h4 id="symptoms-of-overloaded-run-queues" style="position:relative;"><a href="#symptoms-of-overloaded-run-queues" aria-label="symptoms of overloaded run queues permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Symptoms of Overloaded Run Queues</strong>:</h4>
<ul>
<li>High latency for thread scheduling.</li>
<li>Decreased throughput.</li>
</ul>
<h4 id="tools" style="position:relative;"><a href="#tools" aria-label="tools permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Tools</strong>:</h4>
<ol>
<li>
<p><strong><code class="language-text">vmstat</code></strong>:</p>
<ul>
<li>Use to monitor the run queue length:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">vmstat</span> <span class="token number">1</span></code></pre></div>
</li>
<li><strong>Output Example</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs  us  sy  id  wa
3  1      0  15000   2000  25000    0    0     0     0  120  220  50  10  40   0</code></pre></div>
<ul>
<li>Column <code class="language-text">r</code> indicates the run queue length.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong><code class="language-text">sar -q</code></strong>:</p>
<ul>
<li>Provides historical run queue statistics:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">sar <span class="token parameter variable">-q</span> <span class="token number">1</span> <span class="token number">10</span></code></pre></div>
</li>
</ul>
</li>
</ol>
<h4 id="example" style="position:relative;"><a href="#example" aria-label="example permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example</strong>:</h4>
<ul>
<li>A run queue length of 10 on a 4-core CPU indicates saturation. Adding more cores or optimizing application concurrency can resolve the issue.</li>
</ul>
<hr>
<h3 id="655-observability-with-cpu-specific-metrics" style="position:relative;"><a href="#655-observability-with-cpu-specific-metrics" aria-label="655 observability with cpu specific metrics permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>6.5.5 Observability with CPU-Specific Metrics</strong></h3>
<h4 id="metrics-to-observe" style="position:relative;"><a href="#metrics-to-observe" aria-label="metrics to observe permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Metrics to Observe</strong>:</h4>
<ol>
<li><strong>CPU Utilization</strong>:
<ul>
<li>High percentages might indicate overloaded threads.</li>
</ul>
</li>
<li><strong>Context Switches</strong>:
<ul>
<li>Frequent context switches suggest inefficiencies in thread scheduling.</li>
</ul>
</li>
<li><strong>Interrupts</strong>:
<ul>
<li>High interrupt rates might point to excessive I/O activity.</li>
</ul>
</li>
</ol>
<h4 id="tool-example-1" style="position:relative;"><a href="#tool-example-1" aria-label="tool example 1 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Tool Example</strong>:</h4>
<ul>
<li>Use <code class="language-text">mpstat</code> to analyze per-core CPU utilization:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">mpstat <span class="token parameter variable">-P</span> ALL <span class="token number">1</span></code></pre></div>
</li>
</ul>
<h4 id="output-example" style="position:relative;"><a href="#output-example" aria-label="output example permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Output Example</strong>:</h4>
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">CPU    %usr   %sys   %iowait   %idle
all    25.0   10.0     2.0     63.0
  0    30.0   15.0     0.0     55.0
  1    20.0    5.0     5.0     70.0</code></pre></div>
<ul>
<li>Interpretation:
<ul>
<li>Core 0 is heavily utilized, indicating an imbalance.</li>
</ul>
</li>
</ul>
<hr>
<h3 id="656-branch-misprediction-analysis" style="position:relative;"><a href="#656-branch-misprediction-analysis" aria-label="656 branch misprediction analysis permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>6.5.6 Branch Misprediction Analysis</strong></h3>
<h4 id="what-are-branch-mispredictions" style="position:relative;"><a href="#what-are-branch-mispredictions" aria-label="what are branch mispredictions permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>What Are Branch Mispredictions?</strong></h4>
<ul>
<li>CPUs predict the outcome of branches to execute instructions speculatively. Incorrect predictions result in pipeline flushes.</li>
</ul>
<h4 id="tool-example-2" style="position:relative;"><a href="#tool-example-2" aria-label="tool example 2 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Tool Example</strong>:</h4>
<ul>
<li>Use <code class="language-text">perf</code> to measure branch mispredictions:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">perf <span class="token function">stat</span> <span class="token parameter variable">-e</span> branch-misses ./app</code></pre></div>
</li>
<li><strong>Optimization</strong>:
<ul>
<li>Refactor code to reduce branch unpredictability.</li>
<li>Use data-driven techniques like lookup tables or binary decision trees.</li>
</ul>
</li>
</ul>
<hr>
<h3 id="657-memory-bottleneck-analysis" style="position:relative;"><a href="#657-memory-bottleneck-analysis" aria-label="657 memory bottleneck analysis permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>6.5.7 Memory Bottleneck Analysis</strong></h3>
<p>Memory performance impacts CPU cycles. Poor memory locality leads to frequent stalls.</p>
<h4 id="cache-misses" style="position:relative;"><a href="#cache-misses" aria-label="cache misses permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Cache Misses</strong>:</h4>
<ul>
<li>High cache misses reduce CPU efficiency.</li>
<li><strong>Example</strong>:
<ul>
<li>Analyze cache misses with <code class="language-text">perf</code>:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">perf <span class="token function">stat</span> <span class="token parameter variable">-e</span> cache-references,cache-misses ./app</code></pre></div>
<ul>
<li>Optimize loops for sequential memory access to reduce misses.</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h3 id="658-real-world-use-case-optimizing-a-web-server" style="position:relative;"><a href="#658-real-world-use-case-optimizing-a-web-server" aria-label="658 real world use case optimizing a web server permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>6.5.8 Real-World Use Case: Optimizing a Web Server</strong></h3>
<h4 id="scenario" style="position:relative;"><a href="#scenario" aria-label="scenario permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Scenario</strong>:</h4>
<ul>
<li>A web server experiences high CPU utilization with low throughput.</li>
</ul>
<h4 id="steps-1" style="position:relative;"><a href="#steps-1" aria-label="steps 1 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Steps</strong>:</h4>
<ol>
<li>
<p><strong>Profile with <code class="language-text">perf</code></strong>:</p>
<ul>
<li>Identify hotspots:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">perf record <span class="token parameter variable">-p</span> <span class="token variable"><span class="token variable">$(</span>pidof nginx<span class="token variable">)</span></span>
perf report</code></pre></div>
</li>
<li><strong>Finding</strong>:
<ul>
<li>Excessive CPU time spent in <code class="language-text">parse_request()</code>.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Run Queue Analysis</strong>:</p>
<ul>
<li>Use <code class="language-text">sar -q</code> to check for high run queue lengths:
<ul>
<li><strong>Finding</strong>:
<ul>
<li>Run queue length of 12 on an 8-core CPU suggests saturation.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Optimization</strong>:</p>
<ul>
<li>Optimize <code class="language-text">parse_request()</code> to reduce string parsing overhead.</li>
<li>Introduce thread pooling to balance workloads across cores.</li>
</ul>
</li>
</ol>
<h4 id="result" style="position:relative;"><a href="#result" aria-label="result permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Result</strong>:</h4>
<ul>
<li>CPU utilization reduced by 25%.</li>
<li>Throughput increased by 40%.</li>
</ul>
<hr>
<h3 id="key-takeaways-for-methodology" style="position:relative;"><a href="#key-takeaways-for-methodology" aria-label="key takeaways for methodology permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Key Takeaways for Methodology</strong></h3>
<ul>
<li>Use <strong>structured methods</strong> like the USE Method to systematically diagnose CPU bottlenecks.</li>
<li>Combine tools like <code class="language-text">perf</code>, <code class="language-text">mpstat</code>, <code class="language-text">vmstat</code>, and <code class="language-text">bpftrace</code> for comprehensive profiling.</li>
<li>Focus on optimizing run queues, branch predictions, and memory access patterns for substantial performance gains.</li>
</ul>
<hr>
<p>Here is an <strong>in-depth and expanded explanation of Section 6.6: Observability Tools</strong> from Chapter 6, focusing on CPU performance analysis. This section details various tools, their use cases, metrics they provide, and real-world examples to help understand their application.</p>
<hr>
<h2 id="66-observability-tools" style="position:relative;"><a href="#66-observability-tools" aria-label="66 observability tools permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>6.6 Observability Tools</strong></h2>
<p>CPU observability tools are essential for identifying bottlenecks, measuring resource usage, and diagnosing performance issues. This section explores the most commonly used tools for monitoring and analyzing CPU performance, ranging from basic system utilities to advanced profiling and tracing tools.</p>
<hr>
<h3 id="661-basic-tools" style="position:relative;"><a href="#661-basic-tools" aria-label="661 basic tools permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>6.6.1 Basic Tools</strong></h3>
<h4 id="uptime" style="position:relative;"><a href="#uptime" aria-label="uptime permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong><code class="language-text">uptime</code></strong></h4>
<ul>
<li><strong>Purpose</strong>: Provides a quick overview of system load averages over the past 1, 5, and 15 minutes.</li>
<li><strong>Use Case</strong>:
<ul>
<li>Assess whether the system is under heavy load or idle.</li>
</ul>
</li>
<li><strong>Example</strong>:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">uptime</span></code></pre></div>
<ul>
<li>Output:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">17:45:32 up 1 day, 4:32,  4 users,  load average: 1.54, 1.20, 0.98</code></pre></div>
<ul>
<li><strong>Interpretation</strong>:
<ul>
<li>A load average of 1.54 on a single-core CPU indicates full utilization; on a quad-core CPU, it indicates light utilization.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h4 id="top" style="position:relative;"><a href="#top" aria-label="top permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong><code class="language-text">top</code></strong></h4>
<ul>
<li><strong>Purpose</strong>: Displays real-time information about CPU usage, memory usage, and active processes.</li>
<li><strong>Key Features</strong>:
<ul>
<li>Shows the percentage of CPU time spent in user mode (<code class="language-text">%us</code>), system mode (<code class="language-text">%sy</code>), and idle (<code class="language-text">%id</code>).</li>
<li>Highlights processes consuming the most CPU time.</li>
</ul>
</li>
<li><strong>Example</strong>:
<ul>
<li>To sort by CPU usage:
<ul>
<li>Press <code class="language-text">Shift + P</code> in <code class="language-text">top</code>.</li>
</ul>
</li>
<li><strong>Use Case</strong>:
<ul>
<li>Identify CPU-intensive processes causing spikes in utilization.</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h4 id="vmstat" style="position:relative;"><a href="#vmstat" aria-label="vmstat permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong><code class="language-text">vmstat</code></strong></h4>
<ul>
<li><strong>Purpose</strong>: Reports system resource usage, including CPU, memory, and I/O metrics.</li>
<li><strong>Command</strong>:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">vmstat</span> <span class="token number">1</span></code></pre></div>
</li>
<li><strong>Output Example</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs  us  sy  id  wa
2  0      0  10000  2000  25000    0    0     0     0  100  200  40  10  50   0</code></pre></div>
<ul>
<li><code class="language-text">r</code>: Run queue length (threads waiting for CPU time).</li>
<li><code class="language-text">us</code>: User CPU usage.</li>
<li><code class="language-text">sy</code>: System CPU usage.</li>
<li><strong>Interpretation</strong>:
<ul>
<li>A high <code class="language-text">r</code> value relative to the number of cores indicates CPU saturation.</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h4 id="htop" style="position:relative;"><a href="#htop" aria-label="htop permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong><code class="language-text">htop</code></strong></h4>
<ul>
<li><strong>Purpose</strong>: A more user-friendly, interactive version of <code class="language-text">top</code> with additional features.</li>
<li><strong>Features</strong>:
<ul>
<li>Displays CPU usage per core.</li>
<li>Allows filtering and sorting of processes by various metrics.</li>
</ul>
</li>
<li><strong>Use Case</strong>:
<ul>
<li>Monitor CPU utilization across all cores in real time.</li>
</ul>
</li>
</ul>
<hr>
<h3 id="662-advanced-tools" style="position:relative;"><a href="#662-advanced-tools" aria-label="662 advanced tools permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>6.6.2 Advanced Tools</strong></h3>
<h4 id="perf" style="position:relative;"><a href="#perf" aria-label="perf permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong><code class="language-text">perf</code></strong></h4>
<ul>
<li><strong>Purpose</strong>: A powerful Linux tool for performance profiling and event sampling.</li>
<li><strong>Key Features</strong>:
<ul>
<li>Provides detailed metrics like instructions per cycle (IPC), cache misses, and branch mispredictions.</li>
<li>Useful for pinpointing hotspots in applications.</li>
</ul>
</li>
<li><strong>Example</strong>:
<ul>
<li>Measure cache misses and IPC:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">perf <span class="token function">stat</span> <span class="token parameter variable">-e</span> cache-misses,instructions ./app</code></pre></div>
<ul>
<li>Output:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">1,000,000 cache-misses
2,000,000,000 instructions</code></pre></div>
</li>
<li><strong>Interpretation</strong>: A high number of cache misses indicates poor memory locality.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="bpftrace" style="position:relative;"><a href="#bpftrace" aria-label="bpftrace permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong><code class="language-text">bpftrace</code></strong></h4>
<ul>
<li><strong>Purpose</strong>: Uses eBPF (Extended Berkeley Packet Filter) for custom tracing and profiling.</li>
<li><strong>Features</strong>:
<ul>
<li>Real-time CPU profiling using custom one-liners.</li>
</ul>
</li>
<li><strong>Examples</strong>:
<ul>
<li>Trace function calls:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">bpftrace <span class="token parameter variable">-e</span> <span class="token string">'tracepoint:sched:sched_switch { printf("%s -> %s\n", args->prev_comm, args->next_comm); }'</span></code></pre></div>
<ul>
<li>Output: Shows context switches between processes.</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h4 id="turbostat" style="position:relative;"><a href="#turbostat" aria-label="turbostat permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong><code class="language-text">turbostat</code></strong></h4>
<ul>
<li><strong>Purpose</strong>: Monitors CPU frequency, power usage, and thermal metrics.</li>
<li><strong>Use Case</strong>:
<ul>
<li>Analyze CPU performance under varying workloads to identify thermal throttling or frequency scaling issues.</li>
</ul>
</li>
<li><strong>Example</strong>:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">turbostat <span class="token parameter variable">--interval</span> <span class="token number">1</span></code></pre></div>
<ul>
<li>Output includes per-core frequency and power usage.</li>
</ul>
</li>
</ul>
<hr>
<h4 id="cpudist" style="position:relative;"><a href="#cpudist" aria-label="cpudist permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong><code class="language-text">cpudist</code></strong></h4>
<ul>
<li><strong>Purpose</strong>: Measures CPU usage distribution using BCC.</li>
<li><strong>Command</strong>:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">cpudist</code></pre></div>
</li>
<li><strong>Use Case</strong>:
<ul>
<li>Analyze CPU usage distribution across applications to identify outliers.</li>
</ul>
</li>
</ul>
<hr>
<h4 id="runqlat" style="position:relative;"><a href="#runqlat" aria-label="runqlat permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong><code class="language-text">runqlat</code></strong></h4>
<ul>
<li><strong>Purpose</strong>: Measures run queue latency for threads waiting to execute on the CPU.</li>
<li><strong>Command</strong>:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">runqlat <span class="token parameter variable">-m</span></code></pre></div>
<ul>
<li><strong>Output</strong>: Distribution of run queue latencies.</li>
</ul>
</li>
<li><strong>Use Case</strong>:
<ul>
<li>Diagnose delays caused by CPU saturation.</li>
</ul>
</li>
</ul>
<hr>
<h3 id="663-specialized-tools" style="position:relative;"><a href="#663-specialized-tools" aria-label="663 specialized tools permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>6.6.3 Specialized Tools</strong></h3>
<h4 id="flame-graphs" style="position:relative;"><a href="#flame-graphs" aria-label="flame graphs permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Flame Graphs</strong></h4>
<ul>
<li><strong>Purpose</strong>: Visualizes CPU time hierarchically, making it easy to identify hotspots.</li>
<li><strong>Steps</strong>:
<ol>
<li>Capture stack traces using <code class="language-text">perf</code>:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">perf record <span class="token parameter variable">-F</span> <span class="token number">99</span> <span class="token parameter variable">-p</span> <span class="token operator">&lt;</span>pid<span class="token operator">></span></code></pre></div>
</li>
<li>Generate a flame graph:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">perf script <span class="token operator">|</span> stackcollapse-perf.pl <span class="token operator">|</span> flamegraph.pl <span class="token operator">></span> out.svg</code></pre></div>
</li>
</ol>
<ul>
<li><strong>Use Case</strong>:
<ul>
<li>Optimize hotspots consuming the most CPU time.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="heat-maps" style="position:relative;"><a href="#heat-maps" aria-label="heat maps permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Heat Maps</strong></h4>
<ul>
<li><strong>Purpose</strong>: Visualizes CPU usage patterns over time.</li>
<li><strong>Use Case</strong>:
<ul>
<li>Identify temporal patterns, such as spikes in CPU usage during specific workloads.</li>
</ul>
</li>
</ul>
<hr>
<h3 id="664-real-world-examples" style="position:relative;"><a href="#664-real-world-examples" aria-label="664 real world examples permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>6.6.4 Real-World Examples</strong></h3>
<h4 id="example-1-diagnosing-high-cpu-utilization" style="position:relative;"><a href="#example-1-diagnosing-high-cpu-utilization" aria-label="example 1 diagnosing high cpu utilization permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example 1: Diagnosing High CPU Utilization</strong></h4>
<ol>
<li>Use <code class="language-text">htop</code> to identify CPU-bound processes.</li>
<li>Profile the process with <code class="language-text">perf</code>:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">perf record <span class="token parameter variable">-p</span> <span class="token variable"><span class="token variable">$(</span>pidof app<span class="token variable">)</span></span>
perf report</code></pre></div>
</li>
<li>Result: High CPU usage in a string parsing function.</li>
<li>Optimization: Use optimized algorithms to reduce parsing time.</li>
</ol>
<hr>
<h4 id="example-2-investigating-run-queue-delays" style="position:relative;"><a href="#example-2-investigating-run-queue-delays" aria-label="example 2 investigating run queue delays permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example 2: Investigating Run Queue Delays</strong></h4>
<ol>
<li>Use <code class="language-text">vmstat</code> to check run queue length:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">vmstat</span> <span class="token number">1</span></code></pre></div>
<ul>
<li>Finding: Run queue length of 15 on an 8-core CPU indicates contention.</li>
</ul>
</li>
<li>Use <code class="language-text">runqlat</code> to measure latency:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">runqlat <span class="token parameter variable">-m</span></code></pre></div>
<ul>
<li>Result: High latency caused by lock contention.</li>
</ul>
</li>
<li>Optimization: Refactor application to reduce lock contention.</li>
</ol>
<hr>
<h4 id="example-3-analyzing-cache-performance" style="position:relative;"><a href="#example-3-analyzing-cache-performance" aria-label="example 3 analyzing cache performance permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example 3: Analyzing Cache Performance</strong></h4>
<ol>
<li>Use <code class="language-text">perf</code> to measure cache performance:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">perf <span class="token function">stat</span> <span class="token parameter variable">-e</span> cache-references,cache-misses ./app</code></pre></div>
</li>
<li>Findings:
<ul>
<li>High cache misses due to non-sequential memory access.</li>
</ul>
</li>
<li>Optimization:
<ul>
<li>Rewrite data structures to improve cache locality.</li>
</ul>
</li>
</ol>
<hr>
<h3 id="key-takeaways-1" style="position:relative;"><a href="#key-takeaways-1" aria-label="key takeaways 1 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Key Takeaways</strong></h3>
<ul>
<li>Basic tools like <code class="language-text">top</code>, <code class="language-text">vmstat</code>, and <code class="language-text">htop</code> provide quick insights into CPU performance.</li>
<li>Advanced tools like <code class="language-text">perf</code>, <code class="language-text">bpftrace</code>, and <code class="language-text">turbostat</code> allow detailed analysis and profiling.</li>
<li>Visualization tools like Flame Graphs and heat maps help identify hotspots and patterns.</li>
</ul>
<hr>
<p>Here’s an <strong>expanded and detailed explanation of Section 6.7: Visualizations</strong> from Chapter 6, with an in-depth focus on the techniques, tools, examples, and best practices for visualizing CPU performance data. This section aims to provide a thorough understanding of visualization strategies to analyze CPU-related issues effectively.</p>
<hr>
<h2 id="67-visualizations" style="position:relative;"><a href="#67-visualizations" aria-label="67 visualizations permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>6.7 Visualizations</strong></h2>
<p>Visualizing CPU performance metrics is crucial for diagnosing complex performance issues, identifying patterns, and presenting actionable insights. This section explores various visualization methods, tools, and their practical applications.</p>
<hr>
<h3 id="671-heat-maps" style="position:relative;"><a href="#671-heat-maps" aria-label="671 heat maps permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>6.7.1 Heat Maps</strong></h3>
<h4 id="definition" style="position:relative;"><a href="#definition" aria-label="definition permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Definition</strong>:</h4>
<ul>
<li>Heat maps represent CPU activity over time, using colors to indicate the intensity of utilization or other metrics.</li>
<li>Rows typically represent CPU cores, and columns represent time intervals.</li>
</ul>
<h4 id="use-cases" style="position:relative;"><a href="#use-cases" aria-label="use cases permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Use Cases</strong>:</h4>
<ol>
<li><strong>Identify Temporal Patterns</strong>:
<ul>
<li>Detect periodic spikes in CPU usage during specific workloads (e.g., nightly backups).</li>
</ul>
</li>
<li><strong>Spot Core Imbalances</strong>:
<ul>
<li>Highlight cores under heavy load while others are idle, indicating thread affinity issues.</li>
</ul>
</li>
</ol>
<h4 id="tools-1" style="position:relative;"><a href="#tools-1" aria-label="tools 1 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Tools</strong>:</h4>
<ul>
<li>
<p><strong><code class="language-text">perf sched</code></strong>:</p>
<ul>
<li>Generate CPU scheduling heat maps:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">perf sched record
perf sched timehist</code></pre></div>
<ul>
<li>Produces a timeline showing which processes were active on each core.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Visualization Libraries</strong>:</p>
<ul>
<li>Use libraries like Matplotlib in Python for custom heat map generation.</li>
</ul>
</li>
</ul>
<h4 id="example-1" style="position:relative;"><a href="#example-1" aria-label="example 1 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example</strong>:</h4>
<ul>
<li><strong>Scenario</strong>: A cloud-based application exhibits sporadic latency spikes.</li>
<li><strong>Solution</strong>:
<ul>
<li>Use <code class="language-text">perf sched timehist</code> to generate a heat map of CPU activity:
<ul>
<li>Find that spikes correspond to a single core handling excessive threads.</li>
<li>Optimize thread distribution across cores.</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h3 id="672-flame-graphs" style="position:relative;"><a href="#672-flame-graphs" aria-label="672 flame graphs permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>6.7.2 Flame Graphs</strong></h3>
<h4 id="definition-1" style="position:relative;"><a href="#definition-1" aria-label="definition 1 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Definition</strong>:</h4>
<ul>
<li>Flame Graphs are hierarchical visualizations showing CPU time spent in various code paths.</li>
<li>The width of each “flame” represents the amount of CPU time consumed by a function or method.</li>
</ul>
<h4 id="key-features" style="position:relative;"><a href="#key-features" aria-label="key features permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Key Features</strong>:</h4>
<ol>
<li><strong>Hierarchical Representation</strong>:
<ul>
<li>Parent-child relationships between functions are visualized.</li>
</ul>
</li>
<li><strong>Hotspot Identification</strong>:
<ul>
<li>Wide flames indicate functions consuming significant CPU time.</li>
</ul>
</li>
</ol>
<h4 id="steps-to-generate" style="position:relative;"><a href="#steps-to-generate" aria-label="steps to generate permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Steps to Generate</strong>:</h4>
<ol>
<li>Capture stack traces using <code class="language-text">perf</code>:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">perf record <span class="token parameter variable">-F</span> <span class="token number">99</span> <span class="token parameter variable">-p</span> <span class="token operator">&lt;</span>pid<span class="token operator">></span></code></pre></div>
</li>
<li>Convert the traces into a flame graph:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">perf script <span class="token operator">|</span> stackcollapse-perf.pl <span class="token operator">|</span> flamegraph.pl <span class="token operator">></span> flamegraph.svg</code></pre></div>
</li>
</ol>
<h4 id="use-cases-1" style="position:relative;"><a href="#use-cases-1" aria-label="use cases 1 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Use Cases</strong>:</h4>
<ol>
<li><strong>Identify Hotspots</strong>:
<ul>
<li>Locate functions or methods consuming the most CPU time.</li>
</ul>
</li>
<li><strong>Optimize Code Paths</strong>:
<ul>
<li>Prioritize optimizations for the widest flames.</li>
</ul>
</li>
</ol>
<h4 id="example-2" style="position:relative;"><a href="#example-2" aria-label="example 2 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example</strong>:</h4>
<ul>
<li><strong>Scenario</strong>: A web server is CPU-bound, with reduced throughput during high traffic.</li>
<li><strong>Solution</strong>:
<ul>
<li>Generate a Flame Graph:
<ul>
<li>Identify that 50% of CPU time is spent in <code class="language-text">parse_request()</code>.</li>
<li>Optimize the parsing function to reduce CPU usage by 30%.</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h3 id="673-run-queue-latency-graphs" style="position:relative;"><a href="#673-run-queue-latency-graphs" aria-label="673 run queue latency graphs permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>6.7.3 Run Queue Latency Graphs</strong></h3>
<h4 id="definition-2" style="position:relative;"><a href="#definition-2" aria-label="definition 2 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Definition</strong>:</h4>
<ul>
<li>Visualize the time threads spend in the run queue waiting for CPU resources.</li>
</ul>
<h4 id="purpose" style="position:relative;"><a href="#purpose" aria-label="purpose permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Purpose</strong>:</h4>
<ul>
<li>Highlight bottlenecks due to CPU contention or insufficient cores.</li>
</ul>
<h4 id="tools-2" style="position:relative;"><a href="#tools-2" aria-label="tools 2 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Tools</strong>:</h4>
<ul>
<li>
<p><strong><code class="language-text">runqlat</code></strong>:</p>
<ul>
<li>Generates a histogram of run queue latencies.</li>
</ul>
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">runqlat <span class="token parameter variable">-m</span></code></pre></div>
</li>
<li>
<p><strong>Custom Graphing Tools</strong>:</p>
<ul>
<li>Export data to tools like Grafana for advanced visualization.</li>
</ul>
</li>
</ul>
<h4 id="use-cases-2" style="position:relative;"><a href="#use-cases-2" aria-label="use cases 2 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Use Cases</strong>:</h4>
<ol>
<li><strong>Diagnose Scheduling Delays</strong>:
<ul>
<li>High run queue latencies indicate overloaded CPUs.</li>
</ul>
</li>
<li><strong>Evaluate Core Scaling</strong>:
<ul>
<li>Analyze how adding or removing cores affects thread scheduling.</li>
</ul>
</li>
</ol>
<h4 id="example-3" style="position:relative;"><a href="#example-3" aria-label="example 3 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example</strong>:</h4>
<ul>
<li><strong>Scenario</strong>: A real-time video processing application experiences dropped frames.</li>
<li><strong>Solution</strong>:
<ul>
<li>Use <code class="language-text">runqlat</code> to visualize run queue latencies.</li>
<li>Discover delays caused by excessive thread migrations.</li>
<li>Pin threads to specific cores using <code class="language-text">taskset</code>.</li>
</ul>
</li>
</ul>
<hr>
<h3 id="674-gantt-charts-for-cpu-scheduling" style="position:relative;"><a href="#674-gantt-charts-for-cpu-scheduling" aria-label="674 gantt charts for cpu scheduling permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>6.7.4 Gantt Charts for CPU Scheduling</strong></h3>
<h4 id="definition-3" style="position:relative;"><a href="#definition-3" aria-label="definition 3 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Definition</strong>:</h4>
<ul>
<li>Gantt charts visualize CPU scheduling by showing which process or thread occupies a core at specific time intervals.</li>
</ul>
<h4 id="use-cases-3" style="position:relative;"><a href="#use-cases-3" aria-label="use cases 3 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Use Cases</strong>:</h4>
<ol>
<li><strong>Analyze Thread Distribution</strong>:
<ul>
<li>Determine whether threads are evenly distributed across cores.</li>
</ul>
</li>
<li><strong>Identify Idle Time</strong>:
<ul>
<li>Spot periods where cores are underutilized.</li>
</ul>
</li>
</ol>
<h4 id="tools-3" style="position:relative;"><a href="#tools-3" aria-label="tools 3 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Tools</strong>:</h4>
<ul>
<li><strong><code class="language-text">perf sched</code></strong>:
<ul>
<li>Generate Gantt chart-like visualizations:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">perf sched latency</code></pre></div>
</li>
</ul>
</li>
</ul>
<h4 id="example-4" style="position:relative;"><a href="#example-4" aria-label="example 4 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example</strong>:</h4>
<ul>
<li><strong>Scenario</strong>: A parallel computing task has uneven thread performance.</li>
<li><strong>Solution</strong>:
<ul>
<li>Generate a Gantt chart to reveal that some cores are idle due to poor task distribution.</li>
<li>Adjust thread affinity to balance workloads.</li>
</ul>
</li>
</ul>
<hr>
<h3 id="675-histogram-visualizations" style="position:relative;"><a href="#675-histogram-visualizations" aria-label="675 histogram visualizations permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>6.7.5 Histogram Visualizations</strong></h3>
<h4 id="definition-4" style="position:relative;"><a href="#definition-4" aria-label="definition 4 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Definition</strong>:</h4>
<ul>
<li>Histograms display the distribution of specific CPU metrics, such as latency, execution time, or context switches.</li>
</ul>
<h4 id="tools-4" style="position:relative;"><a href="#tools-4" aria-label="tools 4 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Tools</strong>:</h4>
<ul>
<li>
<p><strong><code class="language-text">bpftrace</code></strong>:</p>
<ul>
<li>Create histograms of CPU usage:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">bpftrace <span class="token parameter variable">-e</span> <span class="token string">'kprobe:do_sys_open { @hist[pid] = hist(cpu); }'</span></code></pre></div>
</li>
</ul>
</li>
<li>
<p><strong>Custom Visualization</strong>:</p>
<ul>
<li>Use Python or R to plot histograms based on exported data.</li>
</ul>
</li>
</ul>
<h4 id="example-5" style="position:relative;"><a href="#example-5" aria-label="example 5 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example</strong>:</h4>
<ul>
<li><strong>Scenario</strong>: Investigate CPU cycles spent in system calls.</li>
<li><strong>Solution</strong>:
<ul>
<li>Generate a histogram of syscall latencies using <code class="language-text">bpftrace</code>.</li>
<li>Optimize frequent high-latency syscalls to improve performance.</li>
</ul>
</li>
</ul>
<hr>
<h3 id="676-real-time-dashboards" style="position:relative;"><a href="#676-real-time-dashboards" aria-label="676 real time dashboards permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>6.7.6 Real-Time Dashboards</strong></h3>
<h4 id="definition-5" style="position:relative;"><a href="#definition-5" aria-label="definition 5 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Definition</strong>:</h4>
<ul>
<li>Dashboards aggregate and display CPU metrics in real-time for monitoring.</li>
</ul>
<h4 id="tools-5" style="position:relative;"><a href="#tools-5" aria-label="tools 5 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Tools</strong>:</h4>
<ol>
<li><strong>Grafana</strong>:
<ul>
<li>Visualize metrics from Prometheus, ElasticSearch, or custom exporters.</li>
</ul>
</li>
<li><strong>Custom Tools</strong>:
<ul>
<li>Use libraries like D3.js for interactive dashboards.</li>
</ul>
</li>
</ol>
<h4 id="use-cases-4" style="position:relative;"><a href="#use-cases-4" aria-label="use cases 4 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Use Cases</strong>:</h4>
<ol>
<li><strong>Monitor Production Systems</strong>:
<ul>
<li>Real-time alerts for CPU saturation or runaway processes.</li>
</ul>
</li>
<li><strong>Evaluate Optimization Impact</strong>:
<ul>
<li>Track performance improvements after code changes.</li>
</ul>
</li>
</ol>
<h4 id="example-6" style="position:relative;"><a href="#example-6" aria-label="example 6 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example</strong>:</h4>
<ul>
<li><strong>Scenario</strong>: Monitor a high-frequency trading system for CPU saturation.</li>
<li><strong>Solution</strong>:
<ul>
<li>Use Grafana to display real-time CPU utilization and run queue metrics.</li>
</ul>
</li>
</ul>
<hr>
<h3 id="677-practical-example-end-to-end-visualization-workflow" style="position:relative;"><a href="#677-practical-example-end-to-end-visualization-workflow" aria-label="677 practical example end to end visualization workflow permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>6.7.7 Practical Example: End-to-End Visualization Workflow</strong></h3>
<h4 id="scenario-1" style="position:relative;"><a href="#scenario-1" aria-label="scenario 1 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Scenario</strong>:</h4>
<p>A high-performance e-commerce application shows periodic CPU spikes during peak traffic, causing slow response times.</p>
<h4 id="steps-2" style="position:relative;"><a href="#steps-2" aria-label="steps 2 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Steps</strong>:</h4>
<ol>
<li><strong>Identify Temporal Patterns</strong>:
<ul>
<li>Use <code class="language-text">perf sched timehist</code> to generate a heat map of CPU activity:
<ul>
<li>Find that spikes align with inventory update jobs.</li>
</ul>
</li>
</ul>
</li>
<li><strong>Pinpoint Hotspots</strong>:
<ul>
<li>Generate a Flame Graph for the inventory update job:
<ul>
<li>Identify inefficient SQL query parsing consuming 40% of CPU time.</li>
</ul>
</li>
</ul>
</li>
<li><strong>Analyze Run Queue Delays</strong>:
<ul>
<li>Use <code class="language-text">runqlat</code> to measure thread scheduling delays:
<ul>
<li>Find that high run queue latencies correlate with CPU saturation.</li>
</ul>
</li>
</ul>
</li>
<li><strong>Visualize Results</strong>:
<ul>
<li>Export metrics to Grafana:
<ul>
<li>Create dashboards showing CPU utilization, run queue length, and latency over time.</li>
</ul>
</li>
</ul>
</li>
<li><strong>Optimize</strong>:
<ul>
<li>Refactor SQL query parsing and reduce inventory update frequency.</li>
</ul>
</li>
<li><strong>Evaluate Impact</strong>:
<ul>
<li>Use Flame Graphs and heat maps post-optimization to confirm a 30% reduction in CPU usage.</li>
</ul>
</li>
</ol>
<hr>
<h3 id="key-takeaways-2" style="position:relative;"><a href="#key-takeaways-2" aria-label="key takeaways 2 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Key Takeaways</strong></h3>
<ol>
<li><strong>Heat Maps</strong>: Highlight CPU utilization patterns over time, ideal for spotting imbalances or periodic spikes.</li>
<li><strong>Flame Graphs</strong>: Offer hierarchical insights into where CPU time is spent, making them essential for hotspot analysis.</li>
<li><strong>Run Queue Visualizations</strong>: Help diagnose CPU contention and scheduling delays.</li>
<li><strong>Dashboards</strong>: Provide real-time monitoring and feedback for ongoing performance analysis.</li>
</ol>
<hr>
<h2 id="68-experimentation" style="position:relative;"><a href="#68-experimentation" aria-label="68 experimentation permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>6.8 Experimentation</strong></h2>
<p>Experimentation is a key methodology for validating hypotheses about CPU performance, measuring the effects of optimizations, and ensuring that workloads behave as expected under different conditions. By systematically introducing changes, monitoring outcomes, and analyzing results, we can refine systems for optimal CPU utilization and efficiency.</p>
<hr>
<h3 id="681-objectives-of-experimentation" style="position:relative;"><a href="#681-objectives-of-experimentation" aria-label="681 objectives of experimentation permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>6.8.1 Objectives of Experimentation</strong></h3>
<ol>
<li>
<p><strong>Performance Validation</strong>:</p>
<ul>
<li>Test whether changes (e.g., code optimizations, configuration tweaks) improve CPU performance.</li>
<li>Example: Validate that a new threading model reduces context switches in a multithreaded application.</li>
</ul>
</li>
<li>
<p><strong>Bottleneck Identification</strong>:</p>
<ul>
<li>Stress the system to reveal bottlenecks such as CPU saturation, cache misses, or lock contention.</li>
<li>Example: Use stress tests to identify excessive locking in a database application.</li>
</ul>
</li>
<li>
<p><strong>Workload Characterization</strong>:</p>
<ul>
<li>Measure how the CPU handles different workloads, such as compute-intensive or I/O-bound tasks.</li>
<li>Example: Determine whether a batch processing job is CPU-bound or memory-bound.</li>
</ul>
</li>
<li>
<p><strong>Predictive Analysis</strong>:</p>
<ul>
<li>Simulate future workloads to anticipate scaling needs.</li>
<li>Example: Simulate a 2x increase in user traffic for an e-commerce platform to predict CPU requirements.</li>
</ul>
</li>
</ol>
<hr>
<h3 id="682-types-of-experiments" style="position:relative;"><a href="#682-types-of-experiments" aria-label="682 types of experiments permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>6.8.2 Types of Experiments</strong></h3>
<h4 id="6821-synthetic-workload-testing" style="position:relative;"><a href="#6821-synthetic-workload-testing" aria-label="6821 synthetic workload testing permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>6.8.2.1 Synthetic Workload Testing</strong></h4>
<ul>
<li><strong>Definition</strong>: Use synthetic benchmarks to stress specific aspects of CPU performance.</li>
<li><strong>Tools</strong>:
<ul>
<li><strong><code class="language-text">sysbench</code></strong>: Generates CPU workloads.
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">sysbench cpu <span class="token parameter variable">--threads</span><span class="token operator">=</span><span class="token number">8</span> <span class="token parameter variable">--time</span><span class="token operator">=</span><span class="token number">60</span> run</code></pre></div>
<ul>
<li><strong>Metrics</strong>:
<ul>
<li>Number of events executed.</li>
<li>CPU cycles per event.</li>
</ul>
</li>
</ul>
</li>
<li><strong><code class="language-text">stress-ng</code></strong>: Stress tests CPU cores and other resources.
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">stress-ng <span class="token parameter variable">--cpu</span> <span class="token number">4</span> <span class="token parameter variable">--timeout</span> 60s</code></pre></div>
<ul>
<li><strong>Example Use Case</strong>:
<ul>
<li>Measure how a system handles 100% CPU utilization across all cores for sustained periods.</li>
</ul>
</li>
</ul>
</li>
<li><strong>Custom Scripts</strong>:
<ul>
<li>Write workloads that mimic real-world applications (e.g., matrix multiplications for numerical computing).</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h4 id="6822-real-world-workload-simulation" style="position:relative;"><a href="#6822-real-world-workload-simulation" aria-label="6822 real world workload simulation permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>6.8.2.2 Real-World Workload Simulation</strong></h4>
<ul>
<li><strong>Definition</strong>: Test system behavior using real or representative workloads.</li>
<li><strong>Tools</strong>:
<ul>
<li><strong>Fio</strong>: For simulating disk I/O workloads with CPU involvement.</li>
<li><strong>Custom Benchmarks</strong>:
<ul>
<li>Write application-specific benchmarks to capture actual workload characteristics.</li>
</ul>
</li>
</ul>
</li>
<li><strong>Example</strong>:
<ul>
<li>Simulate an e-commerce platform with:
<ul>
<li>60% CPU usage for web requests.</li>
<li>30% CPU usage for database queries.</li>
<li>10% CPU usage for analytics processing.</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h4 id="6823-scaling-experiments" style="position:relative;"><a href="#6823-scaling-experiments" aria-label="6823 scaling experiments permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>6.8.2.3 Scaling Experiments</strong></h4>
<ul>
<li><strong>Definition</strong>: Evaluate system performance under varying numbers of CPU cores, threads, or workloads.</li>
<li><strong>Use Cases</strong>:
<ul>
<li>Test horizontal scaling by adding cores.</li>
<li>Analyze vertical scaling by increasing CPU frequency or thread counts.</li>
</ul>
</li>
<li><strong>Example</strong>:
<ul>
<li>A database workload initially runs on 4 cores. Gradually increase cores to 8 and 16 while monitoring:
<ul>
<li>Query response times.</li>
<li>CPU utilization per core.</li>
<li>Cache hit rates.</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h3 id="683-methodology-for-experimentation" style="position:relative;"><a href="#683-methodology-for-experimentation" aria-label="683 methodology for experimentation permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>6.8.3 Methodology for Experimentation</strong></h3>
<ol>
<li>
<p><strong>Define Goals</strong>:</p>
<ul>
<li>Determine what you aim to measure (e.g., reduce CPU utilization, improve latency).</li>
<li>Example:
<ul>
<li>Goal: Reduce branch mispredictions in a financial application.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Baseline Measurement</strong>:</p>
<ul>
<li>Collect baseline metrics using tools like <code class="language-text">perf</code>, <code class="language-text">vmstat</code>, or <code class="language-text">htop</code>.</li>
<li>Example:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">perf <span class="token function">stat</span> <span class="token parameter variable">-e</span> branch-misses ./app</code></pre></div>
<ul>
<li>Output:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">50,000 branch-misses</code></pre></div>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Introduce Changes</strong>:</p>
<ul>
<li>Implement one change at a time for isolated impact analysis.</li>
<li>Example:
<ul>
<li>Change the sorting algorithm from <code class="language-text">O(n^2)</code> to <code class="language-text">O(n log n)</code>.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Measure and Compare</strong>:</p>
<ul>
<li>Collect post-change metrics and compare them against the baseline.</li>
<li>Example:
<ul>
<li>After changing the sorting algorithm:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">10,000 branch-misses</code></pre></div>
</li>
<li>Result: 80% reduction in branch mispredictions.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Repeat for Validation</strong>:</p>
<ul>
<li>Run the experiment multiple times to ensure consistent results.</li>
</ul>
</li>
</ol>
<hr>
<h3 id="684-tools-for-experimentation" style="position:relative;"><a href="#684-tools-for-experimentation" aria-label="684 tools for experimentation permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>6.8.4 Tools for Experimentation</strong></h3>
<h4 id="perf-1" style="position:relative;"><a href="#perf-1" aria-label="perf 1 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong><code class="language-text">perf</code></strong></h4>
<ul>
<li><strong>Purpose</strong>: Profile workloads and measure the impact of changes.</li>
<li><strong>Example</strong>:
<ul>
<li>Compare IPC before and after optimization:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">perf <span class="token function">stat</span> <span class="token parameter variable">-e</span> instructions,cycles ./app</code></pre></div>
</li>
</ul>
</li>
</ul>
<h4 id="bpftrace-1" style="position:relative;"><a href="#bpftrace-1" aria-label="bpftrace 1 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong><code class="language-text">bpftrace</code></strong></h4>
<ul>
<li><strong>Purpose</strong>: Create custom one-liners to trace specific CPU events.</li>
<li><strong>Example</strong>:
<ul>
<li>Measure run queue latency:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">bpftrace <span class="token parameter variable">-e</span> <span class="token string">'tracepoint:sched:sched_switch { printf("%s -> %s\n", args->prev_comm, args->next_comm); }'</span></code></pre></div>
</li>
</ul>
</li>
</ul>
<h4 id="stress-ng" style="position:relative;"><a href="#stress-ng" aria-label="stress ng permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong><code class="language-text">stress-ng</code></strong></h4>
<ul>
<li><strong>Purpose</strong>: Apply controlled stress to test system limits.</li>
<li><strong>Example</strong>:
<ul>
<li>Stress 8 CPU cores for 10 minutes:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">stress-ng <span class="token parameter variable">--cpu</span> <span class="token number">8</span> <span class="token parameter variable">--timeout</span> <span class="token number">600</span></code></pre></div>
</li>
</ul>
</li>
</ul>
<h4 id="flame-graphs-1" style="position:relative;"><a href="#flame-graphs-1" aria-label="flame graphs 1 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Flame Graphs</strong></h4>
<ul>
<li><strong>Purpose</strong>: Visualize CPU time distribution across functions.</li>
<li><strong>Example</strong>:
<ul>
<li>Use Flame Graphs to identify hotspots before and after code changes.</li>
</ul>
</li>
</ul>
<hr>
<h3 id="685-practical-examples-of-experimentation" style="position:relative;"><a href="#685-practical-examples-of-experimentation" aria-label="685 practical examples of experimentation permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>6.8.5 Practical Examples of Experimentation</strong></h3>
<h4 id="example-1-optimizing-a-web-server" style="position:relative;"><a href="#example-1-optimizing-a-web-server" aria-label="example 1 optimizing a web server permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example 1: Optimizing a Web Server</strong></h4>
<ol>
<li><strong>Scenario</strong>:
<ul>
<li>High CPU utilization during peak traffic.</li>
</ul>
</li>
<li><strong>Steps</strong>:
<ul>
<li><strong>Baseline</strong>: Measure CPU usage with <code class="language-text">perf</code>.</li>
<li><strong>Experiment</strong>: Enable thread pooling.</li>
<li><strong>Result</strong>:
<ul>
<li>CPU usage reduced by 30%.</li>
<li>Throughput increased by 25%.</li>
</ul>
</li>
</ul>
</li>
</ol>
<h4 id="example-2-numa-performance-tuning" style="position:relative;"><a href="#example-2-numa-performance-tuning" aria-label="example 2 numa performance tuning permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example 2: NUMA Performance Tuning</strong></h4>
<ol>
<li><strong>Scenario</strong>:
<ul>
<li>A database shows inconsistent latency.</li>
</ul>
</li>
<li><strong>Steps</strong>:
<ul>
<li>Test with and without NUMA binding:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">numactl <span class="token parameter variable">--physcpubind</span><span class="token operator">=</span><span class="token number">0</span> <span class="token parameter variable">--membind</span><span class="token operator">=</span><span class="token number">0</span> ./app</code></pre></div>
</li>
<li>Compare memory access times and CPU cycles.</li>
<li><strong>Result</strong>:
<ul>
<li>NUMA-aware binding improved query response times by 20%.</li>
</ul>
</li>
</ul>
</li>
</ol>
<h4 id="example-3-branch-misprediction-mitigation" style="position:relative;"><a href="#example-3-branch-misprediction-mitigation" aria-label="example 3 branch misprediction mitigation permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example 3: Branch Misprediction Mitigation</strong></h4>
<ol>
<li><strong>Scenario</strong>:
<ul>
<li>A Monte Carlo simulation has high branch misprediction rates.</li>
</ul>
</li>
<li><strong>Steps</strong>:
<ul>
<li>Replace conditional branches with lookup tables.</li>
<li><strong>Result</strong>:
<ul>
<li>Branch mispredictions reduced by 40%.</li>
<li>Overall execution time improved by 15%.</li>
</ul>
</li>
</ul>
</li>
</ol>
<hr>
<h3 id="686-best-practices-for-experimentation" style="position:relative;"><a href="#686-best-practices-for-experimentation" aria-label="686 best practices for experimentation permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>6.8.6 Best Practices for Experimentation</strong></h3>
<ol>
<li>
<p><strong>Isolate Variables</strong>:</p>
<ul>
<li>Test one change at a time to understand its impact.</li>
</ul>
</li>
<li>
<p><strong>Use Representative Workloads</strong>:</p>
<ul>
<li>Ensure experiments mimic real-world conditions for accurate results.</li>
</ul>
</li>
<li>
<p><strong>Monitor Side Effects</strong>:</p>
<ul>
<li>Ensure optimizations do not negatively impact other metrics (e.g., reducing CPU utilization but increasing memory usage).</li>
</ul>
</li>
<li>
<p><strong>Automate Tests</strong>:</p>
<ul>
<li>Use scripts to automate benchmarks and data collection.</li>
</ul>
</li>
<li>
<p><strong>Visualize Results</strong>:</p>
<ul>
<li>Use tools like Grafana, Flame Graphs, or Matplotlib to present findings.</li>
</ul>
</li>
</ol>
<hr>
<h3 id="key-takeaways-3" style="position:relative;"><a href="#key-takeaways-3" aria-label="key takeaways 3 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Key Takeaways</strong></h3>
<ul>
<li><strong>Experimentation is a systematic process</strong> for validating and improving CPU performance.</li>
<li><strong>Tools like <code class="language-text">perf</code>, <code class="language-text">stress-ng</code>, and <code class="language-text">bpftrace</code></strong> enable precise measurement and analysis.</li>
<li><strong>Real-world workload simulation</strong> ensures optimizations are effective under practical conditions.</li>
<li><strong>Iterative experimentation</strong> helps refine performance while avoiding regressions.</li>
</ul>
<hr>
<h2 id="69-tuning" style="position:relative;"><a href="#69-tuning" aria-label="69 tuning permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>6.9 Tuning</strong></h2>
<p>CPU tuning involves making adjustments to hardware, software, and system configurations to optimize CPU utilization and performance. Proper tuning ensures that CPU resources are efficiently allocated and workloads run without unnecessary delays or contention.</p>
<hr>
<h3 id="691-objectives-of-cpu-tuning" style="position:relative;"><a href="#691-objectives-of-cpu-tuning" aria-label="691 objectives of cpu tuning permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>6.9.1 Objectives of CPU Tuning</strong></h3>
<ol>
<li>
<p><strong>Maximize Utilization</strong>:</p>
<ul>
<li>Ensure that all CPU cores are being used effectively without overloading.</li>
<li>Example: Redistributing workloads to avoid idle cores.</li>
</ul>
</li>
<li>
<p><strong>Minimize Latency</strong>:</p>
<ul>
<li>Reduce delays caused by CPU contention, memory access, or inefficient scheduling.</li>
<li>Example: Pinning real-time threads to specific cores for predictable execution.</li>
</ul>
</li>
<li>
<p><strong>Balance Power Efficiency</strong>:</p>
<ul>
<li>Optimize CPU power consumption without compromising performance.</li>
<li>Example: Configuring CPUs to switch between performance and power-saving modes dynamically.</li>
</ul>
</li>
<li>
<p><strong>Improve Throughput</strong>:</p>
<ul>
<li>Increase the number of tasks a system can process over a given time.</li>
<li>Example: Optimizing threading models to reduce synchronization overhead.</li>
</ul>
</li>
</ol>
<hr>
<h3 id="692-tuning-techniques" style="position:relative;"><a href="#692-tuning-techniques" aria-label="692 tuning techniques permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>6.9.2 Tuning Techniques</strong></h3>
<h4 id="6921-compiler-optimizations" style="position:relative;"><a href="#6921-compiler-optimizations" aria-label="6921 compiler optimizations permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>6.9.2.1 Compiler Optimizations</strong></h4>
<ul>
<li><strong>Purpose</strong>:
<ul>
<li>Utilize CPU-specific instructions and optimize code generation.</li>
</ul>
</li>
<li><strong>Techniques</strong>:
<ol>
<li><strong>Instruction Set Optimization</strong>:
<ul>
<li>Use <code class="language-text">-march=native</code> to enable CPU-specific features (e.g., AVX, SSE):
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">gcc <span class="token parameter variable">-O2</span> <span class="token parameter variable">-march</span><span class="token operator">=</span>native <span class="token parameter variable">-o</span> app app.c</code></pre></div>
</li>
</ul>
</li>
<li><strong>Optimization Levels</strong>:
<ul>
<li>Use <code class="language-text">-O2</code> or <code class="language-text">-O3</code> for aggressive optimization:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">gcc <span class="token parameter variable">-O3</span> <span class="token parameter variable">-o</span> app app.c</code></pre></div>
</li>
</ul>
</li>
<li><strong>Vectorization</strong>:
<ul>
<li>Use SIMD instructions to process multiple data elements in parallel.</li>
</ul>
</li>
</ol>
</li>
<li><strong>Example</strong>:
<ul>
<li>A matrix multiplication program sees a 2x speedup when compiled with AVX-enabled vectorization.</li>
</ul>
</li>
</ul>
<hr>
<h4 id="6922-numa-non-uniform-memory-access-optimization" style="position:relative;"><a href="#6922-numa-non-uniform-memory-access-optimization" aria-label="6922 numa non uniform memory access optimization permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>6.9.2.2 NUMA (Non-Uniform Memory Access) Optimization</strong></h4>
<ul>
<li><strong>Purpose</strong>:
<ul>
<li>Reduce memory access latency by ensuring threads access memory local to their NUMA nodes.</li>
</ul>
</li>
<li><strong>Techniques</strong>:
<ol>
<li><strong>Thread Affinity</strong>:
<ul>
<li>Bind threads to specific NUMA nodes using <code class="language-text">numactl</code>:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">numactl <span class="token parameter variable">--physcpubind</span><span class="token operator">=</span><span class="token number">0</span> <span class="token parameter variable">--membind</span><span class="token operator">=</span><span class="token number">0</span> ./app</code></pre></div>
</li>
</ul>
</li>
<li><strong>NUMA Awareness in Applications</strong>:
<ul>
<li>Modify applications to allocate memory on local NUMA nodes.</li>
</ul>
</li>
</ol>
</li>
<li><strong>Example</strong>:
<ul>
<li>A database application improves query performance by 30% after ensuring NUMA-local memory allocation.</li>
</ul>
</li>
</ul>
<hr>
<h4 id="6923-thread-and-process-affinity" style="position:relative;"><a href="#6923-thread-and-process-affinity" aria-label="6923 thread and process affinity permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>6.9.2.3 Thread and Process Affinity</strong></h4>
<ul>
<li><strong>Purpose</strong>:
<ul>
<li>Pin threads or processes to specific cores to reduce context switching and improve cache locality.</li>
</ul>
</li>
<li><strong>Tools</strong>:
<ul>
<li>Use <code class="language-text">taskset</code> to set CPU affinity:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">taskset <span class="token parameter variable">-c</span> <span class="token number">0</span>-3 ./app</code></pre></div>
</li>
<li>Use <code class="language-text">chrt</code> for real-time thread prioritization:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">chrt <span class="token parameter variable">-f</span> <span class="token number">99</span> ./app</code></pre></div>
</li>
</ul>
</li>
<li><strong>Example</strong>:
<ul>
<li>A real-time audio processing application reduces jitter by pinning threads to dedicated cores.</li>
</ul>
</li>
</ul>
<hr>
<h4 id="6924-scaling-governors" style="position:relative;"><a href="#6924-scaling-governors" aria-label="6924 scaling governors permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>6.9.2.4 Scaling Governors</strong></h4>
<ul>
<li><strong>Purpose</strong>:
<ul>
<li>Adjust CPU frequency dynamically to balance performance and power consumption.</li>
</ul>
</li>
<li><strong>Techniques</strong>:
<ol>
<li><strong>Performance Governor</strong>:
<ul>
<li>Keeps CPU frequency at maximum for low-latency workloads.
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">cpupower frequency-set <span class="token parameter variable">--governor</span> performance</code></pre></div>
</li>
</ul>
</li>
<li><strong>Powersave Governor</strong>:
<ul>
<li>Reduces frequency for power efficiency.
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">cpupower frequency-set <span class="token parameter variable">--governor</span> powersave</code></pre></div>
</li>
</ul>
</li>
<li><strong>Custom Governors</strong>:
<ul>
<li>Configure thresholds for dynamic frequency scaling.</li>
</ul>
</li>
</ol>
</li>
<li><strong>Example</strong>:
<ul>
<li>A high-frequency trading system uses the <code class="language-text">performance</code> governor to minimize latency, while background processing jobs use <code class="language-text">powersave</code>.</li>
</ul>
</li>
</ul>
<hr>
<h4 id="6925-cache-optimization" style="position:relative;"><a href="#6925-cache-optimization" aria-label="6925 cache optimization permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>6.9.2.5 Cache Optimization</strong></h4>
<ul>
<li><strong>Purpose</strong>:
<ul>
<li>Minimize cache misses by optimizing memory access patterns.</li>
</ul>
</li>
<li><strong>Techniques</strong>:
<ol>
<li><strong>Data Alignment</strong>:
<ul>
<li>Align data structures to cache line boundaries.</li>
</ul>
</li>
<li><strong>Prefetching</strong>:
<ul>
<li>Use software prefetch instructions to load data into the cache before it’s needed.</li>
</ul>
</li>
<li><strong>Sequential Access</strong>:
<ul>
<li>Access memory sequentially to improve cache locality.</li>
</ul>
</li>
</ol>
</li>
<li><strong>Example</strong>:
<ul>
<li>A neural network training application improves performance by 40% after optimizing matrix access patterns to reduce L3 cache misses.</li>
</ul>
</li>
</ul>
<hr>
<h4 id="6926-multithreading-and-parallelization" style="position:relative;"><a href="#6926-multithreading-and-parallelization" aria-label="6926 multithreading and parallelization permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>6.9.2.6 Multithreading and Parallelization</strong></h4>
<ul>
<li><strong>Purpose</strong>:
<ul>
<li>Fully utilize all CPU cores by parallelizing workloads.</li>
</ul>
</li>
<li><strong>Techniques</strong>:
<ol>
<li><strong>Thread Pooling</strong>:
<ul>
<li>Use thread pools to manage concurrent tasks efficiently.</li>
</ul>
</li>
<li><strong>Lock-Free Algorithms</strong>:
<ul>
<li>Replace mutexes with atomic operations to reduce contention.</li>
</ul>
</li>
</ol>
</li>
<li><strong>Example</strong>:
<ul>
<li>A multithreaded simulation achieves a 5x speedup on an 8-core system by using lock-free queues.</li>
</ul>
</li>
</ul>
<hr>
<h4 id="6927-interrupt-handling" style="position:relative;"><a href="#6927-interrupt-handling" aria-label="6927 interrupt handling permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>6.9.2.7 Interrupt Handling</strong></h4>
<ul>
<li><strong>Purpose</strong>:
<ul>
<li>Reduce overhead from frequent interrupts by redistributing IRQs (Interrupt Requests).</li>
</ul>
</li>
<li><strong>Tools</strong>:
<ul>
<li>Use <code class="language-text">irqbalance</code> to distribute interrupts across cores.</li>
<li>Manually pin interrupts:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token builtin class-name">echo</span> <span class="token number">1</span> <span class="token operator">></span> /proc/irq/XX/smp_affinity</code></pre></div>
</li>
</ul>
</li>
<li><strong>Example</strong>:
<ul>
<li>A network-intensive application improves throughput by redistributing network interrupts to reduce contention on core 0.</li>
</ul>
</li>
</ul>
<hr>
<h3 id="693-tools-for-cpu-tuning" style="position:relative;"><a href="#693-tools-for-cpu-tuning" aria-label="693 tools for cpu tuning permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>6.9.3 Tools for CPU Tuning</strong></h3>
<h4 id="1-perf" style="position:relative;"><a href="#1-perf" aria-label="1 perf permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>1. <code class="language-text">perf</code></strong></h4>
<ul>
<li><strong>Purpose</strong>:
<ul>
<li>Profile workloads and identify hotspots.</li>
</ul>
</li>
<li><strong>Example</strong>:
<ul>
<li>Analyze cache misses and IPC:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">perf <span class="token function">stat</span> <span class="token parameter variable">-e</span> cache-misses,instructions ./app</code></pre></div>
</li>
</ul>
</li>
</ul>
<h4 id="2-numactl" style="position:relative;"><a href="#2-numactl" aria-label="2 numactl permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>2. <code class="language-text">numactl</code></strong></h4>
<ul>
<li><strong>Purpose</strong>:
<ul>
<li>Bind processes to specific NUMA nodes.</li>
</ul>
</li>
<li><strong>Example</strong>:
<ul>
<li>Improve memory access times by ensuring local memory usage:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">numactl <span class="token parameter variable">--membind</span><span class="token operator">=</span><span class="token number">0</span> ./app</code></pre></div>
</li>
</ul>
</li>
</ul>
<h4 id="3-cpupower" style="position:relative;"><a href="#3-cpupower" aria-label="3 cpupower permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>3. <code class="language-text">cpupower</code></strong></h4>
<ul>
<li><strong>Purpose</strong>:
<ul>
<li>Configure CPU frequency governors.</li>
</ul>
</li>
<li><strong>Example</strong>:
<ul>
<li>Switch to the performance governor:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">cpupower frequency-set <span class="token parameter variable">--governor</span> performance</code></pre></div>
</li>
</ul>
</li>
</ul>
<h4 id="4-taskset" style="position:relative;"><a href="#4-taskset" aria-label="4 taskset permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>4. <code class="language-text">taskset</code></strong></h4>
<ul>
<li><strong>Purpose</strong>:
<ul>
<li>Set CPU affinity for processes.</li>
</ul>
</li>
<li><strong>Example</strong>:
<ul>
<li>Pin a process to cores 0 and 1:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">taskset <span class="token parameter variable">-c</span> <span class="token number">0</span>-1 ./app</code></pre></div>
</li>
</ul>
</li>
</ul>
<h4 id="5-chrt" style="position:relative;"><a href="#5-chrt" aria-label="5 chrt permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>5. <code class="language-text">chrt</code></strong></h4>
<ul>
<li><strong>Purpose</strong>:
<ul>
<li>Set real-time priorities for threads.</li>
</ul>
</li>
<li><strong>Example</strong>:
<ul>
<li>Run a thread with high priority:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">chrt <span class="token parameter variable">-f</span> <span class="token number">99</span> ./app</code></pre></div>
</li>
</ul>
</li>
</ul>
<hr>
<h3 id="694-real-world-examples" style="position:relative;"><a href="#694-real-world-examples" aria-label="694 real world examples permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>6.9.4 Real-World Examples</strong></h3>
<h4 id="example-1-optimizing-a-web-server-1" style="position:relative;"><a href="#example-1-optimizing-a-web-server-1" aria-label="example 1 optimizing a web server 1 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example 1: Optimizing a Web Server</strong></h4>
<ol>
<li><strong>Scenario</strong>:
<ul>
<li>A web server exhibits high CPU usage and uneven core utilization.</li>
</ul>
</li>
<li><strong>Solution</strong>:
<ul>
<li>Pin the web server process to cores 2–5 using <code class="language-text">taskset</code>.</li>
<li>Enable the performance governor to reduce latency.</li>
</ul>
</li>
</ol>
<h4 id="example-2-numa-optimization-in-a-database" style="position:relative;"><a href="#example-2-numa-optimization-in-a-database" aria-label="example 2 numa optimization in a database permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example 2: NUMA Optimization in a Database</strong></h4>
<ol>
<li><strong>Scenario</strong>:
<ul>
<li>A database workload shows inconsistent query response times.</li>
</ul>
</li>
<li><strong>Solution</strong>:
<ul>
<li>Use <code class="language-text">numactl</code> to bind the database process to a NUMA node.</li>
<li>Allocate memory on the local NUMA node.</li>
</ul>
</li>
</ol>
<h4 id="example-3-reducing-cache-misses-in-machine-learning" style="position:relative;"><a href="#example-3-reducing-cache-misses-in-machine-learning" aria-label="example 3 reducing cache misses in machine learning permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example 3: Reducing Cache Misses in Machine Learning</strong></h4>
<ol>
<li><strong>Scenario</strong>:
<ul>
<li>A machine learning model experiences slow training due to cache inefficiency.</li>
</ul>
</li>
<li><strong>Solution</strong>:
<ul>
<li>Optimize data structures to align with cache line boundaries.</li>
<li>Prefetch input data into the cache.</li>
</ul>
</li>
</ol>
<hr>
<h3 id="key-takeaways-4" style="position:relative;"><a href="#key-takeaways-4" aria-label="key takeaways 4 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Key Takeaways</strong></h3>
<ol>
<li><strong>CPU tuning is iterative</strong>: Apply one change at a time and measure its impact.</li>
<li><strong>Tools like <code class="language-text">perf</code>, <code class="language-text">numactl</code>, and <code class="language-text">cpupower</code></strong> enable fine-grained control over CPU performance.</li>
<li><strong>Focus on NUMA optimization, cache efficiency, and thread affinity</strong> for substantial gains.</li>
</ol>
<hr>
<h3 id="610-exercises" style="position:relative;"><a href="#610-exercises" aria-label="610 exercises permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>6.10 Exercises</strong></h3>
<p>Practical tasks for learning and applying CPU performance analysis:</p>
<ol>
<li>
<p><strong>Profile with <code class="language-text">perf</code></strong>:</p>
<ul>
<li>Measure IPC and CPI for a workload and identify bottlenecks.</li>
</ul>
</li>
<li>
<p><strong>Experiment with NUMA</strong>:</p>
<ul>
<li>Compare performance with and without NUMA binding.</li>
</ul>
</li>
<li>
<p><strong>Generate Flame Graphs</strong>:</p>
<ul>
<li>Visualize CPU usage for a complex application using <code class="language-text">perf</code> and FlameGraph tools.</li>
</ul>
</li>
<li>
<p><strong>Adjust Governors</strong>:</p>
<ul>
<li>Test the impact of <code class="language-text">performance</code> vs. <code class="language-text">powersave</code> governors on batch processing tasks.</li>
</ul>
</li>
</ol>
<hr>
<h3 id="key-takeaways-5" style="position:relative;"><a href="#key-takeaways-5" aria-label="key takeaways 5 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Key Takeaways</strong></h3>
<ul>
<li><strong>Understanding CPU architecture and metrics is critical for diagnosing performance bottlenecks.</strong></li>
<li><strong>Profiling tools like <code class="language-text">perf</code> and <code class="language-text">bpftrace</code> provide deep insights into CPU usage.</strong></li>
<li><strong>Tuning techniques, such as NUMA optimization and affinity adjustments, can significantly enhance performance.</strong></li>
</ul>
<p>To provide a detailed expansion of <strong>Chapter 7: Memory</strong>, I will outline and elaborate on each section, focusing on the key concepts, methodologies, tools, and techniques involved in memory performance analysis and optimization. This will also include practical examples and bold-highlighted quotes/phrases for emphasis.</p>
<hr>
<h1 id="chapter-7-memory" style="position:relative;"><a href="#chapter-7-memory" aria-label="chapter 7 memory permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Chapter 7: Memory</strong></h1>
<p>Memory is a critical component of system performance. This chapter delves into memory management, addressing its architecture, utilization, and tuning methodologies.</p>
<hr>
<h2 id="71-terminology" style="position:relative;"><a href="#71-terminology" aria-label="71 terminology permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>7.1 Terminology</strong></h2>
<h3 id="key-terms-in-memory-management" style="position:relative;"><a href="#key-terms-in-memory-management" aria-label="key terms in memory management permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Key Terms in Memory Management</strong>:</h3>
<ol>
<li><strong>Virtual Memory</strong>:
<ul>
<li>A memory management technique providing applications with the illusion of large, contiguous memory.</li>
<li>Example: A process allocated 2GB of virtual memory may only use 500MB of physical memory at a given time.</li>
</ul>
</li>
<li><strong>Paging</strong>:
<ul>
<li>Dividing memory into fixed-size blocks (pages) to manage allocation.</li>
<li><strong>Highlight</strong>: “Paging enables the OS to load only necessary portions of a program into memory, reducing physical memory demands.”</li>
</ul>
</li>
<li><strong>Swapping</strong>:
<ul>
<li>Moving inactive pages from physical memory to disk when memory is scarce.</li>
</ul>
</li>
<li><strong>Working Set Size (WSS)</strong>:
<ul>
<li>The subset of memory pages actively used by a process over time.</li>
<li><strong>Highlight</strong>: “Optimizing WSS reduces the risk of excessive paging or thrashing.”</li>
</ul>
</li>
</ol>
<hr>
<h2 id="72-concepts" style="position:relative;"><a href="#72-concepts" aria-label="72 concepts permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>7.2 Concepts</strong></h2>
<h3 id="721-virtual-memory" style="position:relative;"><a href="#721-virtual-memory" aria-label="721 virtual memory permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>7.2.1 Virtual Memory</strong></h3>
<ul>
<li>Virtual memory separates logical memory from physical memory, enabling processes to use more memory than physically available.</li>
<li><strong>Example</strong>: A system with 16GB RAM might support 64-bit virtual memory spaces, allowing larger datasets.</li>
</ul>
<h3 id="722-paging-and-demand-paging" style="position:relative;"><a href="#722-paging-and-demand-paging" aria-label="722 paging and demand paging permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>7.2.2 Paging and Demand Paging</strong></h3>
<ul>
<li><strong>Paging</strong>: Transfers fixed-size memory blocks between RAM and disk.</li>
<li><strong>Demand Paging</strong>: Loads pages into memory only when required.</li>
<li><strong>Example</strong>:
<ul>
<li>A program requests memory for a new array. The system allocates virtual memory but only loads pages into RAM when accessed.</li>
</ul>
</li>
</ul>
<h3 id="723-overcommit" style="position:relative;"><a href="#723-overcommit" aria-label="723 overcommit permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>7.2.3 Overcommit</strong></h3>
<ul>
<li><strong>Definition</strong>: Allocating more virtual memory than physical memory.</li>
<li><strong>Example</strong>:
<ul>
<li>Overcommit is beneficial for idle workloads but risks memory exhaustion during peak loads.</li>
</ul>
</li>
</ul>
<h3 id="724-file-system-cache-usage" style="position:relative;"><a href="#724-file-system-cache-usage" aria-label="724 file system cache usage permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>7.2.4 File System Cache Usage</strong></h3>
<ul>
<li><strong>Highlight</strong>: “Unused memory is wasted memory; file system caches use free RAM to improve I/O performance.”</li>
<li>Tools like <code class="language-text">free</code> and <code class="language-text">vmstat</code> display cache usage.</li>
</ul>
<h3 id="725-allocators-and-shared-memory" style="position:relative;"><a href="#725-allocators-and-shared-memory" aria-label="725 allocators and shared memory permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>7.2.5 Allocators and Shared Memory</strong></h3>
<ul>
<li>Allocators like <code class="language-text">malloc</code> and <code class="language-text">free</code> manage memory for applications.</li>
<li>Shared memory segments enable processes to share data efficiently.</li>
<li><strong>Example</strong>: A web server using shared memory reduces inter-process communication overhead.</li>
</ul>
<hr>
<h2 id="73-architecture" style="position:relative;"><a href="#73-architecture" aria-label="73 architecture permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>7.3 Architecture</strong></h2>
<h3 id="731-hardware" style="position:relative;"><a href="#731-hardware" aria-label="731 hardware permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>7.3.1 Hardware</strong></h3>
<ul>
<li>Memory is organized into levels of caches (L1, L2, L3) and DRAM.</li>
<li><strong>Example</strong>: Modern CPUs use multi-level caches to minimize latency.</li>
</ul>
<h3 id="732-software" style="position:relative;"><a href="#732-software" aria-label="732 software permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>7.3.2 Software</strong></h3>
<ul>
<li>Software memory management includes kernel-space structures like page tables.</li>
<li><strong>Highlight</strong>: “Efficient page table management is critical for reducing TLB (Translation Lookaside Buffer) misses.”</li>
</ul>
<hr>
<p>Here’s an <strong>expanded and detailed explanation of Section 7.4: Methodology</strong>, focusing on strategies for memory performance analysis, tools, techniques, and real-world examples. This section provides a step-by-step approach to understanding and optimizing memory usage.</p>
<hr>
<h2 id="74-methodology" style="position:relative;"><a href="#74-methodology" aria-label="74 methodology permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>7.4 Methodology</strong></h2>
<p>Memory performance analysis requires a structured approach to identify bottlenecks, inefficiencies, and areas for optimization. This methodology involves monitoring memory usage, diagnosing problems, and applying targeted solutions.</p>
<hr>
<h3 id="741-steps-for-memory-performance-analysis" style="position:relative;"><a href="#741-steps-for-memory-performance-analysis" aria-label="741 steps for memory performance analysis permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>7.4.1 Steps for Memory Performance Analysis</strong></h3>
<h4 id="step-1-characterize-memory-usage" style="position:relative;"><a href="#step-1-characterize-memory-usage" aria-label="step 1 characterize memory usage permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Step 1: Characterize Memory Usage</strong></h4>
<h5 id="understanding-process-level-memory" style="position:relative;"><a href="#understanding-process-level-memory" aria-label="understanding process level memory permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Understanding Process-Level Memory</strong></h5>
<ul>
<li>
<p><strong>Tools</strong>:</p>
<ul>
<li><strong><code class="language-text">pmap</code></strong>: Displays memory maps for a process.
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">pmap <span class="token parameter variable">-x</span> <span class="token operator">&lt;</span>pid<span class="token operator">></span></code></pre></div>
<ul>
<li><strong>Columns</strong>:
<ul>
<li>Size: Total memory mapped.</li>
<li>RSS (Resident Set Size): Physical memory used.</li>
<li>Shared/Private: Indicates shared and private memory mappings.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Example</strong>:</p>
<ul>
<li>Analyzing a memory-intensive process:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">pmap <span class="token parameter variable">-x</span> <span class="token number">1234</span></code></pre></div>
<ul>
<li>Output:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">Address           Kbytes     RSS    Dirty   Mode
0000000000400000   2048     1024     512    r-xp</code></pre></div>
</li>
<li><strong>Interpretation</strong>:
<ul>
<li>High RSS indicates significant physical memory use.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h5 id="monitoring-overall-system-memory" style="position:relative;"><a href="#monitoring-overall-system-memory" aria-label="monitoring overall system memory permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Monitoring Overall System Memory</strong></h5>
<ul>
<li><strong>Tools</strong>:
<ul>
<li><strong><code class="language-text">free</code></strong>:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">free</span> <span class="token parameter variable">-h</span></code></pre></div>
<ul>
<li>Shows total memory, used memory, buffers, and cache.</li>
</ul>
</li>
<li><strong><code class="language-text">vmstat</code></strong>:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">vmstat</span> <span class="token number">1</span></code></pre></div>
<ul>
<li>Provides ongoing memory usage statistics, including swapping activity.</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h4 id="step-2-detect-memory-leaks" style="position:relative;"><a href="#step-2-detect-memory-leaks" aria-label="step 2 detect memory leaks permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Step 2: Detect Memory Leaks</strong></h4>
<h5 id="definition-6" style="position:relative;"><a href="#definition-6" aria-label="definition 6 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Definition</strong>:</h5>
<ul>
<li>A memory leak occurs when allocated memory is not released after use, leading to gradual resource exhaustion.</li>
</ul>
<h5 id="tools-6" style="position:relative;"><a href="#tools-6" aria-label="tools 6 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Tools</strong>:</h5>
<ol>
<li>
<p><strong><code class="language-text">valgrind</code></strong>:</p>
<ul>
<li>Detects memory leaks and invalid memory accesses:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">valgrind --leak-check<span class="token operator">=</span>full ./app</code></pre></div>
</li>
<li>Example Output:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">==1234== 100 bytes in 5 blocks are definitely lost in loss record 1 of 1</code></pre></div>
</li>
</ul>
</li>
<li>
<p><strong>AddressSanitizer (ASan)</strong>:</p>
<ul>
<li>Compile the application with ASan to detect leaks:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">gcc <span class="token parameter variable">-fsanitize</span><span class="token operator">=</span>address <span class="token parameter variable">-g</span> <span class="token parameter variable">-o</span> app app.c
./app</code></pre></div>
</li>
<li>Output pinpoints memory issues during runtime.</li>
</ul>
</li>
</ol>
<h5 id="example-7" style="position:relative;"><a href="#example-7" aria-label="example 7 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example</strong>:</h5>
<ul>
<li>A Python web application exhibits increasing memory usage over time.</li>
<li><strong>Solution</strong>:
<ul>
<li>Use a memory profiler like <code class="language-text">objgraph</code> to trace object retention.</li>
</ul>
</li>
</ul>
<hr>
<h4 id="step-3-analyze-cache-and-swap-activity" style="position:relative;"><a href="#step-3-analyze-cache-and-swap-activity" aria-label="step 3 analyze cache and swap activity permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Step 3: Analyze Cache and Swap Activity</strong></h4>
<h5 id="cache-analysis" style="position:relative;"><a href="#cache-analysis" aria-label="cache analysis permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Cache Analysis</strong></h5>
<ul>
<li><strong>Definition</strong>: Caches store frequently accessed data to reduce latency.</li>
<li><strong>Tools</strong>:
<ul>
<li><strong><code class="language-text">sar -r</code></strong>:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">sar <span class="token parameter variable">-r</span> <span class="token number">1</span> <span class="token number">10</span></code></pre></div>
<ul>
<li>Reports memory and cache usage over time.</li>
</ul>
</li>
<li><strong>Custom Analysis</strong>:
<ul>
<li>Use Python or R to analyze memory and cache metrics collected via tools like <code class="language-text">psutil</code>.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h5 id="swap-activity" style="position:relative;"><a href="#swap-activity" aria-label="swap activity permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Swap Activity</strong></h5>
<ul>
<li><strong>Definition</strong>: Swapping moves inactive memory pages to disk when RAM is full, but excessive swapping causes performance degradation.</li>
<li><strong>Tools</strong>:
<ul>
<li><strong><code class="language-text">vmstat</code></strong>:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">vmstat</span> <span class="token number">1</span></code></pre></div>
<ul>
<li>Monitors swap in (<code class="language-text">si</code>) and swap out (<code class="language-text">so</code>) activity.</li>
</ul>
</li>
<li><strong><code class="language-text">sar</code></strong>:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">sar <span class="token parameter variable">-W</span> <span class="token number">1</span> <span class="token number">10</span></code></pre></div>
<ul>
<li>Tracks swap performance and paging rates.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h5 id="example-8" style="position:relative;"><a href="#example-8" aria-label="example 8 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example</strong>:</h5>
<ul>
<li>Scenario: A database shows high latency.</li>
<li>Analysis:
<ul>
<li><code class="language-text">vmstat</code> reveals significant swapping (<code class="language-text">si</code> > 500 KB/s).</li>
</ul>
</li>
<li>Solution:
<ul>
<li>Increase RAM or reduce memory consumption by optimizing queries.</li>
</ul>
</li>
</ul>
<hr>
<h4 id="step-4-monitor-application-specific-memory-usage" style="position:relative;"><a href="#step-4-monitor-application-specific-memory-usage" aria-label="step 4 monitor application specific memory usage permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Step 4: Monitor Application-Specific Memory Usage</strong></h4>
<h5 id="tools-7" style="position:relative;"><a href="#tools-7" aria-label="tools 7 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Tools</strong>:</h5>
<ol>
<li>
<p><strong>Application Profilers</strong>:</p>
<ul>
<li>For Java applications, use <strong>JVisualVM</strong> or <strong>Eclipse MAT</strong> to analyze heap usage.</li>
<li>For Python applications, use <code class="language-text">memory_profiler</code>:
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">from</span> memory_profiler <span class="token keyword">import</span> profile

<span class="token decorator annotation punctuation">@profile</span>
<span class="token keyword">def</span> <span class="token function">my_function</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    a <span class="token operator">=</span> <span class="token punctuation">[</span>i <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">100000</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
my_function<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre></div>
</li>
</ul>
</li>
<li>
<p><strong>Trace Memory Allocations</strong>:</p>
<ul>
<li><strong><code class="language-text">bpftrace</code></strong>:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">bpftrace <span class="token parameter variable">-e</span> <span class="token string">'tracepoint:kmem:kmalloc { printf("%d bytes allocated\n", args->bytes_allocated); }'</span></code></pre></div>
</li>
</ul>
</li>
</ol>
<h5 id="example-9" style="position:relative;"><a href="#example-9" aria-label="example 9 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example</strong>:</h5>
<ul>
<li>A machine learning model consumes excessive memory during training.</li>
<li>Solution:
<ul>
<li>Use <code class="language-text">memory_profiler</code> to identify memory spikes in data preprocessing functions.</li>
</ul>
</li>
</ul>
<hr>
<h4 id="step-5-detect-inefficient-memory-access-patterns" style="position:relative;"><a href="#step-5-detect-inefficient-memory-access-patterns" aria-label="step 5 detect inefficient memory access patterns permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Step 5: Detect Inefficient Memory Access Patterns</strong></h4>
<h5 id="definition-7" style="position:relative;"><a href="#definition-7" aria-label="definition 7 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Definition</strong>:</h5>
<ul>
<li>Poor memory access patterns, such as random access, increase cache misses and reduce performance.</li>
</ul>
<h5 id="tools-8" style="position:relative;"><a href="#tools-8" aria-label="tools 8 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Tools</strong>:</h5>
<ol>
<li>
<p><strong><code class="language-text">perf</code></strong>:</p>
<ul>
<li>Analyze cache misses:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">perf <span class="token function">stat</span> <span class="token parameter variable">-e</span> cache-references,cache-misses ./app</code></pre></div>
<ul>
<li>Example Output:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">1,000,000 cache-references
500,000 cache-misses</code></pre></div>
<ul>
<li><strong>Interpretation</strong>: 50% miss rate indicates inefficient memory access.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Custom Tools</strong>:</p>
<ul>
<li>Use BCC tools like <code class="language-text">cachestat</code> for cache hit/miss ratio.</li>
</ul>
</li>
</ol>
<h5 id="example-10" style="position:relative;"><a href="#example-10" aria-label="example 10 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example</strong>:</h5>
<ul>
<li>A scientific application shows slow performance due to random memory access.</li>
<li>Solution:
<ul>
<li>Refactor data structures to use sequential memory access.</li>
</ul>
</li>
</ul>
<hr>
<h4 id="step-6-tune-memory-usage" style="position:relative;"><a href="#step-6-tune-memory-usage" aria-label="step 6 tune memory usage permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Step 6: Tune Memory Usage</strong></h4>
<h5 id="tuning-swappiness" style="position:relative;"><a href="#tuning-swappiness" aria-label="tuning swappiness permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Tuning Swappiness</strong></h5>
<ul>
<li>Adjust the system’s tendency to swap:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">sysctl</span> <span class="token assign-left variable">vm.swappiness</span><span class="token operator">=</span><span class="token number">10</span></code></pre></div>
</li>
</ul>
<h5 id="use-huge-pages" style="position:relative;"><a href="#use-huge-pages" aria-label="use huge pages permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Use Huge Pages</strong></h5>
<ul>
<li>For memory-intensive applications, enable huge pages:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token builtin class-name">echo</span> <span class="token number">512</span> <span class="token operator">></span> /proc/sys/vm/nr_hugepages</code></pre></div>
</li>
</ul>
<h5 id="numa-optimizations" style="position:relative;"><a href="#numa-optimizations" aria-label="numa optimizations permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>NUMA Optimizations</strong></h5>
<ul>
<li>Bind memory allocations to NUMA nodes for locality:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">numactl <span class="token parameter variable">--membind</span><span class="token operator">=</span><span class="token number">0</span> ./app</code></pre></div>
</li>
</ul>
<hr>
<h3 id="742-practical-examples" style="position:relative;"><a href="#742-practical-examples" aria-label="742 practical examples permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>7.4.2 Practical Examples</strong></h3>
<h4 id="example-1-memory-leak-in-a-web-application" style="position:relative;"><a href="#example-1-memory-leak-in-a-web-application" aria-label="example 1 memory leak in a web application permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example 1: Memory Leak in a Web Application</strong></h4>
<ol>
<li><strong>Problem</strong>:
<ul>
<li>A web server crashes after several days of operation.</li>
</ul>
</li>
<li><strong>Solution</strong>:
<ul>
<li>Use <code class="language-text">valgrind</code>:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">valgrind --leak-check<span class="token operator">=</span>full ./server</code></pre></div>
<ul>
<li>Output:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">==1234== 200 bytes in 10 blocks definitely lost in loss record 1 of 2</code></pre></div>
</li>
</ul>
</li>
<li>Fix the code to release memory after use.</li>
</ul>
</li>
</ol>
<hr>
<h4 id="example-2-cache-optimization-in-a-database" style="position:relative;"><a href="#example-2-cache-optimization-in-a-database" aria-label="example 2 cache optimization in a database permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example 2: Cache Optimization in a Database</strong></h4>
<ol>
<li><strong>Problem</strong>:
<ul>
<li>Database query latency increases during peak usage.</li>
</ul>
</li>
<li><strong>Solution</strong>:
<ul>
<li>Use <code class="language-text">perf</code> to analyze cache performance:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">perf <span class="token function">stat</span> <span class="token parameter variable">-e</span> cache-misses ./db_query</code></pre></div>
<ul>
<li>High cache misses indicate inefficient access patterns.</li>
</ul>
</li>
<li>Optimize table indexing to improve query performance.</li>
</ul>
</li>
</ol>
<hr>
<h4 id="example-3-reducing-swapping-in-a-batch-process" style="position:relative;"><a href="#example-3-reducing-swapping-in-a-batch-process" aria-label="example 3 reducing swapping in a batch process permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example 3: Reducing Swapping in a Batch Process</strong></h4>
<ol>
<li><strong>Problem</strong>:
<ul>
<li>A batch job slows significantly as swapping increases.</li>
</ul>
</li>
<li><strong>Solution</strong>:
<ul>
<li>Use <code class="language-text">vmstat</code>:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">vmstat</span> <span class="token number">1</span></code></pre></div>
<ul>
<li>Identify high <code class="language-text">si</code> and <code class="language-text">so</code> rates.</li>
</ul>
</li>
<li>Increase RAM or reduce memory usage by optimizing data structures.</li>
</ul>
</li>
</ol>
<hr>
<h3 id="key-takeaways-6" style="position:relative;"><a href="#key-takeaways-6" aria-label="key takeaways 6 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Key Takeaways</strong></h3>
<ul>
<li><strong>Step-by-step memory analysis</strong> is critical for identifying and solving performance bottlenecks.</li>
<li>Use tools like <code class="language-text">valgrind</code>, <code class="language-text">vmstat</code>, and <code class="language-text">perf</code> to detect leaks, cache inefficiencies, and swapping issues.</li>
<li><strong>Targeted tuning</strong> (e.g., swappiness, NUMA binding) enhances memory performance for specific workloads.</li>
</ul>
<hr>
<h2 id="75-observability-tools" style="position:relative;"><a href="#75-observability-tools" aria-label="75 observability tools permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>7.5 Observability Tools</strong></h2>
<p>Memory observability tools are essential for diagnosing issues, understanding memory usage patterns, and optimizing system performance. These tools provide insights into virtual memory, swapping, caching, and application-specific memory consumption.</p>
<hr>
<h3 id="751-system-level-observability-tools" style="position:relative;"><a href="#751-system-level-observability-tools" aria-label="751 system level observability tools permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>7.5.1 System-Level Observability Tools</strong></h3>
<h4 id="1-vmstat" style="position:relative;"><a href="#1-vmstat" aria-label="1 vmstat permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>1. <code class="language-text">vmstat</code></strong></h4>
<ul>
<li><strong>Purpose</strong>: Provides a real-time snapshot of system performance, including memory usage, swapping, and paging activity.</li>
<li><strong>Command</strong>:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">vmstat</span> <span class="token number">1</span></code></pre></div>
</li>
<li><strong>Key Metrics</strong>:
<ul>
<li><code class="language-text">r</code>: Number of processes waiting for CPU.</li>
<li><code class="language-text">free</code>: Available memory.</li>
<li><code class="language-text">si/so</code>: Swap in/out rates.</li>
</ul>
</li>
<li><strong>Example</strong>:
<ul>
<li>Output:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs  us  sy  id  wa
 1  0    100  12000  2000  15000    0    0     5    10  100  200  30  10  50   5</code></pre></div>
<ul>
<li><strong>Interpretation</strong>:
<ul>
<li><code class="language-text">si</code> and <code class="language-text">so</code> values of <code class="language-text">0</code> indicate no swapping.</li>
<li><code class="language-text">free</code> and <code class="language-text">cache</code> values show available memory and file system cache usage.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="2-free" style="position:relative;"><a href="#2-free" aria-label="2 free permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>2. <code class="language-text">free</code></strong></h4>
<ul>
<li><strong>Purpose</strong>: Displays system memory usage, including buffers and cache.</li>
<li><strong>Command</strong>:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">free</span> <span class="token parameter variable">-h</span></code></pre></div>
</li>
<li><strong>Output</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">             total        used        free      shared  buff/cache   available
Mem:           16G         8G         2G         1G         6G         9G
Swap:           8G         2G         6G</code></pre></div>
</li>
<li><strong>Example</strong>:
<ul>
<li><strong>Interpretation</strong>:
<ul>
<li><code class="language-text">used</code>: Memory actively used by applications.</li>
<li><code class="language-text">buff/cache</code>: Memory used for file system buffers and caching.</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h4 id="3-tophtop" style="position:relative;"><a href="#3-tophtop" aria-label="3 tophtop permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>3. <code class="language-text">top</code>/<code class="language-text">htop</code></strong></h4>
<ul>
<li><strong>Purpose</strong>: Real-time monitoring of system performance, including per-process memory usage.</li>
<li><strong>Key Features</strong>:
<ul>
<li><code class="language-text">%MEM</code>: Percentage of total memory used by a process.</li>
<li><code class="language-text">RES</code>: Resident Set Size (physical memory in use).</li>
</ul>
</li>
<li><strong>Command</strong>:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">htop</span></code></pre></div>
</li>
<li><strong>Example</strong>:
<ul>
<li>Use <code class="language-text">Shift + M</code> in <code class="language-text">htop</code> to sort processes by memory usage.</li>
<li><strong>Output</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">PID  USER     PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND</code></pre></div>
</li>
</ul>
1234  root     20   0   500M   250M   50M  S    5.0   1.6   0:10.23 my_app
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text"></code></pre></div>
</li>
</ul>
<hr>
<h4 id="4-sar" style="position:relative;"><a href="#4-sar" aria-label="4 sar permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>4. <code class="language-text">sar</code></strong></h4>
<ul>
<li><strong>Purpose</strong>: Historical analysis of memory usage, paging, and swapping.</li>
<li><strong>Command</strong>:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">sar <span class="token parameter variable">-r</span> <span class="token number">1</span> <span class="token number">10</span></code></pre></div>
</li>
<li><strong>Output</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">12:00:01 AM kbmemfree kbmemused  %memused kbbuffers kbcached kbcommit
12:00:02 AM   12000     8000       66.7       5000    25000     8000</code></pre></div>
</li>
<li><strong>Example</strong>:
<ul>
<li>Use <code class="language-text">sar -W</code> to analyze swap activity over time:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">sar <span class="token parameter variable">-W</span> <span class="token number">1</span> <span class="token number">10</span></code></pre></div>
<ul>
<li><strong>Insight</strong>: Frequent high swap rates may indicate insufficient RAM.</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h4 id="5-slabtop" style="position:relative;"><a href="#5-slabtop" aria-label="5 slabtop permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>5. <code class="language-text">slabtop</code></strong></h4>
<ul>
<li><strong>Purpose</strong>: Displays kernel memory slab usage.</li>
<li><strong>Command</strong>:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">slabtop</code></pre></div>
</li>
<li><strong>Key Metrics</strong>:
<ul>
<li><code class="language-text">Active/Total</code>: Shows active and total slab objects.</li>
<li><strong>Example</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">OBJS ACTIVE  USE OBJ SIZE  SLABS OBJ/SLAB CACHE SIZE NAME
1024   512  50%    64.00K   64    16      512K      kmalloc-64</code></pre></div>
<ul>
<li><strong>Interpretation</strong>:
<ul>
<li>High usage of a particular slab (e.g., <code class="language-text">kmalloc-64</code>) may indicate a memory leak in the kernel.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h3 id="752-application-specific-observability-tools" style="position:relative;"><a href="#752-application-specific-observability-tools" aria-label="752 application specific observability tools permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>7.5.2 Application-Specific Observability Tools</strong></h3>
<h4 id="1-pmap" style="position:relative;"><a href="#1-pmap" aria-label="1 pmap permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>1. <code class="language-text">pmap</code></strong></h4>
<ul>
<li><strong>Purpose</strong>: Reports memory maps for a process.</li>
<li><strong>Command</strong>:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">pmap <span class="token parameter variable">-x</span> <span class="token operator">&lt;</span>pid<span class="token operator">></span></code></pre></div>
</li>
<li><strong>Output</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">Address           Kbytes     RSS   Dirty Mode
0000000000400000   2048     1024    512   r-xp</code></pre></div>
</li>
<li><strong>Example</strong>:
<ul>
<li>Analyze a memory-intensive process:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">pmap <span class="token parameter variable">-x</span> <span class="token number">1234</span></code></pre></div>
</li>
</ul>
</li>
</ul>
<hr>
<h4 id="2-memory-profilers" style="position:relative;"><a href="#2-memory-profilers" aria-label="2 memory profilers permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>2. Memory Profilers</strong></h4>
<h5 id="for-python" style="position:relative;"><a href="#for-python" aria-label="for python permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>For Python</strong>:</h5>
<ul>
<li><strong><code class="language-text">memory_profiler</code></strong>:
<ul>
<li>Tracks memory usage in Python functions.</li>
<li><strong>Code Example</strong>:
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">from</span> memory_profiler <span class="token keyword">import</span> profile

<span class="token decorator annotation punctuation">@profile</span>
<span class="token keyword">def</span> <span class="token function">my_function</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    data <span class="token operator">=</span> <span class="token punctuation">[</span>i <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">100000</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
    <span class="token keyword">return</span> data

my_function<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre></div>
</li>
</ul>
</li>
</ul>
<h5 id="for-java" style="position:relative;"><a href="#for-java" aria-label="for java permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>For Java</strong>:</h5>
<ul>
<li><strong>JVisualVM</strong>:
<ul>
<li>Monitors heap usage and garbage collection activity.</li>
</ul>
</li>
</ul>
<hr>
<h4 id="3-tracing-allocations-with-bpftrace" style="position:relative;"><a href="#3-tracing-allocations-with-bpftrace" aria-label="3 tracing allocations with bpftrace permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>3. Tracing Allocations with <code class="language-text">bpftrace</code></strong></h4>
<ul>
<li><strong>Purpose</strong>: Monitors memory allocations and tracks leaks.</li>
<li><strong>Command</strong>:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">bpftrace <span class="token parameter variable">-e</span> <span class="token string">'tracepoint:kmem:kmalloc { printf("%d bytes allocated at %lx\n", args->bytes_allocated, args->ptr); }'</span></code></pre></div>
</li>
<li><strong>Output</strong>:
<ul>
<li>Tracks allocation sizes and memory addresses.</li>
</ul>
</li>
</ul>
<hr>
<h3 id="753-advanced-tools" style="position:relative;"><a href="#753-advanced-tools" aria-label="753 advanced tools permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>7.5.3 Advanced Tools</strong></h3>
<h4 id="1-perf-1" style="position:relative;"><a href="#1-perf-1" aria-label="1 perf 1 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>1. <code class="language-text">perf</code></strong></h4>
<ul>
<li><strong>Purpose</strong>: Profiles memory performance, including cache hits and misses.</li>
<li><strong>Command</strong>:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">perf <span class="token function">stat</span> <span class="token parameter variable">-e</span> cache-misses,cache-references ./app</code></pre></div>
</li>
<li><strong>Output</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">1,000,000 cache-references
  100,000 cache-misses</code></pre></div>
</li>
<li><strong>Example</strong>:
<ul>
<li>Use <code class="language-text">perf</code> to identify high cache miss rates and optimize memory access patterns.</li>
</ul>
</li>
</ul>
<h4 id="2-bcc-tools" style="position:relative;"><a href="#2-bcc-tools" aria-label="2 bcc tools permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>2. BCC Tools</strong></h4>
<ul>
<li><strong>Key Tools</strong>:
<ul>
<li><strong><code class="language-text">cachestat</code></strong>:
<ul>
<li>Monitors cache hit/miss ratios:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">cachestat</code></pre></div>
</li>
</ul>
</li>
<li><strong><code class="language-text">memleak</code></strong>:
<ul>
<li>Tracks memory leaks dynamically.</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h3 id="754-practical-examples" style="position:relative;"><a href="#754-practical-examples" aria-label="754 practical examples permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>7.5.4 Practical Examples</strong></h3>
<h4 id="example-1-diagnosing-high-swap-usage" style="position:relative;"><a href="#example-1-diagnosing-high-swap-usage" aria-label="example 1 diagnosing high swap usage permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example 1: Diagnosing High Swap Usage</strong></h4>
<ol>
<li><strong>Scenario</strong>:
<ul>
<li>A database application shows slow query response times.</li>
</ul>
</li>
<li><strong>Analysis</strong>:
<ul>
<li>Use <code class="language-text">vmstat</code>:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">vmstat</span> <span class="token number">1</span></code></pre></div>
<ul>
<li>Observe high <code class="language-text">si</code> and <code class="language-text">so</code> values indicating excessive swapping.</li>
</ul>
</li>
</ul>
</li>
<li><strong>Solution</strong>:
<ul>
<li>Increase physical RAM or reduce memory footprint by optimizing queries.</li>
</ul>
</li>
</ol>
<hr>
<h4 id="example-2-identifying-a-memory-leak" style="position:relative;"><a href="#example-2-identifying-a-memory-leak" aria-label="example 2 identifying a memory leak permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example 2: Identifying a Memory Leak</strong></h4>
<ol>
<li><strong>Scenario</strong>:
<ul>
<li>A web application consumes increasing memory over time.</li>
</ul>
</li>
<li><strong>Analysis</strong>:
<ul>
<li>Use <code class="language-text">valgrind</code> to detect leaks:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">valgrind --leak-check<span class="token operator">=</span>full ./web_app</code></pre></div>
<ul>
<li>Output reveals memory blocks not freed.</li>
</ul>
</li>
</ul>
</li>
<li><strong>Solution</strong>:
<ul>
<li>Fix the application to release allocated memory after use.</li>
</ul>
</li>
</ol>
<hr>
<h4 id="example-3-cache-optimization-in-a-scientific-application" style="position:relative;"><a href="#example-3-cache-optimization-in-a-scientific-application" aria-label="example 3 cache optimization in a scientific application permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example 3: Cache Optimization in a Scientific Application</strong></h4>
<ol>
<li><strong>Scenario</strong>:
<ul>
<li>A numerical simulation exhibits slow performance.</li>
</ul>
</li>
<li><strong>Analysis</strong>:
<ul>
<li>Use <code class="language-text">perf</code>:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">perf <span class="token function">stat</span> <span class="token parameter variable">-e</span> cache-misses ./simulation</code></pre></div>
<ul>
<li>Output shows high cache misses.</li>
</ul>
</li>
</ul>
</li>
<li><strong>Solution</strong>:
<ul>
<li>Refactor the simulation to use sequential memory access patterns, reducing cache misses.</li>
</ul>
</li>
</ol>
<hr>
<h3 id="key-takeaways-7" style="position:relative;"><a href="#key-takeaways-7" aria-label="key takeaways 7 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Key Takeaways</strong></h3>
<ol>
<li><strong>System tools like <code class="language-text">vmstat</code>, <code class="language-text">free</code>, and <code class="language-text">sar</code></strong> provide a holistic view of memory usage and trends.</li>
<li><strong>Application-specific tools like <code class="language-text">pmap</code>, <code class="language-text">memory_profiler</code>, and <code class="language-text">bpftrace</code></strong> are invaluable for debugging and optimizing memory usage.</li>
<li><strong>Advanced tools like <code class="language-text">perf</code> and BCC tools</strong> enable detailed analysis of cache performance and memory allocations.</li>
</ol>
<hr>
<p>Here’s an <strong>in-depth and expanded explanation of Section 7.6: Tuning</strong>, focusing on practical techniques, examples, and best practices for optimizing memory performance. This section covers tuning virtual memory, swap, cache, and application-specific memory usage.</p>
<hr>
<h2 id="76-tuning" style="position:relative;"><a href="#76-tuning" aria-label="76 tuning permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>7.6 Tuning</strong></h2>
<p>Memory tuning involves optimizing system configurations and application behavior to improve memory performance, reduce latency, and minimize resource contention. Proper tuning ensures efficient memory usage, prevents bottlenecks, and maximizes throughput.</p>
<hr>
<h3 id="761-virtual-memory-tuning" style="position:relative;"><a href="#761-virtual-memory-tuning" aria-label="761 virtual memory tuning permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>7.6.1 Virtual Memory Tuning</strong></h3>
<h4 id="1-adjusting-swappiness" style="position:relative;"><a href="#1-adjusting-swappiness" aria-label="1 adjusting swappiness permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>1. Adjusting Swappiness</strong></h4>
<ul>
<li><strong>Definition</strong>: Swappiness controls the balance between using swap space and freeing up memory by evicting inactive pages.</li>
<li><strong>Configuration</strong>:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">sysctl</span> <span class="token assign-left variable">vm.swappiness</span><span class="token operator">=</span><span class="token number">10</span></code></pre></div>
<ul>
<li>Lower values (e.g., 10) prioritize keeping data in RAM.</li>
<li>Higher values (e.g., 60) make the system more likely to use swap.</li>
</ul>
</li>
<li><strong>Example</strong>:
<ul>
<li><strong>Scenario</strong>: A web server with large RAM but occasional swapping.</li>
<li><strong>Solution</strong>:
<ul>
<li>Reduce swappiness to 10 to minimize unnecessary swapping.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="2-increasing-virtual-memory-limits" style="position:relative;"><a href="#2-increasing-virtual-memory-limits" aria-label="2 increasing virtual memory limits permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>2. Increasing Virtual Memory Limits</strong></h4>
<ul>
<li><strong>Configuration</strong>:
<ul>
<li>Edit <code class="language-text">/etc/security/limits.conf</code> to increase memory limits for specific users or groups:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">user hard memlock unlimited</code></pre></div>
</li>
<li>Use <code class="language-text">ulimit</code> for temporary adjustments:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token builtin class-name">ulimit</span> <span class="token parameter variable">-v</span> <span class="token operator">&lt;</span>memory_limit_in_kilobytes<span class="token operator">></span></code></pre></div>
</li>
</ul>
</li>
<li><strong>Example</strong>:
<ul>
<li><strong>Scenario</strong>: A scientific application crashes due to insufficient virtual memory.</li>
<li><strong>Solution</strong>:
<ul>
<li>Increase the <code class="language-text">memlock</code> limit to allow the application to allocate larger datasets.</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h3 id="762-swap-space-optimization" style="position:relative;"><a href="#762-swap-space-optimization" aria-label="762 swap space optimization permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>7.6.2 Swap Space Optimization</strong></h3>
<h4 id="1-proper-swap-sizing" style="position:relative;"><a href="#1-proper-swap-sizing" aria-label="1 proper swap sizing permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>1. Proper Swap Sizing</strong></h4>
<ul>
<li><strong>Best Practices</strong>:
<ul>
<li>For systems with large RAM (>16GB), use a smaller swap size (e.g., 2GB–4GB).</li>
<li>For memory-constrained systems, allocate swap equal to or greater than RAM.</li>
</ul>
</li>
<li><strong>Configuration</strong>:
<ul>
<li>Add or resize swap space:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">fallocate <span class="token parameter variable">-l</span> 4G /swapfile
<span class="token function">chmod</span> <span class="token number">600</span> /swapfile
<span class="token function">mkswap</span> /swapfile
<span class="token function">swapon</span> /swapfile</code></pre></div>
</li>
</ul>
</li>
<li><strong>Example</strong>:
<ul>
<li><strong>Scenario</strong>: A server with 8GB RAM and high swapping activity.</li>
<li><strong>Solution</strong>:
<ul>
<li>Increase swap size to 16GB and reduce swappiness.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="2-monitoring-swap-performance" style="position:relative;"><a href="#2-monitoring-swap-performance" aria-label="2 monitoring swap performance permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>2. Monitoring Swap Performance</strong></h4>
<ul>
<li>Use <code class="language-text">sar</code> to track swap usage:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">sar <span class="token parameter variable">-W</span> <span class="token number">1</span> <span class="token number">10</span></code></pre></div>
</li>
<li><strong>Example</strong>:
<ul>
<li><strong>Scenario</strong>: A database exhibits high latency due to excessive swapping.</li>
<li><strong>Solution</strong>:
<ul>
<li>Upgrade RAM or tune queries to reduce memory usage.</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h3 id="763-file-system-cache-tuning" style="position:relative;"><a href="#763-file-system-cache-tuning" aria-label="763 file system cache tuning permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>7.6.3 File System Cache Tuning</strong></h3>
<h4 id="1-adjusting-cache-pressure" style="position:relative;"><a href="#1-adjusting-cache-pressure" aria-label="1 adjusting cache pressure permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>1. Adjusting Cache Pressure</strong></h4>
<ul>
<li><strong>Definition</strong>: Cache pressure controls how aggressively the kernel reclaims memory from the file system cache.</li>
<li><strong>Configuration</strong>:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">sysctl</span> <span class="token assign-left variable">vm.vfs_cache_pressure</span><span class="token operator">=</span><span class="token number">50</span></code></pre></div>
<ul>
<li>Lower values (e.g., 50) retain more file system cache.</li>
<li>Higher values (e.g., 200) prioritize reclaiming memory for applications.</li>
</ul>
</li>
<li><strong>Example</strong>:
<ul>
<li><strong>Scenario</strong>: A file server needs to prioritize caching large files for faster reads.</li>
<li><strong>Solution</strong>:
<ul>
<li>Set <code class="language-text">vm.vfs_cache_pressure=50</code> to retain cached file metadata longer.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="2-maximizing-cache-usage" style="position:relative;"><a href="#2-maximizing-cache-usage" aria-label="2 maximizing cache usage permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>2. Maximizing Cache Usage</strong></h4>
<ul>
<li>Use tools like <code class="language-text">free</code> to monitor cache:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">free</span> <span class="token parameter variable">-h</span></code></pre></div>
</li>
<li><strong>Example</strong>:
<ul>
<li>A database server improves query performance by increasing the cache size for frequently accessed tables.</li>
</ul>
</li>
</ul>
<hr>
<h3 id="764-numa-tuning" style="position:relative;"><a href="#764-numa-tuning" aria-label="764 numa tuning permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>7.6.4 NUMA Tuning</strong></h3>
<h4 id="1-binding-memory-to-numa-nodes" style="position:relative;"><a href="#1-binding-memory-to-numa-nodes" aria-label="1 binding memory to numa nodes permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>1. Binding Memory to NUMA Nodes</strong></h4>
<ul>
<li><strong>Definition</strong>: Non-Uniform Memory Access (NUMA) allows CPUs to access memory faster when allocated on the same node.</li>
<li><strong>Tools</strong>:
<ul>
<li><strong><code class="language-text">numactl</code></strong>: Bind processes to specific NUMA nodes:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">numactl <span class="token parameter variable">--membind</span><span class="token operator">=</span><span class="token number">0</span> ./app</code></pre></div>
</li>
<li><strong><code class="language-text">numastat</code></strong>: Monitor NUMA memory allocation:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">numastat</code></pre></div>
</li>
</ul>
</li>
<li><strong>Example</strong>:
<ul>
<li><strong>Scenario</strong>: A multi-threaded application shows inconsistent performance.</li>
<li><strong>Solution</strong>:
<ul>
<li>Bind threads and memory to specific NUMA nodes to reduce latency.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="2-optimizing-numa-aware-applications" style="position:relative;"><a href="#2-optimizing-numa-aware-applications" aria-label="2 optimizing numa aware applications permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>2. Optimizing NUMA-Aware Applications</strong></h4>
<ul>
<li>Modify applications to allocate memory close to the CPU performing the computation.</li>
<li><strong>Example</strong>:
<ul>
<li><strong>Scenario</strong>: A high-performance computing workload benefits from NUMA-aware data placement.</li>
<li><strong>Solution</strong>:
<ul>
<li>Use APIs like <code class="language-text">numa_alloc_onnode()</code> to allocate memory explicitly.</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h3 id="765-huge-pages" style="position:relative;"><a href="#765-huge-pages" aria-label="765 huge pages permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>7.6.5 Huge Pages</strong></h3>
<h4 id="1-enabling-huge-pages" style="position:relative;"><a href="#1-enabling-huge-pages" aria-label="1 enabling huge pages permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>1. Enabling Huge Pages</strong></h4>
<ul>
<li><strong>Definition</strong>: Huge pages reduce the number of page table entries, improving TLB (Translation Lookaside Buffer) efficiency.</li>
<li><strong>Configuration</strong>:
<ul>
<li>Reserve huge pages:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token builtin class-name">echo</span> <span class="token number">512</span> <span class="token operator">></span> /proc/sys/vm/nr_hugepages</code></pre></div>
</li>
</ul>
</li>
<li><strong>Example</strong>:
<ul>
<li><strong>Scenario</strong>: A database application with large memory requirements benefits from reduced page table overhead.</li>
<li><strong>Solution</strong>:
<ul>
<li>Enable huge pages and configure the application to use them.</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h3 id="766-application-specific-tuning" style="position:relative;"><a href="#766-application-specific-tuning" aria-label="766 application specific tuning permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>7.6.6 Application-Specific Tuning</strong></h3>
<h4 id="1-java-applications" style="position:relative;"><a href="#1-java-applications" aria-label="1 java applications permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>1. Java Applications</strong></h4>
<ul>
<li><strong>Heap Sizing</strong>:
<ul>
<li>Set initial and maximum heap sizes:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">java</span> <span class="token parameter variable">-Xms4G</span> <span class="token parameter variable">-Xmx8G</span> <span class="token parameter variable">-jar</span> app.jar</code></pre></div>
</li>
</ul>
</li>
<li><strong>Garbage Collection (GC) Tuning</strong>:
<ul>
<li>Use G1GC for low-latency applications:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">java</span> <span class="token parameter variable">-XX:+UseG1GC</span> <span class="token parameter variable">-jar</span> app.jar</code></pre></div>
</li>
</ul>
</li>
<li><strong>Example</strong>:
<ul>
<li><strong>Scenario</strong>: A Java-based web application suffers from frequent GC pauses.</li>
<li><strong>Solution</strong>:
<ul>
<li>Switch to G1GC and fine-tune heap sizes.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="2-python-applications" style="position:relative;"><a href="#2-python-applications" aria-label="2 python applications permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>2. Python Applications</strong></h4>
<ul>
<li>Optimize memory usage with object pooling:
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> queue
obj_pool <span class="token operator">=</span> queue<span class="token punctuation">.</span>Queue<span class="token punctuation">(</span>maxsize<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span>

obj <span class="token operator">=</span> obj_pool<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># Use obj</span>
obj_pool<span class="token punctuation">.</span>put<span class="token punctuation">(</span>obj<span class="token punctuation">)</span></code></pre></div>
</li>
</ul>
<h4 id="3-database-servers" style="position:relative;"><a href="#3-database-servers" aria-label="3 database servers permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>3. Database Servers</strong></h4>
<ul>
<li>Increase buffer pool size to reduce disk I/O:
<div class="gatsby-highlight" data-language="sql"><pre class="language-sql"><code class="language-sql"><span class="token keyword">SET</span> <span class="token keyword">GLOBAL</span> innodb_buffer_pool_size <span class="token operator">=</span> <span class="token number">4</span>G<span class="token punctuation">;</span></code></pre></div>
</li>
<li>Enable caching for frequently accessed queries.</li>
</ul>
<hr>
<h3 id="767-monitoring-and-feedback" style="position:relative;"><a href="#767-monitoring-and-feedback" aria-label="767 monitoring and feedback permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>7.6.7 Monitoring and Feedback</strong></h3>
<h4 id="1-monitoring-tools" style="position:relative;"><a href="#1-monitoring-tools" aria-label="1 monitoring tools permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>1. Monitoring Tools</strong></h4>
<ul>
<li><strong><code class="language-text">vmstat</code></strong>: Monitor memory usage and swap activity:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">vmstat</span> <span class="token number">1</span></code></pre></div>
</li>
<li><strong><code class="language-text">sar</code></strong>: Historical analysis of memory and swap usage:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">sar <span class="token parameter variable">-r</span> <span class="token number">1</span> <span class="token number">10</span></code></pre></div>
</li>
<li><strong><code class="language-text">slabtop</code></strong>: Monitor kernel slab memory usage.</li>
</ul>
<h4 id="2-feedback-loop" style="position:relative;"><a href="#2-feedback-loop" aria-label="2 feedback loop permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>2. Feedback Loop</strong></h4>
<ul>
<li>Continuously monitor performance metrics to validate tuning changes.</li>
</ul>
<hr>
<h3 id="768-practical-examples" style="position:relative;"><a href="#768-practical-examples" aria-label="768 practical examples permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>7.6.8 Practical Examples</strong></h3>
<h4 id="example-1-reducing-swap-usage" style="position:relative;"><a href="#example-1-reducing-swap-usage" aria-label="example 1 reducing swap usage permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example 1: Reducing Swap Usage</strong></h4>
<ol>
<li><strong>Scenario</strong>:
<ul>
<li>A web server experiences high response times during peak usage.</li>
</ul>
</li>
<li><strong>Solution</strong>:
<ul>
<li>Reduce swappiness:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">sysctl</span> <span class="token assign-left variable">vm.swappiness</span><span class="token operator">=</span><span class="token number">10</span></code></pre></div>
</li>
<li>Add more physical RAM if required.</li>
</ul>
</li>
</ol>
<h4 id="example-2-numa-tuning-in-high-performance-computing" style="position:relative;"><a href="#example-2-numa-tuning-in-high-performance-computing" aria-label="example 2 numa tuning in high performance computing permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example 2: NUMA Tuning in High-Performance Computing</strong></h4>
<ol>
<li><strong>Scenario</strong>:
<ul>
<li>A multi-threaded simulation shows inconsistent runtimes.</li>
</ul>
</li>
<li><strong>Solution</strong>:
<ul>
<li>Bind threads to NUMA nodes:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">numactl <span class="token parameter variable">--cpunodebind</span><span class="token operator">=</span><span class="token number">0</span> <span class="token parameter variable">--membind</span><span class="token operator">=</span><span class="token number">0</span> ./simulation</code></pre></div>
</li>
</ul>
</li>
</ol>
<h4 id="example-3-optimizing-cache-pressure-for-a-file-server" style="position:relative;"><a href="#example-3-optimizing-cache-pressure-for-a-file-server" aria-label="example 3 optimizing cache pressure for a file server permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example 3: Optimizing Cache Pressure for a File Server</strong></h4>
<ol>
<li><strong>Scenario</strong>:
<ul>
<li>A file server performs slow read operations.</li>
</ul>
</li>
<li><strong>Solution</strong>:
<ul>
<li>Adjust cache pressure:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">sysctl</span> <span class="token assign-left variable">vm.vfs_cache_pressure</span><span class="token operator">=</span><span class="token number">50</span></code></pre></div>
</li>
</ul>
</li>
</ol>
<hr>
<h3 id="key-takeaways-8" style="position:relative;"><a href="#key-takeaways-8" aria-label="key takeaways 8 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Key Takeaways</strong></h3>
<ol>
<li>Memory tuning is an iterative process involving <strong>swappiness adjustment</strong>, <strong>cache optimization</strong>, and <strong>NUMA configuration</strong>.</li>
<li>Tools like <code class="language-text">numactl</code>, <code class="language-text">vmstat</code>, and <code class="language-text">sar</code> enable fine-grained control over memory performance.</li>
<li>Application-specific tuning (e.g., heap sizing, query optimization) provides targeted performance improvements.</li>
</ol>
<hr>
<p>Here’s an <strong>expanded and detailed explanation of Section 7.7: Practical Examples</strong>, focusing on real-world scenarios for memory performance optimization. Each example includes a deeper dive into the problem, diagnosis, solution, and results to provide actionable insights.</p>
<hr>
<h2 id="77-practical-examples" style="position:relative;"><a href="#77-practical-examples" aria-label="77 practical examples permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>7.7 Practical Examples</strong></h2>
<p>This section provides real-world examples of memory performance issues and solutions, focusing on <strong>leak detection</strong>, <strong>swapping</strong>, <strong>caching</strong>, <strong>NUMA optimization</strong>, and <strong>application tuning</strong>. These cases demonstrate the application of memory observability tools and tuning techniques in various scenarios.</p>
<hr>
<h3 id="771-example-1-detecting-a-memory-leak-in-a-web-application" style="position:relative;"><a href="#771-example-1-detecting-a-memory-leak-in-a-web-application" aria-label="771 example 1 detecting a memory leak in a web application permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>7.7.1 Example 1: Detecting a Memory Leak in a Web Application</strong></h3>
<h4 id="problem" style="position:relative;"><a href="#problem" aria-label="problem permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Problem</strong>:</h4>
<p>A Python-based web application exhibits increasing memory usage over time, eventually leading to crashes under heavy traffic.</p>
<h4 id="diagnosis" style="position:relative;"><a href="#diagnosis" aria-label="diagnosis permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Diagnosis</strong>:</h4>
<ol>
<li>
<p><strong>Monitoring</strong>:</p>
<ul>
<li>Use <code class="language-text">htop</code> to observe memory usage:
<ul>
<li>Memory usage of the process steadily increases over time.</li>
</ul>
</li>
<li>Collect baseline memory usage using <code class="language-text">pmap</code>:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">pmap <span class="token parameter variable">-x</span> <span class="token operator">&lt;</span>pid<span class="token operator">></span></code></pre></div>
</li>
<li>Results:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">Address           Kbytes     RSS   Dirty Mode
0000000000400000   1024       800    200   rw-p</code></pre></div>
<ul>
<li>RSS steadily increases during traffic spikes.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Leak Detection</strong>:</p>
<ul>
<li>Use <code class="language-text">valgrind</code> to check for memory leaks:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">valgrind --leak-check<span class="token operator">=</span>full ./app.py</code></pre></div>
</li>
<li>Output reveals unfreed memory blocks:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">==12345== 500 bytes in 10 blocks are definitely lost in loss record 1 of 2</code></pre></div>
</li>
</ul>
</li>
<li>
<p><strong>Python-Specific Analysis</strong>:</p>
<ul>
<li>Use <code class="language-text">objgraph</code> to analyze object retention:
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> objgraph
objgraph<span class="token punctuation">.</span>show_most_common_types<span class="token punctuation">(</span>limit<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span></code></pre></div>
</li>
<li>Results:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">dict        50000
list        25000</code></pre></div>
</li>
</ul>
</li>
</ol>
<h4 id="solution" style="position:relative;"><a href="#solution" aria-label="solution permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Solution</strong>:</h4>
<ul>
<li>Fix the code to release memory after use:
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">del</span> large_dict</code></pre></div>
</li>
</ul>
<h4 id="result-1" style="position:relative;"><a href="#result-1" aria-label="result 1 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Result</strong>:</h4>
<ul>
<li>Memory usage remains stable under high traffic.</li>
<li>Crash incidents are eliminated.</li>
</ul>
<hr>
<h3 id="772-example-2-reducing-swap-usage-on-a-database-server" style="position:relative;"><a href="#772-example-2-reducing-swap-usage-on-a-database-server" aria-label="772 example 2 reducing swap usage on a database server permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>7.7.2 Example 2: Reducing Swap Usage on a Database Server</strong></h3>
<h4 id="problem-1" style="position:relative;"><a href="#problem-1" aria-label="problem 1 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Problem</strong>:</h4>
<p>A MySQL database exhibits high latency during peak hours due to excessive swapping.</p>
<h4 id="diagnosis-1" style="position:relative;"><a href="#diagnosis-1" aria-label="diagnosis 1 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Diagnosis</strong>:</h4>
<ol>
<li>
<p><strong>Monitoring</strong>:</p>
<ul>
<li>Use <code class="language-text">vmstat</code> to track swap activity:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">vmstat</span> <span class="token number">1</span></code></pre></div>
</li>
<li>Results:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs  us  sy  id  wa
 1  0  10000  12000  5000  15000   500   800    5    10  100  200  30  10  50   5</code></pre></div>
<ul>
<li>High <code class="language-text">si</code> and <code class="language-text">so</code> values indicate frequent swapping.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Configuration Review</strong>:</p>
<ul>
<li>Check swappiness:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">cat</span> /proc/sys/vm/swappiness</code></pre></div>
<ul>
<li>Value is set to <code class="language-text">60</code>, which favors swapping.</li>
</ul>
</li>
</ul>
</li>
</ol>
<h4 id="solution-1" style="position:relative;"><a href="#solution-1" aria-label="solution 1 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Solution</strong>:</h4>
<ol>
<li>Reduce swappiness to prioritize RAM:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">sysctl</span> <span class="token assign-left variable">vm.swappiness</span><span class="token operator">=</span><span class="token number">10</span></code></pre></div>
</li>
<li>Increase database buffer pool size:
<div class="gatsby-highlight" data-language="sql"><pre class="language-sql"><code class="language-sql"><span class="token keyword">SET</span> <span class="token keyword">GLOBAL</span> innodb_buffer_pool_size <span class="token operator">=</span> <span class="token number">4</span>G<span class="token punctuation">;</span></code></pre></div>
</li>
</ol>
<h4 id="result-2" style="position:relative;"><a href="#result-2" aria-label="result 2 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Result</strong>:</h4>
<ul>
<li>Swap usage is significantly reduced.</li>
<li>Query response time improves by 30%.</li>
</ul>
<hr>
<h3 id="773-example-3-optimizing-cache-for-a-file-server" style="position:relative;"><a href="#773-example-3-optimizing-cache-for-a-file-server" aria-label="773 example 3 optimizing cache for a file server permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>7.7.3 Example 3: Optimizing Cache for a File Server</strong></h3>
<h4 id="problem-2" style="position:relative;"><a href="#problem-2" aria-label="problem 2 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Problem</strong>:</h4>
<p>A file server shows slow read performance when handling large files.</p>
<h4 id="diagnosis-2" style="position:relative;"><a href="#diagnosis-2" aria-label="diagnosis 2 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Diagnosis</strong>:</h4>
<ol>
<li>
<p><strong>Monitoring</strong>:</p>
<ul>
<li>Use <code class="language-text">sar</code> to track cache activity:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">sar <span class="token parameter variable">-r</span> <span class="token number">1</span> <span class="token number">10</span></code></pre></div>
</li>
<li>Results:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">kbmemfree  kbbuffers  kbcached
12000       5000       25000</code></pre></div>
<ul>
<li>Frequent cache evictions observed.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Cache Analysis</strong>:</p>
<ul>
<li>Check cache pressure:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">cat</span> /proc/sys/vm/vfs_cache_pressure</code></pre></div>
<ul>
<li>Value is set to <code class="language-text">100</code>, which aggressively reclaims cached data.</li>
</ul>
</li>
</ul>
</li>
</ol>
<h4 id="solution-2" style="position:relative;"><a href="#solution-2" aria-label="solution 2 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Solution</strong>:</h4>
<ol>
<li>Reduce cache pressure:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">sysctl</span> <span class="token assign-left variable">vm.vfs_cache_pressure</span><span class="token operator">=</span><span class="token number">50</span></code></pre></div>
</li>
<li>Increase file system cache allocation.</li>
</ol>
<h4 id="result-3" style="position:relative;"><a href="#result-3" aria-label="result 3 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Result</strong>:</h4>
<ul>
<li>File read speed improves by 20%.</li>
<li>Cache hit rate increases significantly.</li>
</ul>
<hr>
<h3 id="774-example-4-numa-optimization-for-a-high-performance-application" style="position:relative;"><a href="#774-example-4-numa-optimization-for-a-high-performance-application" aria-label="774 example 4 numa optimization for a high performance application permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>7.7.4 Example 4: NUMA Optimization for a High-Performance Application</strong></h3>
<h4 id="problem-3" style="position:relative;"><a href="#problem-3" aria-label="problem 3 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Problem</strong>:</h4>
<p>A multi-threaded simulation application exhibits inconsistent runtimes on a NUMA-enabled server.</p>
<h4 id="diagnosis-3" style="position:relative;"><a href="#diagnosis-3" aria-label="diagnosis 3 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Diagnosis</strong>:</h4>
<ol>
<li>
<p><strong>NUMA Analysis</strong>:</p>
<ul>
<li>Use <code class="language-text">numastat</code> to analyze memory usage across NUMA nodes:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">numastat</code></pre></div>
</li>
<li>Results:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">Node 0 MemFree:  10000 MB
Node 1 MemFree:  5000 MB</code></pre></div>
<ul>
<li>Memory allocation is unbalanced.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Process Affinity</strong>:</p>
<ul>
<li>Check process affinity:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">taskset <span class="token parameter variable">-cp</span> <span class="token operator">&lt;</span>pid<span class="token operator">></span></code></pre></div>
<ul>
<li>Processes are not bound to specific NUMA nodes.</li>
</ul>
</li>
</ul>
</li>
</ol>
<h4 id="solution-3" style="position:relative;"><a href="#solution-3" aria-label="solution 3 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Solution</strong>:</h4>
<ol>
<li>Bind memory and threads to NUMA nodes:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">numactl <span class="token parameter variable">--cpunodebind</span><span class="token operator">=</span><span class="token number">0</span> <span class="token parameter variable">--membind</span><span class="token operator">=</span><span class="token number">0</span> ./simulation</code></pre></div>
</li>
<li>Modify the application to use NUMA-aware memory allocation APIs:
<div class="gatsby-highlight" data-language="c"><pre class="language-c"><code class="language-c"><span class="token keyword">void</span><span class="token operator">*</span> ptr <span class="token operator">=</span> <span class="token function">numa_alloc_onnode</span><span class="token punctuation">(</span>size<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre></div>
</li>
</ol>
<h4 id="result-4" style="position:relative;"><a href="#result-4" aria-label="result 4 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Result</strong>:</h4>
<ul>
<li>Simulation runtime becomes consistent.</li>
<li>Memory access latency reduces by 25%.</li>
</ul>
<hr>
<h3 id="775-example-5-tuning-a-java-application" style="position:relative;"><a href="#775-example-5-tuning-a-java-application" aria-label="775 example 5 tuning a java application permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>7.7.5 Example 5: Tuning a Java Application</strong></h3>
<h4 id="problem-4" style="position:relative;"><a href="#problem-4" aria-label="problem 4 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Problem</strong>:</h4>
<p>A Java-based e-commerce platform experiences frequent garbage collection (GC) pauses, impacting user experience.</p>
<h4 id="diagnosis-4" style="position:relative;"><a href="#diagnosis-4" aria-label="diagnosis 4 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Diagnosis</strong>:</h4>
<ol>
<li>
<p><strong>Heap Analysis</strong>:</p>
<ul>
<li>Use JVisualVM to monitor heap usage:
<ul>
<li>Frequent full GC events observed.</li>
</ul>
</li>
<li>Check GC logs:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">java</span> <span class="token parameter variable">-XX:+PrintGCDetails</span> <span class="token parameter variable">-jar</span> app.jar</code></pre></div>
<ul>
<li>Results:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">[Full GC (Allocation Failure) 500ms]</code></pre></div>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Heap Configuration</strong>:</p>
<ul>
<li>Check heap size:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">java</span> <span class="token parameter variable">-XX:+PrintFlagsFinal</span> <span class="token parameter variable">-version</span> <span class="token operator">|</span> <span class="token function">grep</span> HeapSize</code></pre></div>
<ul>
<li>Initial and maximum heap sizes are too low.</li>
</ul>
</li>
</ul>
</li>
</ol>
<h4 id="solution-4" style="position:relative;"><a href="#solution-4" aria-label="solution 4 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Solution</strong>:</h4>
<ol>
<li>Increase heap size:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">java</span> <span class="token parameter variable">-Xms4G</span> <span class="token parameter variable">-Xmx8G</span> <span class="token parameter variable">-jar</span> app.jar</code></pre></div>
</li>
<li>Switch to G1GC for low-latency garbage collection:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">java</span> <span class="token parameter variable">-XX:+UseG1GC</span> <span class="token parameter variable">-jar</span> app.jar</code></pre></div>
</li>
</ol>
<h4 id="result-5" style="position:relative;"><a href="#result-5" aria-label="result 5 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Result</strong>:</h4>
<ul>
<li>GC pauses reduce by 70%.</li>
<li>User experience improves significantly.</li>
</ul>
<hr>
<h3 id="776-example-6-reducing-memory-fragmentation" style="position:relative;"><a href="#776-example-6-reducing-memory-fragmentation" aria-label="776 example 6 reducing memory fragmentation permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>7.7.6 Example 6: Reducing Memory Fragmentation</strong></h3>
<h4 id="problem-5" style="position:relative;"><a href="#problem-5" aria-label="problem 5 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Problem</strong>:</h4>
<p>A long-running application crashes with “out of memory” errors despite having free RAM.</p>
<h4 id="diagnosis-5" style="position:relative;"><a href="#diagnosis-5" aria-label="diagnosis 5 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Diagnosis</strong>:</h4>
<ol>
<li>
<p><strong>Fragmentation Analysis</strong>:</p>
<ul>
<li>Use <code class="language-text">slabtop</code> to analyze kernel slab usage:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">slabtop</code></pre></div>
</li>
<li>Results:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">OBJS ACTIVE  USE OBJ SIZE  SLABS OBJ/SLAB CACHE SIZE NAME
1024   512  50%    64.00K   64    16      512K      kmalloc-64</code></pre></div>
<ul>
<li>High slab usage indicates memory fragmentation.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Memory Allocation Patterns</strong>:</p>
<ul>
<li>Review application memory allocation logs to identify inefficient patterns.</li>
</ul>
</li>
</ol>
<h4 id="solution-5" style="position:relative;"><a href="#solution-5" aria-label="solution 5 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Solution</strong>:</h4>
<ul>
<li>Use huge pages to reduce fragmentation:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token builtin class-name">echo</span> <span class="token number">512</span> <span class="token operator">></span> /proc/sys/vm/nr_hugepages</code></pre></div>
</li>
<li>Modify the application to allocate larger, contiguous memory blocks.</li>
</ul>
<h4 id="result-6" style="position:relative;"><a href="#result-6" aria-label="result 6 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Result</strong>:</h4>
<ul>
<li>Memory errors are eliminated.</li>
<li>Application runs smoothly for extended periods.</li>
</ul>
<hr>
<h3 id="key-takeaways-for-practical-examples" style="position:relative;"><a href="#key-takeaways-for-practical-examples" aria-label="key takeaways for practical examples permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Key Takeaways for practical examples</strong></h3>
<ol>
<li><strong>Memory issues often manifest in swapping, caching inefficiencies, or application behavior.</strong></li>
<li><strong>Tools like <code class="language-text">vmstat</code>, <code class="language-text">valgrind</code>, <code class="language-text">numastat</code>, and <code class="language-text">slabtop</code> help identify and resolve specific memory performance bottlenecks.</strong></li>
<li><strong>Tuning techniques, including swappiness adjustment, NUMA optimization, and heap sizing, improve performance across diverse workloads.</strong></li>
</ol>
<hr>
<h2 id="key-takeaways-for-memory-performance" style="position:relative;"><a href="#key-takeaways-for-memory-performance" aria-label="key takeaways for memory performance permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Key Takeaways for memory performance</strong></h2>
<ul>
<li>Memory performance is influenced by paging, caching, and allocation techniques.</li>
<li>Tools like <code class="language-text">vmstat</code>, <code class="language-text">sar</code>, and <code class="language-text">bpftrace</code> provide deep insights into memory usage patterns.</li>
<li>Tuning memory requires a balance between swappiness, NUMA allocation, and page sizes.</li>
</ul>
<p>Expanding <strong>Chapter 16: Case Study</strong> with detailed analysis and bold-highlighted key phrases provides an in-depth view of how performance principles and methodologies are applied in real-world scenarios. This section examines a practical case study to demonstrate the application of performance analysis tools and techniques.</p>
<hr>
<h1 id="file-systems" style="position:relative;"><a href="#file-systems" aria-label="file systems permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>File Systems</strong></h1>
<hr>
<h2 id="concepts-of-latency-caching-and-io-operations" style="position:relative;"><a href="#concepts-of-latency-caching-and-io-operations" aria-label="concepts of latency caching and io operations permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Concepts of Latency, Caching, and I/O Operations</strong></h2>
<ol>
<li>
<p><strong>File System Latency</strong>:</p>
<ul>
<li>
<p>Latency is the <strong>time delay</strong> between initiating an I/O request and its completion. It encompasses:</p>
<ul>
<li><strong>Seek Time</strong>: Time taken for the disk head to move to the desired track (important in HDDs).</li>
<li><strong>Rotational Latency</strong>: Time spent waiting for the desired sector to align under the read/write head.</li>
<li><strong>Transfer Time</strong>: Time required to actually transfer data between the disk and memory.</li>
</ul>
</li>
<li>
<p><strong>Key Example</strong>:</p>
<ul>
<li>Reading a single 4 KB block from an HDD might take <strong>10ms</strong> due to seek and rotational delays, but <strong>0.1ms</strong> on an SSD.</li>
</ul>
</li>
<li>
<p><strong>Random vs. Sequential I/O</strong>:</p>
<ul>
<li>Random I/O involves accessing scattered data blocks, resulting in frequent seeks and higher latency.</li>
<li>Sequential I/O reads or writes contiguous blocks, taking advantage of disk prefetching mechanisms.</li>
<li><strong>Example</strong>: A video streaming application benefits from sequential reads, while a database with random queries can suffer from random I/O delays.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Caching</strong>:</p>
<ul>
<li>Caching is critical for improving file system performance by reducing the reliance on slower disk operations.</li>
<li><strong>Write-Back Caching</strong>:
<ul>
<li>Data is temporarily stored in memory before being written to the disk, which boosts performance but risks data loss during power failures.</li>
<li><strong>Example</strong>:
<ul>
<li>A file system using <code class="language-text">write-back</code> might delay flushing data, ensuring faster response for applications.</li>
</ul>
</li>
</ul>
</li>
<li><strong>Read-Ahead Caching</strong>:
<ul>
<li>The system predicts future read requests and preloads data into the cache.</li>
<li><strong>Example</strong>:
<ul>
<li>Streaming a movie benefits from read-ahead because upcoming frames can be prefetched into memory.</li>
</ul>
</li>
</ul>
</li>
<li><strong>Second-Level Cache</strong>:
<ul>
<li>Intermediate storage (e.g., SSD cache for an HDD array) bridges the performance gap.</li>
<li><strong>Example</strong>:
<ul>
<li>Intel Optane memory acts as a cache layer for HDDs in many consumer systems.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Synchronous vs. Asynchronous Writes</strong>:</p>
<ul>
<li><strong>Synchronous Writes</strong>:
<ul>
<li>Guarantees that data is physically written to disk before confirming success.</li>
<li><strong>Example</strong>: A database update requiring immediate durability uses synchronous writes.</li>
</ul>
</li>
<li><strong>Asynchronous Writes</strong>:
<ul>
<li>Allows data to remain in memory temporarily, acknowledging the operation before it’s written to disk.</li>
<li><strong>Example</strong>: Logging services optimize for speed by writing logs asynchronously.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Metadata Handling</strong>:</p>
<ul>
<li>Metadata operations, like creating or modifying files, introduce overhead as they involve updating file system structures (e.g., inode tables).</li>
<li><strong>Example</strong>:
<ul>
<li>Frequent small file creations, as in a mail server, can experience bottlenecks due to excessive metadata updates.</li>
</ul>
</li>
</ul>
</li>
</ol>
<hr>
<h2 id="observability-tools-for-file-systems" style="position:relative;"><a href="#observability-tools-for-file-systems" aria-label="observability tools for file systems permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Observability Tools for File Systems</strong></h2>
<ol>
<li>
<p><strong>Tools for Monitoring and Diagnosis</strong>:</p>
<ul>
<li>
<p><strong><code class="language-text">iostat</code></strong>:</p>
<ul>
<li>Monitors disk I/O performance and highlights key metrics:
<ul>
<li><strong>Device Utilization</strong>: The percentage of time the device is busy.</li>
<li><strong>Throughput</strong>: Data read/write rate in KB/s.</li>
<li><strong>Queue Depth</strong>: Number of requests waiting for the device.</li>
</ul>
</li>
<li><strong>Example</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">iostat -dx 1</code></pre></div>
Output includes:
<ul>
<li><strong>%util</strong>: High utilization indicates the disk is saturated.</li>
<li><strong>await</strong>: Average time (ms) for requests to complete, helping identify latency issues.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong><code class="language-text">sar</code></strong>:</p>
<ul>
<li>Collects and displays historical disk activity:
<ul>
<li><strong>Example Command</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">sar -d 1 10</code></pre></div>
Provides per-device statistics such as average IOPS and request service times.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong><code class="language-text">bpftrace</code></strong>:</p>
<ul>
<li>Captures low-level file system operations using dynamic tracing.</li>
<li><strong>Example Script</strong>:
<ul>
<li>Monitoring file read latency:
<div class="gatsby-highlight" data-language="bpftrace"><pre class="language-bpftrace"><code class="language-bpftrace">tracepoint:syscalls:sys_enter_read {
    @latency[pid, comm] = hist(latency);
}</code></pre></div>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Advanced Tools</strong>:</p>
<ul>
<li><strong><code class="language-text">strace</code></strong>:
<ul>
<li>Tracks system calls made by processes, helping identify delays in file I/O.</li>
<li><strong>Example</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">strace -e trace=open,read,write my_app</code></pre></div>
Reveals how often the application is performing I/O and the time spent on each operation.</li>
</ul>
</li>
<li><strong><code class="language-text">opensnoop</code></strong>:
<ul>
<li>Tracks open system calls in real-time.</li>
<li><strong>Example</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">opensnoop</code></pre></div>
Displays the files accessed by applications.</li>
</ul>
</li>
<li><strong><code class="language-text">cachestat</code></strong>:
<ul>
<li>Monitors cache hits and misses, providing insights into the efficiency of the file system cache.</li>
<li><strong>Example</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">cachestat 1</code></pre></div>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Visualization Tools</strong>:</p>
<ul>
<li>Tools like Grafana integrated with Prometheus or InfluxDB can display:
<ul>
<li><strong>Heatmaps</strong>: Distribution of I/O latency.</li>
<li><strong>Graphs</strong>: Trends in disk usage, cache performance, or throughput.</li>
</ul>
</li>
</ul>
</li>
</ol>
<hr>
<h2 id="tuning-for-performance-and-scalability" style="position:relative;"><a href="#tuning-for-performance-and-scalability" aria-label="tuning for performance and scalability permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Tuning for Performance and Scalability</strong></h2>
<ol>
<li>
<p><strong>File System Types</strong>:</p>
<ul>
<li>Choosing the right file system based on workload is crucial.</li>
<li><strong>Ext4</strong>:
<ul>
<li>General-purpose, efficient journaling file system.</li>
<li><strong>Example</strong>: Best for desktops and general workloads.</li>
</ul>
</li>
<li><strong>XFS</strong>:
<ul>
<li>Scalable and optimized for parallel I/O.</li>
<li><strong>Example</strong>: Preferred for large databases.</li>
</ul>
</li>
<li><strong>ZFS</strong>:
<ul>
<li>Focuses on data integrity with features like snapshots.</li>
<li><strong>Example</strong>: Ideal for backup and archival storage.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>I/O Scheduler Optimization</strong>:</p>
<ul>
<li>Linux offers multiple I/O schedulers:
<ul>
<li><strong>CFQ</strong> (Completely Fair Queuing): Balances performance across workloads.</li>
<li><strong>Deadline</strong>: Reduces latency for latency-sensitive applications.</li>
<li><strong>Example</strong>: For databases, switch to the <code class="language-text">deadline</code> scheduler:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">echo "deadline" > /sys/block/sda/queue/scheduler</code></pre></div>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Mount Options</strong>:</p>
<ul>
<li>Customize mount options for performance:
<ul>
<li><strong><code class="language-text">noatime</code></strong>: Disables updating access timestamps, reducing write operations.</li>
<li><strong><code class="language-text">nodiratime</code></strong>: Optimizes directory metadata updates.</li>
<li><strong>Example</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">mount -o noatime,nodiratime /dev/sda1 /mnt/data</code></pre></div>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Read-Ahead Tuning</strong>:</p>
<ul>
<li>Adjust read-ahead settings for sequential workloads:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">blockdev --setra 2048 /dev/sda</code></pre></div>
</li>
<li>Higher values are beneficial for workloads like video streaming.</li>
</ul>
</li>
<li>
<p><strong>Caching Parameters</strong>:</p>
<ul>
<li>Modify kernel caching settings:
<ul>
<li><strong>Example</strong>:
<ul>
<li>To increase dirty page ratio (write-back caching):
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">echo 20 > /proc/sys/vm/dirty_ratio</code></pre></div>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Workload Separation</strong>:</p>
<ul>
<li>Use dedicated partitions or disks for specific workloads to avoid contention.</li>
<li><strong>Example</strong>:
<ul>
<li>Logs on separate SSDs reduce interference with database workloads on HDDs.</li>
</ul>
</li>
</ul>
</li>
</ol>
<hr>
<h2 id="examples-and-real-life-use-cases" style="position:relative;"><a href="#examples-and-real-life-use-cases" aria-label="examples and real life use cases permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Examples and Real-Life Use Cases</strong></h2>
<ol>
<li>
<p><strong>Video Streaming Service</strong>:</p>
<ul>
<li>Optimized read-ahead cache to ensure smooth playback.</li>
<li>Used heatmaps to monitor latency spikes during peak usage.</li>
</ul>
</li>
<li>
<p><strong>High-Throughput Database</strong>:</p>
<ul>
<li>Switched to the <code class="language-text">deadline</code> I/O scheduler to reduce query response times.</li>
<li>Mounted with <code class="language-text">noatime</code> and increased dirty ratio for faster writes.</li>
</ul>
</li>
<li>
<p><strong>Web Server</strong>:</p>
<ul>
<li>Reduced metadata overhead with <code class="language-text">nodiratime</code>.</li>
<li>Utilized <code class="language-text">bpftrace</code> to identify inefficient file access patterns, improving response times.</li>
</ul>
</li>
</ol>
<hr>
<h2 id="key-highlights" style="position:relative;"><a href="#key-highlights" aria-label="key highlights permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Key Highlights</strong>:</h2>
<ul>
<li><strong>“File system performance hinges on matching configurations to workload patterns.”</strong></li>
<li><strong>“Observability tools like <code class="language-text">iostat</code> and <code class="language-text">sar</code> empower real-time insights and historical trend analysis.”</strong></li>
<li><strong>“Optimizing mount options, scheduler settings, and caching parameters can drastically improve scalability.”</strong></li>
</ul>
<h1 id="disks" style="position:relative;"><a href="#disks" aria-label="disks permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Disks</strong></h1>
<hr>
<h2 id="storage-architecture-and-performance-concepts" style="position:relative;"><a href="#storage-architecture-and-performance-concepts" aria-label="storage architecture and performance concepts permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Storage Architecture and Performance Concepts</strong></h2>
<ol>
<li>
<p><strong>Fundamentals of Storage Architecture</strong>:</p>
<ul>
<li><strong>Hard Disk Drives (HDDs)</strong>:
<ul>
<li>Built with spinning magnetic platters and a mechanical arm (actuator) for reading/writing data.</li>
<li><strong>Performance Traits</strong>:
<ul>
<li>Latency driven by <strong>seek time</strong> and <strong>rotational delay</strong>.</li>
<li>Best suited for <strong>sequential access workloads</strong> (e.g., log storage, media files).</li>
<li>Throughput limited to <strong>~100-200 MB/s</strong> on average.</li>
</ul>
</li>
</ul>
</li>
<li><strong>Solid-State Drives (SSDs)</strong>:
<ul>
<li>No moving parts, relying on NAND flash memory for data storage.</li>
<li><strong>Performance Traits</strong>:
<ul>
<li>Offers <strong>microsecond-level latency</strong> and high IOPS.</li>
<li>Ideal for random read/write workloads such as <strong>databases</strong>.</li>
<li>Sequential throughput exceeds <strong>500 MB/s</strong> (SATA) and <strong>3500 MB/s</strong> (NVMe).</li>
</ul>
</li>
</ul>
</li>
<li><strong>NVMe Drives</strong>:
<ul>
<li>SSDs optimized for PCIe interfaces, bypassing traditional storage controllers.</li>
<li><strong>Performance Advantages</strong>:
<ul>
<li>Up to <strong>7 GB/s throughput</strong> and <strong>millions of IOPS</strong>.</li>
<li>Designed for latency-sensitive applications like <strong>AI/ML workloads</strong> and <strong>high-performance databases</strong>.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Disk Interfaces</strong>:</p>
<ul>
<li><strong>SATA (Serial ATA)</strong>:
<ul>
<li>Standard for consumer SSDs/HDDs.</li>
<li>Maximum speed: <strong>6 Gbps (~600 MB/s)</strong>.</li>
</ul>
</li>
<li><strong>SAS (Serial Attached SCSI)</strong>:
<ul>
<li>Enterprise-grade interface offering better reliability and throughput than SATA.</li>
<li>Speed: <strong>12 Gbps (~1.2 GB/s)</strong>.</li>
</ul>
</li>
<li><strong>PCIe/NVMe</strong>:
<ul>
<li>Next-generation interface for SSDs, allowing direct communication with the CPU.</li>
<li>Speeds range from <strong>8 GB/s to 16 GB/s</strong>, depending on PCIe version.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Caching in Disk Systems</strong>:</p>
<ul>
<li><strong>Write-Back Cache</strong>:
<ul>
<li>Data temporarily stored in RAM before being written to the disk.</li>
<li><strong>Example</strong>:
<ul>
<li>A database server writes transactions to cache, batching them for disk writes to reduce I/O overhead.</li>
</ul>
</li>
</ul>
</li>
<li><strong>Read Cache</strong>:
<ul>
<li>Frequently accessed data is preloaded into memory.</li>
<li><strong>Example</strong>:
<ul>
<li>In a web server, popular static assets like images benefit from read caching, reducing repetitive disk accesses.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>RAID Configurations</strong>:</p>
<ul>
<li>Balances redundancy and performance by combining multiple disks:
<ul>
<li><strong>RAID 0 (Striping)</strong>:
<ul>
<li>Splits data across multiple disks for higher throughput but offers no fault tolerance.</li>
<li>Use Case: Video editing or large-scale read operations.</li>
</ul>
</li>
<li><strong>RAID 1 (Mirroring)</strong>:
<ul>
<li>Duplicates data across disks for redundancy.</li>
<li>Use Case: Critical systems requiring high availability.</li>
</ul>
</li>
<li><strong>RAID 10</strong>:
<ul>
<li>Combines RAID 0 and RAID 1 for fault tolerance and performance.</li>
<li>Use Case: High-performance transactional databases.</li>
</ul>
</li>
<li><strong>RAID 5/6</strong>:
<ul>
<li>Offers redundancy with parity but slower write performance.</li>
<li>Use Case: Large archival systems or backup solutions.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ol>
<hr>
<h2 id="tools-for-disk-performance-monitoring" style="position:relative;"><a href="#tools-for-disk-performance-monitoring" aria-label="tools for disk performance monitoring permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Tools for Disk Performance Monitoring</strong></h2>
<ol>
<li>
<p><strong><code class="language-text">iostat</code></strong>:</p>
<ul>
<li><strong>Purpose</strong>:
<ul>
<li>Provides I/O statistics for devices and partitions.</li>
</ul>
</li>
<li><strong>Key Metrics</strong>:
<ul>
<li><strong>%util</strong>: Percentage of time the disk is busy.</li>
<li><strong>await</strong>: Average wait time for I/O requests in milliseconds.</li>
<li><strong>r/s, w/s</strong>: Read/write operations per second.</li>
</ul>
</li>
<li><strong>Example Usage</strong>:
<ul>
<li>Real-time monitoring:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">iostat -dx 1</code></pre></div>
</li>
<li>Output Breakdown:
<ul>
<li><strong>Device</strong>: <code class="language-text">/dev/sda</code>.</li>
<li><strong>r/s</strong>: 150 (150 read ops per second).</li>
<li><strong>await</strong>: 20 ms (average latency).</li>
</ul>
</li>
<li><strong>Interpretation</strong>:
<ul>
<li>High <strong>%util</strong> (>80%) and <strong>await</strong> (>10 ms) indicate potential I/O bottlenecks.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong><code class="language-text">blktrace</code></strong>:</p>
<ul>
<li><strong>Purpose</strong>:
<ul>
<li>Captures and analyzes low-level block I/O events for detailed performance insights.</li>
</ul>
</li>
<li><strong>Key Capabilities</strong>:
<ul>
<li>Tracks queue depth, I/O latency, and device utilization.</li>
</ul>
</li>
<li><strong>Example Usage</strong>:
<ul>
<li>Start tracing:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">blktrace -d /dev/sda -o trace</code></pre></div>
</li>
<li>Analyze results:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">blkparse trace</code></pre></div>
</li>
</ul>
</li>
<li><strong>Use Case</strong>:
<ul>
<li>Detect misaligned partitioning causing high read/write latencies.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong><code class="language-text">fio</code> (Flexible I/O Tester)</strong>:</p>
<ul>
<li><strong>Purpose</strong>:
<ul>
<li>Simulates I/O workloads to benchmark and stress test storage devices.</li>
</ul>
</li>
<li><strong>Example Usage</strong>:
<ul>
<li>Sequential read test with 4 KB block size:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">fio --name=test --rw=read --bs=4k --size=1G --numjobs=4 --ioengine=libaio</code></pre></div>
</li>
<li>Results include:
<ul>
<li>IOPS: 100,000</li>
<li>Latency: 1.5 ms</li>
</ul>
</li>
<li><strong>Interpretation</strong>:
<ul>
<li>Confirms the suitability of an NVMe SSD for a high-read application workload.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong><code class="language-text">smartctl</code></strong>:</p>
<ul>
<li><strong>Purpose</strong>:
<ul>
<li>Monitors disk health using S.M.A.R.T. attributes.</li>
</ul>
</li>
<li><strong>Example Usage</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">smartctl -a /dev/sda</code></pre></div>
<ul>
<li>Key outputs:
<ul>
<li><strong>Reallocated Sector Count</strong>: Indicator of bad sectors.</li>
<li><strong>Power-On Hours</strong>: Total operating time.</li>
</ul>
</li>
<li><strong>Interpretation</strong>:
<ul>
<li>A high reallocated sector count suggests impending drive failure.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Visualization</strong>:</p>
<ul>
<li>Integrate metrics into tools like <strong>Grafana</strong> or <strong>Prometheus</strong> for real-time dashboards:
<ul>
<li><strong>Latency Heatmaps</strong>:
<ul>
<li>Show latency distribution to detect outliers.</li>
</ul>
</li>
<li><strong>Throughput Graphs</strong>:
<ul>
<li>Monitor sustained read/write performance trends.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ol>
<hr>
<h2 id="tuning-techniques-for-disk-io-workloads" style="position:relative;"><a href="#tuning-techniques-for-disk-io-workloads" aria-label="tuning techniques for disk io workloads permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Tuning Techniques for Disk I/O Workloads</strong></h2>
<ol>
<li>
<p><strong>Optimizing I/O Scheduler</strong>:</p>
<ul>
<li>Modern Linux systems provide multiple I/O schedulers:
<ul>
<li><strong>noop</strong>:
<ul>
<li>Minimal overhead; best for SSDs or NVMe drives.</li>
</ul>
</li>
<li><strong>deadline</strong>:
<ul>
<li>Reduces latency by prioritizing I/O requests with deadlines.</li>
</ul>
</li>
<li><strong>cfq</strong>:
<ul>
<li>Balances fairness and throughput; suitable for mixed workloads.</li>
</ul>
</li>
</ul>
</li>
<li><strong>Example</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">echo "deadline" > /sys/block/sda/queue/scheduler</code></pre></div>
</li>
</ul>
</li>
<li>
<p><strong>Adjusting Read-Ahead</strong>:</p>
<ul>
<li><strong>Purpose</strong>:
<ul>
<li>Configures how much data is preloaded during sequential reads.</li>
</ul>
</li>
<li><strong>Command</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">blockdev --setra 2048 /dev/sda</code></pre></div>
</li>
<li><strong>Use Case</strong>:
<ul>
<li>Improves video streaming or large file access by prefetching more data.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Aligning Partitions</strong>:</p>
<ul>
<li>Ensures partitions align with physical sector boundaries for optimal performance:
<ul>
<li>Use <code class="language-text">parted</code> or <code class="language-text">gdisk</code>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">parted /dev/sda align-check optimal 1</code></pre></div>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Caching Optimization</strong>:</p>
<ul>
<li>Increase write-back cache size for bursty workloads:
<ul>
<li>Adjust <code class="language-text">dirty_ratio</code>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">echo 30 > /proc/sys/vm/dirty_ratio</code></pre></div>
</li>
</ul>
</li>
<li>Reduce cache flush frequency for write-heavy applications:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">echo 3000 > /proc/sys/vm/dirty_expire_centisecs</code></pre></div>
</li>
</ul>
</li>
<li>
<p><strong>RAID Tuning</strong>:</p>
<ul>
<li>Fine-tune RAID configurations:
<ul>
<li>Adjust <strong>stripe size</strong> for optimal performance:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">mdadm --create /dev/md0 --level=0 --chunk=64 --raid-devices=4 /dev/sd[abcd]</code></pre></div>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Workload Isolation</strong>:</p>
<ul>
<li>Separate high-I/O workloads across different disks to avoid contention:
<ul>
<li><strong>Example</strong>:
<ul>
<li>Place logs on a separate SSD while keeping databases on an NVMe drive.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ol>
<hr>
<h2 id="examples-and-use-cases" style="position:relative;"><a href="#examples-and-use-cases" aria-label="examples and use cases permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Examples and Use Cases</strong></h2>
<ol>
<li>
<p><strong>High-Performance Database</strong>:</p>
<ul>
<li><strong>Challenge</strong>:
<ul>
<li>Latency spikes during high-transaction periods.</li>
</ul>
</li>
<li><strong>Solution</strong>:
<ul>
<li>Switched to NVMe storage.</li>
<li>Tuned I/O scheduler to <code class="language-text">deadline</code>.</li>
<li>Increased <code class="language-text">dirty_ratio</code> for efficient write batching.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Video Streaming Service</strong>:</p>
<ul>
<li><strong>Challenge</strong>:
<ul>
<li>Slow sequential read performance during peak hours.</li>
</ul>
</li>
<li><strong>Solution</strong>:
<ul>
<li>Increased read-ahead to 4 MB.</li>
<li>Used RAID 0 for maximum throughput.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Enterprise Backup System</strong>:</p>
<ul>
<li><strong>Challenge</strong>:
<ul>
<li>Frequent parity calculation bottlenecks in RAID 5.</li>
</ul>
</li>
<li><strong>Solution</strong>:
<ul>
<li>Upgraded to RAID 6 with optimized stripe size.</li>
</ul>
</li>
</ul>
</li>
</ol>
<hr>
<h2 id="key-takeaways-9" style="position:relative;"><a href="#key-takeaways-9" aria-label="key takeaways 9 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Key Takeaways</strong>:</h2>
<ul>
<li><strong>“Storage performance relies on understanding IOPS, latency, and throughput trade-offs.”</strong></li>
<li><strong>“Tools like <code class="language-text">blktrace</code> and <code class="language-text">fio</code> provide granular insights into I/O patterns and bottlenecks.”</strong></li>
<li><strong>“Tuning parameters like I/O scheduler, read-ahead, and cache ratios can dramatically boost performance.”</strong></li>
</ul>
<h1 id="networking" style="position:relative;"><a href="#networking" aria-label="networking permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Networking</strong></h1>
<hr>
<h2 id="networking-concepts-protocols-latency-and-congestion" style="position:relative;"><a href="#networking-concepts-protocols-latency-and-congestion" aria-label="networking concepts protocols latency and congestion permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Networking Concepts: Protocols, Latency, and Congestion</strong></h2>
<ol>
<li>
<p><strong>Detailed Overview of Network Protocols</strong>:</p>
<ul>
<li>Protocols are layered according to the <strong>OSI Model</strong> or <strong>TCP/IP Model</strong>, enabling modular functionality:
<ul>
<li><strong>Layer 2 (Data Link)</strong>:
<ul>
<li><strong>Ethernet</strong> and <strong>Wi-Fi</strong> manage local communication.</li>
<li><strong>Example</strong>:
<ul>
<li>Gigabit Ethernet provides <strong>1 Gbps</strong> throughput and is common in LAN setups.</li>
</ul>
</li>
</ul>
</li>
<li><strong>Layer 3 (Network)</strong>:
<ul>
<li><strong>IP (Internet Protocol)</strong>:
<ul>
<li>Core protocol for routing.</li>
<li>IPv4 supports <strong>4.3 billion unique addresses</strong>, whereas IPv6 supports <strong>3.4×10³⁸ addresses</strong>.</li>
</ul>
</li>
</ul>
</li>
<li><strong>Layer 4 (Transport)</strong>:
<ul>
<li><strong>TCP (Transmission Control Protocol)</strong>:
<ul>
<li>Establishes reliable connections with <strong>handshakes, acknowledgments (ACKs)</strong>, and retransmissions.</li>
<li><strong>Example</strong>:
<ul>
<li>Used in web browsing (HTTP), email (SMTP), and file transfer (FTP).</li>
</ul>
</li>
</ul>
</li>
<li><strong>UDP (User Datagram Protocol)</strong>:
<ul>
<li>Lightweight, connectionless protocol for real-time services.</li>
<li><strong>Example</strong>:
<ul>
<li>Online gaming and streaming services like <strong>Netflix</strong>.</li>
</ul>
</li>
</ul>
</li>
<li><strong>Key Point</strong>:
<ul>
<li>“TCP is for reliability; UDP is for speed.”</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Network Latency</strong>:</p>
<ul>
<li>Latency includes the <strong>sum of delays</strong> from the following components:
<ul>
<li><strong>Propagation Delay</strong>:
<ul>
<li>Physical signal travel time.</li>
<li><strong>Example</strong>:
<ul>
<li>A 1,000 km fiber-optic link adds <strong>5 ms propagation delay</strong>.</li>
</ul>
</li>
</ul>
</li>
<li><strong>Serialization Delay</strong>:
<ul>
<li>Time to transmit data onto the wire.</li>
<li>Depends on link speed:
<ul>
<li>A <strong>10 Mbps</strong> link has higher serialization delay than a <strong>10 Gbps</strong> link for the same data.</li>
</ul>
</li>
</ul>
</li>
<li><strong>Processing Delay</strong>:
<ul>
<li>Time spent on routing and packet forwarding by devices.</li>
</ul>
</li>
<li><strong>Queuing Delay</strong>:
<ul>
<li>Time packets wait in a buffer before being transmitted.</li>
<li>High during <strong>network congestion</strong>.</li>
</ul>
</li>
</ul>
</li>
<li><strong>Key Point</strong>:
<ul>
<li>“Latency is the Achilles’ heel of real-time applications; reducing it requires tuning across all layers.”</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Network Congestion</strong>:</p>
<ul>
<li>Congestion occurs when <strong>demand exceeds bandwidth capacity</strong>, leading to:
<ul>
<li><strong>Packet Loss</strong>:
<ul>
<li>Routers discard packets when buffers overflow.</li>
<li><strong>Example</strong>:
<ul>
<li>Packet loss above 1% impacts VoIP and video quality.</li>
</ul>
</li>
</ul>
</li>
<li><strong>Jitter</strong>:
<ul>
<li>Variability in packet arrival times.</li>
<li>Problematic for real-time protocols like <strong>RTP (Real-time Transport Protocol)</strong>.</li>
</ul>
</li>
<li><strong>Bufferbloat</strong>:
<ul>
<li>Excessive buffering causes <strong>high latency</strong>.</li>
</ul>
</li>
</ul>
</li>
<li><strong>Congestion Management Techniques</strong>:
<ul>
<li><strong>TCP Congestion Control</strong>:
<ul>
<li>Algorithms like <strong>Reno</strong>, <strong>Cubic</strong>, and <strong>BBR</strong> dynamically adjust throughput based on network conditions.</li>
<li><strong>BBR Example</strong>:
<ul>
<li>Reduces latency by estimating available bandwidth and minimizing queue buildup.</li>
</ul>
</li>
</ul>
</li>
<li><strong>Quality of Service (QoS)</strong>:
<ul>
<li>Allocates bandwidth for critical traffic (e.g., prioritizing VoIP over bulk downloads).</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ol>
<hr>
<h2 id="observability-tools-for-networking" style="position:relative;"><a href="#observability-tools-for-networking" aria-label="observability tools for networking permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Observability Tools for Networking</strong></h2>
<ol>
<li>
<p><strong>Advanced Packet Analysis with <code class="language-text">tcpdump</code></strong>:</p>
<ul>
<li><strong>Overview</strong>:
<ul>
<li>Command-line tool to capture and analyze network traffic.</li>
</ul>
</li>
<li><strong>Advanced Use Cases</strong>:
<ul>
<li>Filter by protocol and IP:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">tcpdump -i eth0 tcp and host 192.168.1.10</code></pre></div>
</li>
<li>Analyze DNS traffic:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">tcpdump -i eth0 port 53</code></pre></div>
</li>
<li>Save captures for offline debugging:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">tcpdump -w mycapture.pcap</code></pre></div>
</li>
</ul>
</li>
<li><strong>Example</strong>:
<ul>
<li>Identify TCP retransmissions:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">tcpdump -i eth0 "tcp[tcpflags] &amp; (tcp-syn|tcp-ack) != 0"</code></pre></div>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>In-Depth Protocol Debugging with Wireshark</strong>:</p>
<ul>
<li><strong>Overview</strong>:
<ul>
<li>GUI-based packet analyzer for human-readable protocol decoding.</li>
</ul>
</li>
<li><strong>Use Cases</strong>:
<ul>
<li>Highlight retransmissions:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">tcp.analysis.retransmission</code></pre></div>
</li>
<li>Filter traffic by IP or application:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">ip.addr == 192.168.1.10</code></pre></div>
</li>
</ul>
</li>
<li><strong>Example</strong>:
<ul>
<li>Troubleshoot HTTPS issues by decrypting SSL/TLS traffic using preloaded keys.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Latency and Connectivity Diagnostics with <code class="language-text">ping</code></strong>:</p>
<ul>
<li><strong>Overview</strong>:
<ul>
<li>Sends ICMP echo requests to measure RTT and packet loss.</li>
</ul>
</li>
<li><strong>Use Cases</strong>:
<ul>
<li>Measure connectivity to a server:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">ping google.com</code></pre></div>
</li>
<li>Analyze packet loss over 100 pings:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">ping -c 100 example.com</code></pre></div>
</li>
</ul>
</li>
<li><strong>Key Insight</strong>:
<ul>
<li>“Low RTT and no packet loss indicate a healthy connection.”</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Route Analysis with <code class="language-text">traceroute</code></strong>:</p>
<ul>
<li><strong>Overview</strong>:
<ul>
<li>Maps the path packets take through intermediate routers.</li>
</ul>
</li>
<li><strong>Use Cases</strong>:
<ul>
<li>Identify bottlenecks along the route:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">traceroute example.com</code></pre></div>
</li>
<li>Trace network issues to specific hops.</li>
</ul>
</li>
<li><strong>Example</strong>:
<ul>
<li>Detect high latency at hop 3 during international traffic.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Flow Monitoring with NetFlow or sFlow</strong>:</p>
<ul>
<li><strong>Overview</strong>:
<ul>
<li>Monitors network flows to identify bandwidth hogs or anomalies.</li>
</ul>
</li>
<li><strong>Example</strong>:
<ul>
<li>Use <strong>NetFlow</strong> data to find a single IP consuming 50% of bandwidth.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Prometheus + Grafana Dashboards</strong>:</p>
<ul>
<li><strong>Overview</strong>:
<ul>
<li>Monitor metrics like packet drops, latency, and bandwidth utilization over time.</li>
</ul>
</li>
<li><strong>Use Case</strong>:
<ul>
<li>Set alerts for latency spikes above <strong>100 ms</strong>.</li>
</ul>
</li>
</ul>
</li>
</ol>
<hr>
<h2 id="network-performance-tuning-and-optimization" style="position:relative;"><a href="#network-performance-tuning-and-optimization" aria-label="network performance tuning and optimization permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Network Performance Tuning and Optimization</strong></h2>
<ol>
<li>
<p><strong>TCP Optimization</strong>:</p>
<ul>
<li>Adjust TCP settings for improved performance:
<ul>
<li><strong>Increase Receive Buffers</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">sysctl -w net.core.rmem_max=8388608</code></pre></div>
</li>
<li><strong>Reduce Retransmission Timeouts</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">sysctl -w net.ipv4.tcp_retries2=5</code></pre></div>
</li>
</ul>
</li>
<li><strong>Example</strong>:
<ul>
<li>For high-speed file transfers over long distances, increase <strong>window sizes</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">sysctl -w net.ipv4.tcp_window_scaling=1</code></pre></div>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Congestion Control Algorithms</strong>:</p>
<ul>
<li>Switch to advanced algorithms like <strong>BBR</strong> for latency-sensitive workloads:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">sysctl -w net.ipv4.tcp_congestion_control=bbr</code></pre></div>
</li>
</ul>
</li>
<li>
<p><strong>QoS (Quality of Service)</strong>:</p>
<ul>
<li><strong>Traffic Prioritization</strong>:
<ul>
<li>Use <strong>tc</strong> (Traffic Control) to allocate bandwidth:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">tc qdisc add dev eth0 root handle 1: htb
tc class add dev eth0 parent 1: classid 1:1 htb rate 1mbit</code></pre></div>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>NIC Offloading Features</strong>:</p>
<ul>
<li>Enable <strong>TSO (TCP Segmentation Offload)</strong> and <strong>LRO (Large Receive Offload)</strong> to reduce CPU load:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">ethtool -K eth0 tso on lro on</code></pre></div>
</li>
</ul>
</li>
<li>
<p><strong>DNS Optimization</strong>:</p>
<ul>
<li>Use local caching with tools like <code class="language-text">dnsmasq</code> to reduce DNS lookup delays.</li>
<li><strong>Example</strong>:
<ul>
<li>Speed up domain resolution for web servers.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Workload Balancing</strong>:</p>
<ul>
<li>Use load balancers like <strong>HAProxy</strong> or <strong>NGINX</strong> to distribute traffic across multiple servers.</li>
</ul>
</li>
</ol>
<hr>
<h2 id="examples-and-case-studies" style="position:relative;"><a href="#examples-and-case-studies" aria-label="examples and case studies permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Examples and Case Studies</strong></h2>
<ol>
<li>
<p><strong>Online Gaming Platform</strong>:</p>
<ul>
<li><strong>Problem</strong>: High jitter disrupting gameplay.</li>
<li><strong>Solution</strong>:
<ul>
<li>Switched to <strong>BBR</strong> congestion control.</li>
<li>Prioritized UDP traffic with <strong>QoS</strong>.</li>
<li>Diagnosed jitter with <strong>Wireshark</strong> and reduced queuing delays.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Global E-Commerce Website</strong>:</p>
<ul>
<li><strong>Problem</strong>: Latency spikes during Black Friday.</li>
<li><strong>Solution</strong>:
<ul>
<li>Used <strong><code class="language-text">tcpdump</code></strong> to detect retransmissions.</li>
<li>Tuned <strong>TCP receive buffers</strong> for faster throughput.</li>
<li>Deployed <strong>Anycast</strong> to optimize routing paths.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Enterprise VoIP System</strong>:</p>
<ul>
<li><strong>Problem</strong>: Packet loss degrading call quality.</li>
<li><strong>Solution</strong>:
<ul>
<li>Prioritized VoIP traffic with <strong>tc</strong>.</li>
<li>Enabled NIC offloading to reduce CPU bottlenecks.</li>
</ul>
</li>
</ul>
</li>
</ol>
<hr>
<h2 id="key-highlights-1" style="position:relative;"><a href="#key-highlights-1" aria-label="key highlights 1 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Key Highlights</strong>:</h2>
<ul>
<li><strong>“Optimizing protocols like TCP and UDP is essential for high-speed, low-latency communication.”</strong></li>
<li><strong>“Tools like <code class="language-text">tcpdump</code> and Wireshark provide granular insights into packet behavior for troubleshooting.”</strong></li>
<li><strong>“Performance tuning involves buffer adjustments, congestion control, QoS, and DNS caching for maximum efficiency.”</strong></li>
</ul>
<h1 id="cloud-computing" style="position:relative;"><a href="#cloud-computing" aria-label="cloud computing permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Cloud Computing</strong></h1>
<hr>
<h2 id="virtualization-and-its-performance-implications" style="position:relative;"><a href="#virtualization-and-its-performance-implications" aria-label="virtualization and its performance implications permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Virtualization and Its Performance Implications</strong></h2>
<ol>
<li>
<p><strong>Comprehensive Overview of Virtualization</strong>:</p>
<ul>
<li>
<p><strong>What is Virtualization?</strong></p>
<ul>
<li>Virtualization abstracts physical hardware resources to enable multiple isolated virtual environments on a single physical machine.</li>
<li>Key types:
<ul>
<li><strong>Hardware Virtualization</strong>:
<ul>
<li>Full virtualization using hypervisors such as <strong>VMware ESXi</strong>, <strong>KVM</strong>, <strong>Hyper-V</strong>, or <strong>Xen</strong>.</li>
<li><strong>Example</strong>:
<ul>
<li>A single server hosts multiple VMs, each running a separate operating system like Linux or Windows.</li>
</ul>
</li>
</ul>
</li>
<li><strong>Paravirtualization</strong>:
<ul>
<li>Guest OS communicates directly with the hypervisor for enhanced performance.</li>
<li><strong>Example</strong>:
<ul>
<li>Xen hypervisor with paravirtualized drivers for disk and network I/O.</li>
</ul>
</li>
</ul>
</li>
<li><strong>OS-Level Virtualization (Containers)</strong>:
<ul>
<li>Lightweight virtualization where containers share the same OS kernel but remain isolated.</li>
<li>Tools: <strong>Docker</strong>, <strong>LXC</strong>, <strong>Podman</strong>.</li>
<li><strong>Example</strong>:
<ul>
<li>A Node.js app and a Python app run in separate containers but share the same Linux kernel.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Key Point</strong>:</p>
<ul>
<li>“Virtualization balances resource utilization, isolation, and flexibility, while containers emphasize efficiency and speed.”</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Performance Implications of Virtualization</strong>:</p>
<ul>
<li>
<p><strong>Overheads</strong>:</p>
<ul>
<li>Hypervisors consume CPU, memory, and I/O resources, reducing the performance available to guest VMs.</li>
<li><strong>Example</strong>:
<ul>
<li>CPU overhead from context switching between VMs and the host kernel can degrade overall throughput by <strong>5-15%</strong>.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Resource Contention</strong>:</p>
<ul>
<li>Competing workloads can lead to bottlenecks in CPU, memory, and disk I/O.</li>
<li><strong>Example</strong>:
<ul>
<li>A VM running a database might experience degraded IOPS if another VM performs intensive disk operations.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Disk Performance</strong>:</p>
<ul>
<li>Virtual disks introduce latency, especially if shared storage systems are involved.</li>
<li><strong>Example</strong>:
<ul>
<li>A database VM using network-attached storage (NAS) might see <strong>20-30% higher latency</strong> compared to local storage.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Network Latency</strong>:</p>
<ul>
<li>Virtual NICs add slight delays compared to physical NICs.</li>
<li><strong>Example</strong>:
<ul>
<li>Containers running on Kubernetes with a virtual overlay network can experience <strong>5-10ms additional latency</strong>.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Key Optimization Techniques</strong>:</p>
<ul>
<li>Use <strong>paravirtualized drivers</strong> for storage and network I/O (e.g., virtio).</li>
<li>Deploy applications on <strong>bare metal</strong> when latency-sensitive workloads (e.g., high-frequency trading) demand maximum performance.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Comparison: Containers vs. VMs</strong>:</p>
<ul>
<li><strong>Containers</strong>:
<ul>
<li>Faster startup (milliseconds), lightweight, efficient resource utilization.</li>
<li>Limited security isolation compared to VMs.</li>
</ul>
</li>
<li><strong>Virtual Machines</strong>:
<ul>
<li>Strong isolation, broader OS compatibility, higher overhead.</li>
</ul>
</li>
<li><strong>Example</strong>:
<ul>
<li>A microservices architecture with dynamic scaling is ideal for containers, while legacy applications needing full OS support work best on VMs.</li>
</ul>
</li>
</ul>
</li>
</ol>
<hr>
<h2 id="cloud-observability-techniques" style="position:relative;"><a href="#cloud-observability-techniques" aria-label="cloud observability techniques permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Cloud Observability Techniques</strong></h2>
<ol>
<li>
<p><strong>What is Cloud Observability?</strong></p>
<ul>
<li>The ability to monitor, trace, and debug applications and infrastructure in dynamic, distributed cloud environments.</li>
<li>Focus areas:
<ul>
<li><strong>Performance Metrics</strong>: CPU, memory, disk I/O, and network throughput.</li>
<li><strong>Latency</strong>: End-to-end request times.</li>
<li><strong>Errors</strong>: Application and infrastructure failures.</li>
<li><strong>Scalability</strong>: Resource utilization and auto-scaling effectiveness.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Observability Techniques</strong>:</p>
<ul>
<li>
<p><strong>Metrics Collection</strong>:</p>
<ul>
<li>Monitor resource usage in real-time.</li>
<li>Tools:
<ul>
<li><strong>AWS CloudWatch</strong>:
<ul>
<li>Provides EC2 instance metrics like CPU utilization, disk IOPS, and network throughput.</li>
</ul>
</li>
<li><strong>Prometheus</strong>:
<ul>
<li>Collects metrics across Kubernetes pods, nodes, and services.</li>
</ul>
</li>
<li><strong>Grafana</strong>:
<ul>
<li>Visualizes metrics in time-series dashboards.</li>
</ul>
</li>
</ul>
</li>
<li><strong>Example</strong>:
<ul>
<li>Detect memory spikes in a Kubernetes pod causing restarts.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Distributed Tracing</strong>:</p>
<ul>
<li>Tracks requests across multiple services to pinpoint latency bottlenecks.</li>
<li>Tools:
<ul>
<li><strong>Jaeger</strong> and <strong>OpenTelemetry</strong>.</li>
</ul>
</li>
<li><strong>Example</strong>:
<ul>
<li>Trace a user’s request through an API gateway, authentication service, and database to identify delays.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Log Aggregation</strong>:</p>
<ul>
<li>Centralize logs from VMs, containers, and serverless functions.</li>
<li>Tools:
<ul>
<li><strong>Elasticsearch, Logstash, Kibana (ELK Stack)</strong>.</li>
<li><strong>Datadog</strong>: Unified monitoring and logging.</li>
</ul>
</li>
<li><strong>Example</strong>:
<ul>
<li>Search for application error logs in Kubernetes pods experiencing <strong>OOMKilled</strong> events.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Infrastructure Monitoring</strong>:</p>
<ul>
<li>Analyze VM, container, and serverless performance.</li>
<li>Tools:
<ul>
<li><strong>cAdvisor</strong>: Tracks container-level resource usage.</li>
<li><strong>New Relic</strong>: Provides deep insights into application performance.</li>
<li><strong>AWS Lambda Insights</strong>: Monitors execution time and memory for serverless functions.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Automation</strong>:</p>
<ul>
<li>Use observability data for auto-scaling and alerting.</li>
<li><strong>Example</strong>:
<ul>
<li>Automatically scale Kubernetes pods when CPU usage exceeds <strong>80%</strong> for 5 minutes.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Key Point</strong>:</p>
<ul>
<li>“Observability tools transform raw metrics into actionable insights, enabling proactive management.”</li>
</ul>
</li>
</ul>
</li>
</ol>
<hr>
<h2 id="case-studies-on-virtualization-methods-like-containers" style="position:relative;"><a href="#case-studies-on-virtualization-methods-like-containers" aria-label="case studies on virtualization methods like containers permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Case Studies on Virtualization Methods Like Containers</strong></h2>
<ol>
<li>
<p><strong>Case Study 1: E-Commerce Platform Scaling with Kubernetes</strong>:</p>
<ul>
<li><strong>Problem</strong>:
<ul>
<li>Black Friday sales caused web servers in VMs to saturate CPU and memory, leading to downtime.</li>
</ul>
</li>
<li><strong>Solution</strong>:
<ul>
<li>Migrated to Kubernetes, deploying microservices in containers.</li>
<li><strong>Implementation</strong>:
<ul>
<li>Used <strong>Horizontal Pod Autoscaler (HPA)</strong> to scale containers dynamically based on traffic.</li>
<li>Set up <strong>Prometheus</strong> and <strong>Grafana</strong> for real-time monitoring of pod health.</li>
</ul>
</li>
<li><strong>Outcome</strong>:
<ul>
<li>Achieved 3x faster scaling with zero downtime during peak traffic.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Case Study 2: Media Streaming with Serverless Functions</strong>:</p>
<ul>
<li><strong>Problem</strong>:
<ul>
<li>Video transcoding workloads overloaded VMs during peak usage, causing delays.</li>
</ul>
</li>
<li><strong>Solution</strong>:
<ul>
<li>Migrated transcoding tasks to <strong>AWS Lambda</strong> functions.</li>
<li><strong>Implementation</strong>:
<ul>
<li>Used <strong>CloudWatch Metrics</strong> to track cold start times and throughput.</li>
<li>Deployed <strong>S3 triggers</strong> to launch Lambda functions on video uploads.</li>
</ul>
</li>
<li><strong>Outcome</strong>:
<ul>
<li>Reduced transcoding latency by <strong>40%</strong> and scaled seamlessly to handle peak demand.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Case Study 3: Financial Institution with Hybrid Cloud</strong>:</p>
<ul>
<li><strong>Problem</strong>:
<ul>
<li>Regulatory requirements demanded on-premises processing for sensitive workloads but required cloud flexibility for analytics.</li>
</ul>
</li>
<li><strong>Solution</strong>:
<ul>
<li>Deployed a hybrid cloud with on-premises VMs for sensitive workloads and AWS for analytics.</li>
<li><strong>Implementation</strong>:
<ul>
<li>Set up a <strong>direct connect</strong> between on-prem and AWS for low-latency data transfers.</li>
<li>Used <strong>Datadog</strong> for unified observability across environments.</li>
</ul>
</li>
<li><strong>Outcome</strong>:
<ul>
<li>Achieved compliance and reduced operational costs by <strong>25%</strong>.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Case Study 4: DevOps Pipeline with Containers</strong>:</p>
<ul>
<li><strong>Problem</strong>:
<ul>
<li>Long build and deployment times in a VM-based CI/CD pipeline.</li>
</ul>
</li>
<li><strong>Solution</strong>:
<ul>
<li>Transitioned to containerized CI/CD pipeline using <strong>Jenkins</strong> and <strong>Docker</strong>.</li>
<li><strong>Implementation</strong>:
<ul>
<li>Each build ran in an isolated container, eliminating dependency conflicts.</li>
<li>Observability added with <strong>cAdvisor</strong> to monitor resource utilization during builds.</li>
</ul>
</li>
<li><strong>Outcome</strong>:
<ul>
<li>Reduced build times by <strong>60%</strong> and improved developer productivity.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ol>
<hr>
<h2 id="key-highlights-2" style="position:relative;"><a href="#key-highlights-2" aria-label="key highlights 2 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Key Highlights</strong>:</h2>
<ul>
<li><strong>“Virtualization introduces efficiency but requires tuning to mitigate resource contention and overhead.”</strong></li>
<li><strong>“Cloud observability bridges the gap between metrics and insights, enabling proactive issue resolution in dynamic environments.”</strong></li>
<li><strong>“Real-world case studies illustrate the scalability and flexibility benefits of containers, serverless functions, and hybrid cloud models.”</strong></li>
</ul>
<h1 id="benchmarking" style="position:relative;"><a href="#benchmarking" aria-label="benchmarking permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Benchmarking</strong></h1>
<p>Benchmarking is the process of <strong>measuring system performance under controlled conditions</strong> to evaluate its efficiency, scalability, and resource utilization. This chapter explores the types of benchmarks, tools, methodologies, and common pitfalls, providing a structured approach to conducting reliable benchmarks.</p>
<hr>
<h2 id="121-purpose-of-benchmarking" style="position:relative;"><a href="#121-purpose-of-benchmarking" aria-label="121 purpose of benchmarking permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>12.1 Purpose of Benchmarking</strong></h2>
<h3 id="definition-8" style="position:relative;"><a href="#definition-8" aria-label="definition 8 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Definition</strong>:</h3>
<ul>
<li>Benchmarking involves executing workloads on a system to measure and compare performance across <strong>different hardware, configurations, or software versions</strong>.</li>
</ul>
<h3 id="key-goals" style="position:relative;"><a href="#key-goals" aria-label="key goals permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Key Goals</strong>:</h3>
<ol>
<li>
<p><strong>Performance Measurement</strong>:</p>
<ul>
<li>Determine key performance indicators (KPIs) such as <strong>throughput</strong>, <strong>latency</strong>, and <strong>resource utilization</strong>.</li>
<li><strong>Highlight</strong>: “Benchmarking quantifies performance for informed decision-making.”</li>
</ul>
</li>
<li>
<p><strong>Optimization</strong>:</p>
<ul>
<li>Identify bottlenecks and evaluate the impact of optimizations.</li>
<li>Example:
<ul>
<li>Assess the impact of enabling huge pages on a database server’s query throughput.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Scalability Testing</strong>:</p>
<ul>
<li>Measure how the system handles increased load or scaling configurations.</li>
<li><strong>Highlight</strong>: “Scalability benchmarks reveal the limits of system capacity.”</li>
</ul>
</li>
<li>
<p><strong>Comparison</strong>:</p>
<ul>
<li>Compare different hardware platforms, cloud environments, or software versions.</li>
<li>Example:
<ul>
<li>Evaluate the performance of two cloud providers for a high-traffic web application.</li>
</ul>
</li>
</ul>
</li>
</ol>
<hr>
<h2 id="122-types-of-benchmarks" style="position:relative;"><a href="#122-types-of-benchmarks" aria-label="122 types of benchmarks permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>12.2 Types of Benchmarks</strong></h2>
<p>Benchmarks are categorized based on their purpose, scope, and the aspects of system performance they measure. The primary types include <strong>synthetic benchmarks</strong>, <strong>application benchmarks</strong>, <strong>microbenchmarks</strong>, and <strong>end-to-end benchmarks</strong>. Each type serves a specific purpose, and the choice depends on the performance aspect being analyzed.</p>
<hr>
<h3 id="1221-synthetic-benchmarks" style="position:relative;"><a href="#1221-synthetic-benchmarks" aria-label="1221 synthetic benchmarks permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>12.2.1 Synthetic Benchmarks</strong></h3>
<h4 id="definition-9" style="position:relative;"><a href="#definition-9" aria-label="definition 9 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Definition</strong>:</h4>
<p>Synthetic benchmarks simulate workloads to measure specific system components like CPU, memory, disk, or network.</p>
<h4 id="purpose-1" style="position:relative;"><a href="#purpose-1" aria-label="purpose 1 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Purpose</strong>:</h4>
<ul>
<li>Evaluate <strong>individual components</strong> of the system under controlled conditions.</li>
<li>Provide <strong>repeatable and comparable results</strong> for different hardware or software configurations.</li>
</ul>
<h4 id="tools-9" style="position:relative;"><a href="#tools-9" aria-label="tools 9 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Tools</strong>:</h4>
<ol>
<li>
<p><strong>CPU Benchmarking</strong>:</p>
<ul>
<li><strong><code class="language-text">sysbench</code></strong>:
<ul>
<li>Example:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">sysbench <span class="token parameter variable">--test</span><span class="token operator">=</span>cpu --cpu-max-prime<span class="token operator">=</span><span class="token number">20000</span> run</code></pre></div>
<ul>
<li>Measures the number of prime numbers calculated up to a specified value.</li>
</ul>
</li>
<li><strong>Result</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">CPU speed:
    events per second: 1200</code></pre></div>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Disk I/O Benchmarking</strong>:</p>
<ul>
<li><strong>FIO (Flexible I/O Tester)</strong>:
<ul>
<li>Example:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">fio <span class="token parameter variable">--name</span><span class="token operator">=</span>random-read <span class="token parameter variable">--rw</span><span class="token operator">=</span>randread <span class="token parameter variable">--bs</span><span class="token operator">=</span>4k <span class="token parameter variable">--size</span><span class="token operator">=</span>1G <span class="token parameter variable">--numjobs</span><span class="token operator">=</span><span class="token number">4</span> <span class="token parameter variable">--runtime</span><span class="token operator">=</span><span class="token number">60</span></code></pre></div>
<ul>
<li>Measures random read performance with 4KB block size.</li>
</ul>
</li>
<li><strong>Result</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">READ: bw=150MiB/s, IOPS=38400</code></pre></div>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Network Benchmarking</strong>:</p>
<ul>
<li><strong><code class="language-text">iperf3</code></strong>:
<ul>
<li>Example:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">iperf3 <span class="token parameter variable">-c</span> server_ip <span class="token parameter variable">-t</span> <span class="token number">30</span></code></pre></div>
<ul>
<li>Measures network throughput between a client and server.</li>
</ul>
</li>
<li><strong>Result</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">[ ID] Interval        Transfer      Bandwidth
[  4]   0.00-30.00  3.2 GBytes  915 Mbits/sec</code></pre></div>
</li>
</ul>
</li>
</ul>
</li>
</ol>
<h4 id="example-scenario" style="position:relative;"><a href="#example-scenario" aria-label="example scenario permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example Scenario</strong>:</h4>
<ul>
<li><strong>Use Case</strong>:
<ul>
<li>Compare the disk performance of SSDs and HDDs.</li>
</ul>
</li>
<li><strong>Outcome</strong>:
<ul>
<li>SSD achieves 500MB/s sequential write speed compared to 120MB/s for HDD.</li>
</ul>
</li>
</ul>
<hr>
<h3 id="1222-application-benchmarks" style="position:relative;"><a href="#1222-application-benchmarks" aria-label="1222 application benchmarks permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>12.2.2 Application Benchmarks</strong></h3>
<h4 id="definition-10" style="position:relative;"><a href="#definition-10" aria-label="definition 10 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Definition</strong>:</h4>
<p>Application benchmarks measure the performance of specific <strong>real-world applications</strong> under predefined workloads.</p>
<h4 id="purpose-2" style="position:relative;"><a href="#purpose-2" aria-label="purpose 2 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Purpose</strong>:</h4>
<ul>
<li>Test how an application performs in a <strong>production-like environment</strong>.</li>
<li>Identify bottlenecks in application code, database queries, or system configurations.</li>
</ul>
<h4 id="tools-10" style="position:relative;"><a href="#tools-10" aria-label="tools 10 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Tools</strong>:</h4>
<ol>
<li>
<p><strong>Web Applications</strong>:</p>
<ul>
<li><strong>Apache JMeter</strong>:
<ul>
<li>Example:
<ul>
<li>Simulate 100 users accessing an e-commerce website:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">./jmeter <span class="token parameter variable">-n</span> <span class="token parameter variable">-t</span> ecommerce_test.jmx <span class="token parameter variable">-l</span> results.jtl</code></pre></div>
</li>
<li>Measures response times, throughput, and error rates.</li>
</ul>
</li>
<li><strong>Output</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">Avg Response Time: 250ms
Throughput: 150 requests/second
Error Rate: 1.5%</code></pre></div>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Database Workloads</strong>:</p>
<ul>
<li><strong>Sysbench</strong>:
<ul>
<li>Example:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">sysbench <span class="token parameter variable">--test</span><span class="token operator">=</span>oltp_read_write --mysql-host<span class="token operator">=</span>localhost --mysql-user<span class="token operator">=</span>root --mysql-password<span class="token operator">=</span>pass --oltp-table-size<span class="token operator">=</span><span class="token number">100000</span> --num-threads<span class="token operator">=</span><span class="token number">16</span> run</code></pre></div>
<ul>
<li>Measures the database’s ability to handle mixed read/write workloads.</li>
</ul>
</li>
<li><strong>Result</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">Transactions: 3000 (50.00 per second)
Latency: avg 200ms</code></pre></div>
</li>
</ul>
</li>
</ul>
</li>
</ol>
<h4 id="example-scenario-1" style="position:relative;"><a href="#example-scenario-1" aria-label="example scenario 1 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example Scenario</strong>:</h4>
<ul>
<li><strong>Use Case</strong>:
<ul>
<li>Benchmark a Java-based web application during a simulated Black Friday sale.</li>
</ul>
</li>
<li><strong>Outcome</strong>:
<ul>
<li>The application maintained 95% uptime with an average response time of 120ms under 1000 concurrent users.</li>
</ul>
</li>
</ul>
<hr>
<h3 id="1223-microbenchmarks" style="position:relative;"><a href="#1223-microbenchmarks" aria-label="1223 microbenchmarks permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>12.2.3 Microbenchmarks</strong></h3>
<h4 id="definition-11" style="position:relative;"><a href="#definition-11" aria-label="definition 11 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Definition</strong>:</h4>
<p>Microbenchmarks focus on measuring the performance of <strong>small, isolated components</strong> or functions within an application or system.</p>
<h4 id="purpose-3" style="position:relative;"><a href="#purpose-3" aria-label="purpose 3 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Purpose</strong>:</h4>
<ul>
<li>Evaluate the efficiency of specific <strong>code snippets</strong>, <strong>algorithms</strong>, or <strong>system calls</strong>.</li>
<li>Identify bottlenecks in low-level components.</li>
</ul>
<h4 id="tools-11" style="position:relative;"><a href="#tools-11" aria-label="tools 11 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Tools</strong>:</h4>
<ol>
<li>
<p><strong>Code Profiling</strong>:</p>
<ul>
<li><strong><code class="language-text">perf</code></strong>:
<ul>
<li>Example:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">perf <span class="token function">stat</span> <span class="token parameter variable">-e</span> cycles,instructions ./app</code></pre></div>
<ul>
<li>Measures CPU cycles and instructions executed for a given application.</li>
</ul>
</li>
<li><strong>Output</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">100,000,000 cycles
200,000,000 instructions
IPC: 2.00</code></pre></div>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Memory Allocation</strong>:</p>
<ul>
<li><strong><code class="language-text">bpftrace</code></strong>:
<ul>
<li>Example:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">bpftrace <span class="token parameter variable">-e</span> <span class="token string">'tracepoint:kmem:kmalloc { printf("%d bytes allocated\n", args->bytes_alloc); }'</span></code></pre></div>
<ul>
<li>Tracks memory allocations in real time.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ol>
<h4 id="example-scenario-2" style="position:relative;"><a href="#example-scenario-2" aria-label="example scenario 2 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example Scenario</strong>:</h4>
<ul>
<li><strong>Use Case</strong>:
<ul>
<li>Benchmark the performance of a JSON parsing library in a data pipeline.</li>
</ul>
</li>
<li><strong>Outcome</strong>:
<ul>
<li>JSON parsing throughput increased by 30% after switching to a more efficient library.</li>
</ul>
</li>
</ul>
<hr>
<h3 id="1224-end-to-end-benchmarks" style="position:relative;"><a href="#1224-end-to-end-benchmarks" aria-label="1224 end to end benchmarks permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>12.2.4 End-to-End Benchmarks</strong></h3>
<h4 id="definition-12" style="position:relative;"><a href="#definition-12" aria-label="definition 12 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Definition</strong>:</h4>
<p>End-to-end benchmarks evaluate the <strong>overall performance of the system</strong>, including all its components (CPU, memory, disk, network).</p>
<h4 id="purpose-4" style="position:relative;"><a href="#purpose-4" aria-label="purpose 4 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Purpose</strong>:</h4>
<ul>
<li>Assess the <strong>combined impact</strong> of all components under realistic workloads.</li>
<li>Provide insights into system scalability and responsiveness.</li>
</ul>
<h4 id="tools-12" style="position:relative;"><a href="#tools-12" aria-label="tools 12 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Tools</strong>:</h4>
<ol>
<li>
<p><strong>HTTP Workloads</strong>:</p>
<ul>
<li><strong>wrk</strong>:
<ul>
<li>Example:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">wrk <span class="token parameter variable">-t16</span> <span class="token parameter variable">-c500</span> <span class="token parameter variable">-d60s</span> http://example.com</code></pre></div>
<ul>
<li>Simulates high-traffic scenarios for web applications.</li>
</ul>
</li>
<li><strong>Output</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">Requests/sec: 2000
Latency: avg 150ms, max 500ms</code></pre></div>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>System Stress Testing</strong>:</p>
<ul>
<li><strong>stress-ng</strong>:
<ul>
<li>Example:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">stress-ng <span class="token parameter variable">--cpu</span> <span class="token number">8</span> <span class="token parameter variable">--vm</span> <span class="token number">4</span> --vm-bytes 2G <span class="token parameter variable">--timeout</span> 60s</code></pre></div>
<ul>
<li>Stresses CPU, memory, and I/O simultaneously to evaluate system stability.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ol>
<h4 id="example-scenario-3" style="position:relative;"><a href="#example-scenario-3" aria-label="example scenario 3 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example Scenario</strong>:</h4>
<ul>
<li><strong>Use Case</strong>:
<ul>
<li>Benchmark a cloud-based microservices architecture under simulated production workloads.</li>
</ul>
</li>
<li><strong>Outcome</strong>:
<ul>
<li>The system handled 10,000 concurrent requests with 95% of responses below 200ms latency.</li>
</ul>
</li>
</ul>
<hr>
<h3 id="1225-comparison-of-benchmark-types" style="position:relative;"><a href="#1225-comparison-of-benchmark-types" aria-label="1225 comparison of benchmark types permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>12.2.5 Comparison of Benchmark Types</strong></h3>
<table>
<thead>
<tr>
<th><strong>Type</strong></th>
<th><strong>Scope</strong></th>
<th><strong>Purpose</strong></th>
<th><strong>Example Tools</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Synthetic Benchmarks</strong></td>
<td>Isolated components</td>
<td>Measure specific hardware or software performance</td>
<td>Sysbench, FIO, iperf3</td>
</tr>
<tr>
<td><strong>Application Benchmarks</strong></td>
<td>Real-world applications</td>
<td>Evaluate application performance under realistic workloads</td>
<td>Apache JMeter, Sysbench</td>
</tr>
<tr>
<td><strong>Microbenchmarks</strong></td>
<td>Small, isolated components</td>
<td>Analyze specific functions or system calls</td>
<td>perf, bpftrace</td>
</tr>
<tr>
<td><strong>End-to-End Benchmarks</strong></td>
<td>Full system</td>
<td>Assess overall system scalability and responsiveness</td>
<td>wrk, stress-ng</td>
</tr>
</tbody>
</table>
<hr>
<h3 id="key-takeaways-10" style="position:relative;"><a href="#key-takeaways-10" aria-label="key takeaways 10 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Key Takeaways</strong></h3>
<ol>
<li>
<p><strong>Synthetic Benchmarks</strong>:</p>
<ul>
<li>Ideal for comparing hardware or software configurations.</li>
<li><strong>Highlight</strong>: “Synthetic benchmarks provide focused, repeatable measurements of specific components.”</li>
</ul>
</li>
<li>
<p><strong>Application Benchmarks</strong>:</p>
<ul>
<li>Provide insights into real-world performance, revealing bottlenecks in application logic or configuration.</li>
<li><strong>Highlight</strong>: “Application benchmarks replicate production scenarios for accurate performance analysis.”</li>
</ul>
</li>
<li>
<p><strong>Microbenchmarks</strong>:</p>
<ul>
<li>Help optimize low-level functions and algorithms.</li>
<li><strong>Highlight</strong>: “Microbenchmarks identify inefficiencies in specific code paths.”</li>
</ul>
</li>
<li>
<p><strong>End-to-End Benchmarks</strong>:</p>
<ul>
<li>Assess system-wide performance and scalability.</li>
<li><strong>Highlight</strong>: “End-to-end benchmarks test the system as a whole under realistic workloads.”</li>
</ul>
</li>
</ol>
<hr>
<h2 id="123-benchmarking-methodology" style="position:relative;"><a href="#123-benchmarking-methodology" aria-label="123 benchmarking methodology permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>12.3 Benchmarking Methodology</strong></h2>
<p>A structured benchmarking methodology ensures that the results are accurate, reproducible, and actionable. Following a well-defined process minimizes errors, reduces variability, and provides insights that can guide system optimization.</p>
<hr>
<h3 id="1231-step-1-define-goals" style="position:relative;"><a href="#1231-step-1-define-goals" aria-label="1231 step 1 define goals permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>12.3.1 Step 1: Define Goals</strong></h3>
<h4 id="objective" style="position:relative;"><a href="#objective" aria-label="objective permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Objective</strong>:</h4>
<ul>
<li>Clearly outline what you aim to measure and why. Goals may include identifying bottlenecks, comparing configurations, or validating optimizations.</li>
</ul>
<h4 id="examples" style="position:relative;"><a href="#examples" aria-label="examples permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Examples</strong>:</h4>
<ol>
<li><strong>Web Application</strong>:
<ul>
<li>Measure the <strong>average response time</strong> and <strong>throughput</strong> under peak traffic conditions.</li>
</ul>
</li>
<li><strong>Database System</strong>:
<ul>
<li>Evaluate query execution times with and without indexing.</li>
</ul>
</li>
<li><strong>Cloud Infrastructure</strong>:
<ul>
<li>Compare the <strong>network throughput</strong> of two cloud providers.</li>
</ul>
</li>
</ol>
<h4 id="best-practices" style="position:relative;"><a href="#best-practices" aria-label="best practices permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Best Practices</strong>:</h4>
<ol>
<li>Define specific metrics, such as <strong>latency (P95)</strong>, <strong>throughput (requests per second)</strong>, or <strong>resource utilization (CPU, memory)</strong>.
<ul>
<li><strong>Highlight</strong>: “Well-defined goals ensure benchmarks focus on relevant performance aspects.”</li>
</ul>
</li>
<li>Consider the target audience:
<ul>
<li>Developers need fine-grained performance data, while management may focus on high-level KPIs.</li>
</ul>
</li>
</ol>
<hr>
<h3 id="1232-step-2-prepare-the-environment" style="position:relative;"><a href="#1232-step-2-prepare-the-environment" aria-label="1232 step 2 prepare the environment permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>12.3.2 Step 2: Prepare the Environment</strong></h3>
<h4 id="objective-1" style="position:relative;"><a href="#objective-1" aria-label="objective 1 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Objective</strong>:</h4>
<ul>
<li>Set up a controlled and consistent environment to eliminate noise and ensure reproducible results.</li>
</ul>
<h4 id="key-actions" style="position:relative;"><a href="#key-actions" aria-label="key actions permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Key Actions</strong>:</h4>
<ol>
<li>
<p><strong>Isolate the System</strong>:</p>
<ul>
<li>Run benchmarks on a <strong>dedicated machine</strong> or virtual instance.</li>
<li>Example:
<ul>
<li>Stop unnecessary background processes:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">systemctl stop <span class="token function">cron</span></code></pre></div>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Standardize the Configuration</strong>:</p>
<ul>
<li>Use the same hardware, OS, and software versions across tests.</li>
<li>Document the environment:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">lscpu
<span class="token function">free</span> <span class="token parameter variable">-h</span>
<span class="token function">uname</span> <span class="token parameter variable">-a</span></code></pre></div>
</li>
</ul>
</li>
<li>
<p><strong>Warm Up the System</strong>:</p>
<ul>
<li>Ensure the system is in a steady state before measurement.</li>
<li>Example:
<ul>
<li>Run a workload for 5 minutes to populate caches.</li>
</ul>
</li>
</ul>
</li>
</ol>
<h4 id="example-11" style="position:relative;"><a href="#example-11" aria-label="example 11 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example</strong>:</h4>
<ul>
<li><strong>Scenario</strong>:
<ul>
<li>Benchmarking a database server.</li>
<li><strong>Preparation</strong>:
<ul>
<li>Disable OS-level caching:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token builtin class-name">echo</span> <span class="token number">3</span> <span class="token operator">></span> /proc/sys/vm/drop_caches</code></pre></div>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="best-practices-1" style="position:relative;"><a href="#best-practices-1" aria-label="best practices 1 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Best Practices</strong>:</h4>
<ol>
<li>Always document environment details for reproducibility.</li>
<li>Run tests on dedicated hardware or isolated virtual instances.
<ul>
<li><strong>Highlight</strong>: “Benchmarking in a noisy environment skews results and reduces reliability.”</li>
</ul>
</li>
</ol>
<hr>
<h3 id="1233-step-3-select-workloads" style="position:relative;"><a href="#1233-step-3-select-workloads" aria-label="1233 step 3 select workloads permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>12.3.3 Step 3: Select Workloads</strong></h3>
<h4 id="objective-2" style="position:relative;"><a href="#objective-2" aria-label="objective 2 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Objective</strong>:</h4>
<ul>
<li>Choose workloads that closely mimic <strong>real-world scenarios</strong> or stress specific components.</li>
</ul>
<h4 id="types-of-workloads" style="position:relative;"><a href="#types-of-workloads" aria-label="types of workloads permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Types of Workloads</strong>:</h4>
<ol>
<li>
<p><strong>Synthetic</strong>:</p>
<ul>
<li>Simulates isolated components like CPU or disk.</li>
<li>Example:
<ul>
<li>Measure CPU performance using Sysbench:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">sysbench <span class="token parameter variable">--test</span><span class="token operator">=</span>cpu --cpu-max-prime<span class="token operator">=</span><span class="token number">20000</span> run</code></pre></div>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Realistic</strong>:</p>
<ul>
<li>Replicates production traffic patterns.</li>
<li>Example:
<ul>
<li>Simulate API traffic with JMeter:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">./jmeter <span class="token parameter variable">-n</span> <span class="token parameter variable">-t</span> api_test.jmx <span class="token parameter variable">-l</span> results.jtl</code></pre></div>
</li>
</ul>
</li>
</ul>
</li>
</ol>
<h4 id="example-12" style="position:relative;"><a href="#example-12" aria-label="example 12 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example</strong>:</h4>
<ul>
<li><strong>Scenario</strong>:
<ul>
<li>Benchmarking an e-commerce platform during a Black Friday event.</li>
<li><strong>Workload</strong>:
<ul>
<li>70% browsing requests.</li>
<li>20% product searches.</li>
<li>10% checkout operations.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="best-practices-2" style="position:relative;"><a href="#best-practices-2" aria-label="best practices 2 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Best Practices</strong>:</h4>
<ol>
<li>Use a mix of synthetic and realistic workloads for comprehensive analysis.</li>
<li>Include edge cases like <strong>burst traffic</strong> or <strong>peak loads</strong>.
<ul>
<li><strong>Highlight</strong>: “Representative workloads provide results that translate directly to production.”</li>
</ul>
</li>
</ol>
<hr>
<h3 id="1234-step-4-collect-baseline-metrics" style="position:relative;"><a href="#1234-step-4-collect-baseline-metrics" aria-label="1234 step 4 collect baseline metrics permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>12.3.4 Step 4: Collect Baseline Metrics</strong></h3>
<h4 id="objective-3" style="position:relative;"><a href="#objective-3" aria-label="objective 3 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Objective</strong>:</h4>
<ul>
<li>Establish <strong>pre-optimization performance metrics</strong> to identify bottlenecks and compare improvements.</li>
</ul>
<h4 id="tools-13" style="position:relative;"><a href="#tools-13" aria-label="tools 13 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Tools</strong>:</h4>
<ol>
<li>
<p><strong>System Monitoring</strong>:</p>
<ul>
<li><strong><code class="language-text">vmstat</code></strong>:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">vmstat</span> <span class="token number">1</span></code></pre></div>
<ul>
<li>Tracks CPU, memory, and disk activity.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Performance Profiling</strong>:</p>
<ul>
<li><strong><code class="language-text">perf</code></strong>:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">perf <span class="token function">stat</span> <span class="token parameter variable">-e</span> cycles,instructions ./app</code></pre></div>
</li>
</ul>
</li>
<li>
<p><strong>Application Metrics</strong>:</p>
<ul>
<li>Use built-in profiling tools (e.g., JVisualVM for Java applications).</li>
</ul>
</li>
</ol>
<h4 id="example-13" style="position:relative;"><a href="#example-13" aria-label="example 13 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example</strong>:</h4>
<ul>
<li><strong>Scenario</strong>:
<ul>
<li>Baseline a web server:
<ul>
<li>CPU: 70% utilization.</li>
<li>Latency: Average 200ms, P95 300ms.</li>
<li>Throughput: 1000 requests per second.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="best-practices-3" style="position:relative;"><a href="#best-practices-3" aria-label="best practices 3 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Best Practices</strong>:</h4>
<ol>
<li>Always record baseline metrics to quantify improvements.</li>
<li>Use historical data if available for comparison.
<ul>
<li><strong>Highlight</strong>: “Without a baseline, it’s impossible to measure the impact of changes.”</li>
</ul>
</li>
</ol>
<hr>
<h3 id="1235-step-5-conduct-multiple-runs" style="position:relative;"><a href="#1235-step-5-conduct-multiple-runs" aria-label="1235 step 5 conduct multiple runs permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>12.3.5 Step 5: Conduct Multiple Runs</strong></h3>
<h4 id="objective-4" style="position:relative;"><a href="#objective-4" aria-label="objective 4 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Objective</strong>:</h4>
<ul>
<li>Repeat benchmarks multiple times to account for variability and transient factors.</li>
</ul>
<h4 id="key-actions-1" style="position:relative;"><a href="#key-actions-1" aria-label="key actions 1 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Key Actions</strong>:</h4>
<ol>
<li>
<p><strong>Set Run Parameters</strong>:</p>
<ul>
<li>Define run duration and concurrency levels.</li>
<li>Example:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">wrk <span class="token parameter variable">-t8</span> <span class="token parameter variable">-c400</span> <span class="token parameter variable">-d60s</span> http://example.com</code></pre></div>
</li>
</ul>
</li>
<li>
<p><strong>Aggregate Results</strong>:</p>
<ul>
<li>Collect metrics for <strong>average</strong>, <strong>P95</strong>, and <strong>P99</strong> latencies.</li>
<li>Example:
<ul>
<li>Run 5 tests and compute statistical measures:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">Run 1: 150ms
Run 2: 145ms
Run 3: 155ms
Average: 150ms</code></pre></div>
</li>
</ul>
</li>
</ul>
</li>
</ol>
<h4 id="example-14" style="position:relative;"><a href="#example-14" aria-label="example 14 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example</strong>:</h4>
<ul>
<li><strong>Scenario</strong>:
<ul>
<li>Benchmarking an API for latency under peak load.</li>
<li><strong>Results</strong>:
<ul>
<li>Test 1: 95ms (average latency), 200ms (P95).</li>
<li>Test 2: 100ms (average latency), 210ms (P95).</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="best-practices-4" style="position:relative;"><a href="#best-practices-4" aria-label="best practices 4 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Best Practices</strong>:</h4>
<ol>
<li>Perform a minimum of <strong>3-5 runs</strong> for reliable results.</li>
<li>Remove outliers or warm-up runs from final analysis.
<ul>
<li><strong>Highlight</strong>: “Single-run benchmarks can be misleading due to transient factors.”</li>
</ul>
</li>
</ol>
<hr>
<h3 id="1236-step-6-analyze-results" style="position:relative;"><a href="#1236-step-6-analyze-results" aria-label="1236 step 6 analyze results permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>12.3.6 Step 6: Analyze Results</strong></h3>
<h4 id="objective-5" style="position:relative;"><a href="#objective-5" aria-label="objective 5 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Objective</strong>:</h4>
<ul>
<li>Interpret metrics to identify bottlenecks and areas for improvement.</li>
</ul>
<h4 id="key-metrics" style="position:relative;"><a href="#key-metrics" aria-label="key metrics permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Key Metrics</strong>:</h4>
<ol>
<li><strong>Latency</strong>:
<ul>
<li>Measure <strong>average</strong>, <strong>P95</strong>, and <strong>P99</strong> to capture the full spectrum of response times.</li>
</ul>
</li>
<li><strong>Throughput</strong>:
<ul>
<li>Requests per second or transactions per second.</li>
</ul>
</li>
<li><strong>Resource Utilization</strong>:
<ul>
<li>CPU, memory, disk, and network usage.</li>
</ul>
</li>
</ol>
<h4 id="tools-14" style="position:relative;"><a href="#tools-14" aria-label="tools 14 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Tools</strong>:</h4>
<ol>
<li>
<p><strong>Statistical Analysis</strong>:</p>
<ul>
<li>Use Python or R to calculate percentiles and visualize results.</li>
<li>Example (Python):
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">120</span><span class="token punctuation">,</span> <span class="token number">150</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">,</span> <span class="token number">250</span><span class="token punctuation">,</span> <span class="token number">300</span><span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"P95 Latency: </span><span class="token interpolation"><span class="token punctuation">{</span>np<span class="token punctuation">.</span>percentile<span class="token punctuation">(</span>data<span class="token punctuation">,</span> <span class="token number">95</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string"> ms"</span></span><span class="token punctuation">)</span></code></pre></div>
</li>
</ul>
</li>
<li>
<p><strong>Visualization</strong>:</p>
<ul>
<li>Plot trends over time using Grafana or Matplotlib.</li>
</ul>
</li>
</ol>
<h4 id="example-15" style="position:relative;"><a href="#example-15" aria-label="example 15 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example</strong>:</h4>
<ul>
<li><strong>Scenario</strong>:
<ul>
<li>Analyze web application latency before and after optimizations.</li>
<li><strong>Findings</strong>:
<ul>
<li>Before: P95 latency = 300ms.</li>
<li>After: P95 latency = 200ms.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="best-practices-5" style="position:relative;"><a href="#best-practices-5" aria-label="best practices 5 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Best Practices</strong>:</h4>
<ol>
<li>Focus on <strong>percentiles</strong> over averages for latency-sensitive applications.</li>
<li>Visualize data to identify trends and anomalies.
<ul>
<li><strong>Highlight</strong>: “Percentiles reveal outliers that averages may hide.”</li>
</ul>
</li>
</ol>
<hr>
<h3 id="key-takeaways-11" style="position:relative;"><a href="#key-takeaways-11" aria-label="key takeaways 11 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Key Takeaways</strong></h3>
<ol>
<li>
<p><strong>Start with Clear Goals</strong>:</p>
<ul>
<li>Define measurable objectives to guide benchmarking efforts.</li>
<li><strong>Highlight</strong>: “Clear goals ensure benchmarks produce actionable insights.”</li>
</ul>
</li>
<li>
<p><strong>Control the Environment</strong>:</p>
<ul>
<li>Eliminate noise and variability to ensure reproducibility.</li>
<li><strong>Highlight</strong>: “A consistent environment is essential for reliable results.”</li>
</ul>
</li>
<li>
<p><strong>Test Realistic Workloads</strong>:</p>
<ul>
<li>Simulate production traffic patterns to evaluate real-world performance.</li>
<li><strong>Highlight</strong>: “Representative workloads yield meaningful benchmarks.”</li>
</ul>
</li>
<li>
<p><strong>Repeat and Aggregate</strong>:</p>
<ul>
<li>Conduct multiple runs to account for variability and ensure statistical reliability.</li>
<li><strong>Highlight</strong>: “One run is never enough for reliable benchmarking.”</li>
</ul>
</li>
<li>
<p><strong>Use Percentiles</strong>:</p>
<ul>
<li>Focus on percentiles (P95, P99) for latency and throughput analysis.</li>
<li><strong>Highlight</strong>: “Percentiles capture performance outliers critical for user experience.”</li>
</ul>
</li>
</ol>
<hr>
<h2 id="124-tools-for-benchmarking" style="position:relative;"><a href="#124-tools-for-benchmarking" aria-label="124 tools for benchmarking permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>12.4 Tools for Benchmarking</strong></h2>
<p>Benchmarking tools are essential for evaluating system performance under different conditions. This section categorizes tools by their target system component (e.g., CPU, memory, disk, network, or application) and provides detailed usage instructions, real-world examples, and best practices.</p>
<hr>
<h3 id="1241-cpu-benchmarking-tools" style="position:relative;"><a href="#1241-cpu-benchmarking-tools" aria-label="1241 cpu benchmarking tools permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>12.4.1 CPU Benchmarking Tools</strong></h3>
<h4 id="purpose-5" style="position:relative;"><a href="#purpose-5" aria-label="purpose 5 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Purpose</strong>:</h4>
<ul>
<li>Evaluate the computational performance of the CPU, including its ability to execute instructions, handle parallelism, and process workloads efficiently.</li>
</ul>
<h4 id="key-tools" style="position:relative;"><a href="#key-tools" aria-label="key tools permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Key Tools</strong>:</h4>
<ol>
<li>
<p><strong>Sysbench</strong>:</p>
<ul>
<li><strong>Description</strong>:
<ul>
<li>A versatile benchmarking tool that tests CPU performance by executing computationally intensive tasks, such as calculating prime numbers.</li>
</ul>
</li>
<li><strong>Usage</strong>:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">sysbench <span class="token parameter variable">--test</span><span class="token operator">=</span>cpu --cpu-max-prime<span class="token operator">=</span><span class="token number">20000</span> run</code></pre></div>
</li>
<li><strong>Example Output</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">CPU speed:
    events per second: 1200</code></pre></div>
</li>
<li><strong>Real-World Example</strong>:
<ul>
<li>Use Sysbench to compare the performance of CPUs on two cloud providers to decide which one offers better computational power for a high-performance computing workload.</li>
</ul>
</li>
<li><strong>Best Practices</strong>:
<ul>
<li>Run multiple iterations to ensure consistent results.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Geekbench</strong>:</p>
<ul>
<li><strong>Description</strong>:
<ul>
<li>A cross-platform benchmarking tool that measures single-core and multi-core CPU performance.</li>
</ul>
</li>
<li><strong>Real-World Example</strong>:
<ul>
<li>Use Geekbench to compare performance between a laptop and a desktop for machine learning tasks.</li>
</ul>
</li>
<li><strong>Usage</strong>:
<ul>
<li>Download the tool, run the benchmark, and view detailed metrics like <strong>floating-point performance</strong> and <strong>integer performance</strong>.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Perf</strong>:</p>
<ul>
<li><strong>Description</strong>:
<ul>
<li>A Linux tool for analyzing CPU performance and identifying inefficiencies.</li>
</ul>
</li>
<li><strong>Usage</strong>:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">perf <span class="token function">stat</span> <span class="token parameter variable">-e</span> cycles,instructions ./app</code></pre></div>
</li>
<li><strong>Output</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">Performance counter stats for './app':
    100,000 cycles
    150,000 instructions
    IPC: 1.5</code></pre></div>
</li>
<li><strong>Real-World Example</strong>:
<ul>
<li>Use Perf to analyze the instruction-per-cycle (IPC) rate of an application and identify bottlenecks.</li>
</ul>
</li>
</ul>
</li>
</ol>
<hr>
<h3 id="1242-memory-benchmarking-tools" style="position:relative;"><a href="#1242-memory-benchmarking-tools" aria-label="1242 memory benchmarking tools permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>12.4.2 Memory Benchmarking Tools</strong></h3>
<h4 id="purpose-6" style="position:relative;"><a href="#purpose-6" aria-label="purpose 6 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Purpose</strong>:</h4>
<ul>
<li>Assess memory bandwidth, latency, and allocation efficiency.</li>
</ul>
<h4 id="key-tools-1" style="position:relative;"><a href="#key-tools-1" aria-label="key tools 1 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Key Tools</strong>:</h4>
<ol>
<li>
<p><strong>Stream</strong>:</p>
<ul>
<li><strong>Description</strong>:
<ul>
<li>Measures memory bandwidth using operations like copy, scale, add, and triad.</li>
</ul>
</li>
<li><strong>Usage</strong>:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">./stream</code></pre></div>
</li>
<li><strong>Example Output</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">Copy:  8000 MB/s
Scale: 7000 MB/s
Add:   6500 MB/s
Triad: 6400 MB/s</code></pre></div>
</li>
<li><strong>Real-World Example</strong>:
<ul>
<li>Use Stream to compare memory performance on a NUMA-enabled system before and after enabling memory interleaving.</li>
</ul>
</li>
<li><strong>Best Practices</strong>:
<ul>
<li>Run tests on isolated systems to eliminate noise from other processes.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>bpftrace</strong>:</p>
<ul>
<li><strong>Description</strong>:
<ul>
<li>A dynamic tracing tool for analyzing memory allocation in real time.</li>
</ul>
</li>
<li><strong>Usage</strong>:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">bpftrace <span class="token parameter variable">-e</span> <span class="token string">'tracepoint:kmem:kmalloc { printf("%d bytes allocated\n", args->bytes_allocated); }'</span></code></pre></div>
</li>
<li><strong>Real-World Example</strong>:
<ul>
<li>Track real-time memory usage in a web server application to detect memory allocation inefficiencies.</li>
</ul>
</li>
</ul>
</li>
</ol>
<hr>
<h3 id="1243-disk-io-benchmarking-tools" style="position:relative;"><a href="#1243-disk-io-benchmarking-tools" aria-label="1243 disk io benchmarking tools permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>12.4.3 Disk I/O Benchmarking Tools</strong></h3>
<h4 id="purpose-7" style="position:relative;"><a href="#purpose-7" aria-label="purpose 7 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Purpose</strong>:</h4>
<ul>
<li>Evaluate the performance of storage devices, including read/write speeds, random/sequential access, and IOPS (input/output operations per second).</li>
</ul>
<h4 id="key-tools-2" style="position:relative;"><a href="#key-tools-2" aria-label="key tools 2 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Key Tools</strong>:</h4>
<ol>
<li>
<p><strong>FIO (Flexible I/O Tester)</strong>:</p>
<ul>
<li><strong>Description</strong>:
<ul>
<li>Tests the read and write performance of storage devices under various workloads.</li>
</ul>
</li>
<li><strong>Usage</strong>:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">fio <span class="token parameter variable">--name</span><span class="token operator">=</span>randread <span class="token parameter variable">--rw</span><span class="token operator">=</span>randread <span class="token parameter variable">--bs</span><span class="token operator">=</span>4k <span class="token parameter variable">--size</span><span class="token operator">=</span>1G <span class="token parameter variable">--numjobs</span><span class="token operator">=</span><span class="token number">4</span> <span class="token parameter variable">--runtime</span><span class="token operator">=</span><span class="token number">60</span></code></pre></div>
</li>
<li><strong>Example Output</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">READ: bw=200MiB/s, IOPS=50000</code></pre></div>
</li>
<li><strong>Real-World Example</strong>:
<ul>
<li>Use FIO to compare the performance of NVMe and SATA SSDs for a database server.</li>
</ul>
</li>
<li><strong>Best Practices</strong>:
<ul>
<li>Test with different block sizes (<code class="language-text">--bs</code>) to simulate varying workloads.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>ioping</strong>:</p>
<ul>
<li><strong>Description</strong>:
<ul>
<li>Measures storage latency by issuing small read/write operations.</li>
</ul>
</li>
<li><strong>Usage</strong>:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">ioping <span class="token parameter variable">-c</span> <span class="token number">10</span> /mnt/data</code></pre></div>
</li>
<li><strong>Example Output</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">4 KiB from /mnt/data: request=1 time=0.34 ms</code></pre></div>
</li>
<li><strong>Real-World Example</strong>:
<ul>
<li>Test latency on a network-mounted filesystem to ensure acceptable response times.</li>
</ul>
</li>
</ul>
</li>
</ol>
<hr>
<h3 id="1244-network-benchmarking-tools" style="position:relative;"><a href="#1244-network-benchmarking-tools" aria-label="1244 network benchmarking tools permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>12.4.4 Network Benchmarking Tools</strong></h3>
<h4 id="purpose-8" style="position:relative;"><a href="#purpose-8" aria-label="purpose 8 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Purpose</strong>:</h4>
<ul>
<li>Measure network throughput, latency, and packet loss for performance evaluation of network interfaces or infrastructure.</li>
</ul>
<h4 id="key-tools-3" style="position:relative;"><a href="#key-tools-3" aria-label="key tools 3 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Key Tools</strong>:</h4>
<ol>
<li>
<p><strong>Iperf3</strong>:</p>
<ul>
<li><strong>Description</strong>:
<ul>
<li>A popular tool for measuring network bandwidth and diagnosing bottlenecks.</li>
</ul>
</li>
<li><strong>Usage</strong>:
<ul>
<li>On the server:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">iperf3 <span class="token parameter variable">-s</span></code></pre></div>
</li>
<li>On the client:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">iperf3 <span class="token parameter variable">-c</span> server_ip <span class="token parameter variable">-t</span> <span class="token number">30</span></code></pre></div>
</li>
</ul>
</li>
<li><strong>Example Output</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">[ ID] Interval        Transfer      Bandwidth
[  4]   0.00-30.00  3.2 GBytes  915 Mbits/sec</code></pre></div>
</li>
<li><strong>Real-World Example</strong>:
<ul>
<li>Benchmark the network performance of two cloud providers to determine which offers better bandwidth for a video streaming application.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Ping</strong>:</p>
<ul>
<li><strong>Description</strong>:
<ul>
<li>Measures round-trip time (RTT) for packets sent to a target host.</li>
</ul>
</li>
<li><strong>Usage</strong>:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">ping</span> <span class="token parameter variable">-c</span> <span class="token number">10</span> example.com</code></pre></div>
</li>
<li><strong>Example Output</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">64 bytes from example.com: icmp_seq=1 ttl=64 time=0.521 ms</code></pre></div>
</li>
<li><strong>Real-World Example</strong>:
<ul>
<li>Diagnose high-latency issues in a virtual private network (VPN).</li>
</ul>
</li>
</ul>
</li>
</ol>
<hr>
<h3 id="1245-application-benchmarking-tools" style="position:relative;"><a href="#1245-application-benchmarking-tools" aria-label="1245 application benchmarking tools permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>12.4.5 Application Benchmarking Tools</strong></h3>
<h4 id="purpose-9" style="position:relative;"><a href="#purpose-9" aria-label="purpose 9 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Purpose</strong>:</h4>
<ul>
<li>Test real-world applications, including web servers, APIs, and databases, to assess overall performance under realistic workloads.</li>
</ul>
<h4 id="key-tools-4" style="position:relative;"><a href="#key-tools-4" aria-label="key tools 4 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Key Tools</strong>:</h4>
<ol>
<li>
<p><strong>wrk</strong>:</p>
<ul>
<li><strong>Description</strong>:
<ul>
<li>A modern HTTP benchmarking tool for testing web servers.</li>
</ul>
</li>
<li><strong>Usage</strong>:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">wrk <span class="token parameter variable">-t8</span> <span class="token parameter variable">-c400</span> <span class="token parameter variable">-d60s</span> http://example.com</code></pre></div>
</li>
<li><strong>Example Output</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">Requests/sec: 1500
Latency: avg 120ms, max 500ms</code></pre></div>
</li>
<li><strong>Real-World Example</strong>:
<ul>
<li>Benchmark a web application during a simulated peak load to determine its maximum throughput.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Apache JMeter</strong>:</p>
<ul>
<li><strong>Description</strong>:
<ul>
<li>Simulates user interactions with web applications and APIs.</li>
</ul>
</li>
<li><strong>Usage</strong>:
<ul>
<li>Create a test plan to simulate 1000 concurrent users.</li>
</ul>
</li>
<li><strong>Real-World Example</strong>:
<ul>
<li>Evaluate the performance of an e-commerce website under load during a Black Friday simulation.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Sysbench (Database)</strong>:</p>
<ul>
<li><strong>Description</strong>:
<ul>
<li>Tests the performance of MySQL and PostgreSQL databases under read/write workloads.</li>
</ul>
</li>
<li><strong>Usage</strong>:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">sysbench <span class="token parameter variable">--test</span><span class="token operator">=</span>oltp_read_write --mysql-host<span class="token operator">=</span>localhost --mysql-user<span class="token operator">=</span>root --mysql-password<span class="token operator">=</span>pass --oltp-table-size<span class="token operator">=</span><span class="token number">100000</span> --num-threads<span class="token operator">=</span><span class="token number">16</span> run</code></pre></div>
</li>
<li><strong>Example Output</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">Transactions: 3000 (50.00 per second)
Latency: avg 200ms</code></pre></div>
</li>
</ul>
</li>
</ol>
<hr>
<h3 id="1246-visualization-tools-for-benchmark-results" style="position:relative;"><a href="#1246-visualization-tools-for-benchmark-results" aria-label="1246 visualization tools for benchmark results permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>12.4.6 Visualization Tools for Benchmark Results</strong></h3>
<h4 id="purpose-10" style="position:relative;"><a href="#purpose-10" aria-label="purpose 10 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Purpose</strong>:</h4>
<ul>
<li>Visualize benchmark data to identify trends, outliers, and bottlenecks.</li>
</ul>
<h4 id="key-tools-5" style="position:relative;"><a href="#key-tools-5" aria-label="key tools 5 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Key Tools</strong>:</h4>
<ol>
<li><strong>Grafana</strong>:
<ul>
<li>Integrates with data sources like Prometheus to display real-time metrics.</li>
</ul>
</li>
<li><strong>Matplotlib</strong>:
<ul>
<li>Python library for creating custom performance graphs.</li>
</ul>
</li>
</ol>
<h4 id="best-practices-6" style="position:relative;"><a href="#best-practices-6" aria-label="best practices 6 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Best Practices</strong>:</h4>
<ul>
<li>Use percentiles (e.g., P95, P99) to visualize outliers in latency data.</li>
<li>Combine graphs for CPU, memory, and I/O to correlate bottlenecks.</li>
</ul>
<hr>
<h3 id="key-takeaways-12" style="position:relative;"><a href="#key-takeaways-12" aria-label="key takeaways 12 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Key Takeaways</strong></h3>
<ol>
<li>
<p><strong>Use the Right Tool for the Job</strong>:</p>
<ul>
<li>Select tools that align with the specific system component or workload being tested.</li>
<li><strong>Highlight</strong>: “Choosing the right tool is critical for obtaining meaningful results.”</li>
</ul>
</li>
<li>
<p><strong>Run Benchmarks in Isolation</strong>:</p>
<ul>
<li>Eliminate noise from unrelated processes to ensure accurate results.</li>
<li><strong>Highlight</strong>: “Benchmarking is only as reliable as the environment it’s conducted in.”</li>
</ul>
</li>
<li>
<p><strong>Visualize Results</strong>:</p>
<ul>
<li>Use tools like Grafana to identify trends and anomalies.</li>
<li><strong>Highlight</strong>: “Graphs often reveal insights that raw data cannot.”</li>
</ul>
</li>
</ol>
<hr>
<h2 id="125-benchmarking-best-practices" style="position:relative;"><a href="#125-benchmarking-best-practices" aria-label="125 benchmarking best practices permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>12.5 Benchmarking Best Practices</strong></h2>
<p>Benchmarking can reveal critical insights about system performance, but only if conducted with precision and adherence to best practices. This section highlights practical strategies to eliminate variability, improve reproducibility, and derive actionable results.</p>
<hr>
<h3 id="1251-isolate-the-system" style="position:relative;"><a href="#1251-isolate-the-system" aria-label="1251 isolate the system permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>12.5.1 Isolate the System</strong></h3>
<h4 id="purpose-11" style="position:relative;"><a href="#purpose-11" aria-label="purpose 11 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Purpose</strong>:</h4>
<ul>
<li>Minimize interference from external processes or workloads to ensure benchmarking focuses solely on the target system or application.</li>
</ul>
<h4 id="strategies" style="position:relative;"><a href="#strategies" aria-label="strategies permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Strategies</strong>:</h4>
<ol>
<li>
<p><strong>Dedicated Environment</strong>:</p>
<ul>
<li>Use a standalone server, virtual machine, or container for benchmarks.</li>
<li>Disable unnecessary background services:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">systemctl stop <span class="token function">cron</span></code></pre></div>
</li>
<li>Example:
<ul>
<li>Isolate a web server on a dedicated instance to avoid interference from unrelated database queries.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Use Performance Modes</strong>:</p>
<ul>
<li>Enable performance tuning for hardware:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token builtin class-name">echo</span> performance <span class="token operator">></span> /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor</code></pre></div>
</li>
<li>Example:
<ul>
<li>A CPU benchmark may yield inconsistent results in a power-saving mode.</li>
</ul>
</li>
</ul>
</li>
</ol>
<h4 id="real-world-example" style="position:relative;"><a href="#real-world-example" aria-label="real world example permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Real-World Example</strong>:</h4>
<ul>
<li>A web application benchmark was skewed by a background data synchronization task running on the same server. Disabling the task reduced noise and improved result accuracy.</li>
</ul>
<hr>
<h3 id="1252-use-realistic-workloads" style="position:relative;"><a href="#1252-use-realistic-workloads" aria-label="1252 use realistic workloads permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>12.5.2 Use Realistic Workloads</strong></h3>
<h4 id="purpose-12" style="position:relative;"><a href="#purpose-12" aria-label="purpose 12 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Purpose</strong>:</h4>
<ul>
<li>Simulate workloads that mimic actual production scenarios to ensure results are relevant and actionable.</li>
</ul>
<h4 id="strategies-1" style="position:relative;"><a href="#strategies-1" aria-label="strategies 1 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Strategies</strong>:</h4>
<ol>
<li>
<p><strong>Replicate Production Traffic</strong>:</p>
<ul>
<li>Use tools like <strong>wrk</strong> or <strong>JMeter</strong> to replicate API calls, user interactions, or database queries observed in production logs.</li>
<li>Example:
<ul>
<li>Simulate 70% read and 30% write queries for a database workload.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Include Edge Cases</strong>:</p>
<ul>
<li>Test with extreme loads to understand failure thresholds.</li>
<li>Example:
<ul>
<li>Simulate a flash sale scenario for an e-commerce platform with 5000 concurrent users.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Vary Workloads</strong>:</p>
<ul>
<li>Include combinations of light, medium, and heavy workloads.</li>
<li>Example:
<ul>
<li>Evaluate how a web server performs under 100, 500, and 1000 concurrent connections.</li>
</ul>
</li>
</ul>
</li>
</ol>
<h4 id="real-world-example-1" style="position:relative;"><a href="#real-world-example-1" aria-label="real world example 1 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Real-World Example</strong>:</h4>
<ul>
<li>A gaming server benchmark included scenarios of 100, 1000, and 10,000 players to identify scaling issues under extreme load.</li>
</ul>
<hr>
<h3 id="1253-test-at-scale" style="position:relative;"><a href="#1253-test-at-scale" aria-label="1253 test at scale permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>12.5.3 Test at Scale</strong></h3>
<h4 id="purpose-13" style="position:relative;"><a href="#purpose-13" aria-label="purpose 13 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Purpose</strong>:</h4>
<ul>
<li>Evaluate how the system performs under peak traffic or resource usage to determine scalability limits.</li>
</ul>
<h4 id="strategies-2" style="position:relative;"><a href="#strategies-2" aria-label="strategies 2 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Strategies</strong>:</h4>
<ol>
<li>
<p><strong>Simulate High Concurrency</strong>:</p>
<ul>
<li>Test with thousands of concurrent users or threads.</li>
<li>Example:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">wrk <span class="token parameter variable">-t16</span> <span class="token parameter variable">-c1000</span> <span class="token parameter variable">-d60s</span> http://example.com</code></pre></div>
</li>
</ul>
</li>
<li>
<p><strong>Test with Large Datasets</strong>:</p>
<ul>
<li>Use realistic data sizes for databases or storage systems.</li>
<li>Example:
<ul>
<li>Benchmark a database with a 1TB dataset to understand real-world performance.</li>
</ul>
</li>
</ul>
</li>
</ol>
<h4 id="real-world-example-2" style="position:relative;"><a href="#real-world-example-2" aria-label="real world example 2 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Real-World Example</strong>:</h4>
<ul>
<li>A financial analytics platform tested with 10,000 simultaneous queries to validate its ability to handle end-of-day market data processing.</li>
</ul>
<hr>
<h3 id="1254-avoid-single-run-results" style="position:relative;"><a href="#1254-avoid-single-run-results" aria-label="1254 avoid single run results permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>12.5.4 Avoid Single-Run Results</strong></h3>
<h4 id="purpose-14" style="position:relative;"><a href="#purpose-14" aria-label="purpose 14 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Purpose</strong>:</h4>
<ul>
<li>Account for variability in results by running benchmarks multiple times and averaging the outcomes.</li>
</ul>
<h4 id="strategies-3" style="position:relative;"><a href="#strategies-3" aria-label="strategies 3 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Strategies</strong>:</h4>
<ol>
<li>
<p><strong>Conduct Multiple Iterations</strong>:</p>
<ul>
<li>Run each benchmark 3–5 times to ensure consistent results.</li>
<li>Example:
<ul>
<li>Measure latency across 5 runs and calculate the average:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">Run 1: 150ms
Run 2: 145ms
Run 3: 155ms
Average: 150ms</code></pre></div>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Remove Outliers</strong>:</p>
<ul>
<li>Discard the highest and lowest results if they deviate significantly.</li>
<li>Use statistical tools like Python for analysis:
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">150</span><span class="token punctuation">,</span> <span class="token number">145</span><span class="token punctuation">,</span> <span class="token number">155</span><span class="token punctuation">,</span> <span class="token number">300</span><span class="token punctuation">,</span> <span class="token number">140</span><span class="token punctuation">]</span>
filtered <span class="token operator">=</span> <span class="token punctuation">[</span>x <span class="token keyword">for</span> x <span class="token keyword">in</span> data <span class="token keyword">if</span> x <span class="token operator">&lt;</span> np<span class="token punctuation">.</span>percentile<span class="token punctuation">(</span>data<span class="token punctuation">,</span> <span class="token number">95</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>filtered<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre></div>
</li>
</ul>
</li>
</ol>
<h4 id="real-world-example-3" style="position:relative;"><a href="#real-world-example-3" aria-label="real world example 3 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Real-World Example</strong>:</h4>
<ul>
<li>A network latency benchmark showed a spike in one run due to transient congestion. Repeated tests confirmed consistent performance in other iterations.</li>
</ul>
<hr>
<h3 id="1255-document-the-environment" style="position:relative;"><a href="#1255-document-the-environment" aria-label="1255 document the environment permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>12.5.5 Document the Environment</strong></h3>
<h4 id="purpose-15" style="position:relative;"><a href="#purpose-15" aria-label="purpose 15 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Purpose</strong>:</h4>
<ul>
<li>Ensure results are reproducible by recording system configurations, software versions, and environmental variables.</li>
</ul>
<h4 id="strategies-4" style="position:relative;"><a href="#strategies-4" aria-label="strategies 4 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Strategies</strong>:</h4>
<ol>
<li>
<p><strong>Record Hardware Details</strong>:</p>
<ul>
<li>Include CPU model, RAM size, storage type, and network speed.</li>
<li>Example:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">lscpu
<span class="token function">free</span> <span class="token parameter variable">-h</span></code></pre></div>
</li>
</ul>
</li>
<li>
<p><strong>Record Software Configurations</strong>:</p>
<ul>
<li>Include OS version, kernel parameters, and application versions.</li>
<li>Example:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">uname</span> <span class="token parameter variable">-a</span>
<span class="token function">cat</span> /etc/os-release</code></pre></div>
</li>
</ul>
</li>
<li>
<p><strong>Capture Benchmark Parameters</strong>:</p>
<ul>
<li>Document input parameters for tools like <strong>wrk</strong> or <strong>sysbench</strong>.</li>
<li>Example:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">wrk <span class="token parameter variable">-t16</span> <span class="token parameter variable">-c500</span> <span class="token parameter variable">-d60s</span> http://example.com <span class="token operator">></span> benchmark_config.txt</code></pre></div>
</li>
</ul>
</li>
</ol>
<h4 id="real-world-example-4" style="position:relative;"><a href="#real-world-example-4" aria-label="real world example 4 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Real-World Example</strong>:</h4>
<ul>
<li>A storage benchmark on AWS recorded the instance type (m5.large), disk type (gp3), and region for accurate comparison across regions.</li>
</ul>
<hr>
<h3 id="1256-warm-up-the-system" style="position:relative;"><a href="#1256-warm-up-the-system" aria-label="1256 warm up the system permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>12.5.6 Warm Up the System</strong></h3>
<h4 id="purpose-16" style="position:relative;"><a href="#purpose-16" aria-label="purpose 16 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Purpose</strong>:</h4>
<ul>
<li>Allow the system to reach a steady state before measuring performance to eliminate skewed results caused by cold caches or initial setup overhead.</li>
</ul>
<h4 id="strategies-5" style="position:relative;"><a href="#strategies-5" aria-label="strategies 5 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Strategies</strong>:</h4>
<ol>
<li>
<p><strong>Run Pre-Benchmark Workloads</strong>:</p>
<ul>
<li>Execute a light workload for 5–10 minutes to warm up caches and initialize background services.</li>
<li>Example:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">wrk <span class="token parameter variable">-t4</span> <span class="token parameter variable">-c200</span> <span class="token parameter variable">-d300s</span> http://example.com</code></pre></div>
</li>
</ul>
</li>
<li>
<p><strong>Ignore Initial Results</strong>:</p>
<ul>
<li>Discard data from the first few iterations.</li>
<li>Example:
<ul>
<li>Ignore the first 2 minutes of a 10-minute memory bandwidth test.</li>
</ul>
</li>
</ul>
</li>
</ol>
<h4 id="real-world-example-5" style="position:relative;"><a href="#real-world-example-5" aria-label="real world example 5 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Real-World Example</strong>:</h4>
<ul>
<li>A database benchmark showed significantly higher latency for the first few queries due to cold cache effects. Discarding these initial results provided more accurate insights.</li>
</ul>
<hr>
<h3 id="1257-visualize-results" style="position:relative;"><a href="#1257-visualize-results" aria-label="1257 visualize results permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>12.5.7 Visualize Results</strong></h3>
<h4 id="purpose-17" style="position:relative;"><a href="#purpose-17" aria-label="purpose 17 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Purpose</strong>:</h4>
<ul>
<li>Use graphs and visualizations to identify trends, bottlenecks, and anomalies.</li>
</ul>
<h4 id="strategies-6" style="position:relative;"><a href="#strategies-6" aria-label="strategies 6 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Strategies</strong>:</h4>
<ol>
<li>
<p><strong>Plot Latency Distribution</strong>:</p>
<ul>
<li>Use tools like Python or R to visualize average, P95, and P99 latencies.</li>
<li>Example (Python):
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">120</span><span class="token punctuation">,</span> <span class="token number">150</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">,</span> <span class="token number">250</span><span class="token punctuation">,</span> <span class="token number">300</span><span class="token punctuation">]</span>
plt<span class="token punctuation">.</span>hist<span class="token punctuation">(</span>data<span class="token punctuation">,</span> bins<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"Latency Distribution"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre></div>
</li>
</ul>
</li>
<li>
<p><strong>Combine Metrics</strong>:</p>
<ul>
<li>Visualize CPU, memory, and disk metrics together to correlate performance issues.</li>
<li>Use Grafana for real-time dashboards.</li>
</ul>
</li>
</ol>
<h4 id="real-world-example-6" style="position:relative;"><a href="#real-world-example-6" aria-label="real world example 6 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Real-World Example</strong>:</h4>
<ul>
<li>A latency benchmark revealed that 95% of requests completed under 200ms, but P99 latency spiked to 800ms during peak traffic. This insight guided further optimizations.</li>
</ul>
<hr>
<h3 id="1258-use-percentiles-for-analysis" style="position:relative;"><a href="#1258-use-percentiles-for-analysis" aria-label="1258 use percentiles for analysis permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>12.5.8 Use Percentiles for Analysis</strong></h3>
<h4 id="purpose-18" style="position:relative;"><a href="#purpose-18" aria-label="purpose 18 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Purpose</strong>:</h4>
<ul>
<li>Analyze outliers and variability in metrics like latency or throughput.</li>
</ul>
<h4 id="strategies-7" style="position:relative;"><a href="#strategies-7" aria-label="strategies 7 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Strategies</strong>:</h4>
<ol>
<li>
<p><strong>Focus on P95 and P99</strong>:</p>
<ul>
<li>Capture the performance of the slowest requests that affect user experience.</li>
<li>Example:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">wrk <span class="token parameter variable">-t8</span> <span class="token parameter variable">-c400</span> <span class="token parameter variable">-d60s</span> http://example.com</code></pre></div>
<ul>
<li>P95 latency: 250ms, P99 latency: 400ms.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Avoid Solely Using Averages</strong>:</p>
<ul>
<li>Averages can mask outliers and provide misleading insights.</li>
<li>Use statistical summaries to complement averages.</li>
</ul>
</li>
</ol>
<h4 id="real-world-example-7" style="position:relative;"><a href="#real-world-example-7" aria-label="real world example 7 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Real-World Example</strong>:</h4>
<ul>
<li>A web application benchmark had an average latency of 100ms but a P99 latency of 500ms. Addressing P99 improved the experience for edge-case users.</li>
</ul>
<hr>
<h3 id="key-takeaways-13" style="position:relative;"><a href="#key-takeaways-13" aria-label="key takeaways 13 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Key Takeaways</strong></h3>
<ol>
<li>
<p><strong>Eliminate Noise</strong>:</p>
<ul>
<li>Use isolated environments and disable unnecessary processes.</li>
<li><strong>Highlight</strong>: “Noise-free environments produce accurate benchmarks.”</li>
</ul>
</li>
<li>
<p><strong>Simulate Realistic Scenarios</strong>:</p>
<ul>
<li>Use production-like workloads and test at scale.</li>
<li><strong>Highlight</strong>: “Realistic workloads ensure benchmarks translate to actionable results.”</li>
</ul>
</li>
<li>
<p><strong>Repeat and Aggregate</strong>:</p>
<ul>
<li>Conduct multiple iterations and analyze percentiles for reliability.</li>
<li><strong>Highlight</strong>: “Repetition reduces the impact of transient factors.”</li>
</ul>
</li>
<li>
<p><strong>Document Everything</strong>:</p>
<ul>
<li>Record configurations and input parameters for reproducibility.</li>
<li><strong>Highlight</strong>: “Documentation is essential for credible and reproducible benchmarking.”</li>
</ul>
</li>
<li>
<p><strong>Visualize for Insights</strong>:</p>
<ul>
<li>Graph results to identify trends and anomalies.</li>
<li><strong>Highlight</strong>: “Graphs often reveal bottlenecks that raw data cannot.”</li>
</ul>
</li>
</ol>
<hr>
<h2 id="126-common-pitfalls-in-benchmarking" style="position:relative;"><a href="#126-common-pitfalls-in-benchmarking" aria-label="126 common pitfalls in benchmarking permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>12.6 Common Pitfalls in Benchmarking</strong></h2>
<p>Benchmarking is a powerful tool for performance analysis, but common mistakes can lead to misleading or invalid results. This section highlights these pitfalls and provides actionable solutions to mitigate them.</p>
<hr>
<h3 id="1261-ignoring-warm-up-periods" style="position:relative;"><a href="#1261-ignoring-warm-up-periods" aria-label="1261 ignoring warm up periods permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>12.6.1 Ignoring Warm-Up Periods</strong></h3>
<h4 id="pitfall" style="position:relative;"><a href="#pitfall" aria-label="pitfall permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Pitfall</strong>:</h4>
<ul>
<li>Benchmarks often start with “cold” systems where caches, buffers, and memory structures are not yet populated. This can skew results, as performance may improve over time.</li>
</ul>
<h4 id="impact" style="position:relative;"><a href="#impact" aria-label="impact permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Impact</strong>:</h4>
<ul>
<li>Initial results may show artificially high latency or low throughput, which does not reflect steady-state performance.</li>
</ul>
<h4 id="example-16" style="position:relative;"><a href="#example-16" aria-label="example 16 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example</strong>:</h4>
<ol>
<li><strong>Database</strong>:
<ul>
<li>A MySQL benchmark executed without warming up the query cache shows query latency of 500ms.</li>
<li>After running a few queries, the latency drops to 100ms due to caching.</li>
</ul>
</li>
<li><strong>Web Server</strong>:
<ul>
<li>An HTTP benchmarking tool like <code class="language-text">wrk</code> produces high response times in the first 30 seconds because the server’s thread pool is still initializing.</li>
</ul>
</li>
</ol>
<h4 id="solution-6" style="position:relative;"><a href="#solution-6" aria-label="solution 6 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Solution</strong>:</h4>
<ol>
<li>
<p><strong>Pre-Benchmark Warm-Up</strong>:</p>
<ul>
<li>Run a light workload before starting the actual benchmark.</li>
<li>Example for HTTP workloads:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">wrk <span class="token parameter variable">-t4</span> <span class="token parameter variable">-c200</span> <span class="token parameter variable">-d300s</span> http://example.com</code></pre></div>
</li>
</ul>
</li>
<li>
<p><strong>Discard Initial Results</strong>:</p>
<ul>
<li>Ignore the first few iterations in your benchmark data.</li>
<li>Example:
<ul>
<li>Run 10 iterations, but analyze only iterations 4–10.</li>
</ul>
</li>
</ul>
</li>
</ol>
<hr>
<h3 id="1262-overfitting-to-benchmarks" style="position:relative;"><a href="#1262-overfitting-to-benchmarks" aria-label="1262 overfitting to benchmarks permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>12.6.2 Overfitting to Benchmarks</strong></h3>
<h4 id="pitfall-1" style="position:relative;"><a href="#pitfall-1" aria-label="pitfall 1 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Pitfall</strong>:</h4>
<ul>
<li>Optimizing specifically for benchmark results rather than real-world workloads can lead to performance gains that do not translate to production.</li>
</ul>
<h4 id="impact-1" style="position:relative;"><a href="#impact-1" aria-label="impact 1 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Impact</strong>:</h4>
<ul>
<li>Systems may perform well in synthetic benchmarks but fail under actual production traffic patterns.</li>
</ul>
<h4 id="example-17" style="position:relative;"><a href="#example-17" aria-label="example 17 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example</strong>:</h4>
<ol>
<li>
<p><strong>Cache Tuning</strong>:</p>
<ul>
<li>A database is tuned to cache the benchmark dataset entirely in memory. While benchmark results show high throughput, production workloads with larger datasets experience excessive disk I/O.</li>
</ul>
</li>
<li>
<p><strong>Network Benchmarking</strong>:</p>
<ul>
<li>A network benchmark optimized for high-speed transfers uses jumbo frames, but the production environment does not support jumbo frames, leading to dropped packets and reduced performance.</li>
</ul>
</li>
</ol>
<h4 id="solution-7" style="position:relative;"><a href="#solution-7" aria-label="solution 7 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Solution</strong>:</h4>
<ol>
<li>
<p><strong>Test with Realistic Workloads</strong>:</p>
<ul>
<li>Simulate production-like traffic patterns or datasets.</li>
<li>Example:
<ul>
<li>For a database, use anonymized production query logs to create realistic benchmarks.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Avoid Synthetic Overoptimization</strong>:</p>
<ul>
<li>Avoid configurations that solely benefit synthetic workloads.</li>
<li>Example:
<ul>
<li>Instead of tuning caching for a small dataset, benchmark with a range of dataset sizes.</li>
</ul>
</li>
</ul>
</li>
</ol>
<hr>
<h3 id="1263-misinterpreting-metrics" style="position:relative;"><a href="#1263-misinterpreting-metrics" aria-label="1263 misinterpreting metrics permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>12.6.3 Misinterpreting Metrics</strong></h3>
<h4 id="pitfall-2" style="position:relative;"><a href="#pitfall-2" aria-label="pitfall 2 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Pitfall</strong>:</h4>
<ul>
<li>Solely relying on average metrics, such as mean latency, can obscure critical information about outliers or variability.</li>
</ul>
<h4 id="impact-2" style="position:relative;"><a href="#impact-2" aria-label="impact 2 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Impact</strong>:</h4>
<ul>
<li>Averages may hide performance spikes that significantly affect user experience.</li>
</ul>
<h4 id="example-18" style="position:relative;"><a href="#example-18" aria-label="example 18 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example</strong>:</h4>
<ol>
<li>
<p><strong>Latency</strong>:</p>
<ul>
<li>Average latency for a web application is 100ms, but P99 latency spikes to 500ms during peak traffic. The user experience is degraded, but the issue is masked by the average.</li>
</ul>
</li>
<li>
<p><strong>Throughput</strong>:</p>
<ul>
<li>A database shows an average throughput of 1000 transactions per second, but during certain intervals, throughput drops to 300 transactions per second due to locking.</li>
</ul>
</li>
</ol>
<h4 id="solution-8" style="position:relative;"><a href="#solution-8" aria-label="solution 8 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Solution</strong>:</h4>
<ol>
<li>
<p><strong>Focus on Percentiles</strong>:</p>
<ul>
<li>Analyze P95 and P99 latencies to capture outliers.</li>
<li>Example (using <code class="language-text">wrk</code>):
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">wrk <span class="token parameter variable">-t8</span> <span class="token parameter variable">-c400</span> <span class="token parameter variable">-d60s</span> http://example.com</code></pre></div>
<ul>
<li>Output:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">Latency Distribution:
    50%  100ms
    95%  300ms
    99%  500ms</code></pre></div>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Visualize Data</strong>:</p>
<ul>
<li>Use tools like Grafana or Python to plot latency distributions.</li>
<li>Example (Python):
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">,</span> <span class="token number">500</span><span class="token punctuation">,</span> <span class="token number">300</span><span class="token punctuation">,</span> <span class="token number">400</span><span class="token punctuation">]</span>
plt<span class="token punctuation">.</span>hist<span class="token punctuation">(</span>data<span class="token punctuation">,</span> bins<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"Latency Distribution"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre></div>
</li>
</ul>
</li>
</ol>
<hr>
<h3 id="1264-lack-of-reproducibility" style="position:relative;"><a href="#1264-lack-of-reproducibility" aria-label="1264 lack of reproducibility permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>12.6.4 Lack of Reproducibility</strong></h3>
<h4 id="pitfall-3" style="position:relative;"><a href="#pitfall-3" aria-label="pitfall 3 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Pitfall</strong>:</h4>
<ul>
<li>Failing to document system configurations, benchmark parameters, or environmental factors makes it impossible to reproduce results.</li>
</ul>
<h4 id="impact-3" style="position:relative;"><a href="#impact-3" aria-label="impact 3 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Impact</strong>:</h4>
<ul>
<li>Results lose credibility and cannot be validated or compared in the future.</li>
</ul>
<h4 id="example-19" style="position:relative;"><a href="#example-19" aria-label="example 19 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example</strong>:</h4>
<ol>
<li>
<p><strong>Configuration Changes</strong>:</p>
<ul>
<li>A CPU benchmark is run on a system without documenting the scaling governor setting. Subsequent runs yield different results because the governor defaults to “powersave.”</li>
</ul>
</li>
<li>
<p><strong>Software Versions</strong>:</p>
<ul>
<li>A database benchmark is conducted on PostgreSQL 13, but later attempts on PostgreSQL 14 produce different results due to optimizations in the newer version.</li>
</ul>
</li>
</ol>
<h4 id="solution-9" style="position:relative;"><a href="#solution-9" aria-label="solution 9 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Solution</strong>:</h4>
<ol>
<li>
<p><strong>Document Everything</strong>:</p>
<ul>
<li>Record hardware details (CPU, RAM, storage), software versions, and environment variables.</li>
<li>Example:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">lscpu <span class="token operator">></span> benchmark_environment.txt
<span class="token function">free</span> <span class="token parameter variable">-h</span> <span class="token operator">>></span> benchmark_environment.txt
<span class="token function">uname</span> <span class="token parameter variable">-a</span> <span class="token operator">>></span> benchmark_environment.txt</code></pre></div>
</li>
</ul>
</li>
<li>
<p><strong>Automate Configuration</strong>:</p>
<ul>
<li>Use scripts or configuration management tools to standardize the environment.</li>
<li>Example:
<ul>
<li>Docker or Ansible scripts to replicate environments.</li>
</ul>
</li>
</ul>
</li>
</ol>
<hr>
<h3 id="1265-skipping-multiple-runs" style="position:relative;"><a href="#1265-skipping-multiple-runs" aria-label="1265 skipping multiple runs permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>12.6.5 Skipping Multiple Runs</strong></h3>
<h4 id="pitfall-4" style="position:relative;"><a href="#pitfall-4" aria-label="pitfall 4 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Pitfall</strong>:</h4>
<ul>
<li>Relying on a single run for benchmarking ignores variability caused by transient factors like CPU scheduling or network jitter.</li>
</ul>
<h4 id="impact-4" style="position:relative;"><a href="#impact-4" aria-label="impact 4 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Impact</strong>:</h4>
<ul>
<li>Results may not reflect true system performance and can lead to incorrect conclusions.</li>
</ul>
<h4 id="example-20" style="position:relative;"><a href="#example-20" aria-label="example 20 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example</strong>:</h4>
<ol>
<li>
<p><strong>Network Benchmark</strong>:</p>
<ul>
<li>A single run of <code class="language-text">iperf3</code> shows throughput of 900 Mbps, but subsequent runs show an average of 700 Mbps due to congestion.</li>
</ul>
</li>
<li>
<p><strong>Disk I/O</strong>:</p>
<ul>
<li>An <code class="language-text">FIO</code> test on an SSD produces inconsistent results due to background garbage collection.</li>
</ul>
</li>
</ol>
<h4 id="solution-10" style="position:relative;"><a href="#solution-10" aria-label="solution 10 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Solution</strong>:</h4>
<ol>
<li>
<p><strong>Repeat Benchmarks</strong>:</p>
<ul>
<li>Conduct a minimum of 3–5 runs and calculate averages or percentiles.</li>
<li>Example (for <code class="language-text">wrk</code>):
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token keyword">for</span> <span class="token for-or-select variable">i</span> <span class="token keyword">in</span> <span class="token punctuation">{</span><span class="token number">1</span><span class="token punctuation">..</span><span class="token number">5</span><span class="token punctuation">}</span><span class="token punctuation">;</span> <span class="token keyword">do</span> wrk <span class="token parameter variable">-t8</span> <span class="token parameter variable">-c400</span> <span class="token parameter variable">-d60s</span> http://example.com<span class="token punctuation">;</span> <span class="token keyword">done</span></code></pre></div>
</li>
</ul>
</li>
<li>
<p><strong>Aggregate Results</strong>:</p>
<ul>
<li>Use statistical tools to analyze and summarize data.</li>
<li>Example (Python):
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">700</span><span class="token punctuation">,</span> <span class="token number">750</span><span class="token punctuation">,</span> <span class="token number">800</span><span class="token punctuation">,</span> <span class="token number">720</span><span class="token punctuation">,</span> <span class="token number">730</span><span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Average: </span><span class="token interpolation"><span class="token punctuation">{</span>np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">, Std Dev: </span><span class="token interpolation"><span class="token punctuation">{</span>np<span class="token punctuation">.</span>std<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span></code></pre></div>
</li>
</ul>
</li>
</ol>
<hr>
<h3 id="1266-testing-with-unrealistic-workloads" style="position:relative;"><a href="#1266-testing-with-unrealistic-workloads" aria-label="1266 testing with unrealistic workloads permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>12.6.6 Testing with Unrealistic Workloads</strong></h3>
<h4 id="pitfall-5" style="position:relative;"><a href="#pitfall-5" aria-label="pitfall 5 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Pitfall</strong>:</h4>
<ul>
<li>Benchmarks using workloads that do not reflect actual usage patterns can produce results that are irrelevant to production.</li>
</ul>
<h4 id="impact-5" style="position:relative;"><a href="#impact-5" aria-label="impact 5 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Impact</strong>:</h4>
<ul>
<li>Optimizations based on unrealistic workloads may degrade real-world performance.</li>
</ul>
<h4 id="example-21" style="position:relative;"><a href="#example-21" aria-label="example 21 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example</strong>:</h4>
<ol>
<li>
<p><strong>Database</strong>:</p>
<ul>
<li>Running a benchmark with 100% read queries for a mixed workload database application leads to misleadingly high throughput.</li>
</ul>
</li>
<li>
<p><strong>Web Application</strong>:</p>
<ul>
<li>Benchmarking an API with constant request rates does not account for burst traffic patterns in production.</li>
</ul>
</li>
</ol>
<h4 id="solution-11" style="position:relative;"><a href="#solution-11" aria-label="solution 11 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Solution</strong>:</h4>
<ol>
<li>
<p><strong>Simulate Production Traffic</strong>:</p>
<ul>
<li>Use logs or analytics data to design realistic workloads.</li>
<li>Example:
<ul>
<li>For an API benchmark, use 80% GET and 20% POST requests.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Incorporate Burst Scenarios</strong>:</p>
<ul>
<li>Simulate traffic bursts to test system behavior under stress.</li>
<li>Example:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">wrk <span class="token parameter variable">-t16</span> <span class="token parameter variable">-c2000</span> <span class="token parameter variable">-d120s</span> http://example.com</code></pre></div>
</li>
</ul>
</li>
</ol>
<hr>
<h3 id="1267-overlooking-system-bottlenecks" style="position:relative;"><a href="#1267-overlooking-system-bottlenecks" aria-label="1267 overlooking system bottlenecks permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>12.6.7 Overlooking System Bottlenecks</strong></h3>
<h4 id="pitfall-6" style="position:relative;"><a href="#pitfall-6" aria-label="pitfall 6 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Pitfall</strong>:</h4>
<ul>
<li>Running benchmarks without monitoring the system may overlook underlying bottlenecks like CPU saturation, memory exhaustion, or disk I/O contention.</li>
</ul>
<h4 id="impact-6" style="position:relative;"><a href="#impact-6" aria-label="impact 6 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Impact</strong>:</h4>
<ul>
<li>Results may suggest incorrect bottlenecks or mask critical issues.</li>
</ul>
<h4 id="example-22" style="position:relative;"><a href="#example-22" aria-label="example 22 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example</strong>:</h4>
<ol>
<li>
<p><strong>CPU Saturation</strong>:</p>
<ul>
<li>A web server benchmark shows declining throughput under heavy load, but the issue is due to CPU saturation, not the application itself.</li>
</ul>
</li>
<li>
<p><strong>Disk I/O</strong>:</p>
<ul>
<li>A database benchmark shows high latency, but the root cause is excessive disk writes due to inadequate caching.</li>
</ul>
</li>
</ol>
<h4 id="solution-12" style="position:relative;"><a href="#solution-12" aria-label="solution 12 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Solution</strong>:</h4>
<ol>
<li>
<p><strong>Monitor System Metrics</strong>:</p>
<ul>
<li>Use tools like <code class="language-text">vmstat</code>, <code class="language-text">sar</code>, and <code class="language-text">perf</code> during benchmarks.</li>
<li>Example:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">vmstat</span> <span class="token number">1</span></code></pre></div>
</li>
</ul>
</li>
<li>
<p><strong>Correlate Metrics with Results</strong>:</p>
<ul>
<li>Analyze CPU, memory, and disk usage alongside benchmark outputs to identify bottlenecks.</li>
</ul>
</li>
</ol>
<hr>
<h3 id="key-takeaways-14" style="position:relative;"><a href="#key-takeaways-14" aria-label="key takeaways 14 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Key Takeaways</strong></h3>
<ol>
<li>
<p><strong>Warm Up Systems</strong>:</p>
<ul>
<li>Allow caches and buffers to stabilize before collecting data.</li>
<li><strong>Highlight</strong>: “Cold benchmarks lead to skewed results that do not reflect steady-state performance.”</li>
</ul>
</li>
<li>
<p><strong>Use Realistic Workloads</strong>:</p>
<ul>
<li>Simulate actual usage patterns to produce actionable insights.</li>
<li><strong>Highlight</strong>: “Unrealistic benchmarks mislead optimizations.”</li>
</ul>
</li>
<li>
<p><strong>Document and Repeat</strong>:</p>
<ul>
<li>Record all configurations and run benchmarks multiple times for reliability.</li>
<li><strong>Highlight</strong>: “Reproducibility is critical for credible benchmarking.”</li>
</ul>
</li>
<li>
<p><strong>Focus on Percentiles</strong>:</p>
<ul>
<li>Analyze P95 and P99 latencies to capture outliers.</li>
<li><strong>Highlight</strong>: “Averages often hide critical performance issues.”</li>
</ul>
</li>
<li>
<p><strong>Correlate Metrics</strong>:</p>
<ul>
<li>Monitor system behavior to uncover bottlenecks.</li>
<li><strong>Highlight</strong>: “Benchmark data without system metrics is incomplete.”</li>
</ul>
</li>
</ol>
<hr>
<h2 id="127-practical-example-benchmarking-a-web-application" style="position:relative;"><a href="#127-practical-example-benchmarking-a-web-application" aria-label="127 practical example benchmarking a web application permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>12.7 Practical Example: Benchmarking a Web Application</strong></h2>
<h3 id="scenario-2" style="position:relative;"><a href="#scenario-2" aria-label="scenario 2 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Scenario</strong></h3>
<p>A company runs a high-traffic e-commerce platform and needs to benchmark its web application to:</p>
<ol>
<li>Measure <strong>average and peak response times</strong>.</li>
<li>Determine <strong>maximum throughput</strong> under concurrent user loads.</li>
<li>Identify system bottlenecks (e.g., CPU, memory, disk, or database).</li>
</ol>
<hr>
<h3 id="step-1-define-goals" style="position:relative;"><a href="#step-1-define-goals" aria-label="step 1 define goals permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Step 1: Define Goals</strong></h3>
<h4 id="objectives" style="position:relative;"><a href="#objectives" aria-label="objectives permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Objectives</strong>:</h4>
<ol>
<li>Measure <strong>average response time</strong>, <strong>P95 latency</strong>, and <strong>P99 latency</strong> under normal and peak traffic.</li>
<li>Determine the system’s maximum throughput in terms of requests per second (RPS).</li>
<li>Identify bottlenecks in application code, database queries, and system resources.</li>
</ol>
<h4 id="metrics-to-collect" style="position:relative;"><a href="#metrics-to-collect" aria-label="metrics to collect permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Metrics to Collect</strong>:</h4>
<ul>
<li><strong>Latency</strong>:
<ul>
<li>Average, P95, and P99 response times.</li>
</ul>
</li>
<li><strong>Throughput</strong>:
<ul>
<li>Requests per second.</li>
</ul>
</li>
<li><strong>Resource Utilization</strong>:
<ul>
<li>CPU, memory, disk I/O, and network usage.</li>
</ul>
</li>
</ul>
<hr>
<h3 id="step-2-prepare-the-environment" style="position:relative;"><a href="#step-2-prepare-the-environment" aria-label="step 2 prepare the environment permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Step 2: Prepare the Environment</strong></h3>
<h4 id="test-environment" style="position:relative;"><a href="#test-environment" aria-label="test environment permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Test Environment</strong>:</h4>
<ol>
<li>Use a <strong>dedicated virtual machine</strong> for the web server:
<ul>
<li>CPU: 8 cores.</li>
<li>RAM: 32GB.</li>
<li>Disk: SSD.</li>
</ul>
</li>
<li>Deploy the application on an <strong>Nginx web server</strong> with a <strong>MySQL database</strong> backend.</li>
<li>Disable non-essential services to minimize noise:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">systemctl stop <span class="token function">cron</span></code></pre></div>
</li>
</ol>
<h4 id="baseline-configuration" style="position:relative;"><a href="#baseline-configuration" aria-label="baseline configuration permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Baseline Configuration</strong>:</h4>
<ul>
<li>OS: Ubuntu 20.04.</li>
<li>Web server: Nginx 1.20.</li>
<li>Application: Python Flask.</li>
<li>Database: MySQL 8.0.</li>
</ul>
<h4 id="warm-up" style="position:relative;"><a href="#warm-up" aria-label="warm up permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Warm-Up</strong>:</h4>
<ul>
<li>Pre-load the application cache:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">wrk <span class="token parameter variable">-t4</span> <span class="token parameter variable">-c200</span> <span class="token parameter variable">-d300s</span> http://example.com</code></pre></div>
</li>
</ul>
<h4 id="document-configuration" style="position:relative;"><a href="#document-configuration" aria-label="document configuration permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Document Configuration</strong>:</h4>
<p>Record all environment details for reproducibility:</p>
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">lscpu <span class="token operator">></span> environment.txt
<span class="token function">free</span> <span class="token parameter variable">-h</span> <span class="token operator">>></span> environment.txt
<span class="token function">uname</span> <span class="token parameter variable">-a</span> <span class="token operator">>></span> environment.txt</code></pre></div>
<hr>
<h3 id="step-3-select-workloads" style="position:relative;"><a href="#step-3-select-workloads" aria-label="step 3 select workloads permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Step 3: Select Workloads</strong></h3>
<h4 id="workload-design" style="position:relative;"><a href="#workload-design" aria-label="workload design permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Workload Design</strong>:</h4>
<p>Simulate typical user behavior based on analytics data:</p>
<ol>
<li><strong>70% Browsing</strong>:
<ul>
<li>Product page views.</li>
<li>Example URL: <code class="language-text">/product?id=12345</code>.</li>
</ul>
</li>
<li><strong>20% Search</strong>:
<ul>
<li>Search queries.</li>
<li>Example URL: <code class="language-text">/search?q=laptop</code>.</li>
</ul>
</li>
<li><strong>10% Checkout</strong>:
<ul>
<li>Order submissions.</li>
<li>Example URL: <code class="language-text">/checkout</code>.</li>
</ul>
</li>
</ol>
<h4 id="tools-15" style="position:relative;"><a href="#tools-15" aria-label="tools 15 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Tools</strong>:</h4>
<ul>
<li>Use <strong>wrk</strong> for HTTP benchmarking:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">wrk <span class="token parameter variable">-t8</span> <span class="token parameter variable">-c400</span> <span class="token parameter variable">-d60s</span> http://example.com</code></pre></div>
</li>
<li>Use <strong>Apache JMeter</strong> for complex test scenarios:
<ul>
<li>Create a test plan with 1000 virtual users performing the above actions concurrently.</li>
</ul>
</li>
</ul>
<hr>
<h3 id="step-4-collect-baseline-metrics" style="position:relative;"><a href="#step-4-collect-baseline-metrics" aria-label="step 4 collect baseline metrics permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Step 4: Collect Baseline Metrics</strong></h3>
<h4 id="monitoring-tools" style="position:relative;"><a href="#monitoring-tools" aria-label="monitoring tools permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Monitoring Tools</strong>:</h4>
<ol>
<li>
<p><strong>System Metrics</strong>:</p>
<ul>
<li>Use <code class="language-text">vmstat</code> to monitor CPU, memory, and I/O:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">vmstat</span> <span class="token number">1</span></code></pre></div>
</li>
<li>Example Output:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs  us  sy  id  wa
 4  0      0  24000  3000  15000    0    0    20    50   100  200  50  10  40   0</code></pre></div>
</li>
</ul>
</li>
<li>
<p><strong>Application Metrics</strong>:</p>
<ul>
<li>Enable application-level logging for response times and query durations.</li>
</ul>
</li>
<li>
<p><strong>Database Metrics</strong>:</p>
<ul>
<li>Enable the MySQL slow query log:
<div class="gatsby-highlight" data-language="sql"><pre class="language-sql"><code class="language-sql"><span class="token keyword">SET</span> <span class="token keyword">GLOBAL</span> slow_query_log <span class="token operator">=</span> <span class="token string">'ON'</span><span class="token punctuation">;</span>
<span class="token keyword">SET</span> <span class="token keyword">GLOBAL</span> long_query_time <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span></code></pre></div>
</li>
</ul>
</li>
</ol>
<h4 id="baseline-results" style="position:relative;"><a href="#baseline-results" aria-label="baseline results permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Baseline Results</strong>:</h4>
<ul>
<li><strong>Throughput</strong>: 500 requests/second.</li>
<li><strong>Latency</strong>:
<ul>
<li>Average: 200ms.</li>
<li>P95: 300ms.</li>
<li>P99: 500ms.</li>
</ul>
</li>
<li><strong>Resource Utilization</strong>:
<ul>
<li>CPU: 60% utilization.</li>
<li>Memory: 24GB used, no swapping.</li>
</ul>
</li>
</ul>
<hr>
<h3 id="step-5-conduct-benchmarks" style="position:relative;"><a href="#step-5-conduct-benchmarks" aria-label="step 5 conduct benchmarks permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Step 5: Conduct Benchmarks</strong></h3>
<h4 id="load-test-1-moderate-traffic" style="position:relative;"><a href="#load-test-1-moderate-traffic" aria-label="load test 1 moderate traffic permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Load Test 1: Moderate Traffic</strong></h4>
<ul>
<li><strong>Command</strong>:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">wrk <span class="token parameter variable">-t8</span> <span class="token parameter variable">-c400</span> <span class="token parameter variable">-d60s</span> http://example.com</code></pre></div>
</li>
<li><strong>Metrics</strong>:
<ul>
<li>Average Latency: 150ms.</li>
<li>P95 Latency: 250ms.</li>
<li>Throughput: 800 requests/second.</li>
</ul>
</li>
</ul>
<h4 id="load-test-2-peak-traffic" style="position:relative;"><a href="#load-test-2-peak-traffic" aria-label="load test 2 peak traffic permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Load Test 2: Peak Traffic</strong></h4>
<ul>
<li><strong>Command</strong>:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">wrk <span class="token parameter variable">-t16</span> <span class="token parameter variable">-c1000</span> <span class="token parameter variable">-d120s</span> http://example.com</code></pre></div>
</li>
<li><strong>Metrics</strong>:
<ul>
<li>Average Latency: 300ms.</li>
<li>P95 Latency: 600ms.</li>
<li>Throughput: 1200 requests/second.</li>
<li>CPU Utilization: 85%.</li>
<li>Observations:
<ul>
<li>Database query latency spikes to 2 seconds for some queries.</li>
<li>Disk I/O increases significantly due to swapping.</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h3 id="step-6-analyze-results" style="position:relative;"><a href="#step-6-analyze-results" aria-label="step 6 analyze results permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Step 6: Analyze Results</strong></h3>
<h4 id="key-observations" style="position:relative;"><a href="#key-observations" aria-label="key observations permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Key Observations</strong>:</h4>
<ol>
<li><strong>Latency</strong>:
<ul>
<li>P95 latency of 600ms under peak load suggests bottlenecks in the application or database.</li>
</ul>
</li>
<li><strong>Throughput</strong>:
<ul>
<li>Throughput plateaus at 1200 RPS, indicating resource limits (CPU or database queries).</li>
</ul>
</li>
<li><strong>Database</strong>:
<ul>
<li>MySQL slow query log reveals full table scans for certain queries:
<div class="gatsby-highlight" data-language="sql"><pre class="language-sql"><code class="language-sql"><span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> orders <span class="token keyword">WHERE</span> <span class="token keyword">status</span> <span class="token operator">=</span> <span class="token string">'PENDING'</span><span class="token punctuation">;</span></code></pre></div>
</li>
</ul>
</li>
</ol>
<h4 id="graph-results" style="position:relative;"><a href="#graph-results" aria-label="graph results permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Graph Results</strong>:</h4>
<ul>
<li>Visualize latency distribution using Python:
<div class="gatsby-highlight" data-language="python"><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">150</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">,</span> <span class="token number">300</span><span class="token punctuation">,</span> <span class="token number">400</span><span class="token punctuation">,</span> <span class="token number">500</span><span class="token punctuation">,</span> <span class="token number">600</span><span class="token punctuation">]</span>
plt<span class="token punctuation">.</span>hist<span class="token punctuation">(</span>data<span class="token punctuation">,</span> bins<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"Latency Distribution"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre></div>
</li>
</ul>
<hr>
<h3 id="step-7-apply-optimizations" style="position:relative;"><a href="#step-7-apply-optimizations" aria-label="step 7 apply optimizations permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Step 7: Apply Optimizations</strong></h3>
<ol>
<li>
<p><strong>Optimize Application Code</strong>:</p>
<ul>
<li>Use caching for frequently accessed endpoints like <code class="language-text">/product?id=12345</code>.</li>
<li>Implement database connection pooling.</li>
</ul>
</li>
<li>
<p><strong>Database Indexing</strong>:</p>
<ul>
<li>Add an index to the <code class="language-text">orders.status</code> column:
<div class="gatsby-highlight" data-language="sql"><pre class="language-sql"><code class="language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">INDEX</span> idx_status <span class="token keyword">ON</span> orders<span class="token punctuation">(</span><span class="token keyword">status</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre></div>
</li>
</ul>
</li>
<li>
<p><strong>Increase Resources</strong>:</p>
<ul>
<li>Scale the database vertically by upgrading to a larger instance.</li>
</ul>
</li>
</ol>
<hr>
<h3 id="step-8-re-test-after-optimization" style="position:relative;"><a href="#step-8-re-test-after-optimization" aria-label="step 8 re test after optimization permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Step 8: Re-Test After Optimization</strong></h3>
<h4 id="results" style="position:relative;"><a href="#results" aria-label="results permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Results</strong>:</h4>
<ol>
<li>
<p><strong>Load Test 1 (Moderate Traffic)</strong>:</p>
<ul>
<li>Average Latency: 100ms.</li>
<li>P95 Latency: 150ms.</li>
<li>Throughput: 1000 requests/second.</li>
</ul>
</li>
<li>
<p><strong>Load Test 2 (Peak Traffic)</strong>:</p>
<ul>
<li>Average Latency: 200ms.</li>
<li>P95 Latency: 300ms.</li>
<li>Throughput: 1500 requests/second.</li>
<li>Observations:
<ul>
<li>No swapping observed.</li>
<li>Database query execution time reduced to 50ms.</li>
</ul>
</li>
</ul>
</li>
</ol>
<hr>
<h3 id="key-takeaways-for-practical-examples-1" style="position:relative;"><a href="#key-takeaways-for-practical-examples-1" aria-label="key takeaways for practical examples 1 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Key Takeaways for practical examples</strong></h3>
<ol>
<li>
<p><strong>Structured Approach Works</strong>:</p>
<ul>
<li>Start with clear goals, measure baselines, apply realistic workloads, and repeat after optimizations.</li>
</ul>
</li>
<li>
<p><strong>Bottlenecks Revealed</strong>:</p>
<ul>
<li>Full table scans in database queries and insufficient memory caused bottlenecks.</li>
</ul>
</li>
<li>
<p><strong>Impact of Optimizations</strong>:</p>
<ul>
<li>Response times improved by 50%, and throughput increased by 25%.</li>
</ul>
</li>
<li>
<p><strong>Use Graphs for Insight</strong>:</p>
<ul>
<li>Visualizing latency trends helped identify spikes and anomalies.</li>
</ul>
</li>
</ol>
<hr>
<h2 id="key-takeaways-for-benchmarking" style="position:relative;"><a href="#key-takeaways-for-benchmarking" aria-label="key takeaways for benchmarking permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Key Takeaways for benchmarking</strong></h2>
<ol>
<li>
<p><strong>Benchmarking is iterative</strong>:</p>
<ul>
<li>Results guide system optimizations, which must be re-validated through additional benchmarks.</li>
<li><strong>Highlight</strong>: “Benchmark, optimize, and benchmark again.”</li>
</ul>
</li>
<li>
<p><strong>Select the right tools</strong>:</p>
<ul>
<li>Use benchmarks appropriate for the system component under test (e.g., <code class="language-text">fio</code> for disk, <code class="language-text">wrk</code> for HTTP).</li>
</ul>
</li>
<li>
<p><strong>Reproducibility matters</strong>:</p>
<ul>
<li>Document configurations and use consistent environments to ensure valid comparisons.</li>
</ul>
</li>
<li>
<p><strong>Statistical analysis is critical</strong>:</p>
<ul>
<li>Percentiles and visualization tools provide a more comprehensive view than averages.</li>
</ul>
</li>
<li>
<p><strong>how to get consistent results when benchmarking on linux</strong></p>
<ul>
<li><a href="https://easyperf.net/blog/2019/08/02/Perf-measurement-environment-on-Linux">https://easyperf.net/blog/2019/08/02/Perf-measurement-environment-on-Linux</a></li>
</ul>
</li>
</ol>
<h1 id="perf-the-linux-profiler" style="position:relative;"><a href="#perf-the-linux-profiler" aria-label="perf the linux profiler permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong><code class="language-text">perf</code>: The Linux Profiler</strong></h1>
<hr>
<h2 id="detailed-guide-to-the-linux-profiler-perf" style="position:relative;"><a href="#detailed-guide-to-the-linux-profiler-perf" aria-label="detailed guide to the linux profiler perf permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Detailed Guide to the Linux Profiler <code class="language-text">perf</code></strong></h2>
<ol>
<li>
<p><strong>Introduction to <code class="language-text">perf</code></strong>:</p>
<ul>
<li><strong>Definition</strong>:
<ul>
<li><code class="language-text">perf</code> is a Linux performance analysis tool capable of profiling CPU usage, analyzing I/O bottlenecks, tracing kernel events, and debugging application-level performance issues.</li>
</ul>
</li>
<li><strong>Key Capabilities</strong>:
<ul>
<li>Measures hardware performance counters (e.g., CPU cycles, cache misses).</li>
<li>Tracks kernel and user-space events such as system calls and context switches.</li>
<li>Provides insights into memory access patterns, I/O performance, and network activity.</li>
</ul>
</li>
<li><strong>Common Use Cases</strong>:
<ul>
<li>Optimizing high-CPU processes.</li>
<li>Identifying memory bottlenecks caused by cache inefficiencies.</li>
<li>Debugging kernel-level performance issues.</li>
</ul>
</li>
</ul>
<p><strong>Key Point</strong>:</p>
<ul>
<li>”<code class="language-text">perf</code> is the Swiss Army knife of performance analysis, addressing challenges from application inefficiencies to kernel debugging.”</li>
</ul>
</li>
</ol>
<hr>
<h2 id="commands-and-tools-for-event-tracing-and-cpu-profiling" style="position:relative;"><a href="#commands-and-tools-for-event-tracing-and-cpu-profiling" aria-label="commands and tools for event tracing and cpu profiling permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Commands and Tools for Event Tracing and CPU Profiling</strong></h2>
<ol>
<li>
<p><strong>Basic Commands</strong>:</p>
<ul>
<li>
<p><strong><code class="language-text">perf list</code></strong>:</p>
<ul>
<li>Lists all available hardware, software, and tracepoint events.</li>
<li><strong>Example</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">perf list</code></pre></div>
<ul>
<li>Hardware events: <code class="language-text">cpu-cycles</code>, <code class="language-text">instructions</code>, <code class="language-text">cache-references</code>.</li>
<li>Software events: <code class="language-text">page-faults</code>, <code class="language-text">context-switches</code>.</li>
<li>Tracepoints: <code class="language-text">sched:sched_switch</code>, <code class="language-text">syscalls:sys_enter_write</code>.</li>
</ul>
</li>
<li><strong>Key Insight</strong>:
<ul>
<li>Use this command to identify relevant events for your workload.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong><code class="language-text">perf stat</code></strong>:</p>
<ul>
<li>Provides an overview of performance metrics for a specific workload.</li>
<li><strong>Example</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">perf stat -e cpu-cycles,cache-misses ./my_program</code></pre></div>
<ul>
<li>Output:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">1,000,000 cache-misses     # High cache miss rate</code></pre></div>
</li>
</ul>
</li>
<li><strong>Use Case</strong>:
<ul>
<li>Quickly diagnose whether a process is CPU-bound or suffers from memory inefficiencies.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong><code class="language-text">perf record</code> and <code class="language-text">perf report</code></strong>:</p>
<ul>
<li><strong><code class="language-text">perf record</code></strong>: Captures performance data during workload execution.</li>
<li><strong><code class="language-text">perf report</code></strong>: Visualizes the recorded data.</li>
<li><strong>Example</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">perf record ./my_program
perf report</code></pre></div>
<ul>
<li>Output:
<ul>
<li>Displays CPU time spent in each function, sorted by percentage.</li>
</ul>
</li>
<li><strong>Insight</strong>:
<ul>
<li>Identifies hotspots such as inefficient loops or expensive function calls.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Advanced CPU Profiling</strong>:</p>
<ul>
<li>
<p><strong>Hardware Counter Profiling</strong>:</p>
<ul>
<li>Measures low-level CPU events such as cycles, branch mispredictions, and cache behavior.</li>
<li><strong>Example</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">perf stat -e branch-misses,instructions ./my_program</code></pre></div>
<ul>
<li>High <code class="language-text">branch-misses</code> indicates inefficiencies in branch prediction.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Call Graph Profiling</strong>:</p>
<ul>
<li>Captures stack traces for a deeper understanding of code paths.</li>
<li><strong>Example</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">perf record -g ./my_program
perf report</code></pre></div>
<ul>
<li>Displays a flame graph of function calls to identify deep recursion or hotspots.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Real-Time CPU Analysis with <code class="language-text">perf top</code></strong>:</p>
<ul>
<li>Monitors active processes and functions consuming the most CPU in real-time.</li>
<li><strong>Example</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">perf top</code></pre></div>
<ul>
<li>Use Case:
<ul>
<li>Identify high-CPU functions in a busy server application.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Event Tracing with <code class="language-text">perf</code></strong>:</p>
<ul>
<li>
<p><strong>System Call Tracing</strong>:</p>
<ul>
<li>Trace specific system calls such as file I/O or memory allocation.</li>
<li><strong>Example</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">perf trace -e syscalls:sys_enter_open ./my_program</code></pre></div>
<ul>
<li>Output:
<ul>
<li>Shows <code class="language-text">open()</code> system calls and associated files.</li>
</ul>
</li>
<li><strong>Use Case</strong>:
<ul>
<li>Detect excessive or redundant file operations.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Kernel Tracepoints</strong>:</p>
<ul>
<li>Monitor kernel-level events like scheduling or block I/O.</li>
<li><strong>Example</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">perf record -e sched:sched_switch ./my_program
perf report</code></pre></div>
<ul>
<li><strong>Key Insight</strong>:
<ul>
<li>Use tracepoints to analyze context switches and thread scheduling inefficiencies.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Custom Probes</strong>:</p>
<ul>
<li><strong>Dynamic Probes (<code class="language-text">kprobes</code> and <code class="language-text">uprobes</code>)</strong>:
<ul>
<li>Insert custom tracepoints into user-space or kernel functions.</li>
<li><strong>Example</strong>:
<ul>
<li>Add a probe to the <code class="language-text">main()</code> function in a program:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">perf probe -x ./my_program main
perf record -e probe:main ./my_program
perf report</code></pre></div>
</li>
<li><strong>Insight</strong>:
<ul>
<li>Useful for debugging performance-critical functions.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ol>
<hr>
<h2 id="advanced-use-cases-and-examples" style="position:relative;"><a href="#advanced-use-cases-and-examples" aria-label="advanced use cases and examples permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Advanced Use Cases and Examples</strong></h2>
<ol>
<li>
<p><strong>Analyzing Cache Behavior</strong>:</p>
<ul>
<li><strong>Scenario</strong>:
<ul>
<li>A data-intensive application is running slower than expected.</li>
</ul>
</li>
<li><strong>Command</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">perf stat -e cache-references,cache-misses ./data_processor</code></pre></div>
</li>
<li><strong>Output</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">1,500,000 cache-references
1,000,000 cache-misses     # 66.6% miss rate</code></pre></div>
</li>
<li><strong>Interpretation</strong>:
<ul>
<li>High cache-miss rates indicate poor memory locality.</li>
<li>Solution:
<ul>
<li>Optimize data structures to reduce cache misses (e.g., array-of-structures to structure-of-arrays).</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Tracing Context Switches</strong>:</p>
<ul>
<li><strong>Scenario</strong>:
<ul>
<li>High CPU usage in a VM due to frequent context switches.</li>
</ul>
</li>
<li><strong>Command</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">perf record -e context-switches ./vm_task
perf report</code></pre></div>
</li>
<li><strong>Output</strong>:
<ul>
<li>Shows the processes triggering the most context switches.</li>
</ul>
</li>
<li><strong>Solution</strong>:
<ul>
<li>Adjust thread priorities or reduce thread count to minimize context switching overhead.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Debugging I/O Performance</strong>:</p>
<ul>
<li><strong>Scenario</strong>:
<ul>
<li>A database server exhibits high disk latency during peak loads.</li>
</ul>
</li>
<li><strong>Command</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">perf record -e block:block_rq_issue ./database_task
perf report</code></pre></div>
</li>
<li><strong>Output</strong>:
<ul>
<li>Identifies I/O requests causing the highest delays.</li>
</ul>
</li>
<li><strong>Solution</strong>:
<ul>
<li>Optimize query patterns or use faster storage.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Analyzing Branch Predictions</strong>:</p>
<ul>
<li><strong>Scenario</strong>:
<ul>
<li>A compiler optimization task shows poor performance.</li>
</ul>
</li>
<li><strong>Command</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">perf stat -e branch-instructions,branch-misses ./compiler</code></pre></div>
</li>
<li><strong>Output</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">10,000,000 branch-instructions
3,000,000 branch-misses     # 30% misprediction rate</code></pre></div>
</li>
<li><strong>Interpretation</strong>:
<ul>
<li>High misprediction rates indicate inefficient branching logic.</li>
<li>Solution:
<ul>
<li>Reorganize code to improve predictability (e.g., avoid nested <code class="language-text">if</code> conditions).</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Using Flame Graphs for Visualization</strong>:</p>
<ul>
<li><strong>Scenario</strong>:
<ul>
<li>A web application shows high response times under load.</li>
</ul>
</li>
<li><strong>Steps</strong>:
<ul>
<li>Record data:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">perf record -g ./web_server</code></pre></div>
</li>
<li>Generate flame graph:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">perf script | flamegraph.pl > flamegraph.svg</code></pre></div>
</li>
<li>Analyze:
<ul>
<li>The graph reveals which function consumes the most CPU time, enabling targeted optimizations.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ol>
<hr>
<h2 id="key-takeaways-15" style="position:relative;"><a href="#key-takeaways-15" aria-label="key takeaways 15 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Key Takeaways</strong></h2>
<ol>
<li>
<p><strong>Versatility of <code class="language-text">perf</code></strong>:</p>
<ul>
<li>”<code class="language-text">perf</code> is not just a profiler; it’s a comprehensive tool for event tracing, I/O analysis, and system-level debugging.”</li>
</ul>
</li>
<li>
<p><strong>Actionable Insights</strong>:</p>
<ul>
<li>”<code class="language-text">perf stat</code> provides quick metrics, while <code class="language-text">perf record</code> and <code class="language-text">perf report</code> enable deep dives into performance bottlenecks.”</li>
</ul>
</li>
<li>
<p><strong>Advanced Techniques</strong>:</p>
<ul>
<li>“Features like dynamic probes, kernel tracepoints, and flame graph generation make <code class="language-text">perf</code> a must-have for performance tuning.”</li>
</ul>
</li>
<li>
<p><strong>Practical Examples</strong>:</p>
<ul>
<li>Real-world scenarios demonstrate how <code class="language-text">perf</code> resolves issues ranging from CPU inefficiency to memory bottlenecks.</li>
</ul>
</li>
</ol>
<h1 id="ftrace-linux-kernel-tracing-framework" style="position:relative;"><a href="#ftrace-linux-kernel-tracing-framework" aria-label="ftrace linux kernel tracing framework permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong><code class="language-text">Ftrace</code>: Linux Kernel Tracing Framework</strong></h1>
<hr>
<h2 id="what-is-ftrace" style="position:relative;"><a href="#what-is-ftrace" aria-label="what is ftrace permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>What is <code class="language-text">Ftrace</code>?</strong></h2>
<ol>
<li>
<p><strong>Overview</strong>:</p>
<ul>
<li><strong><code class="language-text">Ftrace</code></strong> is the native Linux kernel tracing framework designed for developers and system administrators to trace kernel operations, debug performance issues, and monitor system events.</li>
<li>It is highly flexible, offering tools to trace:
<ul>
<li><strong>Kernel function calls</strong>.</li>
<li><strong>System events</strong> (e.g., scheduling, I/O operations, context switches).</li>
<li><strong>Interrupts and wake-ups</strong>.</li>
</ul>
</li>
<li>Operates via a <strong>virtual file system</strong>, typically mounted at <code class="language-text">/sys/kernel/debug/tracing</code>.</li>
</ul>
</li>
<li>
<p><strong>Primary Use Cases</strong>:</p>
<ul>
<li>Debugging kernel modules.</li>
<li>Identifying long latency paths in function calls.</li>
<li>Monitoring scheduling delays and context switch overhead.</li>
<li>Analyzing disk I/O or network performance issues.</li>
</ul>
<p><strong>Key Insight</strong>:</p>
<ul>
<li>”<code class="language-text">Ftrace</code> empowers engineers to peer into the heart of the Linux kernel, identifying inefficiencies and uncovering root causes of performance bottlenecks.”</li>
</ul>
</li>
</ol>
<hr>
<h2 id="core-components-of-ftrace" style="position:relative;"><a href="#core-components-of-ftrace" aria-label="core components of ftrace permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Core Components of <code class="language-text">Ftrace</code></strong></h2>
<ol>
<li>
<p><strong>Tracefs File System</strong>:</p>
<ul>
<li>
<p><code class="language-text">Ftrace</code> relies on the <strong>tracefs</strong> file system, accessible through <code class="language-text">/sys/kernel/debug/tracing</code>.</p>
</li>
<li>
<p>Key directories and files:</p>
<ul>
<li><strong><code class="language-text">current_tracer</code></strong>:
<ul>
<li>Specifies the active tracer (e.g., <code class="language-text">function</code>, <code class="language-text">sched</code>, <code class="language-text">irqsoff</code>).</li>
</ul>
</li>
<li><strong><code class="language-text">set_ftrace_filter</code></strong>:
<ul>
<li>Filters kernel functions to be traced.</li>
</ul>
</li>
<li><strong><code class="language-text">events/</code></strong>:
<ul>
<li>Contains subdirectories for traceable kernel events (e.g., <code class="language-text">block</code>, <code class="language-text">sched</code>).</li>
</ul>
</li>
<li><strong><code class="language-text">trace</code></strong>:
<ul>
<li>Displays the collected trace logs.</li>
</ul>
</li>
</ul>
<p><strong>Key Command</strong>:</p>
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">mount -t tracefs nodev /sys/kernel/debug/tracing</code></pre></div>
<ul>
<li>Ensures <code class="language-text">tracefs</code> is mounted and accessible.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Tracing Modes</strong>:</p>
<ul>
<li><strong>Function Tracer</strong>:
<ul>
<li>Captures kernel function calls.</li>
</ul>
</li>
<li><strong>Function Graph Tracer</strong>:
<ul>
<li>Tracks call chains and execution times for kernel functions.</li>
</ul>
</li>
<li><strong>Scheduler Tracer</strong>:
<ul>
<li>Monitors context switches and task scheduling.</li>
</ul>
</li>
<li><strong>IRQSOFF Tracer</strong>:
<ul>
<li>Identifies sections of code where interrupts are disabled.</li>
</ul>
</li>
<li><strong>Custom Event Tracing</strong>:
<ul>
<li>Monitors specific kernel events, such as block I/O and page faults.</li>
</ul>
</li>
</ul>
</li>
</ol>
<hr>
<h2 id="examples-of-using-ftrace-for-performance-analysis" style="position:relative;"><a href="#examples-of-using-ftrace-for-performance-analysis" aria-label="examples of using ftrace for performance analysis permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Examples of Using <code class="language-text">Ftrace</code> for Performance Analysis</strong></h2>
<ol>
<li>
<p><strong>Basic Function Tracing</strong></p>
<ul>
<li><strong>Objective</strong>:
<ul>
<li>Trace kernel functions being executed during a specific workload.</li>
</ul>
</li>
<li><strong>Steps</strong>:
<ul>
<li>Enable function tracing:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">echo function > /sys/kernel/debug/tracing/current_tracer</code></pre></div>
</li>
<li>Filter for a specific function (e.g., <code class="language-text">do_sys_open</code>):
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">echo do_sys_open > /sys/kernel/debug/tracing/set_ftrace_filter</code></pre></div>
</li>
<li>Start tracing:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">echo 1 > /sys/kernel/debug/tracing/tracing_on</code></pre></div>
</li>
<li>View the trace log:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">cat /sys/kernel/debug/tracing/trace</code></pre></div>
</li>
<li>Stop tracing:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">echo 0 > /sys/kernel/debug/tracing/tracing_on</code></pre></div>
</li>
</ul>
</li>
</ul>
<p><strong>Example Output</strong>:</p>
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">0)   do_sys_open &lt;- path_openat
0)   vfs_open &lt;- do_sys_open
0)   security_inode_permission &lt;- vfs_open</code></pre></div>
<p><strong>Use Case</strong>:</p>
<ul>
<li>Trace which kernel functions are called when opening a file.</li>
</ul>
<p><strong>Key Insight</strong>:</p>
<ul>
<li>“Function tracing provides granular visibility into the kernel’s execution flow, helping isolate inefficiencies.”</li>
</ul>
</li>
</ol>
<hr>
<ol start="2">
<li>
<p><strong>Function Graph Tracing</strong></p>
<ul>
<li><strong>Objective</strong>:
<ul>
<li>Analyze function execution paths and measure time spent in kernel functions.</li>
</ul>
</li>
<li><strong>Steps</strong>:
<ul>
<li>Enable function graph tracing:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">echo function_graph > /sys/kernel/debug/tracing/current_tracer</code></pre></div>
</li>
<li>Start tracing:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">echo 1 > /sys/kernel/debug/tracing/tracing_on</code></pre></div>
</li>
<li>View detailed function call graphs:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">cat /sys/kernel/debug/tracing/trace</code></pre></div>
</li>
</ul>
</li>
<li><strong>Example Output</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">0)   |  do_sys_open() {
0)   |    vfs_open() {
0)   |      path_lookupat() {
0)   |        inode_permission() {
0)   |        } 1.342 us
0)   |      } 2.678 us
0)   |    } 3.210 us
0)   |  } 6.004 us</code></pre></div>
</li>
</ul>
<p><strong>Use Case</strong>:</p>
<ul>
<li>Measure the time spent in each kernel function to identify performance bottlenecks.</li>
</ul>
<p><strong>Key Insight</strong>:</p>
<ul>
<li>“Function graph tracing is ideal for pinpointing high-latency operations in nested kernel calls.”</li>
</ul>
</li>
</ol>
<hr>
<ol start="3">
<li>
<p><strong>Tracing Scheduler Events</strong></p>
<ul>
<li><strong>Objective</strong>:
<ul>
<li>Monitor task scheduling, context switches, and CPU utilization.</li>
</ul>
</li>
<li><strong>Steps</strong>:
<ul>
<li>Enable the scheduler tracer:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">echo sched > /sys/kernel/debug/tracing/current_tracer</code></pre></div>
</li>
<li>Start tracing:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">echo 1 > /sys/kernel/debug/tracing/tracing_on</code></pre></div>
</li>
<li>View scheduling events:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">cat /sys/kernel/debug/tracing/trace</code></pre></div>
</li>
</ul>
</li>
<li><strong>Example Output</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">task-1234 [001] 120.12345: sched_switch: prev_comm=task1 prev_pid=1234 next_comm=task2 next_pid=5678</code></pre></div>
</li>
</ul>
<p><strong>Use Case</strong>:</p>
<ul>
<li>Detect tasks with frequent context switches or excessive wait times.</li>
</ul>
<p><strong>Key Insight</strong>:</p>
<ul>
<li>“Scheduler tracing highlights inefficiencies in CPU scheduling, helping optimize thread performance.”</li>
</ul>
</li>
</ol>
<hr>
<ol start="4">
<li>
<p><strong>Custom Tracepoints</strong></p>
<ul>
<li><strong>Objective</strong>:
<ul>
<li>Monitor specific kernel events, such as block I/O operations or memory page faults.</li>
</ul>
</li>
<li><strong>Steps</strong>:
<ul>
<li>List available tracepoints:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">ls /sys/kernel/debug/tracing/events</code></pre></div>
</li>
<li>Enable a specific tracepoint (e.g., <code class="language-text">block:block_rq_issue</code>):
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">echo 1 > /sys/kernel/debug/tracing/events/block/block_rq_issue/enable</code></pre></div>
</li>
<li>Start tracing:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">echo 1 > /sys/kernel/debug/tracing/tracing_on</code></pre></div>
</li>
<li>View trace log:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">cat /sys/kernel/debug/tracing/trace</code></pre></div>
</li>
</ul>
</li>
<li><strong>Example Output</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">4567.89123: block_rq_issue: dev 8:0 sector=123456 len=8 rwbs=W</code></pre></div>
</li>
</ul>
<p><strong>Use Case</strong>:</p>
<ul>
<li>Trace block layer events to identify high-latency disk operations.</li>
</ul>
<p><strong>Key Insight</strong>:</p>
<ul>
<li>“Custom tracepoints make <code class="language-text">Ftrace</code> adaptable for monitoring application-specific kernel events.”</li>
</ul>
</li>
</ol>
<hr>
<ol start="5">
<li>
<p><strong>IRQ Analysis</strong></p>
<ul>
<li><strong>Objective</strong>:
<ul>
<li>Identify sections of code where interrupts are disabled for extended durations.</li>
</ul>
</li>
<li><strong>Steps</strong>:
<ul>
<li>Enable the <code class="language-text">irqsoff</code> tracer:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">echo irqsoff > /sys/kernel/debug/tracing/current_tracer</code></pre></div>
</li>
<li>Start tracing:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">echo 1 > /sys/kernel/debug/tracing/tracing_on</code></pre></div>
</li>
<li>View the log:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">cat /sys/kernel/debug/tracing/trace</code></pre></div>
</li>
</ul>
</li>
</ul>
<p><strong>Use Case</strong>:</p>
<ul>
<li>Detect long interrupt-disabled regions that may cause latency spikes in real-time systems.</li>
</ul>
<p><strong>Key Insight</strong>:</p>
<ul>
<li>“IRQ tracing ensures system responsiveness by identifying problematic interrupt handling.”</li>
</ul>
</li>
</ol>
<hr>
<h2 id="real-world-applications-of-ftrace" style="position:relative;"><a href="#real-world-applications-of-ftrace" aria-label="real world applications of ftrace permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Real-World Applications of <code class="language-text">Ftrace</code></strong></h2>
<ol>
<li>
<p><strong>Kernel Module Debugging</strong>:</p>
<ul>
<li><strong>Problem</strong>:
<ul>
<li>A custom kernel module causes sporadic system freezes.</li>
</ul>
</li>
<li><strong>Solution</strong>:
<ul>
<li>Trace function calls within the module:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">echo my_module_function > /sys/kernel/debug/tracing/set_ftrace_filter
echo function > /sys/kernel/debug/tracing/current_tracer
echo 1 > /sys/kernel/debug/tracing/tracing_on</code></pre></div>
</li>
<li>Result:
<ul>
<li>Identified a deadlock due to improper locking mechanisms.</li>
</ul>
</li>
</ul>
</li>
<li><strong>Outcome</strong>:
<ul>
<li>Fixed synchronization issues, eliminating freezes.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Database Performance Optimization</strong>:</p>
<ul>
<li><strong>Problem</strong>:
<ul>
<li>High I/O latency in a database server during peak loads.</li>
</ul>
</li>
<li><strong>Solution</strong>:
<ul>
<li>Trace block I/O events:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">echo 1 > /sys/kernel/debug/tracing/events/block/block_rq_issue/enable
echo 1 > /sys/kernel/debug/tracing/tracing_on</code></pre></div>
</li>
<li>Result:
<ul>
<li>Identified high queue depths causing delays.</li>
</ul>
</li>
</ul>
</li>
<li><strong>Outcome</strong>:
<ul>
<li>Optimized I/O scheduling to balance read/write workloads.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Real-Time Application Tuning</strong>:</p>
<ul>
<li><strong>Problem</strong>:
<ul>
<li>A real-time video processing application misses frame deadlines.</li>
</ul>
</li>
<li><strong>Solution</strong>:
<ul>
<li>Trace scheduling delays:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">echo sched > /sys/kernel/debug/tracing/current_tracer
echo 1 > /sys/kernel/debug/tracing/tracing_on</code></pre></div>
</li>
<li>Result:
<ul>
<li>Detected excessive preemptions and thread contention.</li>
</ul>
</li>
</ul>
</li>
<li><strong>Outcome</strong>:
<ul>
<li>Adjusted thread priorities and improved real-time performance.</li>
</ul>
</li>
</ul>
</li>
</ol>
<hr>
<h2 id="key-takeaways-16" style="position:relative;"><a href="#key-takeaways-16" aria-label="key takeaways 16 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Key Takeaways</strong></h2>
<ol>
<li><strong>Powerful Kernel Visibility</strong>:
<ul>
<li>”<code class="language-text">Ftrace</code> provides unparalleled access to kernel functions, events, and execution paths.”</li>
</ul>
</li>
<li><strong>Comprehensive Toolset</strong>:
<ul>
<li>“From function tracing to custom tracepoints, <code class="language-text">Ftrace</code> is highly adaptable for diverse debugging needs.”</li>
</ul>
</li>
<li><strong>Practical Benefits</strong>:
<ul>
<li>“Real-world applications demonstrate how <code class="language-text">Ftrace</code> resolves performance issues at the kernel level.”</li>
</ul>
</li>
</ol>
<h1 id="bpf-berkeley-packet-filter" style="position:relative;"><a href="#bpf-berkeley-packet-filter" aria-label="bpf berkeley packet filter permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>BPF (Berkeley Packet Filter)</strong></h1>
<hr>
<h2 id="overview-of-bpf-and-its-tools" style="position:relative;"><a href="#overview-of-bpf-and-its-tools" aria-label="overview of bpf and its tools permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Overview of BPF and Its Tools</strong></h2>
<ol>
<li>
<p><strong>What is BPF?</strong></p>
<ul>
<li><strong>Definition</strong>:
<ul>
<li>Berkeley Packet Filter (BPF), extended into <strong>eBPF (Extended BPF)</strong>, is a programmable, in-kernel virtual machine for safely and efficiently executing code within the Linux kernel. It can observe, filter, and modify data at the kernel level without recompiling or restarting the kernel.</li>
</ul>
</li>
<li><strong>Key Characteristics</strong>:
<ul>
<li><strong>High Performance</strong>:
<ul>
<li>BPF programs run in the kernel with <strong>JIT compilation</strong>, offering near-native execution speed.</li>
</ul>
</li>
<li><strong>Safety</strong>:
<ul>
<li>Programs are verified before execution to prevent crashes or security risks.</li>
</ul>
</li>
<li><strong>Flexibility</strong>:
<ul>
<li>BPF supports diverse use cases, from <strong>network observability</strong> and <strong>performance monitoring</strong> to <strong>security enforcement</strong>.</li>
</ul>
</li>
</ul>
</li>
<li><strong>Common Use Cases</strong>:
<ul>
<li>Network traffic monitoring.</li>
<li>System performance debugging.</li>
<li>Event tracing across kernel and user space.</li>
<li>Real-time security analytics.</li>
</ul>
</li>
</ul>
<p><strong>Key Insight</strong>:</p>
<ul>
<li>”<strong>eBPF is the Swiss Army knife for modern Linux observability, offering deep kernel-level visibility and control with minimal overhead.</strong>”</li>
</ul>
</li>
</ol>
<hr>
<ol start="2">
<li>
<p><strong>Key Tools in the BPF Ecosystem</strong></p>
<ul>
<li>
<p><strong>BCC (BPF Compiler Collection)</strong>:</p>
<ul>
<li>A framework for writing and running BPF programs, primarily using <strong>Python</strong> or <strong>C</strong>.</li>
<li>Comes with prebuilt tools for common observability tasks.</li>
<li><strong>Common Tools</strong>:
<ul>
<li><code class="language-text">execsnoop</code>: Tracks command execution.</li>
<li><code class="language-text">opensnoop</code>: Monitors file open system calls.</li>
<li><code class="language-text">tcplife</code>: Measures TCP connection lifetimes.</li>
<li><code class="language-text">funccount</code>: Counts function calls.</li>
</ul>
</li>
<li><strong>Example</strong>:
<ul>
<li>Use <code class="language-text">opensnoop</code> to trace file opens:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">sudo opensnoop</code></pre></div>
</li>
<li><strong>Output</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">PID    COMM           FD   PATH
3456   bash            3   /etc/ld.so.cache
3456   bash            3   /lib/x86_64-linux-gnu/libc.so.6</code></pre></div>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong><code class="language-text">bpftrace</code></strong>:</p>
<ul>
<li>A high-level tracing language inspired by DTrace, making it easy to write custom BPF programs.</li>
<li><strong>Features</strong>:
<ul>
<li>Built-in support for <strong>histograms</strong>, <strong>maps</strong>, and <strong>aggregation</strong>.</li>
<li>Trace <strong>kernel functions</strong>, <strong>user-space applications</strong>, and <strong>syscalls</strong>.</li>
</ul>
</li>
<li><strong>Example</strong>:
<ul>
<li>Count system calls by process:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">tracepoint:raw_syscalls:sys_enter
{
    @syscalls[comm] = count();
}</code></pre></div>
</li>
<li><strong>Output</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">bash    34
nginx   5621
postgres 2381</code></pre></div>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong><code class="language-text">bpftool</code></strong>:</p>
<ul>
<li>A command-line utility for managing and debugging BPF programs.</li>
<li><strong>Features</strong>:
<ul>
<li>Load, unload, and inspect active BPF programs.</li>
<li>Query statistics and attached hooks.</li>
<li>Inspect BPF maps and their contents.</li>
</ul>
</li>
<li><strong>Example</strong>:
<ul>
<li>List loaded BPF programs:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">sudo bpftool prog</code></pre></div>
</li>
<li><strong>Output</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">ID   TYPE         ATTACHED  NAME
5    kprobe       yes       probe_function
8    tracepoint   yes       syscalls:sys_enter_read</code></pre></div>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>cilium</strong>:</p>
<ul>
<li>A BPF-based tool for <strong>network observability</strong>, <strong>security</strong>, and <strong>load balancing</strong> in containerized environments like Kubernetes.</li>
</ul>
</li>
</ul>
<p><strong>Key Insight</strong>:</p>
<ul>
<li>”<strong>Tools like <code class="language-text">bcc</code>, <code class="language-text">bpftrace</code>, and <code class="language-text">bpftool</code> abstract the complexity of BPF programming, making advanced tracing and monitoring accessible to engineers.</strong>”</li>
</ul>
</li>
</ol>
<hr>
<h2 id="advanced-performance-analysis-using-bpf" style="position:relative;"><a href="#advanced-performance-analysis-using-bpf" aria-label="advanced performance analysis using bpf permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Advanced Performance Analysis Using BPF</strong></h2>
<ol>
<li>
<p><strong>CPU Profiling</strong></p>
<ul>
<li><strong>Scenario</strong>:
<ul>
<li>A Java application consumes excessive CPU during data processing tasks.</li>
</ul>
</li>
<li><strong>Command</strong>:
<ul>
<li>Use the <code class="language-text">profile</code> tool from <code class="language-text">BCC</code> to identify the most CPU-intensive functions:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">sudo /usr/share/bcc/tools/profile -F 99 -p $(pidof java)</code></pre></div>
<ul>
<li><code class="language-text">-F 99</code>: Samples 99 times per second.</li>
<li><code class="language-text">-p</code>: Targets a specific process ID.</li>
</ul>
</li>
</ul>
</li>
<li><strong>Output</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">70%  java       [kernel]  __do_page_fault
20%  java       libjvm.so  execute_bytecode
 5%  java       libc.so.6  memcpy
 5%  java       java       processData</code></pre></div>
</li>
<li><strong>Interpretation</strong>:
<ul>
<li><code class="language-text">__do_page_fault</code> indicates excessive memory paging.</li>
</ul>
</li>
<li><strong>Optimization</strong>:
<ul>
<li>Increase memory allocation to reduce page faults.</li>
</ul>
</li>
</ul>
<p><strong>Key Insight</strong>:</p>
<ul>
<li>”<strong>Profiling tools powered by BPF pinpoint hotspots at both kernel and application levels, enabling targeted optimizations.</strong>”</li>
</ul>
</li>
</ol>
<hr>
<ol start="2">
<li>
<p><strong>File I/O Analysis</strong></p>
<ul>
<li><strong>Scenario</strong>:
<ul>
<li>A database system exhibits high disk I/O latency during peak hours.</li>
</ul>
</li>
<li><strong>Command</strong>:
<ul>
<li>Use <code class="language-text">opensnoop</code> to trace file open system calls:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">sudo opensnoop</code></pre></div>
</li>
</ul>
</li>
<li><strong>Output</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">PID    COMM       FD   PATH
1234   postgres    5   /var/lib/postgresql/data/table1
1234   postgres    6   /var/lib/postgresql/data/table2</code></pre></div>
</li>
<li><strong>Interpretation</strong>:
<ul>
<li>Frequent file opens indicate inefficient query execution or logging behavior.</li>
</ul>
</li>
<li><strong>Optimization</strong>:
<ul>
<li>Optimize query patterns or batch log writes.</li>
</ul>
</li>
</ul>
<p><strong>Key Insight</strong>:</p>
<ul>
<li>”<strong>Tracing file I/O with BPF tools like <code class="language-text">opensnoop</code> reveals inefficiencies that might be hidden at the application layer.</strong>”</li>
</ul>
</li>
</ol>
<hr>
<ol start="3">
<li>
<p><strong>Network Observability</strong></p>
<ul>
<li><strong>Scenario</strong>:
<ul>
<li>A web server reports slow response times during high traffic.</li>
</ul>
</li>
<li><strong>Command</strong>:
<ul>
<li>Use <code class="language-text">tcplife</code> to measure the lifespan of TCP connections:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">sudo /usr/share/bcc/tools/tcplife</code></pre></div>
</li>
</ul>
</li>
<li><strong>Output</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">PID   COMM      LADDR          LPORT   RADDR          RPORT   DURATION
5678  nginx     192.168.1.10   443     192.168.1.20   5623    234ms</code></pre></div>
</li>
<li><strong>Interpretation</strong>:
<ul>
<li>Long connection durations indicate a backend issue or slow client acknowledgment.</li>
</ul>
</li>
<li><strong>Optimization</strong>:
<ul>
<li>Implement keep-alive connections or optimize backend query times.</li>
</ul>
</li>
</ul>
<p><strong>Key Insight</strong>:</p>
<ul>
<li>”<strong><code class="language-text">tcplife</code> and similar tools simplify real-time monitoring of network behavior, providing actionable insights for debugging latency.</strong>”</li>
</ul>
</li>
</ol>
<hr>
<ol start="4">
<li>
<p><strong>Custom BPF Program with <code class="language-text">bpftrace</code></strong></p>
<ul>
<li><strong>Scenario</strong>:
<ul>
<li>Analyze the execution time of a custom function in a Python application.</li>
</ul>
</li>
<li><strong>Script</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">uprobe:/usr/bin/python3:custom_function
{
    @start[tid] = nsecs;
}

uretprobe:/usr/bin/python3:custom_function
{
    @latency = hist(nsecs - @start[tid]);
    delete(@start[tid]);
}</code></pre></div>
</li>
<li><strong>Output</strong>:
<ul>
<li>A histogram of function execution times in nanoseconds.</li>
</ul>
</li>
<li><strong>Use Case</strong>:
<ul>
<li>Debug slow functions or identify variations in execution time.</li>
</ul>
</li>
</ul>
<p><strong>Key Insight</strong>:</p>
<ul>
<li>”<strong>Custom BPF programs with <code class="language-text">bpftrace</code> enable fine-grained performance analysis tailored to specific workloads.</strong>”</li>
</ul>
</li>
</ol>
<hr>
<ol start="5">
<li>
<p><strong>Memory Allocation Profiling</strong></p>
<ul>
<li><strong>Scenario</strong>:
<ul>
<li>A C application suffers from memory leaks.</li>
</ul>
</li>
<li><strong>Command</strong>:
<ul>
<li>Trace <code class="language-text">kmalloc</code> and <code class="language-text">kfree</code> events:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">tracepoint:kmem:kmalloc
{
    @allocs[comm] += args->bytes_alloc;
}

tracepoint:kmem:kfree
{
    @frees[comm] += args->bytes_alloc;
}</code></pre></div>
</li>
</ul>
</li>
<li><strong>Output</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">App        Allocated       Freed
app1       1024 KB         512 KB</code></pre></div>
</li>
<li><strong>Interpretation</strong>:
<ul>
<li>Unfreed memory indicates potential leaks.</li>
</ul>
</li>
<li><strong>Optimization</strong>:
<ul>
<li>Review and fix unfreed memory allocations.</li>
</ul>
</li>
</ul>
</li>
</ol>
<hr>
<h2 id="key-highlights-3" style="position:relative;"><a href="#key-highlights-3" aria-label="key highlights 3 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Key Highlights</strong></h2>
<ol>
<li>
<p><strong>Powerful Observability</strong>:</p>
<ul>
<li>“BPF enables real-time, low-overhead tracing of system and application behavior across kernel and user space.”</li>
</ul>
</li>
<li>
<p><strong>Flexible Tooling</strong>:</p>
<ul>
<li>“From prebuilt tools in <code class="language-text">BCC</code> to custom scripts in <code class="language-text">bpftrace</code>, the ecosystem supports a wide range of use cases.”</li>
</ul>
</li>
<li>
<p><strong>Actionable Insights</strong>:</p>
<ul>
<li>“Advanced performance analysis with BPF transforms raw data into optimization strategies, whether debugging I/O, CPU, or memory bottlenecks.”</li>
</ul>
</li>
<li>
<p><strong>Real-World Applications</strong>:</p>
<ul>
<li>“eBPF has been used to optimize databases, web servers, and real-time analytics systems, demonstrating its versatility and impact.”</li>
</ul>
</li>
</ol>
<h1 id="chapter-16-case-study" style="position:relative;"><a href="#chapter-16-case-study" aria-label="chapter 16 case study permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Chapter 16: Case Study</strong></h1>
<p>The chapter provides a step-by-step walkthrough of analyzing, diagnosing, and solving a complex performance issue in a real-world environment. It emphasizes <strong>structured methodologies</strong>, <strong>practical tools</strong>, and <strong>clear results</strong> to showcase the value of systematic performance tuning.</p>
<hr>
<h2 id="161-overview-of-the-case" style="position:relative;"><a href="#161-overview-of-the-case" aria-label="161 overview of the case permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>16.1 Overview of the Case</strong></h2>
<h3 id="scenario-3" style="position:relative;"><a href="#scenario-3" aria-label="scenario 3 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Scenario</strong>:</h3>
<ul>
<li>A <strong>web-based application</strong> experiences slow response times under high user traffic, leading to customer dissatisfaction and increased resource costs.</li>
</ul>
<h3 id="symptoms" style="position:relative;"><a href="#symptoms" aria-label="symptoms permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Symptoms</strong>:</h3>
<ol>
<li><strong>High CPU usage</strong> on the application server.</li>
<li><strong>Increased memory consumption</strong>, resulting in swapping.</li>
<li><strong>Intermittent latency spikes</strong> during peak traffic hours.</li>
</ol>
<h3 id="environment" style="position:relative;"><a href="#environment" aria-label="environment permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Environment</strong>:</h3>
<ul>
<li>Application: <strong>Java-based web application</strong> with MySQL database.</li>
<li>Hardware: <strong>8-core CPU</strong>, <strong>32GB RAM</strong>, and SSD storage.</li>
<li>Operating System: Linux with kernel version 5.x.</li>
</ul>
<h3 id="objective-6" style="position:relative;"><a href="#objective-6" aria-label="objective 6 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Objective</strong>:</h3>
<ul>
<li>Diagnose the root causes of performance degradation and implement <strong>tuning strategies</strong> to improve response times and resource efficiency.</li>
</ul>
<hr>
<p>Here’s an <strong>expanded and detailed explanation of Section 16.2: Methodology</strong>, focusing on the step-by-step approach used to diagnose, analyze, and solve performance issues in the case study. This section highlights tools, techniques, and best practices with real-world examples to guide performance optimization.</p>
<hr>
<h2 id="162-methodology" style="position:relative;"><a href="#162-methodology" aria-label="162 methodology permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>16.2 Methodology</strong></h2>
<p>A structured methodology is essential for identifying and resolving complex performance issues systematically. In this case study, the performance optimization process follows a series of well-defined steps: <strong>Baseline Measurement</strong>, <strong>Bottleneck Identification</strong>, and <strong>Hypothesis Formation</strong>.</p>
<hr>
<h3 id="1621-step-1-baseline-performance-measurement" style="position:relative;"><a href="#1621-step-1-baseline-performance-measurement" aria-label="1621 step 1 baseline performance measurement permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>16.2.1 Step 1: Baseline Performance Measurement</strong></h3>
<h4 id="purpose-19" style="position:relative;"><a href="#purpose-19" aria-label="purpose 19 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Purpose</strong>:</h4>
<ul>
<li>Establish <strong>baseline metrics</strong> for system performance, including CPU, memory, I/O, and network utilization, to identify anomalies during diagnosis.</li>
</ul>
<h4 id="tools-and-techniques" style="position:relative;"><a href="#tools-and-techniques" aria-label="tools and techniques permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Tools and Techniques</strong>:</h4>
<h5 id="1-system-monitoring-tools" style="position:relative;"><a href="#1-system-monitoring-tools" aria-label="1 system monitoring tools permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>1. System Monitoring Tools</strong></h5>
<ul>
<li>
<p><strong><code class="language-text">vmstat</code></strong>:</p>
<ul>
<li>Tracks CPU usage, memory allocation, and I/O activity.</li>
<li>Command:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">vmstat</span> <span class="token number">1</span></code></pre></div>
</li>
<li>Example Output:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs  us  sy  id  wa
 3  1   1024  12000  3000  15000    5   10    50   100   200  300  40  15  40   5</code></pre></div>
<ul>
<li><strong>Key Observations</strong>:
<ul>
<li>High <code class="language-text">r</code> (run queue): Indicates processes waiting for CPU.</li>
<li>Non-zero <code class="language-text">si</code> and <code class="language-text">so</code>: Suggests swapping is occurring, which could degrade performance.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong><code class="language-text">sar</code></strong>:</p>
<ul>
<li>Collects historical metrics for memory, CPU, and disk usage.</li>
<li>Command:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">sar <span class="token parameter variable">-r</span> <span class="token number">1</span> <span class="token number">10</span></code></pre></div>
</li>
<li>Example Output:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">kbmemfree kbmemused  %memused kbbuffers kbcached kbcommit
12000     30000      71.4     2000      15000    25000</code></pre></div>
<ul>
<li><strong>Key Observations</strong>:
<ul>
<li>High <code class="language-text">kbcommit</code> relative to <code class="language-text">kbmemfree</code> indicates memory pressure.</li>
<li>High <code class="language-text">kbcached</code> is expected for efficient file system usage.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h5 id="2-application-specific-profiling" style="position:relative;"><a href="#2-application-specific-profiling" aria-label="2 application specific profiling permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>2. Application-Specific Profiling</strong></h5>
<ul>
<li>
<p><strong>JVisualVM</strong> (for Java applications):</p>
<ul>
<li>Profiles application threads and memory usage.</li>
<li>Observations:
<ul>
<li>High garbage collection (GC) activity.</li>
<li>Method <code class="language-text">processRequest()</code> accounts for <strong>60% of CPU time</strong>.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Flame Graphs</strong>:</p>
<ul>
<li>Visualize where CPU time is spent.</li>
<li>Command:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">perf record <span class="token parameter variable">-F</span> <span class="token number">99</span> <span class="token parameter variable">-p</span> <span class="token operator">&lt;</span>pid<span class="token operator">></span>
perf script <span class="token operator">|</span> stackcollapse-perf.pl <span class="token operator">|</span> flamegraph.pl <span class="token operator">></span> out.svg</code></pre></div>
</li>
<li>Output:
<ul>
<li>A wide flame for <code class="language-text">processRequest</code> highlights inefficiency in application logic.</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h4 id="deliverables" style="position:relative;"><a href="#deliverables" aria-label="deliverables permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Deliverables</strong>:</h4>
<ul>
<li>Collect data on <strong>CPU utilization</strong>, <strong>memory consumption</strong>, <strong>disk I/O rates</strong>, and <strong>network throughput</strong>.</li>
<li>Document high-level patterns, such as CPU hotspots and swapping activity.</li>
</ul>
<hr>
<h3 id="1622-step-2-identifying-the-bottleneck" style="position:relative;"><a href="#1622-step-2-identifying-the-bottleneck" aria-label="1622 step 2 identifying the bottleneck permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>16.2.2 Step 2: Identifying the Bottleneck</strong></h3>
<h4 id="purpose-20" style="position:relative;"><a href="#purpose-20" aria-label="purpose 20 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Purpose</strong>:</h4>
<ul>
<li>Pinpoint the exact cause of performance degradation by analyzing the baseline metrics.</li>
</ul>
<h4 id="techniques-and-tools" style="position:relative;"><a href="#techniques-and-tools" aria-label="techniques and tools permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Techniques and Tools</strong>:</h4>
<h5 id="1-cpu-analysis" style="position:relative;"><a href="#1-cpu-analysis" aria-label="1 cpu analysis permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>1. CPU Analysis</strong></h5>
<ul>
<li><strong>Command</strong>:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">perf <span class="token function">top</span></code></pre></div>
</li>
<li>Example Output:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">Overhead  Command     Shared Object           Symbol
60.00%    [kernel]    [k] copy_user_generic_unrolled
30.00%    app         [.] processRequest</code></pre></div>
</li>
<li><strong>Key Observations</strong>:
<ul>
<li><strong>60% CPU time in kernel functions</strong> suggests frequent system calls or I/O operations.</li>
<li><strong>30% CPU time in application code</strong> highlights inefficient processing logic.</li>
</ul>
</li>
</ul>
<h5 id="2-memory-analysis" style="position:relative;"><a href="#2-memory-analysis" aria-label="2 memory analysis permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>2. Memory Analysis</strong></h5>
<ul>
<li><strong>Command</strong>:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">free</span> <span class="token parameter variable">-h</span></code></pre></div>
</li>
<li>Example Output:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">             total        used        free      shared  buff/cache   available
Mem:           32G         30G         2G          1G         5G         3G
Swap:          8G          4G         4G</code></pre></div>
</li>
<li><strong>Key Observations</strong>:
<ul>
<li>Low free memory (<code class="language-text">2G</code>) and high swap usage (<code class="language-text">4G</code>) indicate memory pressure.</li>
</ul>
</li>
</ul>
<h5 id="3-database-query-profiling" style="position:relative;"><a href="#3-database-query-profiling" aria-label="3 database query profiling permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>3. Database Query Profiling</strong></h5>
<ul>
<li><strong>Command</strong>:
<div class="gatsby-highlight" data-language="sql"><pre class="language-sql"><code class="language-sql"><span class="token keyword">EXPLAIN</span> <span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> orders <span class="token keyword">WHERE</span> <span class="token keyword">status</span> <span class="token operator">=</span> <span class="token string">'PENDING'</span><span class="token punctuation">;</span></code></pre></div>
</li>
<li>Example Output:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">id  select_type table  type  possible_keys key  rows  Extra
1   SIMPLE      orders ALL   NULL          NULL 10000 Using where</code></pre></div>
</li>
<li><strong>Key Observations</strong>:
<ul>
<li>Full table scans (<code class="language-text">type = ALL</code>) indicate missing indexes.</li>
</ul>
</li>
</ul>
<hr>
<h4 id="deliverables-1" style="position:relative;"><a href="#deliverables-1" aria-label="deliverables 1 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Deliverables</strong>:</h4>
<ul>
<li><strong>Identified Bottlenecks</strong>:
<ol>
<li>Inefficient application logic in <code class="language-text">processRequest</code>.</li>
<li>Swapping caused by insufficient memory.</li>
<li>Slow database queries due to missing indexes.</li>
</ol>
</li>
</ul>
<hr>
<h3 id="1623-step-3-hypothesis-formation" style="position:relative;"><a href="#1623-step-3-hypothesis-formation" aria-label="1623 step 3 hypothesis formation permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>16.2.3 Step 3: Hypothesis Formation</strong></h3>
<h4 id="purpose-21" style="position:relative;"><a href="#purpose-21" aria-label="purpose 21 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Purpose</strong>:</h4>
<ul>
<li>Develop hypotheses to explain the observed bottlenecks and propose solutions.</li>
</ul>
<h4 id="hypotheses" style="position:relative;"><a href="#hypotheses" aria-label="hypotheses permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Hypotheses</strong>:</h4>
<ol>
<li>
<p><strong>Application Logic Bottleneck</strong>:</p>
<ul>
<li>The <code class="language-text">processRequest</code> function spends excessive time in loops and memory operations.</li>
<li><strong>Proposed Solution</strong>:
<ul>
<li>Optimize the function by refactoring or parallelizing the code.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Memory Bottleneck</strong>:</p>
<ul>
<li>High swapping degrades performance during peak traffic.</li>
<li><strong>Proposed Solution</strong>:
<ul>
<li>Reduce swappiness or increase application memory allocation.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Database Query Bottleneck</strong>:</p>
<ul>
<li>Full table scans lead to increased query latency.</li>
<li><strong>Proposed Solution</strong>:
<ul>
<li>Add indexes for frequently queried columns.</li>
</ul>
</li>
</ul>
</li>
</ol>
<hr>
<h4 id="deliverables-2" style="position:relative;"><a href="#deliverables-2" aria-label="deliverables 2 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Deliverables</strong>:</h4>
<ul>
<li>A clear list of hypotheses linking observed metrics to potential causes.</li>
<li>Proposed solutions for each bottleneck, ready for validation in subsequent steps.</li>
</ul>
<hr>
<h3 id="key-takeaways-from-methodology" style="position:relative;"><a href="#key-takeaways-from-methodology" aria-label="key takeaways from methodology permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Key Takeaways from Methodology</strong></h3>
<ol>
<li>
<p><strong>Structured Approach</strong>:</p>
<ul>
<li>Begin with baseline measurements to understand system behavior under normal conditions.</li>
<li><strong>Highlight</strong>: “Baseline metrics are critical for identifying deviations during diagnosis.”</li>
</ul>
</li>
<li>
<p><strong>Multi-Level Analysis</strong>:</p>
<ul>
<li>Combine <strong>system-level tools</strong> (<code class="language-text">vmstat</code>, <code class="language-text">perf</code>) with <strong>application-specific tools</strong> (Flame Graphs, JVisualVM).</li>
<li><strong>Highlight</strong>: “Analyzing both system and application metrics ensures comprehensive diagnosis.”</li>
</ul>
</li>
<li>
<p><strong>Hypothesis-Driven Investigation</strong>:</p>
<ul>
<li>Formulate clear hypotheses based on observed data to focus optimization efforts.</li>
<li><strong>Highlight</strong>: “A structured hypothesis ensures targeted and efficient troubleshooting.”</li>
</ul>
</li>
</ol>
<hr>
<h2 id="163-applying-solutions" style="position:relative;"><a href="#163-applying-solutions" aria-label="163 applying solutions permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>16.3 Applying Solutions</strong></h2>
<p>This section outlines the application of targeted solutions to address identified bottlenecks in the web-based application. The focus is on optimizing <strong>application logic</strong>, <strong>memory usage</strong>, and <strong>database performance</strong>. Each solution includes tools, actions, and results.</p>
<hr>
<h3 id="1631-solution-1-optimize-application-code" style="position:relative;"><a href="#1631-solution-1-optimize-application-code" aria-label="1631 solution 1 optimize application code permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>16.3.1 Solution 1: Optimize Application Code</strong></h3>
<h4 id="problem-6" style="position:relative;"><a href="#problem-6" aria-label="problem 6 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Problem</strong>:</h4>
<ul>
<li>High CPU usage in the <code class="language-text">processRequest</code> function, consuming 30% of total CPU time, as identified in the Flame Graph and <code class="language-text">perf</code> analysis.</li>
</ul>
<h4 id="action-plan" style="position:relative;"><a href="#action-plan" aria-label="action plan permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Action Plan</strong>:</h4>
<ol>
<li>
<p><strong>Profile the Application</strong>:</p>
<ul>
<li>Use JVisualVM to monitor method-level CPU utilization.</li>
<li>Observation:
<ul>
<li>The <code class="language-text">processRequest</code> function uses nested loops, resulting in inefficient processing of data.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Refactor Code</strong>:</p>
<ul>
<li>Original Code:
<div class="gatsby-highlight" data-language="java"><pre class="language-java"><code class="language-java"><span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> requests<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> j <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> j <span class="token operator">&lt;</span> responses<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> j<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token keyword">if</span> <span class="token punctuation">(</span>requests<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">matches</span><span class="token punctuation">(</span>responses<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>j<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
            <span class="token function">processResult</span><span class="token punctuation">(</span>requests<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">,</span> responses<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>j<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span></code></pre></div>
</li>
<li>Optimized Code:
<ul>
<li>Use a <strong>hash map</strong> for faster lookups:
<div class="gatsby-highlight" data-language="java"><pre class="language-java"><code class="language-java"><span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Response</span><span class="token punctuation">></span></span> responseMap <span class="token operator">=</span> responses<span class="token punctuation">.</span><span class="token function">stream</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span><span class="token class-name">Collectors</span><span class="token punctuation">.</span><span class="token function">toMap</span><span class="token punctuation">(</span><span class="token class-name">Response</span><span class="token operator">::</span><span class="token function">getKey</span><span class="token punctuation">,</span> <span class="token class-name">Function</span><span class="token punctuation">.</span><span class="token function">identity</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

requests<span class="token punctuation">.</span><span class="token function">forEach</span><span class="token punctuation">(</span>request <span class="token operator">-></span> <span class="token punctuation">{</span>
    <span class="token class-name">Response</span> response <span class="token operator">=</span> responseMap<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>request<span class="token punctuation">.</span><span class="token function">getKey</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token keyword">if</span> <span class="token punctuation">(</span>response <span class="token operator">!=</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token function">processResult</span><span class="token punctuation">(</span>request<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre></div>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Implement Parallelization</strong>:</p>
<ul>
<li>Leverage Java’s <strong>parallel streams</strong> for multi-threaded processing:
<div class="gatsby-highlight" data-language="java"><pre class="language-java"><code class="language-java">requests<span class="token punctuation">.</span><span class="token function">parallelStream</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">forEach</span><span class="token punctuation">(</span>request <span class="token operator">-></span> <span class="token punctuation">{</span>
    <span class="token class-name">Response</span> response <span class="token operator">=</span> responseMap<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>request<span class="token punctuation">.</span><span class="token function">getKey</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token keyword">if</span> <span class="token punctuation">(</span>response <span class="token operator">!=</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token function">processResult</span><span class="token punctuation">(</span>request<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre></div>
</li>
</ul>
</li>
</ol>
<h4 id="result-7" style="position:relative;"><a href="#result-7" aria-label="result 7 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Result</strong>:</h4>
<ul>
<li>CPU usage for <code class="language-text">processRequest</code> reduced from <strong>30% to 10%</strong>.</li>
<li>Overall request processing time improved by <strong>40%</strong>.</li>
</ul>
<hr>
<h3 id="1632-solution-2-reduce-swapping" style="position:relative;"><a href="#1632-solution-2-reduce-swapping" aria-label="1632 solution 2 reduce swapping permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>16.3.2 Solution 2: Reduce Swapping</strong></h3>
<h4 id="problem-7" style="position:relative;"><a href="#problem-7" aria-label="problem 7 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Problem</strong>:</h4>
<ul>
<li>High memory usage and frequent swapping (as observed via <code class="language-text">vmstat</code> and <code class="language-text">sar</code>) lead to degraded application performance during peak traffic.</li>
</ul>
<h4 id="action-plan-1" style="position:relative;"><a href="#action-plan-1" aria-label="action plan 1 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Action Plan</strong>:</h4>
<ol>
<li>
<p><strong>Adjust Swappiness</strong>:</p>
<ul>
<li>Reduce swappiness to prioritize RAM usage over swap:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">sysctl</span> <span class="token assign-left variable">vm.swappiness</span><span class="token operator">=</span><span class="token number">10</span></code></pre></div>
</li>
</ul>
</li>
<li>
<p><strong>Increase Application Memory Allocation</strong>:</p>
<ul>
<li>Adjust Java heap size to use more RAM:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">java</span> <span class="token parameter variable">-Xmx24G</span> <span class="token parameter variable">-Xms16G</span> <span class="token parameter variable">-jar</span> app.jar</code></pre></div>
</li>
</ul>
</li>
<li>
<p><strong>Enable Huge Pages</strong>:</p>
<ul>
<li>Configure huge pages to optimize memory management:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token builtin class-name">echo</span> <span class="token number">512</span> <span class="token operator">></span> /proc/sys/vm/nr_hugepages</code></pre></div>
</li>
<li>Update Java options to use huge pages:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">java</span> <span class="token parameter variable">-XX:+UseLargePages</span> <span class="token parameter variable">-Xmx24G</span> <span class="token parameter variable">-Xms16G</span> <span class="token parameter variable">-jar</span> app.jar</code></pre></div>
</li>
</ul>
</li>
<li>
<p><strong>Monitor Impact</strong>:</p>
<ul>
<li>Use <code class="language-text">free</code> to verify reduced swap usage:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">free</span> <span class="token parameter variable">-h</span></code></pre></div>
<ul>
<li>Example Output:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">             total        used        free      shared  buff/cache   available
Mem:           32G         20G         8G          1G         4G         12G
Swap:          8G          0G         8G</code></pre></div>
</li>
</ul>
</li>
</ul>
</li>
</ol>
<h4 id="result-8" style="position:relative;"><a href="#result-8" aria-label="result 8 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Result</strong>:</h4>
<ul>
<li>Swap usage reduced to <strong>near-zero</strong>.</li>
<li>Application response time improved by <strong>20%</strong> under peak load.</li>
</ul>
<hr>
<h3 id="1633-solution-3-optimize-database-queries" style="position:relative;"><a href="#1633-solution-3-optimize-database-queries" aria-label="1633 solution 3 optimize database queries permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>16.3.3 Solution 3: Optimize Database Queries</strong></h3>
<h4 id="problem-8" style="position:relative;"><a href="#problem-8" aria-label="problem 8 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Problem</strong>:</h4>
<ul>
<li>Slow query performance, with full table scans (as identified using MySQL’s <code class="language-text">EXPLAIN</code>).</li>
</ul>
<h4 id="action-plan-2" style="position:relative;"><a href="#action-plan-2" aria-label="action plan 2 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Action Plan</strong>:</h4>
<ol>
<li>
<p><strong>Analyze Slow Queries</strong>:</p>
<ul>
<li>Use MySQL slow query log:
<div class="gatsby-highlight" data-language="sql"><pre class="language-sql"><code class="language-sql"><span class="token keyword">SET</span> <span class="token keyword">GLOBAL</span> slow_query_log <span class="token operator">=</span> <span class="token string">'ON'</span><span class="token punctuation">;</span>
<span class="token keyword">SET</span> <span class="token keyword">GLOBAL</span> long_query_time <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span> <span class="token comment">-- Log queries taking more than 1 second</span></code></pre></div>
</li>
<li>Observed Query:
<div class="gatsby-highlight" data-language="sql"><pre class="language-sql"><code class="language-sql"><span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> orders <span class="token keyword">WHERE</span> <span class="token keyword">status</span> <span class="token operator">=</span> <span class="token string">'PENDING'</span><span class="token punctuation">;</span></code></pre></div>
</li>
</ul>
</li>
<li>
<p><strong>Optimize Query with Indexes</strong>:</p>
<ul>
<li>Add an index to the <code class="language-text">status</code> column:
<div class="gatsby-highlight" data-language="sql"><pre class="language-sql"><code class="language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">INDEX</span> idx_status <span class="token keyword">ON</span> orders<span class="token punctuation">(</span><span class="token keyword">status</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre></div>
</li>
</ul>
</li>
<li>
<p><strong>Rewrite Inefficient Queries</strong>:</p>
<ul>
<li>Original Query:
<div class="gatsby-highlight" data-language="sql"><pre class="language-sql"><code class="language-sql"><span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> orders <span class="token keyword">WHERE</span> <span class="token keyword">status</span> <span class="token operator">=</span> <span class="token string">'PENDING'</span> <span class="token operator">AND</span> <span class="token keyword">date</span> <span class="token operator">>=</span> <span class="token string">'2024-01-01'</span><span class="token punctuation">;</span></code></pre></div>
</li>
<li>Optimized Query:
<ul>
<li>Use a composite index:
<div class="gatsby-highlight" data-language="sql"><pre class="language-sql"><code class="language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">INDEX</span> idx_status_date <span class="token keyword">ON</span> orders<span class="token punctuation">(</span><span class="token keyword">status</span><span class="token punctuation">,</span> <span class="token keyword">date</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre></div>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Monitor Performance</strong>:</p>
<ul>
<li>Re-run <code class="language-text">EXPLAIN</code>:
<div class="gatsby-highlight" data-language="sql"><pre class="language-sql"><code class="language-sql"><span class="token keyword">EXPLAIN</span> <span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> orders <span class="token keyword">WHERE</span> <span class="token keyword">status</span> <span class="token operator">=</span> <span class="token string">'PENDING'</span> <span class="token operator">AND</span> <span class="token keyword">date</span> <span class="token operator">>=</span> <span class="token string">'2024-01-01'</span><span class="token punctuation">;</span></code></pre></div>
<ul>
<li>Optimized Output:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">id  select_type table  type   possible_keys        key            rows  Extra
1   SIMPLE      orders range  idx_status_date      idx_status_date 100  Using where</code></pre></div>
</li>
</ul>
</li>
</ul>
</li>
</ol>
<h4 id="result-9" style="position:relative;"><a href="#result-9" aria-label="result 9 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Result</strong>:</h4>
<ul>
<li>Query execution time reduced from <strong>1.5 seconds to 0.3 seconds</strong>.</li>
<li>Database load reduced, improving overall system responsiveness.</li>
</ul>
<hr>
<h3 id="1634-validation" style="position:relative;"><a href="#1634-validation" aria-label="1634 validation permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>16.3.4 Validation</strong></h3>
<p>After applying these solutions, comprehensive testing and monitoring confirmed the improvements:</p>
<h4 id="stress-testing" style="position:relative;"><a href="#stress-testing" aria-label="stress testing permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Stress Testing</strong>:</h4>
<ul>
<li>Tool: <code class="language-text">wrk</code> for HTTP benchmarking.
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">wrk <span class="token parameter variable">-t8</span> <span class="token parameter variable">-c400</span> <span class="token parameter variable">-d60s</span> http://example.com</code></pre></div>
</li>
<li>Metrics:
<ul>
<li><strong>Before Optimization</strong>:
<ul>
<li>Average latency: <strong>300ms</strong></li>
<li>Requests per second: <strong>500</strong></li>
</ul>
</li>
<li><strong>After Optimization</strong>:
<ul>
<li>Average latency: <strong>100ms</strong></li>
<li>Requests per second: <strong>1200</strong></li>
</ul>
</li>
<li><strong>Highlight</strong>: “Latency reduced by 66%, throughput increased by 140%.”</li>
</ul>
</li>
</ul>
<h4 id="system-monitoring" style="position:relative;"><a href="#system-monitoring" aria-label="system monitoring permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>System Monitoring</strong>:</h4>
<ul>
<li>Observations from <code class="language-text">sar</code> and <code class="language-text">vmstat</code>:
<ul>
<li>CPU utilization is evenly distributed.</li>
<li>Memory swapping is eliminated.</li>
<li>Database query response times are consistent.</li>
</ul>
</li>
</ul>
<hr>
<h3 id="key-takeaways-17" style="position:relative;"><a href="#key-takeaways-17" aria-label="key takeaways 17 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Key Takeaways</strong></h3>
<ol>
<li>
<p><strong>Code Optimization</strong>:</p>
<ul>
<li>Use profiling tools (e.g., JVisualVM) to identify and refactor inefficient code paths.</li>
<li><strong>Highlight</strong>: “Parallelization and data structure optimization yield significant CPU performance improvements.”</li>
</ul>
</li>
<li>
<p><strong>Memory Tuning</strong>:</p>
<ul>
<li>Adjust swappiness, use huge pages, and allocate sufficient heap size to minimize swapping.</li>
<li><strong>Highlight</strong>: “Proper memory tuning ensures efficient resource utilization during peak loads.”</li>
</ul>
</li>
<li>
<p><strong>Database Indexing</strong>:</p>
<ul>
<li>Analyze and optimize queries with indexes to eliminate full table scans.</li>
<li><strong>Highlight</strong>: “Database query optimization directly reduces system load and latency.”</li>
</ul>
</li>
<li>
<p><strong>Iterative Approach</strong>:</p>
<ul>
<li>Apply one solution at a time, measure impact, and proceed based on results.</li>
<li><strong>Highlight</strong>: “Systematic implementation and validation ensure effective tuning.”</li>
</ul>
</li>
</ol>
<hr>
<h2 id="164-validation" style="position:relative;"><a href="#164-validation" aria-label="164 validation permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>16.4 Validation</strong></h2>
<p>Validation is a critical step to confirm the success of performance optimizations. It involves <strong>stress testing</strong>, <strong>system monitoring</strong>, and <strong>performance benchmarking</strong> to measure the impact of changes. This section details how validation was conducted for each optimization applied in the case study.</p>
<hr>
<h3 id="1641-performance-testing" style="position:relative;"><a href="#1641-performance-testing" aria-label="1641 performance testing permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>16.4.1 Performance Testing</strong></h3>
<h4 id="objective-7" style="position:relative;"><a href="#objective-7" aria-label="objective 7 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Objective</strong>:</h4>
<ul>
<li>Simulate real-world scenarios to evaluate the system’s ability to handle increased traffic and workloads after optimization.</li>
</ul>
<h4 id="tools-16" style="position:relative;"><a href="#tools-16" aria-label="tools 16 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Tools</strong>:</h4>
<ol>
<li>
<p><strong>wrk</strong>:</p>
<ul>
<li>A modern HTTP benchmarking tool for simulating concurrent requests.</li>
<li>Command:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">wrk <span class="token parameter variable">-t8</span> <span class="token parameter variable">-c400</span> <span class="token parameter variable">-d60s</span> http://example.com</code></pre></div>
</li>
<li>Parameters:
<ul>
<li><code class="language-text">-t8</code>: 8 threads.</li>
<li><code class="language-text">-c400</code>: 400 concurrent connections.</li>
<li><code class="language-text">-d60s</code>: Test duration of 60 seconds.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Apache JMeter</strong>:</p>
<ul>
<li>Create complex, multi-step test scenarios with dynamic inputs.</li>
</ul>
</li>
</ol>
<h4 id="procedure" style="position:relative;"><a href="#procedure" aria-label="procedure permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Procedure</strong>:</h4>
<ol>
<li>
<p><strong>Baseline Testing</strong>:</p>
<ul>
<li>Conduct tests on the unoptimized system to establish baseline metrics.</li>
<li>Metrics:
<ul>
<li>Average latency: <strong>300ms</strong>.</li>
<li>Requests per second: <strong>500</strong>.</li>
<li>Error rate: <strong>5%</strong>.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Post-Optimization Testing</strong>:</p>
<ul>
<li>Repeat tests after implementing each solution.</li>
<li>Metrics after all optimizations:
<ul>
<li>Average latency: <strong>100ms</strong>.</li>
<li>Requests per second: <strong>1200</strong>.</li>
<li>Error rate: <strong>&#x3C;1%</strong>.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>High-Traffic Simulation</strong>:</p>
<ul>
<li>Increase concurrent connections and duration to simulate peak loads:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">wrk <span class="token parameter variable">-t16</span> <span class="token parameter variable">-c1000</span> <span class="token parameter variable">-d120s</span> http://example.com</code></pre></div>
</li>
</ul>
</li>
</ol>
<h4 id="observations" style="position:relative;"><a href="#observations" aria-label="observations permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Observations</strong>:</h4>
<ul>
<li>The optimized system sustained <strong>2x the traffic</strong> compared to the baseline without performance degradation.</li>
<li>Latency remained consistent under high traffic.</li>
</ul>
<hr>
<h3 id="1642-system-monitoring" style="position:relative;"><a href="#1642-system-monitoring" aria-label="1642 system monitoring permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>16.4.2 System Monitoring</strong></h3>
<h4 id="objective-8" style="position:relative;"><a href="#objective-8" aria-label="objective 8 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Objective</strong>:</h4>
<ul>
<li>Use real-time monitoring to ensure that resource utilization aligns with expected improvements.</li>
</ul>
<h4 id="tools-17" style="position:relative;"><a href="#tools-17" aria-label="tools 17 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Tools</strong>:</h4>
<ol>
<li>
<p><strong>vmstat</strong>:</p>
<ul>
<li>Tracks CPU, memory, and I/O metrics in real-time.</li>
<li>Command:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">vmstat</span> <span class="token number">1</span></code></pre></div>
</li>
<li>Observations:
<ul>
<li>
<p><strong>Before Optimization</strong>:</p>
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">r  b   swpd   free   buff  cache   si   so    bi    bo   us  sy  id  wa
3  1   1024  8000   3000  12000   10   15    50   100  60  20  10  10</code></pre></div>
<ul>
<li>High <code class="language-text">si</code> (swap-in) and <code class="language-text">so</code> (swap-out) rates.</li>
<li>Low <code class="language-text">id</code> (idle) percentage indicates CPU saturation.</li>
</ul>
</li>
<li>
<p><strong>After Optimization</strong>:</p>
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">r  b   swpd   free   buff  cache   si   so    bi    bo   us  sy  id  wa
2  0      0  16000  4000  20000    0    0    30    50   40  10  50   0</code></pre></div>
<ul>
<li><code class="language-text">si</code> and <code class="language-text">so</code> reduced to zero, confirming elimination of swapping.</li>
<li>Higher <code class="language-text">id</code> percentage indicates reduced CPU load.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>sar</strong>:</p>
<ul>
<li>Provides historical performance trends for CPU, memory, and I/O.</li>
<li>Command:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">sar <span class="token parameter variable">-r</span> <span class="token number">1</span> <span class="token number">10</span></code></pre></div>
</li>
<li>Observations:
<ul>
<li>Memory usage stabilized with increased free memory and reduced swap utilization.</li>
<li>CPU load balanced across cores.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Grafana and Prometheus</strong>:</p>
<ul>
<li>Create dashboards to visualize metrics like latency, throughput, and resource utilization over time.</li>
</ul>
</li>
</ol>
<h4 id="results-1" style="position:relative;"><a href="#results-1" aria-label="results 1 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Results</strong>:</h4>
<ul>
<li><strong>Memory Usage</strong>:
<ul>
<li>Swap usage reduced to <strong>near-zero</strong>, freeing resources for critical operations.</li>
</ul>
</li>
<li><strong>CPU Utilization</strong>:
<ul>
<li>Evenly distributed across all cores, with no single core exceeding <strong>70% utilization</strong>.</li>
</ul>
</li>
<li><strong>Disk I/O</strong>:
<ul>
<li>Reduced disk reads and writes due to elimination of swapping.</li>
</ul>
</li>
</ul>
<hr>
<h3 id="1643-database-query-performance" style="position:relative;"><a href="#1643-database-query-performance" aria-label="1643 database query performance permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>16.4.3 Database Query Performance</strong></h3>
<h4 id="objective-9" style="position:relative;"><a href="#objective-9" aria-label="objective 9 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Objective</strong>:</h4>
<ul>
<li>Verify the impact of query optimizations on database performance.</li>
</ul>
<h4 id="tools-18" style="position:relative;"><a href="#tools-18" aria-label="tools 18 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Tools</strong>:</h4>
<ol>
<li>
<p><strong>MySQL Slow Query Log</strong>:</p>
<ul>
<li>Tracks queries taking longer than a specified duration.</li>
<li>Configuration:
<div class="gatsby-highlight" data-language="sql"><pre class="language-sql"><code class="language-sql"><span class="token keyword">SET</span> <span class="token keyword">GLOBAL</span> slow_query_log <span class="token operator">=</span> <span class="token string">'ON'</span><span class="token punctuation">;</span>
<span class="token keyword">SET</span> <span class="token keyword">GLOBAL</span> long_query_time <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span> <span class="token comment">-- Log queries longer than 1 second</span></code></pre></div>
</li>
<li><strong>Before Optimization</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">Query: SELECT * FROM orders WHERE status = 'PENDING';
Execution Time: 1.5 seconds</code></pre></div>
</li>
<li><strong>After Optimization</strong>:
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">Query: SELECT * FROM orders WHERE status = 'PENDING';
Execution Time: 0.3 seconds</code></pre></div>
</li>
</ul>
</li>
<li>
<p><strong>EXPLAIN</strong>:</p>
<ul>
<li>Analyze query execution plans before and after adding indexes.</li>
<li>Output (Post-Optimization):
<div class="gatsby-highlight" data-language="text"><pre class="language-text"><code class="language-text">id  select_type table  type   possible_keys        key            rows  Extra
1   SIMPLE      orders range  idx_status_date      idx_status_date 100  Using where</code></pre></div>
</li>
</ul>
</li>
<li>
<p><strong>Benchmarking with Sysbench</strong>:</p>
<ul>
<li>Simulate database workloads to measure query performance.</li>
<li>Command:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">sysbench <span class="token parameter variable">--test</span><span class="token operator">=</span>oltp --mysql-host<span class="token operator">=</span>localhost --mysql-user<span class="token operator">=</span>root --mysql-password<span class="token operator">=</span>pass --oltp-table-size<span class="token operator">=</span><span class="token number">1000000</span> --num-threads<span class="token operator">=</span><span class="token number">16</span> run</code></pre></div>
</li>
</ul>
</li>
</ol>
<h4 id="results-2" style="position:relative;"><a href="#results-2" aria-label="results 2 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Results</strong>:</h4>
<ul>
<li>Query response time improved by <strong>80%</strong>.</li>
<li>Overall database throughput increased by <strong>50%</strong>.</li>
</ul>
<hr>
<h3 id="1644-regression-testing" style="position:relative;"><a href="#1644-regression-testing" aria-label="1644 regression testing permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>16.4.4 Regression Testing</strong></h3>
<h4 id="objective-10" style="position:relative;"><a href="#objective-10" aria-label="objective 10 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Objective</strong>:</h4>
<ul>
<li>Ensure that applied optimizations do not introduce new issues or regressions.</li>
</ul>
<h4 id="steps-3" style="position:relative;"><a href="#steps-3" aria-label="steps 3 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Steps</strong>:</h4>
<ol>
<li>
<p><strong>Functional Testing</strong>:</p>
<ul>
<li>Verify all application features work as expected.</li>
<li>Tools: Selenium or Postman for automated testing.</li>
</ul>
</li>
<li>
<p><strong>Load Testing</strong>:</p>
<ul>
<li>Simulate workloads similar to real-world usage patterns.</li>
<li>Observations:
<ul>
<li>No errors or timeouts during high-traffic periods.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Integration Testing</strong>:</p>
<ul>
<li>Confirm compatibility between optimized components, such as the application and database.</li>
</ul>
</li>
</ol>
<hr>
<h3 id="1645-real-world-validation" style="position:relative;"><a href="#1645-real-world-validation" aria-label="1645 real world validation permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>16.4.5 Real-World Validation</strong></h3>
<h4 id="scenario-4" style="position:relative;"><a href="#scenario-4" aria-label="scenario 4 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Scenario</strong>:</h4>
<ul>
<li>A simulated Black Friday event with a 2x increase in traffic was conducted post-optimization.</li>
</ul>
<h4 id="outcome" style="position:relative;"><a href="#outcome" aria-label="outcome permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Outcome</strong>:</h4>
<ul>
<li>The system handled the increased traffic without crashes or latency spikes.</li>
<li>Key metrics:
<ul>
<li>Latency: Maintained an average of <strong>100ms</strong>.</li>
<li>Throughput: Sustained <strong>1200 requests per second</strong>.</li>
<li>Error Rate: Less than <strong>0.1%</strong>.</li>
</ul>
</li>
</ul>
<hr>
<h3 id="key-takeaways-18" style="position:relative;"><a href="#key-takeaways-18" aria-label="key takeaways 18 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Key Takeaways</strong></h3>
<ol>
<li>
<p><strong>Thorough Testing</strong>:</p>
<ul>
<li>Tools like <code class="language-text">wrk</code>, <code class="language-text">vmstat</code>, and <code class="language-text">sar</code> provided actionable insights into performance improvements.</li>
<li><strong>Highlight</strong>: “Performance testing validates the system’s readiness for real-world workloads.”</li>
</ul>
</li>
<li>
<p><strong>Real-Time Monitoring</strong>:</p>
<ul>
<li>Continuous monitoring ensured optimizations had the desired impact without introducing new issues.</li>
<li><strong>Highlight</strong>: “Monitoring tools provide feedback loops critical for validating tuning changes.”</li>
</ul>
</li>
<li>
<p><strong>Database Validation</strong>:</p>
<ul>
<li>Query optimization significantly reduced database load and response times.</li>
<li><strong>Highlight</strong>: “Database performance directly impacts system scalability under heavy workloads.”</li>
</ul>
</li>
<li>
<p><strong>Iterative Process</strong>:</p>
<ul>
<li>Validation confirmed the success of each optimization step, ensuring measurable and sustainable improvements.</li>
<li><strong>Highlight</strong>: “Iterative validation builds confidence in applied solutions.”</li>
</ul>
</li>
</ol>
<hr>
<p>Here is an <strong>expanded and detailed explanation of Section 16.5: Lessons Learned</strong>, with in-depth insights, examples, and best practices derived from the case study. This section synthesizes the experience into actionable takeaways for future performance analysis and optimization projects.</p>
<hr>
<h2 id="165-lessons-learned" style="position:relative;"><a href="#165-lessons-learned" aria-label="165 lessons learned permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>16.5 Lessons Learned</strong></h2>
<p>The lessons learned from this case study highlight the importance of structured methodologies, the right tools, and iterative optimization in diagnosing and resolving performance issues. Each lesson is tied to a specific aspect of the process, supported by examples.</p>
<hr>
<h3 id="1651-the-importance-of-baseline-metrics" style="position:relative;"><a href="#1651-the-importance-of-baseline-metrics" aria-label="1651 the importance of baseline metrics permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>16.5.1 The Importance of Baseline Metrics</strong></h3>
<h4 id="lesson" style="position:relative;"><a href="#lesson" aria-label="lesson permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Lesson</strong>:</h4>
<ul>
<li><strong>“Baseline metrics provide a reference point for identifying deviations and measuring improvements.”</strong></li>
</ul>
<h4 id="what-happened" style="position:relative;"><a href="#what-happened" aria-label="what happened permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>What Happened</strong>:</h4>
<ul>
<li>The lack of an initial performance baseline delayed diagnosis, as there were no clear benchmarks for expected behavior.</li>
<li>After measuring CPU, memory, and database performance using tools like <code class="language-text">vmstat</code>, <code class="language-text">sar</code>, and JVisualVM, deviations from normal behavior were more evident.</li>
</ul>
<h4 id="example-23" style="position:relative;"><a href="#example-23" aria-label="example 23 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example</strong>:</h4>
<ul>
<li><strong>CPU Bottleneck</strong>:
<ul>
<li>Baseline CPU utilization was found to be 40% under normal load.</li>
<li>During high traffic, CPU usage spiked to 95%, revealing inefficiencies in the <code class="language-text">processRequest</code> function.</li>
</ul>
</li>
</ul>
<h4 id="best-practices-7" style="position:relative;"><a href="#best-practices-7" aria-label="best practices 7 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Best Practices</strong>:</h4>
<ol>
<li>Regularly collect system performance baselines, including <strong>CPU, memory, disk, and network metrics</strong>.</li>
<li>Use tools like <strong>Prometheus</strong> and <strong>Grafana</strong> to visualize trends over time for easier anomaly detection.</li>
</ol>
<hr>
<h3 id="1652-structured-methodology-yields-better-results" style="position:relative;"><a href="#1652-structured-methodology-yields-better-results" aria-label="1652 structured methodology yields better results permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>16.5.2 Structured Methodology Yields Better Results</strong></h3>
<h4 id="lesson-1" style="position:relative;"><a href="#lesson-1" aria-label="lesson 1 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Lesson</strong>:</h4>
<ul>
<li><strong>“A systematic approach reduces guesswork and focuses efforts on measurable problems.”</strong></li>
</ul>
<h4 id="what-happened-1" style="position:relative;"><a href="#what-happened-1" aria-label="what happened 1 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>What Happened</strong>:</h4>
<ul>
<li>The structured methodology (baseline measurement → bottleneck identification → hypothesis formation → validation) minimized trial-and-error approaches.</li>
<li>Using the <strong>USE method</strong> (Utilization, Saturation, Errors), the team identified that <strong>high CPU utilization</strong> and <strong>swapping</strong> were the primary bottlenecks.</li>
</ul>
<h4 id="example-24" style="position:relative;"><a href="#example-24" aria-label="example 24 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example</strong>:</h4>
<ul>
<li>The Flame Graph pinpointed the <code class="language-text">processRequest</code> function as consuming 30% of CPU resources. Refactoring this function resulted in a <strong>40% performance improvement</strong>.</li>
</ul>
<h4 id="best-practices-8" style="position:relative;"><a href="#best-practices-8" aria-label="best practices 8 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Best Practices</strong>:</h4>
<ol>
<li>Adopt the <strong>USE method</strong> or similar frameworks to guide performance investigations.</li>
<li>Document each step, including hypotheses and results, for repeatable success.</li>
</ol>
<hr>
<h3 id="1653-the-power-of-the-right-tools" style="position:relative;"><a href="#1653-the-power-of-the-right-tools" aria-label="1653 the power of the right tools permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>16.5.3 The Power of the Right Tools</strong></h3>
<h4 id="lesson-2" style="position:relative;"><a href="#lesson-2" aria-label="lesson 2 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Lesson</strong>:</h4>
<ul>
<li><strong>“Using the right tools at each stage of analysis is critical for accurate diagnosis and optimization.”</strong></li>
</ul>
<h4 id="what-happened-2" style="position:relative;"><a href="#what-happened-2" aria-label="what happened 2 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>What Happened</strong>:</h4>
<ul>
<li>Tools like <strong>perf</strong>, <strong>vmstat</strong>, and <strong>sar</strong> helped diagnose system-level bottlenecks, while <strong>JVisualVM</strong> and <strong>Flame Graphs</strong> identified application-specific issues.</li>
</ul>
<h4 id="examples-1" style="position:relative;"><a href="#examples-1" aria-label="examples 1 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Examples</strong>:</h4>
<ol>
<li><strong>CPU Profiling</strong>:
<ul>
<li><strong>Tool</strong>: <code class="language-text">perf</code>.</li>
<li>Identified that <strong>60% of CPU time</strong> was spent in <code class="language-text">copy_user_generic_unrolled</code>, indicating excessive memory copying.</li>
</ul>
</li>
<li><strong>Memory Analysis</strong>:
<ul>
<li><strong>Tool</strong>: <code class="language-text">vmstat</code>.</li>
<li>Observed frequent swapping (<code class="language-text">si</code> and <code class="language-text">so</code> values > 500 KB/s) during peak loads.</li>
</ul>
</li>
</ol>
<h4 id="best-practices-9" style="position:relative;"><a href="#best-practices-9" aria-label="best practices 9 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Best Practices</strong>:</h4>
<ol>
<li>Build expertise with a suite of tools like <strong>bpftrace</strong>, <strong>slabtop</strong>, and <strong>EXPLAIN</strong> for comprehensive system and application analysis.</li>
<li>Use visualization tools (e.g., Grafana, Flame Graphs) to communicate findings effectively.</li>
</ol>
<hr>
<h3 id="1654-iterative-tuning-produces-sustainable-gains" style="position:relative;"><a href="#1654-iterative-tuning-produces-sustainable-gains" aria-label="1654 iterative tuning produces sustainable gains permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>16.5.4 Iterative Tuning Produces Sustainable Gains</strong></h3>
<h4 id="lesson-3" style="position:relative;"><a href="#lesson-3" aria-label="lesson 3 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Lesson</strong>:</h4>
<ul>
<li><strong>“Optimization is an iterative process—test one change at a time and measure its impact.”</strong></li>
</ul>
<h4 id="what-happened-3" style="position:relative;"><a href="#what-happened-3" aria-label="what happened 3 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>What Happened</strong>:</h4>
<ul>
<li>Sequentially applying optimizations (e.g., refactoring code, reducing swappiness, adding database indexes) allowed the team to measure the individual impact of each change.</li>
</ul>
<h4 id="example-25" style="position:relative;"><a href="#example-25" aria-label="example 25 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example</strong>:</h4>
<ul>
<li>Refactoring the <code class="language-text">processRequest</code> function reduced CPU usage from <strong>30% to 10%</strong>.</li>
<li>After reducing swappiness and increasing heap size, swapping was eliminated, further improving response times.</li>
</ul>
<h4 id="best-practices-10" style="position:relative;"><a href="#best-practices-10" aria-label="best practices 10 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Best Practices</strong>:</h4>
<ol>
<li>Test each change individually using tools like <strong>wrk</strong> or <strong>Apache JMeter</strong> to isolate its effects.</li>
<li>Use a feedback loop with monitoring tools (e.g., <code class="language-text">sar</code>, <code class="language-text">vmstat</code>) to validate improvements.</li>
</ol>
<hr>
<h3 id="1655-memory-tuning-can-eliminate-major-bottlenecks" style="position:relative;"><a href="#1655-memory-tuning-can-eliminate-major-bottlenecks" aria-label="1655 memory tuning can eliminate major bottlenecks permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>16.5.5 Memory Tuning Can Eliminate Major Bottlenecks</strong></h3>
<h4 id="lesson-4" style="position:relative;"><a href="#lesson-4" aria-label="lesson 4 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Lesson</strong>:</h4>
<ul>
<li><strong>“Proper memory management prevents swapping and ensures consistent application performance.”</strong></li>
</ul>
<h4 id="what-happened-4" style="position:relative;"><a href="#what-happened-4" aria-label="what happened 4 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>What Happened</strong>:</h4>
<ul>
<li>High memory usage caused swapping, significantly degrading performance during peak traffic. Adjusting swappiness and enabling huge pages resolved the issue.</li>
</ul>
<h4 id="example-26" style="position:relative;"><a href="#example-26" aria-label="example 26 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example</strong>:</h4>
<ul>
<li>Reducing swappiness to <code class="language-text">10</code> and enabling huge pages:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash"><span class="token function">sysctl</span> <span class="token assign-left variable">vm.swappiness</span><span class="token operator">=</span><span class="token number">10</span>
<span class="token builtin class-name">echo</span> <span class="token number">512</span> <span class="token operator">></span> /proc/sys/vm/nr_hugepages</code></pre></div>
<ul>
<li>Result:
<ul>
<li>Swap usage reduced to <strong>near-zero</strong>.</li>
<li>Latency decreased by <strong>20%</strong> during peak loads.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="best-practices-11" style="position:relative;"><a href="#best-practices-11" aria-label="best practices 11 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Best Practices</strong>:</h4>
<ol>
<li>Continuously monitor memory usage with tools like <strong>free</strong>, <strong>sar</strong>, and <strong>vmstat</strong>.</li>
<li>Tune kernel parameters (e.g., swappiness, huge pages) for memory-intensive workloads.</li>
</ol>
<hr>
<h3 id="1656-database-optimization-is-critical-for-scalability" style="position:relative;"><a href="#1656-database-optimization-is-critical-for-scalability" aria-label="1656 database optimization is critical for scalability permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>16.5.6 Database Optimization is Critical for Scalability</strong></h3>
<h4 id="lesson-5" style="position:relative;"><a href="#lesson-5" aria-label="lesson 5 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Lesson</strong>:</h4>
<ul>
<li><strong>“Optimized database queries directly impact system scalability and responsiveness.”</strong></li>
</ul>
<h4 id="what-happened-5" style="position:relative;"><a href="#what-happened-5" aria-label="what happened 5 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>What Happened</strong>:</h4>
<ul>
<li>Database queries caused latency due to full table scans. Adding indexes reduced query execution time by <strong>80%</strong>.</li>
</ul>
<h4 id="example-27" style="position:relative;"><a href="#example-27" aria-label="example 27 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example</strong>:</h4>
<ul>
<li>Adding a composite index:
<div class="gatsby-highlight" data-language="sql"><pre class="language-sql"><code class="language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">INDEX</span> idx_status_date <span class="token keyword">ON</span> orders<span class="token punctuation">(</span><span class="token keyword">status</span><span class="token punctuation">,</span> <span class="token keyword">date</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre></div>
<ul>
<li>Query execution time reduced from <strong>1.5 seconds to 0.3 seconds</strong>.</li>
</ul>
</li>
</ul>
<h4 id="best-practices-12" style="position:relative;"><a href="#best-practices-12" aria-label="best practices 12 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Best Practices</strong>:</h4>
<ol>
<li>Regularly analyze slow queries using <strong>EXPLAIN</strong> and MySQL slow query logs.</li>
<li>Add indexes to columns frequently used in WHERE clauses or JOIN conditions.</li>
</ol>
<hr>
<h3 id="1657-the-role-of-comprehensive-validation" style="position:relative;"><a href="#1657-the-role-of-comprehensive-validation" aria-label="1657 the role of comprehensive validation permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>16.5.7 The Role of Comprehensive Validation</strong></h3>
<h4 id="lesson-6" style="position:relative;"><a href="#lesson-6" aria-label="lesson 6 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Lesson</strong>:</h4>
<ul>
<li><strong>“Validation ensures optimizations achieve their goals without introducing regressions.”</strong></li>
</ul>
<h4 id="what-happened-6" style="position:relative;"><a href="#what-happened-6" aria-label="what happened 6 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>What Happened</strong>:</h4>
<ul>
<li>Comprehensive validation (stress testing, monitoring, regression testing) confirmed that applied solutions met performance goals without side effects.</li>
</ul>
<h4 id="example-28" style="position:relative;"><a href="#example-28" aria-label="example 28 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example</strong>:</h4>
<ul>
<li>High-traffic simulation using <code class="language-text">wrk</code>:
<div class="gatsby-highlight" data-language="bash"><pre class="language-bash"><code class="language-bash">wrk <span class="token parameter variable">-t16</span> <span class="token parameter variable">-c1000</span> <span class="token parameter variable">-d120s</span> http://example.com</code></pre></div>
<ul>
<li>Metrics:
<ul>
<li>Latency reduced by <strong>66%</strong>.</li>
<li>Throughput increased by <strong>140%</strong>.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="best-practices-13" style="position:relative;"><a href="#best-practices-13" aria-label="best practices 13 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Best Practices</strong>:</h4>
<ol>
<li>Always validate changes under real-world conditions using tools like <code class="language-text">wrk</code> and <strong>Apache JMeter</strong>.</li>
<li>Perform regression testing to ensure no unintended effects.</li>
</ol>
<hr>
<h3 id="1658-collaboration-across-teams" style="position:relative;"><a href="#1658-collaboration-across-teams" aria-label="1658 collaboration across teams permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>16.5.8 Collaboration Across Teams</strong></h3>
<h4 id="lesson-7" style="position:relative;"><a href="#lesson-7" aria-label="lesson 7 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Lesson</strong>:</h4>
<ul>
<li><strong>“Effective performance tuning requires collaboration between system administrators, developers, and database administrators.”</strong></li>
</ul>
<h4 id="what-happened-7" style="position:relative;"><a href="#what-happened-7" aria-label="what happened 7 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>What Happened</strong>:</h4>
<ul>
<li>Collaboration between the application development and database teams ensured that optimizations (e.g., code refactoring, query tuning) were aligned with system-level adjustments (e.g., memory tuning).</li>
</ul>
<h4 id="example-29" style="position:relative;"><a href="#example-29" aria-label="example 29 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Example</strong>:</h4>
<ul>
<li>The database team added indexes while developers optimized queries and reduced query frequency.</li>
</ul>
<h4 id="best-practices-14" style="position:relative;"><a href="#best-practices-14" aria-label="best practices 14 permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Best Practices</strong>:</h4>
<ol>
<li>Foster communication between teams to align optimization efforts.</li>
<li>Document and share findings for continuous learning.</li>
</ol>
<hr>
<h3 id="key-takeaways-for-lessons-learned" style="position:relative;"><a href="#key-takeaways-for-lessons-learned" aria-label="key takeaways for lessons learned permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Key Takeaways for lessons learned</strong></h3>
<ol>
<li>
<p><strong>Structured Methodology</strong>:</p>
<ul>
<li>Following a clear process ensures targeted and effective optimizations.</li>
<li><strong>Highlight</strong>: “Structured approaches reduce guesswork and maximize results.”</li>
</ul>
</li>
<li>
<p><strong>Iterative Improvements</strong>:</p>
<ul>
<li>Sequential testing of changes minimizes risk and ensures measurable impact.</li>
<li><strong>Highlight</strong>: “Small, incremental improvements compound into significant performance gains.”</li>
</ul>
</li>
<li>
<p><strong>Cross-Team Collaboration</strong>:</p>
<ul>
<li>Successful optimization involves developers, system administrators, and database teams working together.</li>
<li><strong>Highlight</strong>: “Collaboration ensures holistic and sustainable solutions.”</li>
</ul>
</li>
<li>
<p><strong>Monitoring and Validation</strong>:</p>
<ul>
<li>Continuous monitoring and rigorous testing are essential for confirming improvements.</li>
<li><strong>Highlight</strong>: “Validation provides confidence that applied changes meet performance goals.”</li>
</ul>
</li>
</ol>
<hr>
<h2 id="key-takeaways-for-case-study" style="position:relative;"><a href="#key-takeaways-for-case-study" aria-label="key takeaways for case study permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong>Key Takeaways for case study</strong></h2>
<ul>
<li><strong>Comprehensive Diagnosis</strong>:
<ul>
<li>Use tools like <code class="language-text">perf</code>, <code class="language-text">sar</code>, and <code class="language-text">JVisualVM</code> to identify CPU, memory, and application-level bottlenecks.</li>
</ul>
</li>
<li><strong>Iterative Optimization</strong>:
<ul>
<li>Apply one change at a time and measure its impact to ensure effective tuning.</li>
</ul>
</li>
<li><strong>Significant Gains</strong>:
<ul>
<li>Post-optimization, the system handled <strong>2x the traffic</strong> with <strong>50% fewer resources</strong>.</li>
</ul>
</li>
</ul>
<p>Here’s an <strong>expanded and detailed explanation of Chapter 12: Benchmarking</strong>, with in-depth insights, detailed examples, and bold-highlighted key phrases to provide a comprehensive understanding of benchmarking principles, tools, and best practices.</p>
<hr>
<h1 id="questions" style="position:relative;"><a href="#questions" aria-label="questions permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Questions</h1>
<ul>
<li>how to get consistent results when benchmarking on linux?
<ul>
<li><a href="https://easyperf.net/blog/2019/08/02/Perf-measurement-environment-on-Linux">consistent performance measurement on linux</a></li>
</ul>
</li>
<li>what’s linux perf analysis in 60 second?
<ul>
<li>uptime</li>
<li>dmesg -T | tail</li>
<li>vmstat 1</li>
<li>mpstat -P ALL</li>
<li>pidstat 1</li>
<li>iostat -xz 1</li>
<li>free -m</li>
<li>sar -n DEV 1</li>
<li>sar -n TCP,ETCP 1</li>
<li>top</li>
</ul>
</li>
</ul>
<h1 id="references" style="position:relative;"><a href="#references" aria-label="references permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>References</h1>
<ul>
<li><a href="https://oliver-hu.medium.com/systems-performance-reading-notes-chapter-6-cpu-d70627188b85">https://oliver-hu.medium.com/systems-performance-reading-notes-chapter-6-cpu-d70627188b85</a></li>
<li><a href="https://oliver-hu.medium.com/systems-performance-reading-notes-chapter-7-memory-6e87ac8fcfdd">https://oliver-hu.medium.com/systems-performance-reading-notes-chapter-7-memory-6e87ac8fcfdd</a></li>
<li><a href="https://oliver-hu.medium.com/system-performance-chapter-8-file-system-7322f82fbc7c">https://oliver-hu.medium.com/system-performance-chapter-8-file-system-7322f82fbc7c</a></li>
<li><a href="https://lrita.github.io/images/posts/linux/Percona2016_LinuxSystemsPerf.pdf">https://lrita.github.io/images/posts/linux/Percona2016_LinuxSystemsPerf.pdf</a></li>
<li><a href="https://www.brendangregg.com/USEmethod/use-rosetta.html">https://www.brendangregg.com/USEmethod/use-rosetta.html</a></li>
<li><a href="https://www.brendangregg.com/linuxperf.html">https://www.brendangregg.com/linuxperf.html</a></li>
<li><a href="https://easyperf.net/blog/2019/08/02/Perf-measurement-environment-on-Linux">https://easyperf.net/blog/2019/08/02/Perf-measurement-environment-on-Linux</a></li>
<li><a href="https://elvischidera.com/2022-01-20-designing-data-intensive-applications">https://elvischidera.com/2022-01-20-designing-data-intensive-applications</a></li>
<li><a href="https://danlebrero.com/2021/09/01/designing-data-intensive-applications-summary/">https://danlebrero.com/2021/09/01/designing-data-intensive-applications-summary/</a></li>
<li><a href="https://github.com/keyvanakbary/learning-notes/blob/master/books/designing-data-intensive-applications.md">https://github.com/keyvanakbary/learning-notes/blob/master/books/designing-data-intensive-applications.md</a></li>
</ul></section><hr/><footer><div class="bio"><div data-gatsby-image-wrapper="" style="width:50px;height:50px" class="gatsby-image-wrapper bio-avatar"><div aria-hidden="true" data-placeholder-image="" style="opacity:1;transition:opacity 500ms linear;background-color:#685848;width:50px;height:50px;position:relative"></div><picture><source type="image/avif" data-srcset="/static/b811602c8c8ce14b66aae6613c8968f4/d4bf4/tony-avatar.avif 50w,/static/b811602c8c8ce14b66aae6613c8968f4/ee81f/tony-avatar.avif 100w" sizes="50px"/><source type="image/webp" data-srcset="/static/b811602c8c8ce14b66aae6613c8968f4/3faea/tony-avatar.webp 50w,/static/b811602c8c8ce14b66aae6613c8968f4/6a679/tony-avatar.webp 100w" sizes="50px"/><img data-gatsby-image-ssr="" layout="fixed" data-main-image="" style="opacity:0" sizes="50px" decoding="async" loading="lazy" data-src="/static/b811602c8c8ce14b66aae6613c8968f4/d24ee/tony-avatar.jpg" data-srcset="/static/b811602c8c8ce14b66aae6613c8968f4/d24ee/tony-avatar.jpg 50w,/static/b811602c8c8ce14b66aae6613c8968f4/64618/tony-avatar.jpg 100w" alt="Profile picture"/></picture><noscript><picture><source type="image/avif" srcSet="/static/b811602c8c8ce14b66aae6613c8968f4/d4bf4/tony-avatar.avif 50w,/static/b811602c8c8ce14b66aae6613c8968f4/ee81f/tony-avatar.avif 100w" sizes="50px"/><source type="image/webp" srcSet="/static/b811602c8c8ce14b66aae6613c8968f4/3faea/tony-avatar.webp 50w,/static/b811602c8c8ce14b66aae6613c8968f4/6a679/tony-avatar.webp 100w" sizes="50px"/><img data-gatsby-image-ssr="" layout="fixed" data-main-image="" style="opacity:0" sizes="50px" decoding="async" loading="lazy" src="/static/b811602c8c8ce14b66aae6613c8968f4/d24ee/tony-avatar.jpg" srcSet="/static/b811602c8c8ce14b66aae6613c8968f4/d24ee/tony-avatar.jpg 50w,/static/b811602c8c8ce14b66aae6613c8968f4/64618/tony-avatar.jpg 100w" alt="Profile picture"/></picture></noscript><script type="module">const t="undefined"!=typeof HTMLImageElement&&"loading"in HTMLImageElement.prototype;if(t){const t=document.querySelectorAll("img[data-main-image]");for(let e of t){e.dataset.src&&(e.setAttribute("src",e.dataset.src),e.removeAttribute("data-src")),e.dataset.srcset&&(e.setAttribute("srcset",e.dataset.srcset),e.removeAttribute("data-srcset"));const t=e.parentNode.querySelectorAll("source[data-srcset]");for(let e of t)e.setAttribute("srcset",e.dataset.srcset),e.removeAttribute("data-srcset");e.complete&&(e.style.opacity=1,e.parentNode.parentNode.querySelector("[data-placeholder-image]").style.opacity=0)}}</script></div><p>Written by <strong>Tony Vo</strong> <!-- -->father, husband, son and software developer<!-- --> <a href="https://twitter.com/ttrungvo">Twitter</a></p></div></footer></article><nav class="blog-post-nav"><ul style="display:flex;flex-wrap:wrap;justify-content:space-between;list-style:none;padding:0"><li><a rel="prev" href="/observability-engineer-summary/">← <!-- -->observability engineer by Charity, Liz Fong and George summary - wip</a></li><li><a rel="next" href="/building-second-brain/">building the second brain by Tiago Forte summary<!-- --> →</a></li></ul></nav><div><div id="disqus_thread"></div></div></main><footer>© <!-- -->2024<!-- -->, Built with<!-- --> <a href="https://www.gatsbyjs.com">Gatsby</a></footer></div></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/data-intensive-system-perf/";/*]]>*/</script><!-- slice-start id="_gatsby-scripts-1" -->
          <script
            id="gatsby-chunk-mapping"
          >
            window.___chunkMapping="{\"app\":[\"/app-02f27bb33b7a634980a7.js\"],\"component---src-pages-404-js\":[\"/component---src-pages-404-js-c5ce6f61d00d5bc2a364.js\"],\"component---src-pages-index-js\":[\"/component---src-pages-index-js-85895703483e94bddc30.js\"],\"component---src-pages-tags-js\":[\"/component---src-pages-tags-js-5f4699c03df20c034ba6.js\"],\"component---src-pages-using-typescript-tsx\":[\"/component---src-pages-using-typescript-tsx-a71142f2de4e781bfbb8.js\"],\"component---src-templates-blog-post-js\":[\"/component---src-templates-blog-post-js-e6b9723f7baba56e9afc.js\"],\"component---src-templates-tags-js\":[\"/component---src-templates-tags-js-396a8b4d37b1d972a6c6.js\"]}";
          </script>
        <script>window.___webpackCompilationHash="22a3c8113d226550f456";</script><script src="/webpack-runtime-5298344da22db0a7d8dc.js" async></script><script src="/framework-dd535bfdf9fc8b5d9656.js" async></script><script src="/app-02f27bb33b7a634980a7.js" async></script><!-- slice-end id="_gatsby-scripts-1" --></body></html>